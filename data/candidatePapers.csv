"id","url","score","title","summary","venue","year","authors","citationCount","referenceCount","influentialCitationCount"
"2029349c55c1dba3493c5b3bd25152f18ba21ae2","https://www.semanticscholar.org/paper/2029349c55c1dba3493c5b3bd25152f18ba21ae2",136,"Augmented Language Models: a Survey","The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks.","",2023,"Grégoire Mialon,Roberto Dessì,M. Lomeli,Christoforos Nalmpantis,Ramakanth Pasunuru,Roberta Raileanu,Baptiste Rozière,Timo Schick,Jane Dwivedi-Yu,Asli Celikyilmaz,Edouard Grave,Yann LeCun,Thomas Scialom",1,169,1
"9325c4bee1de9dc9b91cfb43fa65320817d2eea4","https://www.semanticscholar.org/paper/9325c4bee1de9dc9b91cfb43fa65320817d2eea4",50,"Complex QA and language models hybrid architectures, Survey","Current solutions and promising strategies are reviewed, using elements such as hybrid LLM architectures, human-in-the-loop reinforcement learning, prompting adaptation, neuro-symbolic and structured knowledge grounding, program synthesis, and others, and an overview of the current research and trends in the area of complex QA.","",2023,"Xavier Daull,P. Bellot,Emmanuel Bruno,Vincent Martin,Elisabeth Murisasco",0,346,0
"d3a7a4543d83f568f79d1febe8379465ff0140c9","https://www.semanticscholar.org/paper/d3a7a4543d83f568f79d1febe8379465ff0140c9",25,"A Survey of Deep Learning for Mathematical Reasoning","This survey paper reviews the key tasks, datasets, and methods at the intersec-tion of mathematical reasoning and deep learning over the past decade, and evaluates existing benchmarks and methods and discusses future research directions.","ArXiv",2022,"Pan Lu,Liang Qiu,Wenhao Yu,S. Welleck,Kai-Wei Chang",1,216,1
"873a581320d928249609d3c07229d5af182a379c","https://www.semanticscholar.org/paper/873a581320d928249609d3c07229d5af182a379c",24,"Is ChatGPT a General-Purpose Natural Language Processing Task Solver?","It is found that ChatGPT performs well on many tasks favoring reasoning capabilities while it still faces challenges when solving specific tasks such as sequence tagging, and with extensive empirical studies, both the effectiveness and limitations of the current version of ChatG PT are demonstrated.","",2023,"Chengwei Qin,Aston Zhang,Zhuosheng Zhang,Jiaao Chen,Michihiro Yasunaga,Diyi Yang",2,86,0
"5484d228bfc50efbac6e86677bc2ec2ee4ede1a6","https://www.semanticscholar.org/paper/5484d228bfc50efbac6e86677bc2ec2ee4ede1a6",23,"Scaling Instruction-Finetuned Language Models","This result shows that instruction and UL2 continued pre-training are complementary compute-eﬃcient methods to improve the performance of language models without increasing model scale.","ArXiv",2022,"Hyung Won Chung,Le Hou,S. Longpre,Barret Zoph,Yi Tay,W. Fedus,Eric Li,Xuezhi Wang,M. Dehghani,Siddhartha Brahma,Albert Webson,S. Gu,Zhuyun Dai,Mirac Suzgun,Xinyun Chen,Aakanksha Chowdhery,Dasha Valter,Sharan Narang,Gaurav Mishra,A. Yu,Vincent Zhao,Yanping Huang,Andrew M. Dai,Hongkun Yu,Slav Petrov,E. Chi,J. Dean,Jacob Devlin,Adam Roberts,Denny Zhou,Quoc Le,Jason Wei",41,104,11
"f2b0017ddd77fa38760a18145e63553105a1a236","https://www.semanticscholar.org/paper/f2b0017ddd77fa38760a18145e63553105a1a236",21,"The Flan Collection: Designing Data and Methods for Effective Instruction Tuning","It is found task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings actually yields stronger performance in all settings.","ArXiv",2023,"S. Longpre,Le Hou,Tu Vu,Albert Webson,Hyung Won Chung,Yi Tay,Denny Zhou,Quoc V. Le,Barret Zoph,Jason Wei,Adam Roberts",0,91,0
"6d7b8a478801bd9d21df82d5f33ae6eced90da5e","https://www.semanticscholar.org/paper/6d7b8a478801bd9d21df82d5f33ae6eced90da5e",20,"Solving math word problems with process- and outcome-based feedback","It is found that pure outcome-based supervision produces similar final-answer error rates with less label supervision, but for correct reasoning steps it is necessary to use processbased supervision or supervision from learned reward models that emulate process-based feedback.","ArXiv",2022,"J. Uesato,Nate Kushman,Ramana Kumar,Francis Song,Noah Siegel,L. Wang,Antonia Creswell,Geoffrey Irving,I. Higgins",3,61,2
"e002bb8dae5a18a5ea1e7e1aafa16e19ad545662","https://www.semanticscholar.org/paper/e002bb8dae5a18a5ea1e7e1aafa16e19ad545662",19,"Solving Math Word Problems with Process-based and Outcome-based Feedback","This work runs the first comprehensive comparison between process- and outcome- based approaches trained on a natural language task, GSM8K, and finds that pure outcome-based supervision produces similar final-answer error rates with less label supervision.","",2022,"J. Uesato,Nate Kushman,Ramana Kumar,Francis Song,Noah Siegel,L. Wang,Antonia Creswell,Geoffery Irving,I. Higgins",0,61,0
"e8db669c8cb1c07557ede15e2771968f9370330b","https://www.semanticscholar.org/paper/e8db669c8cb1c07557ede15e2771968f9370330b",19,"Large language models are not zero-shot communicators","A simple task is designed and widely used state-of-the-art models are evaluated, finding that, despite only evaluating on utterances that require a binary inference (yes or no), most perform close to random.","ArXiv",2022,"Laura Ruis,Akbir Khan,Stella Rose Biderman,Sara Hooker,Tim Rocktaschel,Edward Grefenstette",2,100,0
"5791c2b41dd23310c53d6738a4c0d587107c2dc8","https://www.semanticscholar.org/paper/5791c2b41dd23310c53d6738a4c0d587107c2dc8",19,"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text Generation","MURMUR is a neuro-symbolic modular approach to text generation from semi-structured data with multi-step reasoning that generates highly faithful and correct reasoning paths that lead to 26% more logically consistent summaries on LogicNLG, compared to direct prompting.","ArXiv",2022,"Swarnadeep Saha,Xinyan Velocity Yu,Mohit Bansal,Ramakanth Pasunuru,Asli Celikyilmaz",0,71,0
"4d17732d90440682b0500f4e209c6cc4fac20e0e","https://www.semanticscholar.org/paper/4d17732d90440682b0500f4e209c6cc4fac20e0e",17,"Teaching Algorithmic Reasoning via In-context Learning","This work shows that it is possible to teach algorithmic reasoning to LLMs via in-context learning, which it is referred to as algorithmic prompting, and evaluates the approach on a variety of arithmetic and quantitative reasoning tasks, and demonstrates boosts in performance over existing prompting techniques.","ArXiv",2022,"Hattie Zhou,Azade Nova,H. Larochelle,Aaron C. Courville,Behnam Neyshabur,Hanie Sedghi",7,70,3
"ed99a2572fb5f4240aa6068e3bf274832e831306","https://www.semanticscholar.org/paper/ed99a2572fb5f4240aa6068e3bf274832e831306",17,"Recitation-Augmented Language Models","It is shown that by utilizing recitation as the intermediate step, a recite-and-answer scheme can achieve new state-of-the-art performance in various closed-book question answering (CBQA) tasks.","ArXiv",2022,"Zhiqing Sun,Xuezhi Wang,Yi Tay,Yiming Yang,Denny Zhou",2,71,1
"663a41c866d49ce052801fbc88947d39764cad29","https://www.semanticscholar.org/paper/663a41c866d49ce052801fbc88947d39764cad29",17,"Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them","It is found that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex to surpass it on 17 of the23 tasks.","ArXiv",2022,"Mirac Suzgun,Nathan Scales,Nathanael Scharli,Sebastian Gehrmann,Yi Tay,Hyung Won Chung,Aakanksha Chowdhery,Quoc V. Le,E. Chi,Denny Zhou,Jason Wei",26,55,5
"1bb6d5761903c7ac978188ae36e2648905e95dc5","https://www.semanticscholar.org/paper/1bb6d5761903c7ac978188ae36e2648905e95dc5",17,"Transcending Scaling Laws with 0.1% Extra Compute","U-PaLM outperforms PaLM on many few-shot setups, i.e., English NLP tasks, reasoning tasks with chain-of-thought, multilingual tasks, MMLU and challenging BIG-Bench tasks, and is able to substantially improve the scaling properties of large language models on downstream metrics.","ArXiv",2022,"Yi Tay,Jason Wei,Hyung Won Chung,V. Tran,David R. So,Siamak Shakeri,Xavier García,Huaixiu Zheng,J. Rao,Aakanksha Chowdhery,Denny Zhou,Donald Metzler,Slav Petrov,N. Houlsby,Quoc V. Le,M. Dehghani",8,53,1
"03fca0b32fa443ea5a343a2e8859f1e221d03d9c","https://www.semanticscholar.org/paper/03fca0b32fa443ea5a343a2e8859f1e221d03d9c",17,"Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning","This work exploits large language models (LLMs) as decomposers for effective table-based reasoning and proposes a “parsing-execution-ﬁlling” strategy to alleviate the hallucination dilemma of the chain of thought by decoupling logic and numerical computation in each step.","ArXiv",2023,"Yunhu Ye,Binyuan Hui,Min Yang,Binhua Li,Fei Huang,Yongbin Li",1,53,0
"8bfc22de7fe66286ad9ae705d677246757fbf8a8","https://www.semanticscholar.org/paper/8bfc22de7fe66286ad9ae705d677246757fbf8a8",17,"Large Language Models Can Be Easily Distracted by Irrelevant Context","This work investigates the distractibility of large language models, i.e., how the model problem-solving accuracy can be influenced by irrelevant context, and introduces Grade-School Math with Irrelevant Context (GSM-IC), an arithmetic reasoning dataset with irrelevant information in the problem description.","ArXiv",2023,"Freda Shi,Xinyun Chen,Kanishka Misra,Nathan Scales,David Dohan,E. Chi,Nathanael Scharli,Denny Zhou",1,57,0
"03532123ccffae8d411264320e8a5ae2b6eddea0","https://www.semanticscholar.org/paper/03532123ccffae8d411264320e8a5ae2b6eddea0",16,"Demonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive NLP","This work proposes D EMONSTRATE – S EARCH –P REDICT (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM, and can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions.","ArXiv",2022,"O. Khattab,Keshav Santhanam,Xiang Lisa Li,D. Hall,Percy Liang,Christopher Potts,M. Zaharia",4,62,0
"ad5573cb25fd403f7620332f363ae87327c69a49","https://www.semanticscholar.org/paper/ad5573cb25fd403f7620332f363ae87327c69a49",16,"The Impact of Symbolic Representations on In-context Learning for Few-shot Reasoning","Comprehensive experiments are included to systematically compare LMLP with CoT in deductive reasoning settings, showing that L MLP enjoys more than 25% higher accuracy than COT on length generalization bench-marks even with fewer parameters.","ArXiv",2022,"Hanlin Zhang,Yi-Fan Zhang,Li Erran Li,Eric Xing",2,67,0
"f7da57d40e68831fb1818b38d608c1332fd39359","https://www.semanticscholar.org/paper/f7da57d40e68831fb1818b38d608c1332fd39359",16,"Transformer models: an introduction and catalog","","",2023,"X. Amatriain",0,79,0
"d697b440dd0e65a05fe027e4c0ea85f62dcba033","https://www.semanticscholar.org/paper/d697b440dd0e65a05fe027e4c0ea85f62dcba033",16,"Can large language models reason about medical questions?","It is speculated that scaling model and data, enhancing prompt alignment and allowing for better contextualization of the completions will be sufﬁcient for LLMs to reach human-level performance on this type of task.","ArXiv",2022,"Valentin Li'evin,C. Hother,O. Winther",12,52,2
"cef330bacf014d60daabbd489647b2006af130ca","https://www.semanticscholar.org/paper/cef330bacf014d60daabbd489647b2006af130ca",16,"Discovering Language Model Behaviors with Model-Written Evaluations","","ArXiv",2022,"Ethan Perez,Sam Ringer,Kamilė Lukošiūtė,Karina Nguyen,Edwin Chen,Scott Heiner,Craig Pettit,Catherine Olsson,Sandipan Kundu,Saurav Kadavath,Andy Jones,Anna Chen,Benjamin Mann,Brian Israel,Bryan Seethor,C. McKinnon,C. Olah,Daisong Yan,Daniela Amodei,Dario Amodei,Dawn Drain,Dustin Li,Eli Tran-Johnson,G. Khundadze,John Kernion,J. Landis,Jamie Kerr,J. Mueller,Jeeyoon Hyun,J. Landau,Kamal Ndousse,L. Goldberg,Liane Lovitt,Martin Lucas,Michael Sellitto,Miranda Zhang,Neerav Kingsland,Nelson Elhage,Nicholas Joseph,Noem'i Mercado,Nova DasSarma,Oliver Rausch,Robin Larson,Sam McCandlish,Scott Johnston,S. Kravec,Sheer El Showk,Tamera Lanham,Timothy Telleen-Lawton,Tom B. Brown,T. Henighan,Tristan Hume,Yuntao Bai,Zac Hatfield-Dodds,Jack Clark,Sam Bowman,Amanda Askell,Roger C. Grosse,Danny Hernandez,Deep Ganguli,Evan Hubinger,Nicholas Schiefer,Jared Kaplan",4,86,1
"3eed4de25636ac90f39f6e1ef70e3507ed61a2a6","https://www.semanticscholar.org/paper/3eed4de25636ac90f39f6e1ef70e3507ed61a2a6",16,"Talking About Large Language Models","The hope is that increased scientific precision will encourage more philosophical nuance in the discourse around artificial intelligence, both within the field and in the public sphere.","ArXiv",2022,"M. Shanahan",5,38,0
"2cd72e71299c5d62d5cdb1164df5236172d418c4","https://www.semanticscholar.org/paper/2cd72e71299c5d62d5cdb1164df5236172d418c4",15,"Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits","A new learning paradigm that enables language models (LMs) to re -align with human values, S ECOND T HOUGHTS achieves superior performance in three value alignment benchmark datasets but also shows strong human-value transfer learning ability in few-shot scenarios.","ArXiv",2023,"Ruibo Liu,Chenyan Jia,Ge Zhang,Ziyu Zhuang,Tony X. Liu,Soroush Vosoughi",0,90,0
"54a4517022703a27e1670d3b84214521882f0108","https://www.semanticscholar.org/paper/54a4517022703a27e1670d3b84214521882f0108",15,"Contrastive Distillation Is a Sample-Efficient Self-Supervised Loss Policy for Transfer Learning","A self-supervised loss policy is proposed called contrastive distillation which manifests latent variables with high mutual information with both source and target tasks from weights to tokens which outperforms common methods of transfer learning and suggests a useful design axis of trading for generalizability for online transfer.","ArXiv",2022,"Christopher T. Lengerich,Gabriel Synnaeve,Amy Zhang,H. Leather,Kurt Shuster,Franccois Charton,Charysse Redwood",0,60,0
"69619a2a47faee7a29ec596db13172e2a42ff921","https://www.semanticscholar.org/paper/69619a2a47faee7a29ec596db13172e2a42ff921",15,"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for Large Language Models","Synthetic prompting is introduced, a method that leverages a few handcrafted examples to prompt the model to generate more examples by itself, and selects effective demonstrations to elicit better reasoning.","ArXiv",2023,"Zhihong Shao,Yeyun Gong,Yelong Shen,Minlie Huang,Nan Duan,Weizhu Chen",1,37,0
"79b88230fabb59a1d368641bbc822af0f09bf262","https://www.semanticscholar.org/paper/79b88230fabb59a1d368641bbc822af0f09bf262",14,"Self-Consistency Improves Chain of Thought Reasoning in Language Models","A simple ensemble strategy, self-consistency, that robustly improves accuracy across a variety of language models and model scales without the need for additional training or auxiliary models is explored.","ArXiv",2022,"Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou",118,75,32
"4bea09d4c897fb201c032b9eb605a943b1e70435","https://www.semanticscholar.org/paper/4bea09d4c897fb201c032b9eb605a943b1e70435",14,"CORRPUS: Detecting Story Inconsistencies via Codex-Bootstrapped Neurosymbolic Reasoning","It is shown that the CoRRPUS system and abstracted prompting procedures can beat current state-of-the-art structured LLM techniques on pre-existing story understanding tasks (bAbI task 2 and Re 3 ) with minimal hand engineering.","ArXiv",2022,"Yi Dong,Lara J. Martin,Chris Callison-Burch",0,69,0
"9a9e68d400069f023f7dc9b982226c95159a509d","https://www.semanticscholar.org/paper/9a9e68d400069f023f7dc9b982226c95159a509d",14,"Dissociating language and thought in large language models: a cognitive perspective","","ArXiv",2023,"Kyle Mahowald,Anna A. Ivanova,I. Blank,N. Kanwisher,J. Tenenbaum,Evelina Fedorenko",8,412,0
"b2542a738b75ee9b7ce1a13d8b78f9095d212412","https://www.semanticscholar.org/paper/b2542a738b75ee9b7ce1a13d8b78f9095d212412",14,"Generate rather than Retrieve: Large Language Models are Strong Context Generators","The proposed method is evaluated on three different knowledge-intensive tasks and its effectiveness on both zero-shot and supervised settings is demonstrated.","ArXiv",2022,"W. Yu,Dan Iter,Shuohang Wang,Yichong Xu,Mingxuan Ju,Soumya Sanyal,Chenguang Zhu,Michael Zeng,Meng Jiang",11,62,3
"766709f901c660863d3e7f7fa11a4e2f696da438","https://www.semanticscholar.org/paper/766709f901c660863d3e7f7fa11a4e2f696da438",14,"Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks","The checkpoint that achieved the best overall performance across all tasks was the one with the lowest encode.rate of 1e-4.","ArXiv",2022,"Zhenhailong Wang,Xiaoman Pan,Dian Yu,Dong Yu,Jianshu Chen,Heng Ji",0,59,0
"90350aa626bed47b02d0c162462e5b0ca82be6b2","https://www.semanticscholar.org/paper/90350aa626bed47b02d0c162462e5b0ca82be6b2",14,"Automatic Chain of Thought Prompting in Large Language Models","An automatic CoT prompting method that samples questions with diversity and generates reasoning chains to construct demonstrations and consistently matches or exceeds the performance of the CoT paradigm that requires manual designs of demonstrations.","ArXiv",2022,"Zhuosheng Zhang,Aston Zhang,Mu Li,Alexander J. Smola",18,38,4
"2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75","https://www.semanticscholar.org/paper/2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75",14,"Grounding Language Models to Images for Multimodal Generation","An ef-fective, general solution for leveraging pretrained language models in visually grounded settings, enabling them to process and generate arbitrarily interleaved image-and-text data.","ArXiv",2023,"Jing Yu Koh,R. Salakhutdinov,Daniel Fried",0,56,0
"d2170504c4ad9403bea118ae8debdfda95978546","https://www.semanticscholar.org/paper/d2170504c4ad9403bea118ae8debdfda95978546",13,"The Wisdom of Hindsight Makes Language Models Better Instruction Followers","HIR is proposed, a novel algorithm for aligning language models with instructions by converting feedback to instruction by relabeling the original one and training the model for better alignment in a supervised manner and it outperforms the baseline algorithms and is comparable to or even surpasses supervised finetuning.","ArXiv",2023,"Tianjun Zhang,Fangchen Liu,Justin Wong,P. Abbeel,Joseph Gonzalez",0,51,0
"04bc67f263a247ab49c19a3712be8c9c77297f08","https://www.semanticscholar.org/paper/04bc67f263a247ab49c19a3712be8c9c77297f08",13,"Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models","A novel semi-parametric language model architecture, Knowledge-in-Context (KiC), which empowers a parametric text-to-text language model with a knowledge-rich external memory and finds that KiC can be identified as a special mixture-of-experts (MoE) model, where the knowledge selector plays the role of a router that is used to determine the sequence- to-expert assignment in MoE.","ArXiv",2022,"Xiaoman Pan,Wenlin Yao,Hongming Zhang,Dian Yu,Dong Yu,Jianshu Chen",0,91,0
"22d314c347a6c5c0bbf528a102455229ce0b36b5","https://www.semanticscholar.org/paper/22d314c347a6c5c0bbf528a102455229ce0b36b5",13,"Harnessing Knowledge and Reasoning for Human-Like Natural Language Generation: A Brief Review","The importance of NLG being guided by knowledge, in order to convey human-like reasoning through language generation, is explored, and ten goals for intelligent NLG systems to pursue are proposed.","ArXiv",2022,"Jiangjie Chen,Yanghua Xiao",0,146,0
"fb49e88c6bd676516898e911e42b4f8479e6f1bf","https://www.semanticscholar.org/paper/fb49e88c6bd676516898e911e42b4f8479e6f1bf",13,"Ask Me Anything: A simple strategy for prompting language models","This simple strategy enables the open-source GPT-J-6B model to match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular benchmarks.","ArXiv",2022,"Simran Arora,A. Narayan,Mayee F. Chen,Laurel J. Orr,Neel Guha,Kush S Bhatia,Ines Chami,Frederic Sala,Christopher R'e",10,71,0
"236bba82c1f048b3aa1f661460ec462f2dc9257f","https://www.semanticscholar.org/paper/236bba82c1f048b3aa1f661460ec462f2dc9257f",13,"REPLUG: Retrieval-Augmented Black-Box Language Models","R E P LUG is introduced, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model and can be easily applied to any existing retrieval and language models.","ArXiv",2023,"Weijia Shi,Sewon Min,Michihiro Yasunaga,Minjoon Seo,Rich James,M. Lewis,Luke Zettlemoyer,Wen-tau Yih",1,44,0
"85996f9fc312777f487dd51bf9e96bb3704c2fb7","https://www.semanticscholar.org/paper/85996f9fc312777f487dd51bf9e96bb3704c2fb7",13,"On the Planning Abilities of Large Language Models (A Critical Investigation with a Proposed Benchmark)","The results show that LLM's ability to autonomously generate executable plans is quite meager, averaging only about 3% success rate, and the heuristic and human-in-the-loop modes show slightly more promise.","",2023,"Karthik Valmeekam,S. Sreedharan,Matthew Marquez,Alberto Olmo,Subbarao Kambhampati",0,36,0
"1853a05df0ac03f8e4445ec65f7599359e89fb2b","https://www.semanticscholar.org/paper/1853a05df0ac03f8e4445ec65f7599359e89fb2b",13,"ThoughtSource: A central hub for large language model reasoning data","The goal of ThoughtSource is to improve future artiﬁcial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data.","ArXiv",2023,"Simon Ott,Konstantin Hebenstreit,Valentin Li'evin,C. Hother,M. Moradi,Maximilian Mayrhauser,Robert Praas,O. Winther,M. Samwald",0,35,0
"13a0d8bb38f739990c8cd65a44061c6534f17221","https://www.semanticscholar.org/paper/13a0d8bb38f739990c8cd65a44061c6534f17221",13,"OPT: Open Pre-trained Transformer Language Models","This work presents Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained transformers ranging from 125M to 175B parameters, which they aim to fully and responsibly share with interested researchers.","ArXiv",2022,"Susan Zhang,Stephen Roller,Naman Goyal,Mikel Artetxe,Moya Chen,Shuohui Chen,Christopher Dewan,Mona Diab,Xian Li,Xi Victoria Lin,Todor Mihaylov,Myle Ott,Sam Shleifer,Kurt Shuster,Daniel Simig,Punit Singh Koura,Anjali Sridhar,Tianlu Wang,Luke Zettlemoyer",275,115,50
"5922f437512158970c417f4413bface021df5f78","https://www.semanticscholar.org/paper/5922f437512158970c417f4413bface021df5f78",13,"A Generalist Agent","","ArXiv",2022,"S. Reed,Konrad Zolna,Emilio Parisotto,Sergio Gomez Colmenarejo,Alexander Novikov,Gabriel Barth-Maron,Mai Gimenez,Yury Sulsky,Jackie Kay,J. T. Springenberg,Tom Eccles,Jake Bruce,Ali Razavi,Ashley D. Edwards,N. Heess,Yutian Chen,R. Hadsell,Oriol Vinyals,Mahyar Bordbar,N. D. Freitas",134,102,20
"559bfba3bee31f6061a5d5c7061f22794de47e39","https://www.semanticscholar.org/paper/559bfba3bee31f6061a5d5c7061f22794de47e39",13,"State-of-the-art generalisation research in NLP: a taxonomy and review","A taxonomy for characterising and understanding generalisation research in NLP is presented, a taxonomy is used to present a comprehensive map of published generalisation studies, and recommendations for which areas might deserve attention in the future are made.","ArXiv",2022,"D. Hupkes,Mario Giulianelli,Verna Dankers,Mikel Artetxe,Yanai Elazar,Tiago Pimentel,Christos Christodoulopoulos,Karim Lasri,Naomi Saphra,Arabella J. Sinclair,Dennis Ulmer,Florian Schottmann,Khuyagbaatar Batsuren,Kaiser Sun,Koustuv Sinha,Leila Khalatbari,Maria Ryskina,Rita Frieske,Ryan Cotterell,Zhijing Jin",4,697,0
"075f83cac2742dbb36ee49d30f7aee2a322f3127","https://www.semanticscholar.org/paper/075f83cac2742dbb36ee49d30f7aee2a322f3127",13,"Towards Better Few-Shot and Finetuning Performance with Forgetful Causal Language Models","This work proposes a simple technique, Forgetful Causal Masking (FCM), which improves both few-shot and netuning performance of PaLM and considers a simple extension, T-FCM, which introduces bidirectional context to causal language model without altering the sequence order.","",2022,"Hao Liu,Xinyang Geng,Lisa Lee,Igor Mordatch,S. Levine,Sharan Narang,P. Abbeel",0,59,0
"3a07a87090a061ca41dd30ac8398a9a5d9d39826","https://www.semanticscholar.org/paper/3a07a87090a061ca41dd30ac8398a9a5d9d39826",13,"Dense Text Retrieval based on Pretrained Language Models: A Survey","This survey aims to provide a comprehensive, practical reference focused on the major progress for dense text retrieval, and takes a new perspective to organize the related work by four major aspects, including architecture, training, indexing and integration, and summarize the mainstream techniques for each aspect.","ArXiv",2022,"Wayne Xin Zhao,Jing Liu,Ruiyang Ren,Ji-rong Wen",4,344,0
"89c3bd70ad33c4f8832f00ab98872b77861ee0ec","https://www.semanticscholar.org/paper/89c3bd70ad33c4f8832f00ab98872b77861ee0ec",13,"Discovering Latent Knowledge in Language Models Without Supervision","It is shown that despite using no supervision and no model outputs, the method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms zero-shot accuracy by 4% on average.","ArXiv",2022,"Collin Burns,Hao-Tong Ye,D. Klein,J. Steinhardt",4,64,1
"0ca25741b79f8780614a7cd730a6170fccdc5abb","https://www.semanticscholar.org/paper/0ca25741b79f8780614a7cd730a6170fccdc5abb",13,"A Survey for In-context Learning","This paper presents a formal definition of ICL and clarify its correlation to related studies, and organizes and discusses advanced techniques, including training strategies, demonstration designing strategies, as well as related analysis.","ArXiv",2022,"Qingxiu Dong,Lei Li,Damai Dai,Ce Zheng,Zhiyong Wu,Baobao Chang,Xu Sun,Jingjing Xu,Zhifang Sui",0,74,0
"2f21201ac9fcb88a72c56471402388ec2fc365a8","https://www.semanticscholar.org/paper/2f21201ac9fcb88a72c56471402388ec2fc365a8",12,"Inferring Implicit Relations in Complex Questions with Language Models","This work investigates why current models struggle with implicit reasoning question answering (QA) tasks, by decoupling inference of reasoning steps from their execution, and evaluates models from the GPT-3 family, finding that while these models struggle on the implicit reasoning QA task, they often succeed at inferring implicit relations.","ArXiv",2022,"Uri Katz,Mor Geva,Jonathan Berant",2,53,0
"598d9b235f5ab148fc757240d9bc39a47b8eaf72","https://www.semanticscholar.org/paper/598d9b235f5ab148fc757240d9bc39a47b8eaf72",12,"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks","Under both few-shot and zero-shot settings, PoT can show an average performance gain over CoT by around 12% across all the evaluated datasets, and by combining PoT with self-consistency decoding, can achieve SoT performance on all math problem datasets and near-SoTA performance on ﬁnancial datasets.","ArXiv",2022,"Wenhu Chen,Xueguang Ma,Xinyi Wang,William W. Cohen",20,38,5
"9431181f8115a2360621df5ed76e1a23b88e3b2f","https://www.semanticscholar.org/paper/9431181f8115a2360621df5ed76e1a23b88e3b2f",12,"Evaluating Human-Language Model Interaction","A framework, Human-AI Language-based Interaction Evaluation (H-LINE), is developed that expands non-interactive evaluation along three dimensions, capturing the interactive process, not only the output of the system, and notions of preference beyond quality.","ArXiv",2022,"Mina Lee,Megha Srivastava,Amelia Hardy,John Thickstun,Esin Durmus,Ashwin Paranjape,Ines Gerard-Ursin,Xiang Lisa Li,Faisal Ladhak,Frieda Rong,Rose E. Wang,Minae Kwon,Joon Sung Park,Hancheng Cao,Tony Lee,Rishi Bommasani,Michael Bernstein,Percy Liang",1,168,0
"f84728f28cd3f234ecce8fe899d6cb001b18a263","https://www.semanticscholar.org/paper/f84728f28cd3f234ecce8fe899d6cb001b18a263",12,"Nonparametric Masked Language Modeling","It is shown that N P M can be efﬁciently trained with a contrastive objective and an in-batch approximation to full corpus retrieval, and is particularly better on dealing with rare patterns (word senses or facts), and predicting rare or nearly unseen words.","ArXiv",2022,"Sewon Min,Weijia Shi,M. Lewis,Xilun Chen,Wen-tau Yih,Hanna Hajishirzi,Luke Zettlemoyer",2,85,1
"645b10b7802a035e034488e3640fc0bc415de34c","https://www.semanticscholar.org/paper/645b10b7802a035e034488e3640fc0bc415de34c",12,"UL2: Unifying Language Learning Paradigms","By scaling the model up to 20B parameters, this paper achieves SOTA performance on 50 well-established supervised NLP tasks ranging from language generation, language understanding, text classiﬁcation, question answering, commonsense reasoning, long text reasoning, structured knowledge grounding and information retrieval.","",2022,"Yi Tay,M. Dehghani,V. Tran,Xavier García,Jason Wei,Xuezhi Wang,Hyung Won Chung,Dara Bahri,Tal Schuster,Huaixiu Zheng,Denny Zhou,N. Houlsby,Donald Metzler",1,125,1
"e3bdf0e84ca06ad456dcd2b073cc72fe81c5b46e","https://www.semanticscholar.org/paper/e3bdf0e84ca06ad456dcd2b073cc72fe81c5b46e",12,"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning","ROSCOE is presented, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics and can measure semantic consistency, logicality, informativeness, fluency, and factuality — among other traits — by leveraging properties of step-by-step rationales.","ArXiv",2022,"O. Yu. Golovneva,Moya Chen,Spencer Poff,Martin Corredor,Luke Zettlemoyer,M. Fazel-Zarandi,Asli Celikyilmaz",1,52,1
"e66f0f822d4c4853b39b27daaafa2993005fd55e","https://www.semanticscholar.org/paper/e66f0f822d4c4853b39b27daaafa2993005fd55e",12,"Large Language Models are few(1)-shot Table Reasoners","This paper evaluated LLMs on popular table QA and fact veriﬁcation datasets like WikiTableQuestion, FetaQA, TabFact, and FEVEROUS and found that LLMs are competent at complex reasoning over table structures, though these models are not pre-trained on any table corpus.","ArXiv",2022,"Wenhu Chen",8,47,1
"e9f5c4bb0db632eaf48c4d4ce83a29753d2d861b","https://www.semanticscholar.org/paper/e9f5c4bb0db632eaf48c4d4ce83a29753d2d861b",12,"Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)","This work proposes an extensible assessment framework to test the capabilities of LLMs on reasoning about actions and change, a central aspect of human intelligence and provides multiple test cases that are more involved than any of the previously established benchmarks.","ArXiv",2022,"Karthik Valmeekam,Alberto Olmo,S. Sreedharan,Subbarao Kambhampati",13,34,3
"ec4c8d99eb1c028c43af6d8bbf727392d351cb59","https://www.semanticscholar.org/paper/ec4c8d99eb1c028c43af6d8bbf727392d351cb59",12,"Efficient Training of Language Models to Fill in the Middle","There is extensive evidence that training models with a large fraction of data transformed in this way does not harm the original left-to-right generative capability, as measured by perplexity and sampling evaluations across a wide range of scales.","ArXiv",2022,"Mohammad Bavarian,Heewoo Jun,N. Tezak,J. Schulman,C. McLeavey,Jerry Tworek,Mark Chen",14,60,1
"c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd","https://www.semanticscholar.org/paper/c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd",12,"Internet-augmented language models through few-shot prompting for open-domain question answering","It is suggested that it might be crucial to slow down the race towards the biggest model and instead shift attention towards more effective ways to use models, including but not limited to, better prompting or increasing inference-time compute.","ArXiv",2022,"Angeliki Lazaridou,E. Gribovskaya,Wojciech Stokowiec,N. Grigorev",12,44,3
"e37018d3cfab9cfc29a7b78404e6c86ea18a907e","https://www.semanticscholar.org/paper/e37018d3cfab9cfc29a7b78404e6c86ea18a907e",12,"GPT-NeoX-20B: An Open-Source Autoregressive Language Model","GPT-NeoX-20B is introduced, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license.","BIGSCIENCE",2022,"Sid Black,Stella Rose Biderman,Eric Hallahan,Quentin G. Anthony,Leo Gao,Laurence Golding,Horace He,Connor Leahy,Kyle McDonell,Jason Phang,M. Pieler,Usvsn Sai Prashanth,Shivanshu Purohit,Laria Reynolds,J. Tow,Benqi Wang,Samuel Weinbach",76,141,10
"1d26c947406173145a4665dd7ab255e03494ea28","https://www.semanticscholar.org/paper/1d26c947406173145a4665dd7ab255e03494ea28",12,"GLM-130B: An Open Bilingual Pre-trained Model","An attempt to open-source a 100B-scale model at least as good as GPT-3 and unveil how models of such a scale can be successfully pre-trained, including its design choices, training strategies for both efficiency and stability, and engineering efforts is introduced.","ArXiv",2022,"Aohan Zeng,Xiao Liu,Zhengxiao Du,Zihan Wang,Hanyu Lai,Ming Ding,Zhuoyi Yang,Yifan Xu,Wendi Zheng,Xiao Xia,W. Tam,Zixuan Ma,Yufei Xue,Jidong Zhai,Wenguang Chen,P. Zhang,Yuxiao Dong,Jie Tang",16,118,5
"2303ee0de927266c296287202519f17bdea9e4e8","https://www.semanticscholar.org/paper/2303ee0de927266c296287202519f17bdea9e4e8",12,"Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization","This paper explores how the retrieval of soft prompts obtained through prompt tuning can assist hard prompts in zero-shot task generalization and finds that retrieving source embeddings trained on similar answer choice formats is more important than those on similar task types.","ArXiv",2022,"Seonghyeon Ye,Joel Jang,Doyoung Kim,Yongrae Jo,Minjoon Seo",3,76,0
"ec7324a15009a9bd0b676f6b17762f759cf5dd9a","https://www.semanticscholar.org/paper/ec7324a15009a9bd0b676f6b17762f759cf5dd9a",12,"Large Language Models Are Human-Level Prompt Engineers","It is shown that APE-engineered prompts can be applied to steer models toward truthfulness and/or informativeness, as well as to improve few-shot learning performance by simply prepending them to standard in-context learning prompts.","ArXiv",2022,"Yongchao Zhou,Andrei Ioan Muresanu,Ziwen Han,Keiran Paster,Silviu Pitis,Harris Chan,Jimmy Ba",13,51,2
"9cc5c25517c3a78183a052e8e93a44e85bb17432","https://www.semanticscholar.org/paper/9cc5c25517c3a78183a052e8e93a44e85bb17432",12,"Improving Cross-task Generalization of Unified Table-to-text Models with Compositional Task Configurations","This paper designs the task conﬁgurations to explicitly specify the task type, as well as its input and output types, and shows that this not only allows the model to better learn shared knowledge across different tasks at training, but also allows us to control the model by composing new conﰂgurations that apply novel input-output combinations in a zero-shot manner.","ArXiv",2022,"Jifan Chen,Yuhao Zhang,Lan Liu,Rui Dong,Xinchi Chen,Patrick Ng,William Yang Wang,Zhiheng Huang",0,46,0
"ea0688f9e7dfb0d3c2249486af65209c25809544","https://www.semanticscholar.org/paper/ea0688f9e7dfb0d3c2249486af65209c25809544",12,"Faithful Chain-of-Thought Reasoning","Faithful CoT is proposed, a faithful-by-construction framework that decomposes a reasoning task into two stages: Translation (Natural Language query $\rightarrow$ symbolic reasoning chain) and Problem Solving (reasoning chain $\ rightarrow$ answer), using an LM and a deterministic solver respectively.","ArXiv",2023,"QING LYU,Shreya Havaldar,Adam Stein,Li Zhang,D. Rao,Eric Wong,Marianna Apidianaki,Chris Callison-Burch",1,31,0
"fbd49b25bdab98c171af49962a41139c73dacbde","https://www.semanticscholar.org/paper/fbd49b25bdab98c171af49962a41139c73dacbde",12,"Specializing Smaller Language Models towards Multi-Step Reasoning","This work shows two important aspects of model abilities: there exists a very complex balance/ tradeoff between language models’ multi-dimensional abilities and by paying the price of decreased generic ability, it can clearly lift up the scaling curve of models smaller than 10B towards a specialized multi-step math reasoning ability.","ArXiv",2023,"Yao Fu,Hao-Chun Peng,Litu Ou,Ashish Sabharwal,Tushar Khot",0,31,0
"4ef5410ec4b546eda642fe786cc1bdbb5a7251e1","https://www.semanticscholar.org/paper/4ef5410ec4b546eda642fe786cc1bdbb5a7251e1",11,"Attributed Text Generation via Post-hoc Research and Revision","RARR is a system that automatically attribution for the output of any text generation model and post-edits the output to unsupported content while preserving the original output as much as possible and improves attribution while otherwise preserving theOriginal input to a much greater degree than previously explored edit models.","ArXiv",2022,"Luyu Gao,Zhuyun Dai,Panupong Pasupat,Anthony Chen,Arun Tejasvi Chaganty,Yicheng Fan,Vincent Zhao,N. Lao,Hongrae Lee,Da-Cheng Juan,Kelvin Guu",6,62,1
"239b5649b12f28fd610de036afba41b9246db6c9","https://www.semanticscholar.org/paper/239b5649b12f28fd610de036afba41b9246db6c9",11,"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning","This work introduces Parsel 2, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, based on hierarchical function descriptions in natural language, which can be used across domains requiring hierarchical reasoning, e.g. code synthesis, theorem proving, and robotic planning.","ArXiv",2022,"E. Zelikman,Qian Huang,Gabriel Poesia,Noah D. Goodman,N. Haber",0,64,0
"edcd520e553dc58c728eceb8433e3d155955a89a","https://www.semanticscholar.org/paper/edcd520e553dc58c728eceb8433e3d155955a89a",11,"Complementary Explanations for Effective In-Context Learning","This work proposes a maximal-marginal-relevance-based exemplar selection approach for constructing exemplar sets that are both relevant as well as complementary, which successfully improves the in-context learning performance across three real-world tasks on multiple LLMs.","ArXiv",2022,"Xi Ye,Srini Iyer,Asli Celikyilmaz,V. Stoyanov,Greg Durrett,Ramakanth Pasunuru",4,38,1
"29be9045fb09f0c947fb24c76bd1136d47880d96","https://www.semanticscholar.org/paper/29be9045fb09f0c947fb24c76bd1136d47880d96",11,"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions","IRCoT is proposed, a new approach that interleaves retrieval with CoT for multi-step QA, guiding the retrieval with coT and in turn using retrieved results to improve CoT.","ArXiv",2022,"H. Trivedi,Niranjan Balasubramanian,Tushar Khot,Ashish Sabharwal",3,35,0
"1e9e1da1097d6e9d3849ea6539b170893c325bdb","https://www.semanticscholar.org/paper/1e9e1da1097d6e9d3849ea6539b170893c325bdb",11,"ThinkSum: Probabilistic reasoning over sets using large language models","It is argued that because the probabilistic inference in T HINK S UM is performed outside of calls to the LLM, it is less sensitive to prompt design, yields more interpretable predictions, and can be ﬂexibly combined with latent variable models to extract structured knowledge from LLMs.","ArXiv",2022,"Batu Mehmet Ozturkler,Nikolay Malkin,Zhen Wang,N. Jojic",2,35,0
"c43a4a7b7ea4f4889de051321cb0073fd577f843","https://www.semanticscholar.org/paper/c43a4a7b7ea4f4889de051321cb0073fd577f843",11,"Causal Reasoning of Entities and Events in Procedural Texts","This work proposes CREPE, the first benchmark on causal reasoning of event plausibility and entity states, and boosts model performance to .59 F1 by creatively representing events as programming languages while prompting language models pretrained on code.","ArXiv",2023,"Li Zhang,Hai Xu,Yue Yang,Shuyan Zhou,Weiqiu You,Manni Arora,Chris Callison-Burch",0,85,0
"0fbcb934048a0da9c12ccffe2417e48793884992","https://www.semanticscholar.org/paper/0fbcb934048a0da9c12ccffe2417e48793884992",11,"Unifying Molecular and Textual Representations via Multi-task Language Modelling","This work proposes a multi-domain, multi-task language model that can handle chemical and natural language concurrently, without requiring expensive pre-training on single domains or task-speciﬁc models, and suggests that such models can robustly and e-ciently accelerate discovery in physical sciences by superseding problem-speciation and enhancing human-model interactions.","ArXiv",2023,"Dimitrios Christofidellis,Giorgio Giannone,Jannis Born,O. Winther,T. Laino,M. Manica",0,42,0
"de1c7ae2818aa26fc86a0ea8ed70014cffc8b20a","https://www.semanticscholar.org/paper/de1c7ae2818aa26fc86a0ea8ed70014cffc8b20a",11,"Fine-tuning language models to find agreement among humans with diverse preferences","A large language modeling model is tuned to generate statements that maximize the expected approval for a group of people with potentially diverse opinions and produces consensus statements that are preferred by human users over those from prompted LLMs and outperforms a tight baseline that lacks the ranking step.","ArXiv",2022,"Michiel A. Bakker,Martin Chadwick,H. Sheahan,Michael Henry Tessler,Lucy Campbell-Gillingham,Jan Balaguer,Nathan McAleese,A. Glaese,J. Aslanides,M. Botvinick,C. Summerfield",5,44,0
"79d083a742fe2c20f543f442f5324e63a4d4ae2d","https://www.semanticscholar.org/paper/79d083a742fe2c20f543f442f5324e63a4d4ae2d",11,"Auditing Large Language Models: A Three-Layered Approach","","SSRN Electronic Journal",2023,"Jakob Mokander,Jonas Schuett,Hannah Rose Kirk,Luciano Floridi",0,240,0
"205eab69e430b4da93ecf3fd9115f0919b448040","https://www.semanticscholar.org/paper/205eab69e430b4da93ecf3fd9115f0919b448040",11,"WeLM: A Well-Read Pre-trained Language Model for Chinese","A well-read pre-trained language model for Chinese that is able to seamlessly perform different types of tasks with zero or few-shot demonstrations, and has basic skills at explaining and calibrating the decisions from itself, which can be promising directions for future research.","ArXiv",2022,"Hui Su,Xiao Zhou,Houjin Yu,Yuwen Chen,Zilin Zhu,Yang Yu,Jie Zhou",1,85,0
"711d5e8ddbb840ad31a9ffa3d38590603ba69a92","https://www.semanticscholar.org/paper/711d5e8ddbb840ad31a9ffa3d38590603ba69a92",11,"Prompting GPT-3 To Be Reliable","This systematic empirical study sheds new insights on the reliability of prompting LLMs, but more importantly, its prompting strategies can help practitioners more reliably use LLMs like GPT-3.","ArXiv",2022,"Chenglei Si,Zhe Gan,Zhengyuan Yang,Shuohang Wang,Jianfeng Wang,Jordan L. Boyd-Graber,Lijuan Wang",8,100,1
"ff21066b94e9e09ffda6acfbc1c550b05a09b333","https://www.semanticscholar.org/paper/ff21066b94e9e09ffda6acfbc1c550b05a09b333",11,"Leveraging Large Language Models for Multiple Choice Question Answering","It is shown that a model with high MCSB ability performs much better with the natural approach than with the traditional approach across 20 diverse datasets and largely closes the gap with the SOTA, suggesting that the MCQA ability of LLMs has been previously underestimated.","ArXiv",2022,"Joshua Robinson,C. Rytting,D. Wingate",1,71,0
"7b0f98f51040700aae3cd9f0e3432dedcd69fb30","https://www.semanticscholar.org/paper/7b0f98f51040700aae3cd9f0e3432dedcd69fb30",11,"When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories","It is found that LMs struggle with less popular factual knowledge, and that scaling fails to appreciably improve memorization of factual knowledge in the tail, and a simple, yet effective, method for powerful andcient retrieval-augmented LMs, which retrieves non-parametric memories only when necessary is devised.","ArXiv",2022,"Alex Mallen,Akari Asai,Victor Zhong,R. Das,Hannaneh Hajishirzi,Daniel Khashabi",2,45,0
"cd5fd34d6446f3965b2760a81c49b24b13477d5b","https://www.semanticscholar.org/paper/cd5fd34d6446f3965b2760a81c49b24b13477d5b",11,"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain-of-Thought","To enable systematic exploration of the reasoning ability of LLMs, a new synthetic question-answering dataset is presented, where each example is generated from a synthetic world model represented in ﬁrst-order logic, which allows us to parse the generated chain-of-thought into symbolic proofs for formal analysis.","ArXiv",2022,"Abulhair Saparov,He He",7,36,1
"43d3dbabea106b59e1ec248457c88b19636e4f47","https://www.semanticscholar.org/paper/43d3dbabea106b59e1ec248457c88b19636e4f47",11,"Can language models handle recursively nested grammatical structures? A case study on comparing models and humans","","ArXiv",2022,"Andrew Kyle Lampinen",3,79,0
"a8fd9c1625011741f74401ff9bdc1c584e25c86d","https://www.semanticscholar.org/paper/a8fd9c1625011741f74401ff9bdc1c584e25c86d",11,"Language Models are General-Purpose Interfaces","This work proposes a semi-causal language modeling objective to jointly pretrain the interface and the modular encoders, and subsume the advantages and capabilities from both causal and non-causing modeling, thereby combining the best of two worlds.","ArXiv",2022,"Y. Hao,Haoyu Song,Li Dong,Shaohan Huang,Zewen Chi,Wenhui Wang,Shuming Ma,Furu Wei",17,133,0
"15bacb240e2598457af4ded3039b6988aa9706f0","https://www.semanticscholar.org/paper/15bacb240e2598457af4ded3039b6988aa9706f0",11,"Few-shot Adaptation Works with UnpredicTable Data","This work automatically extracting 413,299 tasks from internet tables - orders of magnitude more than the next-largest public datasets - and finds that narrow subsets of the authors' dataset sometimes outperform more diverse datasets.","ArXiv",2022,"Jun Shern Chan,M. Pieler,Jonathan Jao,J. Scheurer,Ethan Perez",2,144,0
"07ec0d4cc6a2be39def51139d228292c6a0dc627","https://www.semanticscholar.org/paper/07ec0d4cc6a2be39def51139d228292c6a0dc627",11,"Guess the Instruction! Flipped Learning Makes Language Models Stronger Zero-Shot Learners","FLIPPED gives particularly large improvements on unseen labels, outperforming T0-11B by up to +20% average F1 score, indicating that the strong task generalization of FLIPPED comes from improved generalization to novel labels.","ArXiv",2022,"Seonghyeon Ye,Doyoung Kim,Joel Jang,Joongbo Shin,Minjoon Seo",1,71,0
"3fa70115248377c3d1517c9f978791a296fbc1dd","https://www.semanticscholar.org/paper/3fa70115248377c3d1517c9f978791a296fbc1dd",11,"Large Language Models Can Self-Improve","This work uses a pre-trained LLM to generate “high-conﬁdence” rationale-augmented answers for unlabeled questions using Chain-of-Thought prompting and self-consistency, and conducts ablation studies and shows that ablation on reasoning is critical for self-improvement.","ArXiv",2022,"Jiaxin Huang,S. Gu,Le Hou,Yuexin Wu,Xuezhi Wang,Hongkun Yu,Jiawei Han",22,51,3
"6ae3e52ae55578c10722db3c2f898442f20e336c","https://www.semanticscholar.org/paper/6ae3e52ae55578c10722db3c2f898442f20e336c",11,"LMentry: A Language Model Benchmark of Elementary Language Tasks","LMentry is speciﬁcally designed to provide quick and interpretable insights into the capabilities and robustness of large language models, providing a quick, automatic, and easy-to-run “unit test”, without resorting to large benchmark suites of complex tasks.","ArXiv",2022,"Avia Efrat,Or Honovich,Omer Levy",1,41,0
"327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9","https://www.semanticscholar.org/paper/327f1561b544b0a3b9d8d5d0e6d82c2a5911fca9",11,"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model","BLOOM is a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers and achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning.","ArXiv",2022,"Teven Le Scao,Angela Fan,Christopher Akiki,Elizabeth-Jane Pavlick,Suzana Ili'c,Daniel Hesslow,Roman Castagn'e,A. Luccioni,Franccois Yvon,Matthias Gallé,J. Tow,Alexander M. Rush,Stella Rose Biderman,Albert Webson,Pawan Sasanka Ammanamanchi,Thomas Wang,Benoît Sagot,Niklas Muennighoff,Albert Villanova del Moral,Olatunji Ruwase,Rachel Bawden,Stas Bekman,Angelina McMillan-Major,Iz Beltagy,Huu Nguyen,Lucile Saulnier,Samson Tan,Pedro Ortiz Suarez,Victor Sanh,Hugo Laurenccon,Yacine Jernite,Julien Launay,Margaret Mitchell,Colin Raffel,Aaron Gokaslan,Adi Simhi,Aitor Soroa Etxabe,Alham Fikri Aji,Amit Alfassy,Anna Rogers,Ariel Kreisberg Nitzav,Canwen Xu,Chenghao Mou,Chris C. Emezue,Christopher Klamm,Colin Leong,Daniel Alexander van Strien,David Ifeoluwa Adelani,Dragomir R. Radev,Eduardo G. Ponferrada,Efrat Levkovizh,Ethan Kim,E. Natan,F. Toni,Gérard Dupont,Germán Kruszewski,Giada Pistilli,Hady ElSahar,Hamza Benyamina,Hieu Tran,Ian Yu,Idris Abdulmumin,Isaac Johnson,Itziar Gonzalez-Dios,Javier de la Rosa,Jenny Chim,Jesse Dodge,Jian Zhu,Jonathan Chang,Jorg Frohberg,Josephine L. Tobing,J. Bhattacharjee,Khalid Almubarak,Kimbo Chen,Kyle Lo,Leandro von Werra,Leon Weber,Long Phan,Loubna Ben Allal,Ludovic Tanguy,Manan Dey,M. Muñoz,Maraim Masoud,Mar'ia Grandury,Mario vSavsko,Max Huang,Maximin Coavoux,Mayank Singh,Mike Tian-Jian Jiang,Minh Chien Vu,M. A. Jauhar,Mustafa Ghaleb,Nishant Subramani,Nora Kassner,Nurulaqilla Khamis,Olivier Nguyen,Omar Espejel,Ona de Gibert,Paulo Villegas,Peter Henderson,Pierre Colombo,Priscilla Amuok,Quentin Lhoest,Rheza Harliman,Rishi Bommasani,R. L'opez,Rui Ribeiro,Salomey Osei,Sampo Pyysalo,Sebastian Nagel,Shamik Bose,Shamsuddeen Hassan Muhammad,Shanya Sharma,S. Longpre,Somaieh Nikpoor,Stanislav Silberberg,S. Pai,S. Zink,Tiago Timponi Torrent,Timo Schick,Tristan Thrush,V. Danchev,Vassilina Nikoulina,Veronika Laippala,Violette Lepercq,V. Prabhu,Zaid Alyafeai,Zeerak Talat,Arun Raja,Benjamin Heinzerling,Chenglei Si,Elizabeth Salesky,Sabrina J. Mielke,Wilson Y. Lee,Abheesht Sharma,Andrea Santilli,Antoine Chaffin,Arnaud Stiegler,Debajyoti Datta,Eliza Szczechla,Gunjan Chhablani,Han Wang,Harshit Pandey,Hendrik Strobelt,Jason Alan Fries,Jos Rozen,Leo Gao,Lintang Sutawika,M Saiful Bari,Maged S. Al-shaibani,Matteo Manica,Nihal V. Nayak,Ryan Teehan,Samuel Albanie,Sheng Shen,Srulik Ben-David,Stephen H. Bach,Taewoon Kim,T. Bers,Thibault Févry,Trishala Neeraj,Urmish Thakker,Vikas Raunak,Xiang Tang,Zheng Xin Yong,Zhiqing Sun,Shaked Brody,Y. Uri,Hadar Tojarieh,Adam Roberts,Hyung Won Chung,Jaesung Tae,Jason Phang,Ofir Press,Conglong Li,D. Narayanan,Hatim Bourfoune,J. Casper,Jeff Rasley,Max Ryabinin,Mayank Mishra,Minjia Zhang,M. Shoeybi,Myriam Peyrounette,N. Patry,Nouamane Tazi,Omar Sanseviero,Patrick von Platen,Pierre Cornette,Pierre Franccois Lavall'ee,R. Lacroix,Samyam Rajbhandari,Sanchit Gandhi,Shaden Smith,S. Requena,Suraj Patil,Tim Dettmers,Ahmed Baruwa,Amanpreet Singh,Anastasia Cheveleva,Anne-Laure Ligozat,Arjun Subramonian,Aur'elie N'ev'eol,Charles Lovering,Daniel H Garrette,D. Tunuguntla,Ehud Reiter,Ekaterina Taktasheva,E. Voloshina,Eli Bogdanov,Genta Indra Winata,Hailey Schoelkopf,Jan-Christoph Kalo,Jekaterina Novikova,J. Forde,Jordan Clive,Jungo Kasai,Ken Kawamura,Liam Hazan,Marine Carpuat,Miruna Clinciu,Najoung Kim,Newton Cheng,Oleg Serikov,Omer Antverg,Oskar van der Wal,Rui Zhang,Ruochen Zhang,Sebastian Gehrmann,S. Pais,Tatiana Shavrina,Thomas Scialom,Tian Yun,Tomasz Limisiewicz,Verena Rieser,Vitaly Protasov,V. Mikhailov,Yada Pruksachatkun,Yonatan Belinkov,Zachary Bamberger,Zdenvek Kasner,A. Rueda,A. Pestana,A. Feizpour,Ammar Khan,Amy Faranak,A. Santos,A. Hevia,Antigona Unldreaj,Arash Aghagol,Arezoo Abdollahi,A. Tammour,Azadeh HajiHosseini,Bahareh Behroozi,B. Ajibade,B. Saxena,Carlos Muñoz Ferrandis,Danish Contractor,D. Lansky,Davis David,Douwe Kiela,D. A. Nguyen,Edward Tan,Emily Baylor,Ezinwanne Ozoani,Fatim T Mirza,Frankline Ononiwu,Habib Rezanejad,H.A. Jones,Indrani Bhattacharya,Irene Solaiman,Irina Sedenko,I. Nejadgholi,J. Passmore,Joshua Seltzer,Julio Bonis Sanz,Karen Fort,L. Dutra,Mairon Samagaio,Maraim Elbadri,M. Mieskes,Marissa Gerchick,Martha Akinlolu,Michael McKenna,Mike Qiu,M. Ghauri,Mykola Burynok,Nafis Abrar,Nazneen Rajani,Nour Elkott,N. Fahmy,O. Samuel,Ran An,R. Kromann,Ryan Hao,S. Alizadeh,Sarmad Shubber,Silas L. Wang,Sourav Roy,S. Viguier,Thanh-Cong Le,Tobi Oyebade,T. Le,Yoyo Yang,Z. Nguyen,Abhinav Ramesh Kashyap,Alfredo Palasciano,A. Callahan,Anima Shukla,Antonio Miranda-Escalada,A. Singh,Benjamin Beilharz,Bo Wang,C. Brito,Chenxi Zhou,Chirag Jain,Chuxin Xu,Clémentine Fourrier,Daniel Le'on Perin'an,Daniel Molano,Dian Yu,Enrique Manjavacas,Fabio Barth,Florian Fuhrimann,Gabriel Altay,Giyaseddin Bayrak,Gully A. Burns,Helena U. Vrabec,I. Bello,Isha Dash,J. Kang,John Giorgi,J. Golde,J. Posada,Karthi Sivaraman,Lokesh Bulchandani,Lu Liu,Luisa Shinzato,Madeleine Hahn de Bykhovetz,Maiko Takeuchi,Marc Pàmies,M. A. Castillo,Marianna Nezhurina,Mario Sanger,M. Samwald,Michael Cullan,Michael Weinberg,M. Wolf,Mina Mihaljcic,Minna Liu,M. Freidank,Myungsun Kang,Natasha Seelam,N. Dahlberg,N. Broad,N. Muellner,Pascale Fung,Patricia Haller,R. Chandrasekhar,R. Eisenberg,Robert Martin,Rodrigo L. Canalli,Rosaline Su,Ruisi Su,Samuel Cahyawijaya,Samuele Garda,Shlok S Deshmukh,Shubhanshu Mishra,Sid Kiblawi,Simon Ott,Sinee Sang-aroonsiri,Srishti Kumar,Stefan Schweter,S. Bharati,T. A. Laud,Th'eo Gigant,Tomoya Kainuma,Wojciech Kusa,Yanis Labrak,Yashasvi Bajaj,Y. Venkatraman,Yifan Xu,Ying Xu,Yun-chao Xu,Z. Tan,Zhongli Xie,Zifan Ye,M. Bras,Younes Belkada,Thomas Wolf",56,157,11
"05d77715d49714506a920f26c5432b92078cd37c","https://www.semanticscholar.org/paper/05d77715d49714506a920f26c5432b92078cd37c",11,"Attributed Question Answering: Evaluation and Modeling for Attributed Large Language Models","This work formulate and study Attributed QA as a key first step in the development of attributed LLMs, and proposes a reproducible evaluation framework for the task and benchmark a broad set of architectures.","ArXiv",2022,"Bernd Bohnet,V. Tran,Pat Verga,Roee Aharoni,D. Andor,Livio Baldini Soares,Jacob Eisenstein,Kuzman Ganchev,Jonathan Herzig,Kai Hui,T. Kwiatkowski,Ji Ma,Jianmo Ni,Tal Schuster,William W. Cohen,Michael Collins,Dipanjan Das,Donald Metzler,Slav Petrov,Kellie Webster",1,54,0
"1e122149779c644855d1cccca5d96135db0482cb","https://www.semanticscholar.org/paper/1e122149779c644855d1cccca5d96135db0482cb",11,"Self-Prompting Large Language Models for Open-Domain QA","This paper shows that the ODQA architecture can be dramatically simplified by treating Large Language Models (LLMs) as a knowledge corpus and proposes a Self-Prompting framework for LLMs to perform ODZA so as to eliminate the need for training data and external knowledge corpus.","ArXiv",2022,"Junlong Li,Zhuosheng Zhang,Hai Zhao",0,39,0
"b7c4677cc6950d556f8d58084f87b2cb9cfe29b8","https://www.semanticscholar.org/paper/b7c4677cc6950d556f8d58084f87b2cb9cfe29b8",11,"Are Language Models Worse than Humans at Following Prompts? It's Complicated","","ArXiv",2023,"Albert Webson,Alyssa Marie Loo,Qinan Yu,Elizabeth-Jane Pavlick",2,34,0
"5882dd04d95c9c88cdec389059fcf44d56cbb789","https://www.semanticscholar.org/paper/5882dd04d95c9c88cdec389059fcf44d56cbb789",11,"Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation","The paper shows that the choice of datasets used for training a model contributes to how well it performs on a task as well as on how the prompt should be structured, and investigates how the number of examples in the prompt and the type of example selection affect the model's performance.","ArXiv",2023,"Jessica Huynh,Cathy Jiao,Prakhar Gupta,Shikib Mehri,Payal Bajaj,Vishrav Chaudhary,M. Eskénazi",0,47,0
"86d03160e6f05deb17d0169e515f5a55d6361f7c","https://www.semanticscholar.org/paper/86d03160e6f05deb17d0169e515f5a55d6361f7c",11,"Exploring the Benefits of Training Expert Language Models over Instruction Tuning","An unexpected finding is reported that an expert LM fine-tuned on just a single task can outperform an MT LM trained with 300+ different tasks on 11 different unseen datasets and on 13 datasets of the BIG-bench benchmark by a mean accuracy of 3.20% and 1.29%, respectively.","ArXiv",2023,"Joel Jang,Seung-bin Kim,Seonghyeon Ye,Doyoung Kim,L. Logeswaran,Moontae Lee,Kyungjae Lee,Minjoon Seo",0,69,0
"ffc8a0e3779ce0d772c46b55e78a2c51bd8bcc23","https://www.semanticscholar.org/paper/ffc8a0e3779ce0d772c46b55e78a2c51bd8bcc23",11,"On Improving Summarization Factual Consistency from Natural Language Feedback","This work collects a high-quality dataset, DeFacto, containing human demonstrations and informational feedback in natural language consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary, and evaluates if models can automatically correct factual inconsistencies in generated summaries.","ArXiv",2022,"Yixin Liu,Budhaditya Deb,Milagro Teruel,Aaron L Halfaker,Dragomir R. Radev,A. Awadallah",0,60,0
"9e3b52669d81dbf0d638a5f5d1d537c7087195d6","https://www.semanticscholar.org/paper/9e3b52669d81dbf0d638a5f5d1d537c7087195d6",11,"When Neural Model Meets NL2Code: A Survey","This survey focuses on how does neural network (NN) solves NL2Code and proposes a comprehensive framework, which is able to cover all studies in this task, and in-depth parse the existing studies into this framework.","ArXiv",2022,"Daoguang Zan,Bei Chen,Fengji Zhang,Di Lu,Bingchao Wu,Bei Guan,Yongji Wang,Jian-Guang Lou",1,156,0
"ec6a9627807c0b4035040b95ff1f2767c88b26bc","https://www.semanticscholar.org/paper/ec6a9627807c0b4035040b95ff1f2767c88b26bc",10,"RARR: Researching and Revising What Language Models Say, Using Language Models","It is shown that when applied to the output of several state-of-the-art LMs on a diverse set of generation tasks, that RARR improves attribution while otherwise preserving the original input to a much greater degree than previously explored edit models.","",2022,"Luyu Gao,Zhuyun Dai,Panupong Pasupat,Anthony Chen,Arun Tejasvi Chaganty,Yicheng Fan,Vincent Zhao,N. Lao,Hongrae Lee,Da-Cheng Juan,Kelvin Guu",2,58,1
"6d934171cb679bb804ff73a945746e2ed70e1a80","https://www.semanticscholar.org/paper/6d934171cb679bb804ff73a945746e2ed70e1a80",10,"Visconde: Multi-document QA with GPT-3 and Neural Reranking","A question-answering system that can answer questions whose supporting evidence is spread over multiple (potentially long) documents, called Visconde, uses a three-step pipeline to perform the task: decompose, retrieve, and aggregate.","ArXiv",2022,"Jayr Alencar Pereira,R. Fidalgo,R. Lotufo,Rodrigo Nogueira",0,36,0
"4f4e98cc9133e1814ac2eee9fc4693bf80d1d0d4","https://www.semanticscholar.org/paper/4f4e98cc9133e1814ac2eee9fc4693bf80d1d0d4",10,"Improving Multimodal Interactive Agents with Reinforcement Learning from Human Feedback","How to use reinforcement learning from human feedback (RLHF) to improve upon simulated, embodied agents trained to a base level of com-petency with imitation learning is demonstrated.","ArXiv",2022,"Josh Abramson,Arun Ahuja,Federico Carnevale,Petko Georgiev,Alex Goldin,Alden Hung,Jessica Landon,Jirka Lhotka,T. Lillicrap,Alistair Muldal,George Powell,Adam Santoro,Guy Scully,Sanjana Srivastava,Tamara von Glehn,Greg Wayne,Nathaniel Wong,Chen Yan,Rui Zhu",2,43,0
"4288d44c2b8e6a89607780caf1272061028f6f97","https://www.semanticscholar.org/paper/4288d44c2b8e6a89607780caf1272061028f6f97",10,"On the Advance of Making Language Models Better Reasoners","This paper conducts extensive experiments using the latest language model code-davinci-002 and demonstrates that D I V E RS E can achieve new state-of-the-art performance on six out of eight reasoning benchmarks, out-performing the PaLM model with 540B parameters.","ArXiv",2022,"Yifei Li,Zeqi Lin,Shizhuo Zhang,Qiang Fu,Bei Chen,Jian-Guang Lou,Weizhu Chen",34,62,10
"0f4ab3fe492ececbfd38be9682047371e2e9b8c6","https://www.semanticscholar.org/paper/0f4ab3fe492ececbfd38be9682047371e2e9b8c6",10,"Honest Students from Untrusted Teachers: Learning an Interpretable Question-Answering Pipeline from a Pretrained Language Model","A new way to build trustworthy pipeline systems from a combination of end-task annotations and frozen pretrained language models, called markup-and-mask, which combines aspects of extractive and free-text explanations.","ArXiv",2022,"Jacob Eisenstein,D. Andor,Bernd Bohnet,Michael Collins,David Mimno",4,44,1
"b4b37f87e0357f2e4cec70af67b2f088f6efce70","https://www.semanticscholar.org/paper/b4b37f87e0357f2e4cec70af67b2f088f6efce70",10,"A Survey of Knowledge-Enhanced Pre-trained Language Models","A comprehensive review of Knowledge-Enhanced Pre-trained Language Models (KE-PLMs) is presented to provide a clear insight into this thriving industry and introduces appropriate taxonomies respectively for Natural Language Understanding (NLU) and Natural Language Generation (NLG) to highlight the focus of these two kinds of tasks.","ArXiv",2022,"Linmei Hu,Zeyi Liu,Ziwang Zhao,Lei Hou,Liqiang Nie,Juanzi Li",0,247,0
"c23d9d44e8bc68408cea9f305d1f24d915bc0d0d","https://www.semanticscholar.org/paper/c23d9d44e8bc68408cea9f305d1f24d915bc0d0d",10,"Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey","A survey of recent work that uses large, pre-trained transformer-based language models to solve NLP tasks via pre-training then fine-tuning, prompting, or text generation approaches.","ArXiv",2021,"Bonan Min,Hayley H. Ross,Elior Sulem,Amir Pouran Ben Veyseh,Thien Huu Nguyen,Oscar Sainz,Eneko Agirre,Ilana Heinz,D. Roth",39,322,2
"b17cc18e4130505b939f7d527082eb6be2a7fd5b","https://www.semanticscholar.org/paper/b17cc18e4130505b939f7d527082eb6be2a7fd5b",10,"Rationale-Augmented Ensembles in Language Models","It is demonstrated that rationale-augmented ensembles achieve more accurate and interpretable results than existing prompting approaches—including standard prompting without rationales and rationale-based chain-of-thought prompting—while simultaneously improving interpretability of model predictions through the associated rationales.","ArXiv",2022,"Xuezhi Wang,Jason Wei,D. Schuurmans,Quoc Le,E. Chi,Denny Zhou",24,52,11
"196cc546041cb6db167784f632037f0a1dcf4a79","https://www.semanticscholar.org/paper/196cc546041cb6db167784f632037f0a1dcf4a79",10,"Generating Natural Language Proofs with Verifier-Guided Search","A novel stepwise method, NLProofS (Natural Language Proof Search), which learns to generate relevant steps conditioning on the hypothesis, which improves the correctness of predicted proofs from 27.7% to 33.3% in the distractor setting of EntailmentBank, demonstrating the effectiveness of NL proofS in generating challenging human-authored proofs.","Conference on Empirical Methods in Natural Language Processing",2022,"Kaiyu Yang,Jia Deng,Danqi Chen",8,70,2
"55e3fe05598be7c3dd357d51166869f6571b824f","https://www.semanticscholar.org/paper/55e3fe05598be7c3dd357d51166869f6571b824f",10,"Large Language Models are Pretty Good Zero-Shot Video Game Bug Detectors","This study explores the possibil-ity of leveraging the zero-shot capabilities of large language models for video game bug detection by formulating the bug detection problem as a question-answering task, and shows thatLarge language models can identify which event is buggy in a sequence of textual descriptions of events from a game.","ArXiv",2022,"Mohammad Reza Taesiri,F. Macklon,Yihe Wang,Hengshuo Shen,C. Bezemer",0,51,0
"b7c09e2d5ac1268205ebd7c54f11ad5c935beced","https://www.semanticscholar.org/paper/b7c09e2d5ac1268205ebd7c54f11ad5c935beced",10,"LAMBADA: Backward Chaining for Automated Reasoning in Natural Language","A Backward Chaining algorithm is developed, which is called L AM - BADA, that decomposes reasoning into four sub-modules, each of which can be simply implemented by few-shot prompted LM inference and achieves massive accuracy boosts over state-of-the-art forward reasoning methods on two challenging logical reasoning datasets.","ArXiv",2022,"Seyed Mehran Kazemi,Najoung Kim,Deepti Bhatia,Xinyuan Xu,Deepak Ramachandran",2,34,0
"df24c0f317fc73b893c852a3fce9536ba8607dfa","https://www.semanticscholar.org/paper/df24c0f317fc73b893c852a3fce9536ba8607dfa",10,"BioReader: a Retrieval-Enhanced Text-to-Text Transformer for Biomedical Literature","This work introduces BioReader, the first retrieval-enhanced text-to-text model for biomedical natural language processing and shows that domain knowledge can be easily altered or supplemented to make the model generate correct predictions bypassing the retraining step and thus addressing the literature overload issue.","Conference on Empirical Methods in Natural Language Processing",2022,"Giacomo Frisoni,M. Mizutani,G. Moro,Lorenzo Valgimigli",0,102,0
"12f4eff1b991d4953b563544242d106e4c751c65","https://www.semanticscholar.org/paper/12f4eff1b991d4953b563544242d106e4c751c65",10,"In-Context Retrieval-Augmented Language Models","It is shown that in-context RALM which uses off-the-shelf general purpose retrievers provides surprisingly large LM gains across model sizes and diverse corpora and has considerable potential to increase the prevalence of LM grounding.","ArXiv",2023,"Ori Ram,Yoav Levine,Itay Dalmedigos,Dor Muhlgay,A. Shashua,K. Leyton-Brown,Y. Shoham",0,40,0
"31d05bdc1ad24c4c3f5416ea542ad2e76ad580d9","https://www.semanticscholar.org/paper/31d05bdc1ad24c4c3f5416ea542ad2e76ad580d9",10,"Pretraining Language Models with Human Preferences","The results suggest that the authors should move beyond imitation learning when pretraining LMs and incorporate human preferences from the start of training, i.e., learning and then unlearning undesirable behavior.","",2023,"Tomasz Korbak,Kejian Shi,Angelica Chen,Rasika Bhalerao,C. L. Buckley,Jason Phang,Sam Bowman,Ethan Perez",0,81,0
"c88cafa3e980765a64febe369ceb7c2aa7261d2a","https://www.semanticscholar.org/paper/c88cafa3e980765a64febe369ceb7c2aa7261d2a",10,"Complexity-Based Prompting for Multi-Step Reasoning","This work proposes complexity-based prompting, a simple and effective example selection scheme for multi-step reasoning that achieves substantially better performance on math word reasoning tasks over strong baselines and demonstrates the robustness of the methods under format perturbation and distribution shift.","ArXiv",2022,"Yao Fu,Hao-Chun Peng,Ashish Sabharwal,Peter Clark,Tushar Khot",15,40,5
"7d5175db1b99552491063d2d9581b0b51e1d2932","https://www.semanticscholar.org/paper/7d5175db1b99552491063d2d9581b0b51e1d2932",10,"Despite ""super-human"" performance, current LLMs are unsuited for decisions about ethics and safety","This work provides a simple new prompting strategy that leads to yet another supposedly “super-human” result, this time out-performing humans at common sense ethical reasoning (as measured by accuracy on a subset of the ETHICS dataset).","ArXiv",2022,"Joshua Albrecht,Ellie Kitanidis,Abraham J. Fetterman",1,42,0
"f02e8f1c9b5ab12ddfb1977570f9f5445a99a973","https://www.semanticscholar.org/paper/f02e8f1c9b5ab12ddfb1977570f9f5445a99a973",10,"Large Language Models are reasoners with Self-Verification","This work proposes a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked, and calculates an explainable verification score based on the accuracy.","ArXiv",2022,"Yixuan Weng,Minjun Zhu,Shizhu He,Kang Liu,Jun Zhao",1,41,0
"655d34b590e8911e072013ad21582c0382447600","https://www.semanticscholar.org/paper/655d34b590e8911e072013ad21582c0382447600",10,"Unsupervised Explanation Generation via Correct Instantiations","N EON is proposed, a two-phrase, unsupervised explanation generation framework that generates corrected instantia- tions of the statement, then uses them to prompt large PLMs to complete the explanation and demonstrate that N EON remains effective when generalizing to different scenarios.","ArXiv",2022,"Sijie Cheng,Zhiyong Wu,Jiangjie Chen,Zhixing Li,Yang Liu,Lingpeng Kong",0,49,0
"6c67d6046c01d61e89bc11ccd260e20603fe2398","https://www.semanticscholar.org/paper/6c67d6046c01d61e89bc11ccd260e20603fe2398",10,"Semi-Parametric Video-Grounded Text Generation","A semi-parametric video-grounded text generation model, SeViT, is proposed, offering a novel perspective on scalable video-language modeling toward long untrimmed videos and has a signiﬁcant advantage in longer videos and causal video understanding.","ArXiv",2023,"Sungdong Kim,Jin-Hwa Kim,Jiyoung Lee,Minjoon Seo",0,68,0
"40c318400809abf5e50aba5a5a80c8012a7715d5","https://www.semanticscholar.org/paper/40c318400809abf5e50aba5a5a80c8012a7715d5",10,"GPTScore: Evaluate as You Desire","A novel evaluation framework, GPTScore, which utilizes the emergent abilities (e.g., zero-shot instruction) of generative pre-trained models to score generated texts to overcome several long-standing challenges in text evaluation.","ArXiv",2023,"Jinlan Fu,See-Kiong Ng,Zhengbao Jiang,Pengfei Liu",0,49,0
"074f9767bf81f04448ce6d997b7e29dc92b10fe7","https://www.semanticscholar.org/paper/074f9767bf81f04448ce6d997b7e29dc92b10fe7",10,"General Intelligence Requires Rethinking Exploration","This work proposes the problem of generalized exploration to conceptually unify exploration-driven learning between supervised learning and reinforcement learning, allowing it to highlight key similarities across learning settings and open research challenges.","ArXiv",2022,"Minqi Jiang,Tim Rocktaschel,Edward Grefenstette",0,190,0
"7547589d925ce4782159b73d017b27d55b5f41c8","https://www.semanticscholar.org/paper/7547589d925ce4782159b73d017b27d55b5f41c8",10,"Is GPT-3 a Good Data Annotator?","This analysis aims to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP by comparing it with traditional data annotation methods and analyzing its output on a range of tasks.","ArXiv",2022,"Bosheng Ding,Chengwei Qin,Linlin Liu,Lidong Bing,Shafiq R. Joty,Boyang Li",2,52,0
"cad43496b7196db48a806723ee4e2c502128f316","https://www.semanticscholar.org/paper/cad43496b7196db48a806723ee4e2c502128f316",10,"Inclusive Artificial Intelligence","","ArXiv",2022,"Dilip Arumugam,Shi Dong,B. V. Roy",0,35,0
"3994eb8e237a94dae1efc6e767a09044b8550ace","https://www.semanticscholar.org/paper/3994eb8e237a94dae1efc6e767a09044b8550ace",10,"FCM: Forgetful Causal Masking Makes Causal Language Models Better Zero-Shot Learners","Experimental results show that the proposed technique improves PaLM’s zero and few-shot performance on a diverse suite of tasks, including commonsense reasoning, natural language inference and cloze completion, and also helps representation learning.","ArXiv",2022,"Hao Liu,Xinyang Geng,Lisa Lee,Igor Mordatch,S. Levine,Sharan Narang,P. Abbeel",1,53,0
"4e5f7cd537a1bbcd090f9887b1b59f39a3715dba","https://www.semanticscholar.org/paper/4e5f7cd537a1bbcd090f9887b1b59f39a3715dba",10,"Instruction Induction: From Few Examples to Natural Language Task Descriptions","It is discovered that, to a large extent, the ability to generate instructions does indeed emerge when using a model that is both large enough and aligned to follow instructions; this surprising result suggests that instruction induction might be a viable learning paradigm in and of itself.","ArXiv",2022,"Or Honovich,Uri Shaham,Samuel R. Bowman,Omer Levy",7,44,3
"5c70d4f334b7da45b156d223afcb256dbabd9b2f","https://www.semanticscholar.org/paper/5c70d4f334b7da45b156d223afcb256dbabd9b2f",10,"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning","It is found that using zero-shot CoT reasoning in a prompt can signiﬁcantly increase a model’s likelihood to produce undesirable output and should be avoided on tasks where models can make inferences about marginalized groups or harmful topics.","ArXiv",2022,"Omar Shaikh,Hongxin Zhang,William B. Held,Michael Bernstein,Diyi Yang",1,48,0
"5c32c653735b43a0a8923ca65ac191bd4bf15311","https://www.semanticscholar.org/paper/5c32c653735b43a0a8923ca65ac191bd4bf15311",10,"Precise Zero-Shot Dense Retrieval without Relevance Labels","The experiments show that HyDE outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to ﬁne-tuned retrievers, across various tasks and languages.","ArXiv",2022,"Luyu Gao,Xueguang Ma,Jimmy Lin,Jamie Callan",1,38,1
"060cee8411181e8151ab1e3212b81528accd9b8b","https://www.semanticscholar.org/paper/060cee8411181e8151ab1e3212b81528accd9b8b",10,"On Transforming Reinforcement Learning by Transformer: The Development Trajectory","This survey collects and dissect recent advances concerning the transformation of RL with transformers (transformer-based RL (TRL), and examines the main applications of TRL in robotic manipulation, text-based games (TBGs), navigation and autonomous driving.","ArXiv",2022,"Shengchao Hu,Li Shen,Ya Zhang,Yixin Chen,Dacheng Tao",2,269,0
"6ad26eb2d2aa6679d16d9c16fb75cd2cbe1127bc","https://www.semanticscholar.org/paper/6ad26eb2d2aa6679d16d9c16fb75cd2cbe1127bc",10,"See, Think, Confirm: Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning","A novel framework named Interactive Prompting Visual Reasoner (IPVR) for few-shot knowledge-based visual reasoning, which achieves better performance than the previous few- shot learning baselines and enjoys the total transparency and trustworthiness of the whole reasoning process by providing rationales for each reasoning step.","ArXiv",2023,"Zhenfang Chen,Qinhong Zhou,Yikang Shen,Yining Hong,Hao Zhang,Chuang Gan",0,76,0
"795736777f08e92a80c95dab7f205d1d7c28a10b","https://www.semanticscholar.org/paper/795736777f08e92a80c95dab7f205d1d7c28a10b",10,"The CRINGE Loss: Learning what language not to model","This work proposes a novel procedure to train with negative data called the C RINGE loss (ContRastive Iterative Negative GEneration), and shows the effectiveness of this approach across three different experiments on the tasks of safe generation, contradiction avoidance, and open-domain dialogue.","ArXiv",2022,"Leonard Adolphs,Tianyu Gao,Jing Xu,Kurt Shuster,Sainbayar Sukhbaatar,J. Weston",1,44,0
"a8afd12bcd51488ba69bd838ef6dbf2728d5121a","https://www.semanticscholar.org/paper/a8afd12bcd51488ba69bd838ef6dbf2728d5121a",10,"Prompting Is Programming: A Query Language For Large Language Models","LMQL is implemented, which leverages the constraints and control flow from an LMP prompt to generate an efficient inference procedure that minimizes the number of expensive calls to the underlying language model.","ArXiv",2022,"Luca Beurer-Kellner,Marc Fischer,Martin T. Vechev",4,34,0
"e659fa1e79a2a151be331125c14339988542aac3","https://www.semanticscholar.org/paper/e659fa1e79a2a151be331125c14339988542aac3",10,"Batch Prompting: Efficient Inference with Large Language Model APIs","Batch prompting, a simple alternative prompting approach that enables the LLM to run inference in batches, instead of one sample at a time, is proposed, which reduces both token and time costs while retaining downstream performance.","ArXiv",2023,"Zhoujun Cheng,Jungo Kasai,Tao Yu",0,66,0
"a732b89acf14bf7a2a7282b4f7fbb863d79a4347","https://www.semanticscholar.org/paper/a732b89acf14bf7a2a7282b4f7fbb863d79a4347",9,"Learning, Fast and Slow: A Goal-Directed Memory-Based Approach for Dynamic Environments","It is posited that the future of Reinforcement Learning (RL) will be to model goals and sub-goals for various tasks, and plan it out in a goal-directed memory-based approach.","ArXiv",2023,"Tan Chong Min John,M. Motani",0,38,0
"0e6e8274d0dcbc1c3c1ccdbd87f3e5d53fdf62b4","https://www.semanticscholar.org/paper/0e6e8274d0dcbc1c3c1ccdbd87f3e5d53fdf62b4",9,"QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension","This study is the largest survey of the deep learning models in NLP field to date, providing an overview of the various formats and domains of the current resources, and highlighting the current lacunae for future work.","ACM Computing Surveys",2021,"Anna Rogers,Matt Gardner,Isabelle Augenstein",54,343,4
"798abf86efae9e37b9b6a694ef87b6c1dbaab263","https://www.semanticscholar.org/paper/798abf86efae9e37b9b6a694ef87b6c1dbaab263",9,"Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models","This work presents compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine- Tuning smaller LMs on a curriculum of such component tasks.","Conference on Empirical Methods in Natural Language Processing",2022,"Victor S. Bursztyn,David Demeter,Doug Downey,Larry Birnbaum",0,33,0
"02ab15d5a21715724889cf2a34242a330972fbb5","https://www.semanticscholar.org/paper/02ab15d5a21715724889cf2a34242a330972fbb5",9,"Decoding a Neural Retriever’s Latent Space for Query Suggestion","It is shown that it is possible to decode a meaningful query from its latent representation and, when moving in the right direction in latent space, to decode an query that retrieves the relevant paragraph from the collection.","Conference on Empirical Methods in Natural Language Processing",2022,"Leonard Adolphs,Michelle Chen Huebscher,C. Buck,Sertan Girgin,Olivier Bachem,Massimiliano Ciaramita,Thomas Hofmann",2,53,0
"108c25905be36b2a7a0fc7256ac314985ecd9699","https://www.semanticscholar.org/paper/108c25905be36b2a7a0fc7256ac314985ecd9699",9,"Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models","This work demonstrates that large language models can succeed in extrapolation without modifying their architecture or training procedure, and shows how generating step-by-step rationales and introducing marker tokens are both required for effective extrapolation.","MATHNLP",2022,"M. Bueno,Carlos Gemmel,Jeffrey Stephen Dalton,R. Lotufo,Rodrigo Nogueira",1,65,0
"6d5555348f453bac901c5b57e8a4eeb3074b4071","https://www.semanticscholar.org/paper/6d5555348f453bac901c5b57e8a4eeb3074b4071",9,"Learning to Reason With Relational Abstractions","This work introduces new types of sequences that more explicitly provide an abstract characterization of the transitions through intermediate solution steps to the goal state and shows that models that are supplied with such sequences as prompts can solve tasks with a signiﬁcantly higher accuracy, and models that is trained to produce such sequences solve problems better than those that are trained with previously used human-generated sequences and other baselines.","ArXiv",2022,"A. Nam,Mengye Ren,Chelsea Finn,James L. McClelland",0,39,0
"44d6c201a4056e260e9844bdbb01461ea9b1a011","https://www.semanticscholar.org/paper/44d6c201a4056e260e9844bdbb01461ea9b1a011",9,"A data-driven approach for learning to control computers","This workigate the setting of computer control using keyboard and mouse, with goals specified via natural language, and suggests a formula for achieving competency beyond MiniWob ++ and towards controlling computers, in general, as a human would.","International Conference on Machine Learning",2022,"P. Humphreys,David Raposo,Tobias Pohlen,Gregory Thornton,Rachita Chhaparia,Alistair Muldal,Josh Abramson,Petko Georgiev,Alex Goldin,Adam Santoro,T. Lillicrap",11,31,1
"9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1","https://www.semanticscholar.org/paper/9aed848be4e9e401b0e61a2e5d60dbdafa0c6cc1",9,"A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams","A student survey comparing the quality, appropriateness, andulty of machine- generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated Questions and are suitable for ﬁnal exams.","ArXiv",2022,"Sarah Zhang,Reece Shuttleworth,Derek Austin,Yann Hicke,Leonard Tang,Sathwik Karnik,Darnell Granberry,Iddo Drori",2,15,1
"717d52007edbb7ddb3f70621636eed36521ba7e0","https://www.semanticscholar.org/paper/717d52007edbb7ddb3f70621636eed36521ba7e0",9,"Reward Gaming in Conditional Text Generation","This discussion piece would like to highlight reward gaming in the natural language generation (NLG) community using concrete conditional text generation examples and discuss potential fixes and areas for future work.","ArXiv",2022,"Richard Yuanzhe Pang,Vishakh Padmakumar,Thibault Sellam,Ankur P. Parikh,He He",0,79,0
"f5d93cf5d81575aeee61faeddde4437fbcb74cd0","https://www.semanticscholar.org/paper/f5d93cf5d81575aeee61faeddde4437fbcb74cd0",9,"The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development","This work developed a prototype system -- the Programmer's Assistant -- in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM.","",2023,"Steven I. Ross,Fernando Martinez,Stephanie Houde,Michael J. Muller,Justin D. Weisz",2,111,0
"e63c0f7d2ff2939ccec5c2461a22b97fff3b0a86","https://www.semanticscholar.org/paper/e63c0f7d2ff2939ccec5c2461a22b97fff3b0a86",9,"The Capacity for Moral Self-Correction in Large Language Models","","",2023,"Deep Ganguli,Amanda Askell,Nicholas Schiefer,Thomas Liao,Kamil.e Lukovsiut.e,Anna Chen,Anna Goldie,Azalia Mirhoseini,Catherine Olsson,Danny Hernandez,Dawn Drain,Dustin Li,Eli Tran-Johnson,Ethan Perez,John Kernion,Jamie Kerr,J. Mueller,J. Landau,Kamal Ndousse,Karina Nguyen,Liane Lovitt,Michael Sellitto,Nelson Elhage,Noem'i Mercado,Nova DasSarma,R. Lasenby,Robin Larson,Sam Ringer,Sandipan Kundu,Saurav Kadavath,Scott Johnston,S. Kravec,Sheer El Showk,Tamera Lanham,Timothy Telleen-Lawton,T. Henighan,Tristan Hume,Yuntao Bai,Zac Hatfield-Dodds,Benjamin Mann,Dario Amodei,Nicholas Joseph,Sam McCandlish,Tom B. Brown,C. Olah,Jack Clark,Sam Bowman,Jared Kaplan",0,61,0
"62f0db3a5ad5c795ec18fc7a6e7b01836809df57","https://www.semanticscholar.org/paper/62f0db3a5ad5c795ec18fc7a6e7b01836809df57",9,"Language Models are Multilingual Chain-of-Thought Reasoners","It is shown that the multilingual reasoning abilities of language models extend to other tasks such as commonsense reasoning and word-in-context semantic judgment, and that models have strikingly strong mult bilingual reasoning abilities, even in underrepresented languages such as Bengali and Swahili.","ArXiv",2022,"Freda Shi,Mirac Suzgun,Markus Freitag,Xuezhi Wang,Suraj Srivats,Soroush Vosoughi,Hyung Won Chung,Yi Tay,Sebastian Ruder,Denny Zhou,Dipanjan Das,Jason Wei",18,50,1
"712f21411526e8450036d7199637808590be3579","https://www.semanticscholar.org/paper/712f21411526e8450036d7199637808590be3579",9,"Reflection of Thought: Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems","","ArXiv",2022,"Fan Zhou,Haoyu Dong,Qian Liu,Zhoujun Cheng,Shi Han,Dongmei Zhang",1,36,1
"965e409a3e7b5670d609837fac9823b160d6639c","https://www.semanticscholar.org/paper/965e409a3e7b5670d609837fac9823b160d6639c",9,"Logical Tasks for Measuring Extrapolation and Rule Comprehension","This work describes and characterize logical tasks and discusses system requirements for their solution, and discusses the relevance of logical tasks to concepts such as extrapolation, explainability, and inductive bias.","ArXiv",2022,"Ippei Fujisawa,R. Kanai",0,61,0
"a4a41319d5805a29316f24ed9519f09db77d4c29","https://www.semanticscholar.org/paper/a4a41319d5805a29316f24ed9519f09db77d4c29",9,"Benchmarking Large Language Models for News Summarization","It is found that LMM summaries are judged to be on par with human written summaries, and instruction tuning, and not model size, is the key to the LLM’s zero-shot summarization capability.","ArXiv",2023,"Tianyi Zhang,Faisal Ladhak,Esin Durmus,Percy Liang,K. McKeown,Tatsunori Hashimoto",2,42,1
"5697a0ede5425954d48daa6e1893dc87bd7d8be7","https://www.semanticscholar.org/paper/5697a0ede5425954d48daa6e1893dc87bd7d8be7",9,"Contrastive Search Is What You Need For Neural Text Generation","Surprisingly, the anisotropic problem only exists in the two specific English GPT-2-small/medium models, and all other evaluated LMs are naturally isotropic which is in contrast to the conclusion drawn by previous studies.","ArXiv",2022,"Yixuan Su,N. Collier",5,44,0
"e6745fb621481ccb0ed53c267a37292e499c1b42","https://www.semanticscholar.org/paper/e6745fb621481ccb0ed53c267a37292e499c1b42",9,"Automatic Generation of Socratic Subquestions for Teaching Math Word Problems","This work explores the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving and proposes various guided question generation schemes based on input conditioning and reinforcement learning.","Conference on Empirical Methods in Natural Language Processing",2022,"K. Shridhar,Jakub Macina,Mennatallah El-Assady,Tanmay Sinha,Manu Kapur,Mrinmaya Sachan",2,64,0
"68edfd62d2619fb4af7c2469edb95b9e2fe4544a","https://www.semanticscholar.org/paper/68edfd62d2619fb4af7c2469edb95b9e2fe4544a",9,"Execution-based Code Generation using Deep Reinforcement Learning","PPOCoder is a new framework for code generation that combines pretrained PL models with Proximal Policy Optimization (PPO) deep reinforcement learning and employs execution feedback as the external source of knowledge into the model optimization, which is transferable across different code generation tasks and PLs.","ArXiv",2023,"Parshin Shojaee,Aneesh Jain,S. Tipirneni,C. Reddy",0,45,0
"6e6983417939dbcb04a50a46a489ce6bbfe8aa9d","https://www.semanticscholar.org/paper/6e6983417939dbcb04a50a46a489ce6bbfe8aa9d",9,"Using In-Context Learning to Improve Dialogue Safety","This work investigates a retrieval-based framework for reducing bias and toxicity in responses generated from neural-based chatbots, which uses in-context learning to steer a model towards safer generations.","ArXiv",2023,"Nicholas Meade,Spandana Gella,Devamanyu Hazarika,Prakhar Gupta,Di Jin,Siva Reddy,Yang Liu,Dilek Z. Hakkani-Tür",0,51,0
"782f3d43b37790a83c98d5fd3ef142b296f20616","https://www.semanticscholar.org/paper/782f3d43b37790a83c98d5fd3ef142b296f20616",9,"CrossCodeBench: Benchmarking Cross-Task Generalization of Source Code Models","A large-scale benchmark that includes 216 existing code-related tasks is proposed and it is demonstrated that the cross-task generalization of models can be largely improved by in-context learning methods such as few-shot learning and learning from task instructions, which shows the promising prospects of conducting cross- task learning research on this benchmark.","ArXiv",2023,"Changan Niu,Chuanyi Li,Vincent Ng,Bin Luo",0,76,0
"eb9b60db6832b00b9932584663bec104d6d415dd","https://www.semanticscholar.org/paper/eb9b60db6832b00b9932584663bec104d6d415dd",9,"Tree-Based Representation and Generation of Natural and Mathematical Language","A series of modifications to existing language models are proposed to jointly represent and generate text and math: representing mathematical expressions as sequences of node tokens in their operator tree format, using math symbol and tree position embeddings to preserve the semantic and structural properties of mathematical expressions, and using a constrained decoding method to generate mathematically valid expressions.","",2023,"Alexander Scarlatos,Andrew S. Lan",0,36,0
"ae10c4b220a0bc0999bf169d5c219086d1f1aeed","https://www.semanticscholar.org/paper/ae10c4b220a0bc0999bf169d5c219086d1f1aeed",9,"Edinburgh Research Explorer Taxonomy of risks posed by language models","A comprehensive taxonomy of ethical and social risks associated with LMs is developed, drawing on expertise and literature from computer science, linguistics, and the social sciences to ensure that language models are developed responsibly.","",2022,"Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,P. Huang,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,W. Hawkins,T. Stepleton,A. Birhane,L. Hendricks,Rimell,Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,Tom,Stepleton,A. Birhane,Lisa Anne Hendricks,Laura Rimell",0,218,0
"f2c17758e74707d379b87372528221656d14b697","https://www.semanticscholar.org/paper/f2c17758e74707d379b87372528221656d14b697",9,"Taxonomy of Risks posed by Language Models","A comprehensive taxonomy of ethical and social risks associated with LMs is developed, drawing on expertise and literature from computer science, linguistics, and the social sciences to ensure that language models are developed responsibly.","Conference on Fairness, Accountability and Transparency",2022,"Laura Weidinger,J. Uesato,M. Rauh,C. Griffin,Po-Sen Huang,John F. J. Mellor,A. Glaese,M. Cheng,B. Balle,A. Kasirzadeh,C. Biles,S. Brown,Z. Kenton,W. Hawkins,T. Stepleton,A. Birhane,Lisa Anne Hendricks,Laura Rimell,William S. Isaac,Julia Haas,Sean Legassick,Geoffrey Irving,Iason Gabriel",23,209,5
"e23c5bf7362988624ec67bd4fe405b71e8b5c0ad","https://www.semanticscholar.org/paper/e23c5bf7362988624ec67bd4fe405b71e8b5c0ad",9,"Variational Open-Domain Question Answering","The Rényi variational bound, a lower bound to the task marginal likelihood, can be exploited to aid optimization and use importance sampling to estimate the task log-likelihood lower bound and its gradients using samples drawn from an auxiliary retriever.","ArXiv",2022,"Valentin Li'evin,Andreas Geert Motzfeldt,Ida Riis Jensen,O. Winther",0,53,0
"f5b3cb14e0947c62b470d2072483481f14258738","https://www.semanticscholar.org/paper/f5b3cb14e0947c62b470d2072483481f14258738",9,"A Solvable Model of Neural Scaling Laws","Key findings are the manner in which the power laws that occur in the statistics of natural datasets are extended by nonlinear random feature maps and then translated into power-law scalings of the test loss and how the finite extent of the data’s spectral power law causes the model’'s performance to plateau.","ArXiv",2022,"A. Maloney,Daniel A. Roberts,J. Sully",4,74,1
"dee23912cf0586b690b1c0eb386bc92d38ce8c16","https://www.semanticscholar.org/paper/dee23912cf0586b690b1c0eb386bc92d38ce8c16",9,"Fine-Tuning Language Models via Epistemic Neural Networks","It is shown that, using an epinet to prioritize uncertain data, BERT on GLUE tasks to the same performance while using 2x less data and performance in synthetic neural network generative models designed to build understanding is investigated.","ArXiv",2022,"Ian Osband,S. Asghari,B. V. Roy,Nathan McAleese,J. Aslanides,Geoffrey Irving",0,51,0
"99ca5162211a895a5dfbff9d7e36e21e09ca646e","https://www.semanticscholar.org/paper/99ca5162211a895a5dfbff9d7e36e21e09ca646e",9,"Measuring Progress on Scalable Oversight for Large Language Models","It is found that human participants who interact with an unreliable large-language-model dialog assistant through chat—a trivial baseline strategy for scalable oversight—substantially outperform both the model alone and their own unaided performance, an encouraging sign that scalable oversight will be tractable to study with present models.","ArXiv",2022,"Sam Bowman,Jeeyoon Hyun,Ethan Perez,Edwin Chen,Craig Pettit,Scott Heiner,Kamilė Lukošiūtė,Amanda Askell,Andy Jones,Anna Chen,Anna Goldie,Azalia Mirhoseini,C. McKinnon,C. Olah,Daniela Amodei,Dario Amodei,Dawn Drain,Dustin Li,Eli Tran-Johnson,John Kernion,Jamie Kerr,J. Mueller,Jeff Ladish,J. Landau,Kamal Ndousse,Liane Lovitt,Nelson Elhage,Nicholas Schiefer,Nicholas Joseph,Noem'i Mercado,Nova DasSarma,Robin Larson,Sam McCandlish,S. Kundu,Scott Johnston,S. Kravec,Sheer El Showk,Stanislav Fort,Timothy Telleen-Lawton,Tom B. Brown,T. Henighan,Tristan Hume,Yuntao Bai,Zac Hatfield-Dodds,Benjamin Mann,Jared Kaplan",5,29,1
"557a5147d88ad361b807d4c93decac6d57d2d5e9","https://www.semanticscholar.org/paper/557a5147d88ad361b807d4c93decac6d57d2d5e9",9,"Law Informs Code: A Legal Informatics Approach to Aligning Artificial Intelligence with Humans","Law Informs Code describes how the data generated by legal processes and the theoretical constructs and practices of law can facilitate the robust specification of inherently vague human goals for AI.","SSRN Electronic Journal",2022,"John J. Nay",1,318,0
"3ad346ae7af5c30964c4916dbcee798f72e1bdb7","https://www.semanticscholar.org/paper/3ad346ae7af5c30964c4916dbcee798f72e1bdb7",9,"Translating Natural Language to Planning Goals with Large-Language Models","The empirical results on GPT 3.5 variants show that LLMs are much better suited towards translation rather than planning, and these models are promising for translation to structured planning languages, but care should be taken in their use.","ArXiv",2023,"Yaqi Xie,Chenyao Yu,Tongyao Zhu,Jinbin Bai,Ze Gong,Harold Soh",0,34,0
"7ce0c89a452e3c2917b63847495533865697c79c","https://www.semanticscholar.org/paper/7ce0c89a452e3c2917b63847495533865697c79c",9,"Can Large Language Models Truly Understand Prompts? A Case Study with Negated Prompts","This work shows that there exists a scaling law between the size of Language Models and their zero-shot performance on different downstream NLP tasks but this phenomenon does not hold when evaluating large LMs on tasks with negated prompts, but instead shows an inverse scaling law.","ArXiv",2022,"Joel Jang,Seonghyeon Ye,Minjoon Seo",6,26,0
"1450c89fd9bd4b9978a1c85f9ac70ae379c9d36d","https://www.semanticscholar.org/paper/1450c89fd9bd4b9978a1c85f9ac70ae379c9d36d",9,"Query Refinement Prompts for Closed-Book Long-Form Question Answering","Query refinement prompts are defined that encourage LLMs to explicitly express the multifacetedness in questions and generate long-form answers covering multiple facets of the question to outperform fully finetuned models in the closed book setting, as well as achieve results comparable to retrieve-then-generate open-book models.","ArXiv",2022,"Reinald Kim Amplayo,Kellie Webster,Michael Collins,Dipanjan Das,Shashi Narayan",1,42,0
"c90a33f1f0049d524e9b5b3174d35611fd9a8096","https://www.semanticscholar.org/paper/c90a33f1f0049d524e9b5b3174d35611fd9a8096",9,"Pretraining in Deep Reinforcement Learning: A Survey","This survey seeks to systematically review existing works in pretraining for deep reinforcement learning, provide a taxonomy of these methods, discuss each sub-ﬁeld, and bring attention to open problems and future directions.","ArXiv",2022,"Zhihui Xie,Zichuan Lin,Junyou Li,Shuai Li,Deheng Ye",1,213,0
"a4bdc300db297756f36bedee2859b62df8e268c2","https://www.semanticscholar.org/paper/a4bdc300db297756f36bedee2859b62df8e268c2",9,"Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding","This work presents crowd sampling, a family of decoding methods based on Bayesian risk minimization, to ad-dress this diversity-quality trade-off in open-ended natural-language generation.","ArXiv",2022,"Mirac Suzgun,Luke Melas-Kyriazi,Dan Jurafsky",3,83,0
"8cf05ed2b7cd3b0f601c454914a678c24d393de3","https://www.semanticscholar.org/paper/8cf05ed2b7cd3b0f601c454914a678c24d393de3",9,"Task-aware Retrieval with Instructions","TART shows strong capabilities to adapt to a new retrieval task via instructions and advances the state of the art on two zero-shot retrieval benchmarks, BEIR and LOTTE, outperforming models up to three times larger.","ArXiv",2022,"Akari Asai,Timo Schick,Patrick Lewis,Xilun Chen,Gautier Izacard,Sebastian Riedel,Hannaneh Hajishirzi,Wen-tau Yih",4,88,0
"fd8c1b8741163d8737652fbcd3507bcd7d6225c7","https://www.semanticscholar.org/paper/fd8c1b8741163d8737652fbcd3507bcd7d6225c7",9,"Multitask Vision-Language Prompt Tuning","This paper demonstrates the effectiveness of learning a single transferable prompt from multiple source tasks to initialize the prompt for each target task and shows many target tasks can beneﬁt each other from sharing prompt vectors and thus can be jointly learned via multitask prompt tuning.","ArXiv",2022,"Sheng Shen,Shijia Yang,Tianjun Zhang,Bohan Zhai,Joseph Gonzalez,K. Keutzer,Trevor Darrell",0,104,0
"943afe24f79b42a763fd422ed2e2297a52b7389e","https://www.semanticscholar.org/paper/943afe24f79b42a763fd422ed2e2297a52b7389e",9,"Editing Models with Task Arithmetic","This work proposes a new paradigm for steering the behavior of neural networks, centered around task vectors, and shows that task arithmetic is a simple, efﬁcient and effective way of editing models.","ArXiv",2022,"Gabriel Ilharco,Marco Tulio Ribeiro,Mitchell Wortsman,Suchin Gururangan,Ludwig Schmidt,Hannaneh Hajishirzi,Ali Farhadi",6,102,1
"b674db9649f1c21c670ea98a0e91e095c2d0a4cf","https://www.semanticscholar.org/paper/b674db9649f1c21c670ea98a0e91e095c2d0a4cf",9,"Teaching Small Language Models to Reason","The proposed method improves task performance across arithmetic, commonsense and symbolic reasoning datasets and transfer of such reasoning capabilities to models with less than 100 billion parameters via knowledge distillation is explored.","ArXiv",2022,"Lucie Charlotte Magister,Jonathan Mallinson,Jakub Adamek,Eric Malmi,Aliaksei Severyn",7,19,0
"6f4cc536f9ed83d0dbf7e919dc609be12aa0848a","https://www.semanticscholar.org/paper/6f4cc536f9ed83d0dbf7e919dc609be12aa0848a",9,"Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor","Experiments show that despite containing a fair amount of noise, training on Unnatural Instructions rivals the effectiveness of training on open-source manually-curated datasets, sur-passing the performance of models such as T0++ and Tk-Instruct across various benchmarks.","ArXiv",2022,"Or Honovich,Thomas Scialom,Omer Levy,Timo Schick",3,40,0
"bc36e46688725d574fb3e4e74808435c85bd61cd","https://www.semanticscholar.org/paper/bc36e46688725d574fb3e4e74808435c85bd61cd",9,"JASMINE: Arabic GPT Models for Few-Shot Learning","JASMINE is introduced, a suite of powerful Arabic autoregressive Transformer language models ranging in size between 300 million- 13 billion parameters, and a novel benchmark for both automated and human evaluation of these models focused at investigating potential social biases, harms, and toxicity in these models.","ArXiv",2022,"E. Nagoudi,M. Abdul-Mageed,AbdelRahim Elmadany,Alcides Alcoba Inciarte,Md. Tawkat Islam Khondaker",0,43,0
"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","https://www.semanticscholar.org/paper/26218bdcc3945c7edae7aa2adbfba4cd820a2df3",9,"Flamingo: a Visual Language Model for Few-Shot Learning","It is demonstrated that a single Flamingo model can achieve a new state of the art for few-shot learning, simply by prompting the model with task-speciﬁc examples.","ArXiv",2022,"Jean-Baptiste Alayrac,Jeff Donahue,Pauline Luc,Antoine Miech,Iain Barr,Yana Hasson,Karel Lenc,A. Mensch,Katie Millican,Malcolm Reynolds,Roman Ring,Eliza Rutherford,Serkan Cabi,Tengda Han,Zhitao Gong,S. Samangooei,Marianne Monteiro,Jacob Menick,Sebastian Borgeaud,Andy Brock,Aida Nematzadeh,Sahand Sharifzadeh,Mikolaj Binkowski,Ricardo Barreira,Oriol Vinyals,A. Zisserman,K. Simonyan",243,173,29
"7ed237af793f43c442b3e8e1bc9ace906a276b2a","https://www.semanticscholar.org/paper/7ed237af793f43c442b3e8e1bc9ace906a276b2a",9,"Transfer Knowledge from Natural Language to Electrocardiography: Can We Detect Cardiovascular Disease Through Language Models?","This work proposes an approach for cardiovascular disease diagnosis and automatic ECG diagnosis report generation and introduces an additional loss function by Optimal Transport to align the distribution between ECG and language embedding and proves the feasibility of transferring knowledge from LLMs to the cardiac domain.","ArXiv",2023,"Jielin Qiu,W. Han,Jiacheng Zhu,Mengdi Xu,Michael Rosenberg,Emerson Liu,Douglas Weber,Ding Zhao",1,95,0
"9595f62731d88406b9f1a1aca8f372ba57b70a6c","https://www.semanticscholar.org/paper/9595f62731d88406b9f1a1aca8f372ba57b70a6c",8,"Representation Learning for Continuous Action Spaces is Beneficial for Efficient Policy Learning","An efficient policy learning method in latent state and action spaces is proposed that extends the idea of state representations to action representations for better policy generalization capability and is demonstrated by MountainCar, CarRacing and Cheetah experiments.","Neural Networks",2022,"Tingting Zhao,Ying Wang,Weidong Sun,Yarui Chen,Gang Niu,M. Sugiyama",0,51,0
"71b676fdf3ee3eec9c11089a957e55749a8334d5","https://www.semanticscholar.org/paper/71b676fdf3ee3eec9c11089a957e55749a8334d5",8,"A Survey of Machine Learning for Computer Architecture and Systems","This article presents a comprehensive review of the work that applies ML for computer architecture and system design, and summarizes the common problems in computer architecture/system design that can be solved by ML techniques and the typical ML techniques employed to resolve each of them.","ACM Computing Surveys",2021,"Nan Wu,Yuan Xie",12,343,0
"eac5e5ef2bb1d158645ee8ae8f3e167767316b46","https://www.semanticscholar.org/paper/eac5e5ef2bb1d158645ee8ae8f3e167767316b46",8,"Understanding and Improving Zero-shot Multi-hop Reasoning in Generative Question Answering","It is demonstrated that multi-hop reasoning does not emerge naturally in generative QA models, but can be encouraged by advances in training or modeling techniques.","International Conference on Computational Linguistics",2022,"Zhengbao Jiang,J. Araki,Haibo Ding,Graham Neubig",1,40,0
"2c953a3c378b40dadf2e3fb486713c8608b8e282","https://www.semanticscholar.org/paper/2c953a3c378b40dadf2e3fb486713c8608b8e282",8,"Pretrained Transformers for Text Ranking: BERT and Beyond","This tutorial provides an overview of text ranking with neural network architectures known as transformers, of which BERT (Bidirectional Encoder Representations from Transformers) is the best-known example, and covers a wide range of techniques.","North American Chapter of the Association for Computational Linguistics",2020,"Jimmy J. Lin,Rodrigo Nogueira,Andrew Yates",282,483,28
"7087dd676c98c3358571b1daa5778b0095a30d9a","https://www.semanticscholar.org/paper/7087dd676c98c3358571b1daa5778b0095a30d9a",8,"A Survey on Causal Reinforcement Learning","This work divides existing CRL approaches into two categories according to whether their causality-based information is given in advance or not, and analyzes each category in terms of the formalization of different models, ranging from the Markov Decision Process (MDP), Partially Observed Markov decision process (POMDP), Multi-Arm Bandits (MAB), and Dynamic Treatment Regime (DTR).","ArXiv",2023,"Yan Zeng,Ruichu Cai,Fuchun Sun,Libo Huang,Z. Hao",0,190,0
"28692beece311a90f5fa1ca2ec9d0c2ce293d069","https://www.semanticscholar.org/paper/28692beece311a90f5fa1ca2ec9d0c2ce293d069",8,"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing","The basics of this promising paradigm in natural language processing are introduced, a unified set of mathematical notations that can cover a wide variety of existing work are described, and existing work is organized along several dimensions.","ACM Computing Surveys",2021,"Pengfei Liu,Weizhe Yuan,Jinlan Fu,Zhengbao Jiang,Hiroaki Hayashi,Graham Neubig",405,175,61
"f403082b101821f5377ae82fe4ed7d02f6abd3ad","https://www.semanticscholar.org/paper/f403082b101821f5377ae82fe4ed7d02f6abd3ad",8,"A Survey of Meta-Reinforcement Learning","This survey describes the meta-RL problem setting in detail as well as its major variations and discusses howMeta-RL research can be clustered based on the presence of a task distribution and the learning budget available for each individual task.","ArXiv",2023,"Jacob Beck,Risto Vuorio,E. Liu,Zheng Xiong,L. Zintgraf,Chelsea Finn,Shimon Whiteson",0,278,0
"0581387bf8411046a562994040f5edd0ad549293","https://www.semanticscholar.org/paper/0581387bf8411046a562994040f5edd0ad549293",8,"QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time Reasoning","This study lays a technical foundation for location and time reasoning and suggests that effectively introducing open-world knowledge is one of the panaceas for the tasks.","ArXiv",2023,"Weimin Shi,Mingchen Zhuge,Zhong Zhou,D. Gao,Deng-Ping Fan",0,34,0
"9adec13eb929b374d3e2866908fd46dbdb504902","https://www.semanticscholar.org/paper/9adec13eb929b374d3e2866908fd46dbdb504902",8,"Dynamic Prompt Learning via Policy Gradient for Semi-structured Mathematical Reasoning","A novel approach is proposed, P ROMPT PG, which utilizes policy gradient to learn to select in-context examples from a small amount of training data and then constructs the corresponding prompt for the test example, which outperforms the best baseline on the accuracy metric and reduces the prediction variance.","ArXiv",2022,"Pan Lu,Liang Qiu,Kai-Wei Chang,Y. Wu,Song-Chun Zhu,Tanmay Rajpurohit,Peter Clark,A. Kalyan",9,43,2
"5704b6ccdccba5645421daef67e1651dbc373b9b","https://www.semanticscholar.org/paper/5704b6ccdccba5645421daef67e1651dbc373b9b",8,"Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals","Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers, and improves on 4 games in the Atari environment with sparse rewards, and requires 1000x less training frames compared to the previous SOTA Agent 57 on Skiing.","ArXiv",2023,"Yue Wu,Yewen Fan,Paul Pu Liang,A. Azaria,Yuan-Fang Li,Tom Michael Mitchell",0,60,0
"4e114c28b589cb5ec4b567b87becd2e2e718fa65","https://www.semanticscholar.org/paper/4e114c28b589cb5ec4b567b87becd2e2e718fa65",8,"Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model","The strengths and weaknesses of different retriever-augmented language models such as REALM, k NN-LM, FiD, ATLAS, and Flan-T5 in reasoning over the selected documents in different tasks are studied.","ArXiv",2022,"Parishad BehnamGhader,Santiago Miret,Siva Reddy",0,23,0
"9a258f42e333ed5ff79037724eb01747ede0bb49","https://www.semanticscholar.org/paper/9a258f42e333ed5ff79037724eb01747ede0bb49",8,"Few-Shot Self-Rationalization with Natural Language Prompts","This work identifies the right prompting approach by extensively exploring natural language prompts on FEB and demonstrates that making progress on few-shot self-rationalization is possible, and presents FEB—a stan-dardized collection of four existing English-language datasets and associated metrics.","NAACL-HLT",2021,"Ana Marasović,Iz Beltagy,Doug Downey,Matthew E. Peters",28,73,5
"76f023c3a819fc58989a064a1b50825b11fce95d","https://www.semanticscholar.org/paper/76f023c3a819fc58989a064a1b50825b11fce95d",8,"Capturing Failures of Large Language Models via Human Cognitive Biases","The results indicate that experimental methodology from cognitive science can help characterize how machine learning systems behave, and draw inspiration from human cognitive biases as motivation to generate hypotheses for problems that models may have and develop experiments that elicit these problems.","ArXiv",2022,"Erik Jones,J. Steinhardt",7,54,0
"316206a2f89eb94ce02a81fba1dc304586f21b39","https://www.semanticscholar.org/paper/316206a2f89eb94ce02a81fba1dc304586f21b39",8,"Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations","Through extensive analyses, it is found that the correct input-label mappings can have varying impacts on the downstream in-context learning performances, depending on the experimental configuration.","Conference on Empirical Methods in Natural Language Processing",2022,"Junyeob Kim,Hyuhng Joon Kim,Hyunsoo Cho,Hwiyeol Jo,Sang-Woo Lee,Sang-goo Lee,Kang Min Yoo,Taeuk Kim",10,43,1
"5b70e69b65b29d231d37bea354b25c05daec07e2","https://www.semanticscholar.org/paper/5b70e69b65b29d231d37bea354b25c05daec07e2",8,"Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence","A new calibration study is presented, where models are discouraged from presenting any single answer when presented with multiple conflicting answer candidates in retrieved evidences, and it is discovered that contradictions among knowledge sources affect model confidence only marginally.","Conference on Empirical Methods in Natural Language Processing",2022,"Hung-Ting Chen,Michael J.Q. Zhang,Eunsol Choi",1,44,0
"0efa0441da820b1905572666ba1974a06a9663fb","https://www.semanticscholar.org/paper/0efa0441da820b1905572666ba1974a06a9663fb",8,"NaturalProver: Grounded Mathematical Proof Generation with Language Models","N ATURAL P ROVER is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to the authors' knowledge the first demonstration of these capabilities using neural language models.","ArXiv",2022,"S. Welleck,Jiacheng Liu,Ximing Lu,Hannaneh Hajishirzi,Yejin Choi",6,53,0
"4d81c33b295c092016ac236cfd32020a5bb70b97","https://www.semanticscholar.org/paper/4d81c33b295c092016ac236cfd32020a5bb70b97",8,"Optimizing Prompts for Text-to-Image Generation","This work proposes prompt adaptation, a general framework that automatically adapts original user input to model-preferred prompts, and proposes a reward function that encourages the policy to generate more aesthetically pleasing images while preserving the original user intentions.","ArXiv",2022,"Y. Hao,Zewen Chi,Li Dong,Furu Wei",1,34,0
"7c48d59f7be422f6e68b8cddd53b17fbab19599f","https://www.semanticscholar.org/paper/7c48d59f7be422f6e68b8cddd53b17fbab19599f",8,"Critic-Guided Decoding for Controlled Text Generation","Evaluation of the novel critic decoding method for controlled language generation (CriticControl) that combines the strengths of reinforcement learning and weighted decoding shows that it generates more coherent and well-controlled texts than previous methods.","ArXiv",2022,"Minbeom Kim,Hwanhee Lee,Kang Min Yoo,Joonsuk Park,Hwaran Lee,Kyomin Jung",0,51,0
"52b79321a4862d44db09065e4b40021e2ec1eb0c","https://www.semanticscholar.org/paper/52b79321a4862d44db09065e4b40021e2ec1eb0c",8,"On Realization of Intelligent Decision-Making in the Real World: A Foundation Decision Model Perspective","It is argued that a foundation decision model (FDM) can be established by formu-lating various decision-making tasks as a sequence decoding task using the Transformer architecture; this would be a promising solution to advance the applications of IDM in more complex real world tasks.","ArXiv",2022,"Ying Wen,Ziyu Wan,M. Zhou,Shufang Hou,Zhe Cao,Chenyang Le,Jingxiao Chen,Zheng Tian,Weinan Zhang,J. Wang",0,95,0
"23cae400cfd1a7c455c721256b838e98a307d5e6","https://www.semanticscholar.org/paper/23cae400cfd1a7c455c721256b838e98a307d5e6",8,"ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on Simplified Radiology Reports","The initial insights of this study indicate a great potential in using large language models like ChatGPT to improve patient-centered care in radiology and other medical domains.","ArXiv",2022,"Katharina Jeblick,B. Schachtner,Jakob Dexl,Andreas Mittermeier,Anna Theresa Stüber,Johanna Topalis,Tobias Weber,P. Wesp,B. Sabel,J. Ricke,M. Ingrisch",3,45,0
"8973ad5fc1264594a1fda3bd9e04258074cea9cc","https://www.semanticscholar.org/paper/8973ad5fc1264594a1fda3bd9e04258074cea9cc",8,"Neural Architecture Search: Insights from 1000 Papers","This survey provides an organized and comprehensive guide to neural architecture search, giving a taxonomy of search spaces, algorithms, and speedup techniques, and discusses resources such as benchmarks, best practices, other surveys, and open-source libraries.","ArXiv",2023,"Colin White,Mahmoud Safari,R. Sukthanker,Binxin Ru,T. Elsken,Arber Zela,Debadeepta Dey,F. Hutter",0,322,0
"ab4467bd55ddfe7b575aad37df11720ec93965d6","https://www.semanticscholar.org/paper/ab4467bd55ddfe7b575aad37df11720ec93965d6",8,"Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning","This study proposes an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrates a 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classiﬁcation datasets, supporting the hypothesis that large language models implicitly infer a latent concept variable.","ArXiv",2023,"Xinyi Wang,Wanrong Zhu,William Yang Wang",1,40,0
"2b6fe1d6a34c2b4a3113209cb30111247d78585d","https://www.semanticscholar.org/paper/2b6fe1d6a34c2b4a3113209cb30111247d78585d",8,"Towards Agile Text Classifiers for Everyone","It is argued that this enables a paradigm shift for text classification, especially for models supporting safer online discourse, whereby classifiers are trained using small, targeted datasets that can be quickly developed for a particular policy.","",2023,"Maximilian Mozes,Jessica Hoffmann,Katrin Tomanek,Muhamed Kouate,Nithum Thain,Ann Yuan,Tolga Bolukbasi,Lucas Dixon",0,38,0
"390c71025beb7e7613640ecd331fa9a1179ca568","https://www.semanticscholar.org/paper/390c71025beb7e7613640ecd331fa9a1179ca568",8,"Guiding Pretraining in Reinforcement Learning with Large Language Models","A method that uses background knowledge from text corpora to shape exploration and rewards an agent for achieving goals suggested by a language model prompted with a description of the agent's current state, called ELLM (Exploring with LLMs).","",2023,"Yuqing Du,Olivia Watkins,Zihan Wang,Cédric Colas,Trevor Darrell,P. Abbeel,Abhishek Gupta,Jacob Andreas",0,59,0
"5d4e29995fba13ed87df00d894cbd96f20f2196a","https://www.semanticscholar.org/paper/5d4e29995fba13ed87df00d894cbd96f20f2196a",8,"ANSEL Photobot: A Robot Event Photographer with Semantic Intelligence","This work illustrates how to produce a photo-taking robot with an exceptional level of semantic awareness by leveraging recent advances in general purpose language (LM) and vision-language (VLM) models.","",2023,"D. Rivkin,Gregory Dudek,Nikhil Kakodkar,D. Meger,Oliver Limoyo,Xue Liu,F. Hogan",0,38,0
"2ac93ba3f4cce13d31546c7c8d6ac6fa79ed34bf","https://www.semanticscholar.org/paper/2ac93ba3f4cce13d31546c7c8d6ac6fa79ed34bf",8,"Enabling Conversational Interaction with Mobile UI using Large Language Models","This paper proposes a design space to categorize conversations between the user and the agent when collaboratively accomplishing mobile tasks, and designs prompting techniques to adapt an LLM to conversational tasks on mobile UIs.","ArXiv",2022,"Bryan Wang,Gang Li,Yang Li",2,66,0
"262d6a0f6eb3f4c81e47fecd7e14be004295a7cf","https://www.semanticscholar.org/paper/262d6a0f6eb3f4c81e47fecd7e14be004295a7cf",8,"A Causal Framework to Quantify the Robustness of Mathematical Reasoning with Language Models","This work proposes a novel framework, which pins down the causal effect of various factors in the input, e.g., the surface form of the problem text, the operands and math operators on the output solution, and shows that robustness does not appear to continuously improve as a function of scale, but that the recent GPT-3-Instruct achieves a dra-matic improvement in both robustness and sensitivity, compared to all other GPT variants.","ArXiv",2022,"Alessandro Stolfo,Zhijing Jin,K. Shridhar,B. Schölkopf,Mrinmaya Sachan",2,55,0
"01da025a208ff4f35ba036ce882b21aa505243f3","https://www.semanticscholar.org/paper/01da025a208ff4f35ba036ce882b21aa505243f3",8,"Self-adaptive In-context Learning","This paper advocates a new principle for ICL: self-adaptive in-context learning, and proposes a general select-then-rank framework and instantiate it with new selection and ranking algorithms.","ArXiv",2022,"Zhiyong Wu,Yaoxiang Wang,Jiacheng Ye,Lingpeng Kong",1,39,0
"eb70971db1248785528667deddba68088944a375","https://www.semanticscholar.org/paper/eb70971db1248785528667deddba68088944a375",8,"Little Red Riding Hood Goes Around the Globe: Crosslingual Story Planning and Generation with Large Language Models","","ArXiv",2022,"E. Razumovskaia,Joshua Maynez,Annie Louis,Mirella Lapata,Shashi Narayan",0,38,0
"ee805f55c98920f74d0182aaf136330a97b4123f","https://www.semanticscholar.org/paper/ee805f55c98920f74d0182aaf136330a97b4123f",8,"ScatterShot: Interactive In-context Example Curation for Text Transformation","ScatterShot iteratively slices unlabeled data into task-specific patterns, samples informative inputs from underexplored or not-yet-saturated slices in an active learning manner, and helps users label more efficiently with the help of an LLM and the current example set.","",2023,"Tongshuang Sherry Wu,Hua Shen,Daniel S. Weld,Jeffrey Heer,Marco Tulio Ribeiro",0,70,0
"f59f27ae53bc860818cd3363d799a4b85fe6b4f9","https://www.semanticscholar.org/paper/f59f27ae53bc860818cd3363d799a4b85fe6b4f9",8,"Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models","It is argued that using data with a diverse set of clear and meaningful labels is key to training D2T generation systems capable of generalizing to novel domains.","ArXiv",2022,"Zdenvek Kasner,Ioannis Konstas,Ondrej Dusek",0,72,0
"2fa6dbd2f147b6fa34d22c80aa225cc2cad0d96e","https://www.semanticscholar.org/paper/2fa6dbd2f147b6fa34d22c80aa225cc2cad0d96e",8,"Complex Reading Comprehension Through Question Decomposition","A novel learning approach is proposed that helps language models better understand multi-hop questions and perform “com-plex, compositional” reasoning.","ArXiv",2022,"Xiao-Yu Guo,Yuan-Fang Li,Gholamreza Haffari",2,22,1
"9dab4c20648cd4c7c6830e6274a95294b014aac9","https://www.semanticscholar.org/paper/9dab4c20648cd4c7c6830e6274a95294b014aac9",8,"QAmeleon: Multilingual QA with Only 5 Examples","This approach uses a PLM to automatically generate multilingual data upon which QA models are trained, thus avoiding costly annotation and shows that few-shot prompt tuning for data synthesis scales across languages and is a viable alternative to large-scale annotation.","ArXiv",2022,"Priyanka Agrawal,Chris Alberti,Fantine Huot,Joshua Maynez,Ji Ma,Sebastian Ruder,Kuzman Ganchev,Dipanjan Das,Mirella Lapata",3,57,0
"d164fc8d71ca304bbd7833de5d03ad0a5ca32afa","https://www.semanticscholar.org/paper/d164fc8d71ca304bbd7833de5d03ad0a5ca32afa",8,"Multi-document Summarization via Deep Learning Techniques: A Survey","This survey, the first of its kind, systematically overviews the recent deep-learning-based MDS models and proposes a novel taxonomy to summarize the design strategies of neural networks and conduct a comprehensive summary of the state of the art.","ACM Computing Surveys",2020,"Congbo Ma,W. Zhang,Mingyu Guo,Hu Wang,Quan Z. Sheng",34,209,2
"998592c0f3aaa6d64a1a3a79aa9e9caa3c7a5633","https://www.semanticscholar.org/paper/998592c0f3aaa6d64a1a3a79aa9e9caa3c7a5633",8,"Dynamic Scheduled Sampling with Imitation Loss for Neural Text Generation","D Y SI is introduced, which maintains the schedule based solely on the training time accuracy, while enhancing the curriculum learning by introducing an imitation loss, which attempts to make the behavior of the decoder in-distinguishable from the behavior from a teacher-forced decoder.","ArXiv",2023,"Xiang Lin,Prathyusha Jwalapuram,Shafiq R. Joty",0,55,0
"c710d9a8c30b3130caaf3ea45e786de6b5a3eed8","https://www.semanticscholar.org/paper/c710d9a8c30b3130caaf3ea45e786de6b5a3eed8",8,"Adversarial Training for High-Stakes Reliability","This work created a series of adversarial training techniques—including a tool that assists human adversaries—to create and eliminate failures in a classiﬁer that ﬁlters text completions suggested by a generator, and found that adversarialTraining increased robustness to the adversarial attacks that it trained on, without affecting in-distribution performance.","ArXiv",2022,"Daniel M. Ziegler,Seraphina Nix,Lawrence Chan,Tim Bauman,Peter Schmidt-Nielsen,Tao Lin,Adam Scherlis,Noa Nabeshima,Ben Weinstein-Raun,D. Haas,Buck Shlegeris,Nate Thomas",7,65,0
"e10ed48cceca216d8ac43113c0562cf340dbdce3","https://www.semanticscholar.org/paper/e10ed48cceca216d8ac43113c0562cf340dbdce3",8,"Unveiling Transformers with LEGO: a synthetic reasoning task","It is found that in some data regime the trained transformer finds “shortcut” solutions to follow the chain of reasoning, which impedes the model’s ability to generalize to simple variants of the main task, and moreover one can prevent such shortcut with appropriate architecture modification or careful data preparation.","ArXiv",2022,"Yi Zhang,A. Backurs,Sébastien Bubeck,Ronen Eldan,Suriya Gunasekar,Tal Wagner",11,42,3
"2bd7ba07f9ae9102cefbf650ae24f7990de541ad","https://www.semanticscholar.org/paper/2bd7ba07f9ae9102cefbf650ae24f7990de541ad",8,"Regulating ChatGPT and other Large Generative AI Models","This paper sitsuate these new generative models in the current debate on trustworthy AI regulation, and suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between L GAIM developers, deployers, professional and non-professional users, as well as recipients of LGA IM output.","ArXiv",2023,"P. Hacker,A. Engel,M. Mauer",0,145,0
"292da1c4640c105aa5d7919a1ded9a1225c07d4d","https://www.semanticscholar.org/paper/292da1c4640c105aa5d7919a1ded9a1225c07d4d",8,"Large Language Models and the Reverse Turing Test","","Neural Computation",2022,"T. Sejnowski",3,82,0
"bc6650c553e341062569c0c39ec36d8a5063bf67","https://www.semanticscholar.org/paper/bc6650c553e341062569c0c39ec36d8a5063bf67",8,"S TANDING ON THE S HOULDERS OF G IANT F ROZEN L ANGUAGE M ODELS","Condense relevant information from 100+ retrieved documents into the input sequence length of the frozen LM reader to reach and surpass leading tuning approaches on Natural Questions, a open-domain question answering benchmark.","",,"",0,0,0
"5d49c7401c5f2337c4cc88d243ae39ed659afe64","https://www.semanticscholar.org/paper/5d49c7401c5f2337c4cc88d243ae39ed659afe64",8,"Red Teaming Language Models with Language Models","This work automatically finds cases where a target LM behaves in a harmful way, by generating test cases (“red teaming”) using another LM, and evaluates the target LM’s replies to generated test questions using a classifier trained to detect offensive content.","Conference on Empirical Methods in Natural Language Processing",2022,"Ethan Perez,Saffron Huang,Francis Song,Trevor Cai,Roman Ring,J. Aslanides,A. Glaese,Nathan McAleese,Geoffrey Irving",58,100,2
"1e7fcebce44eb35cb7dd48645af76378155faea8","https://www.semanticscholar.org/paper/1e7fcebce44eb35cb7dd48645af76378155faea8",8,"Improving Passage Retrieval with Zero-Shot Question Generation","This work proposes a simple and effective re-ranking method for improving passage retrieval in open question answering that improves strong unsupervised retrieval models by 6%-18% absolute and strong supervised models by up to 12% in terms of top-20 passage retrieval accuracy.","Conference on Empirical Methods in Natural Language Processing",2022,"Devendra Singh Sachan,M. Lewis,Mandar Joshi,Armen Aghajanyan,Wen-tau Yih,J. Pineau,Luke Zettlemoyer",15,46,4
"fb30166c218bef3597b0d9789ad340defc3989ca","https://www.semanticscholar.org/paper/fb30166c218bef3597b0d9789ad340defc3989ca",8,"In-BoXBART: Get Instructions into Biomedical Multi-Task Learning","This is the first attempt to propose a uniﬁed model in the biomedical domain and use instructions to achieve generalization across several biomedical tasks, and indicates that there is room for improvement across tasks in the BoX, implying the scope for future research direction.","NAACL-HLT",2022,"Mihir Parmar,Swaroop Mishra,Mirali Purohit,Man Luo,M. H. Murad,Chitta Baral",4,60,0
"3b8b2d43e38eb4d48d97b14a8f981e96a6c60df0","https://www.semanticscholar.org/paper/3b8b2d43e38eb4d48d97b14a8f981e96a6c60df0",8,"Standing on the Shoulders of Giant Frozen Language Models","Condense relevant information from 100+ retrieved documents into the input sequence length of the frozen LM reader to reach and surpass leading tuning approaches on Natural Questions, a open-domain question answering benchmark.","ArXiv",2022,"Yoav Levine,Itay Dalmedigos,Ori Ram,Yoel Zeldes,Daniel Jannai,Dor Muhlgay,Yoni Osin,Opher Lieber,Barak Lenz,S. Shalev-Shwartz,A. Shashua,Kevin Leyton-Brown,Y. Shoham",15,39,6
"47dc00cf21a0e7452b6f61207f119a9cc01c52b8","https://www.semanticscholar.org/paper/47dc00cf21a0e7452b6f61207f119a9cc01c52b8",8,"HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models","This paper proposes a simple prompting strategy HELP ME THINK where GPT3 is encouraged to help non-expert users by asking a set of relevant questions and leveraging user answers to execute the task.","ArXiv",2022,"Swaroop Mishra,E. Nouri",4,33,0
"51a00995498ec296e5f19d5e7e59fe901cbc08b4","https://www.semanticscholar.org/paper/51a00995498ec296e5f19d5e7e59fe901cbc08b4",8,"Using Large Language Models to Simulate Multiple Humans","A new type of test, called a Turing Experiment (TE), for evaluating how well a language model, such as GPT-3, can simulate different aspects of human behavior, and reveals a""hyper-accuracy distortion""present in some language models.","ArXiv",2022,"Gati Aher,RosaI. Arriaga,A. Kalai",7,46,1
"d3135733aa39dec20ce72aa138589dda27c8406d","https://www.semanticscholar.org/paper/d3135733aa39dec20ce72aa138589dda27c8406d",8,"Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering","This work designs language models to learn to generate lectures and explanations as the chain of thought (CoT) to mimic the multi-hop reasoning process when answering S CIENCE QA questions and explores the upper bound of GPT-3 and shows that CoT helps language models learn from fewer data.","ArXiv",2022,"Pan Lu,Swaroop Mishra,Tony Xia,Liang Qiu,Kai-Wei Chang,Song-Chun Zhu,Oyvind Tafjord,Peter Clark,A. Kalyan",14,70,2
"e86009d9f9b1cdf083a48d087552bc4153784451","https://www.semanticscholar.org/paper/e86009d9f9b1cdf083a48d087552bc4153784451",8,"Promptagator: Few-shot Dense Retrieval From 8 Examples","This paper proposes Promptbase Query Generation for Retriever (PROMPTAGATOR), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data.","ArXiv",2022,"Zhuyun Dai,Vincent Zhao,Ji Ma,Yi Luan,Jianmo Ni,Jing Lu,A. Bakalov,Kelvin Guu,Keith B. Hall,Ming-Wei Chang",14,70,3
"8f0bbd0920cc13dbd3fec5f254facca7991875a4","https://www.semanticscholar.org/paper/8f0bbd0920cc13dbd3fec5f254facca7991875a4",8,"News Summarization and Evaluation in the Era of GPT-3","It is shown that not only do humans overwhelmingly prefer GPT-3 summaries, but these also do not suffer from common dataset-speciﬁc issues such as poor factuality, and both reference-based and reference-free automatic metrics cannot reliably evaluate zero-shot summaries.","ArXiv",2022,"Tanya Goyal,Junyi Jessy Li,Greg Durrett",17,64,2
"8fbd7ddf1ea30c991f3b1152a245df77caa18e16","https://www.semanticscholar.org/paper/8fbd7ddf1ea30c991f3b1152a245df77caa18e16",8,"Learning by Distilling Context","This work shows that context distillation is a general method to train language models, and it can effectively internalize 3 types of training signals, and can internalize step-by-step reasoning for complex tasks.","ArXiv",2022,"Charles Burton Snell,D. Klein,Ruiqi Zhong",6,38,0
"7d29a84a589aa5655e5d3fed8d725ea472816599","https://www.semanticscholar.org/paper/7d29a84a589aa5655e5d3fed8d725ea472816599",8,"Explanations from Large Language Models Make Small Reasoners Better","This work systematically explore three explanation generation approaches from LLM and utilizes a multi-task learning framework to facilitate small models to acquire strong reasoning power together with explanation generation capabilities.","ArXiv",2022,"SHIYANG LI,Jianshu Chen,Yelong Shen,Zhiyu Chen,Xinlu Zhang,Zekun Li,Hong Wang,Jingu Qian,Baolin Peng,Yi Mao,Wenhu Chen,Xifeng Yan",10,38,1
"9a3f1a51ab2b3816655e4c4f58a022421ea7b34b","https://www.semanticscholar.org/paper/9a3f1a51ab2b3816655e4c4f58a022421ea7b34b",8,"""John is 50 years old, can his son be 65?"" Evaluating NLP Models' Understanding of Feasibility","This work introduces FeasibilityQA, a question-answering dataset involving binary classification (BCQ) and multi-choice multi-correct questions (MCQ) that test understanding of feasibility, and shows that even state-of-the-art models such as GPT-3, G PT-2, and T5 struggle to answer the feasibility questions correctly.","ArXiv",2022,"Himanshu Gupta,Neeraj Varshney,Swaroop Mishra,Kuntal Kumar Pal,Saurabh Arjun Sawant,Kevin Scaria,Siddharth Goyal,Chitta Baral",2,44,0
"8b24e92e70a498c6a8d16e00e6ab5d5c529ab183","https://www.semanticscholar.org/paper/8b24e92e70a498c6a8d16e00e6ab5d5c529ab183",8,"A Universal Discriminator for Zero-Shot Generalization","This work challenges this convention by showing that discriminative approaches perform substantially better than generative ones on a large number of NLP tasks, and jointly train a generalized UD in combination with generative tasks, which maintains its advantage on discrim inative tasks and simultaneously works onGenerative tasks.","ArXiv",2022,"Haike Xu,Zongyu Lin,Jing Zhou,Yanan Zheng,Zhilin Yang",1,38,0
"d0c67804d7f8cc8d79c7346ec8a011f43a21c553","https://www.semanticscholar.org/paper/d0c67804d7f8cc8d79c7346ec8a011f43a21c553",8,"Data-Efficient Finetuning Using Cross-Task Nearest Neighbors","It is shown that training on a carefully chosen subset of instances can outperform training on all available data on a variety of datasets, and small subsets of P3 and T5 models that outperform the 3-billion parameter variant of T0 by 3–30% on 12 out of 14 evaluation datasets while using at most 2% of the data used to train T0-3B.","ArXiv",2022,"Hamish Ivison,Noah A. Smith,Hannaneh Hajishirzi,Pradeep Dasigi",1,52,1
"2e6fa3095df1d1ed041dfb4f5a18e31d4b7bd7bb","https://www.semanticscholar.org/paper/2e6fa3095df1d1ed041dfb4f5a18e31d4b7bd7bb",8,"In-Context Learning with Many Demonstration Examples","A long-range language model EVALM based on an efficient transformer mechanism that can achieve higher performance with more demonstrations under many-shot instruction tuning, and further extending the length of instructions can further improve the upper bound of scaling in-context learning.","ArXiv",2023,"Mukai Li,Shansan Gong,Jiangtao Feng,Yiheng Xu,Jinchao Zhang,Zhiyong Wu,Lingpeng Kong",0,57,0
"e295c65efbec7754cc194af0999d489292a3c8b4","https://www.semanticscholar.org/paper/e295c65efbec7754cc194af0999d489292a3c8b4",8,"Residual Learning of Neural Text Generation with n-gram Language Model","Experimental results on three typical language tasks demonstrate that the proposed neural LM attains additional performance gains over popular standalone neural models consistently and allows for effective domain adaptation by simply switching to a domain-specific $n$-gram model, without any extra training.","Conference on Empirical Methods in Natural Language Processing",2022,"Huayang Li,Deng Cai,J. Xu,Taro Watanabe",1,50,0
"60964d20095f7008d4285632cc991e63099a3d77","https://www.semanticscholar.org/paper/60964d20095f7008d4285632cc991e63099a3d77",8,"Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey","A systematical taxonomy regarding how existing methods integrate structured knowledge into story generation is presented and multidimensional insights into the challenges of knowledge-enhanced story generation are given and light is cast on promising directions for future study.","ArXiv",2022,"Yuxin Wang,Jieru Lin,Zhiwei Yu,Wei Hu,Börje F. Karlsson",0,161,0
"c042d0169ea4f4e4490d406befb973ebab135e7e","https://www.semanticscholar.org/paper/c042d0169ea4f4e4490d406befb973ebab135e7e",8,"Vision Encoders in Visual Question Answering","This work formats the inputs used to prompt a VLM using a modified text-only template from a closed-book question answering task that the language-model component of the VLM was pretrained on, enabling the V LM to leverage the similarities between the tasks, such as the answer-length distribution, when generating answers to the visual questions.","",2022,"Ryan R. Anderson",0,72,0
"d68c8db0e1b8b7f1e6c44393e0a425daa44a16c7","https://www.semanticscholar.org/paper/d68c8db0e1b8b7f1e6c44393e0a425daa44a16c7",8,"VIMA: General Robot Manipulation with Multimodal Prompts","This work designs a transformer-based generalist robot agent, VIMA, that processes these prompts and outputs motor actions autoregressively and achieves strong scalability in both model capacity and data size.","ArXiv",2022,"Yunfan Jiang,Agrim Gupta,Zichen Zhang,Guanzhi Wang,Yongqiang Dou,Yanjun Chen,Li Fei-Fei,Anima Anandkumar,Yuke Zhu,Linxi (Jim) Fan",9,125,1
"4294e8a4a1ea06a3cfc55bbacc03299a72260473","https://www.semanticscholar.org/paper/4294e8a4a1ea06a3cfc55bbacc03299a72260473",7,"AI in Human-computer Gaming: Techniques, Challenges and Opportunities","A survey of recent successful game AIs, covering board game AIS, card game A is, first-person shooting game Ais, and real-time strategy game AI, to compare the main difficulties among different kinds of games and the corresponding techniques utilized for achieving professional human-level AIs.","Machine Intelligence Research",2021,"Qiyue Yin,Jun Yang,Kaiqi Huang,Meijing Zhao,Wancheng Ni,Bin Liang,Yan Huang,Shu Wu,Liangsheng Wang",1,68,0
"7dfd7b37267f5c290d107de529c428413ba297ad","https://www.semanticscholar.org/paper/7dfd7b37267f5c290d107de529c428413ba297ad",7,"Reinforce-lib: A Reinforcement Learning Library for Scientific Research","This paper proposes a modern, modular, simple and understandable Python RL library called reinforce-lib, aimed at enabling newcomers, practitioners, and researchers to easily employ RL to solve new scientific problems.","Proceedings of International Symposium on Grids &amp; Clouds 2022 — PoS(ISGC2022)",2022,"Luca Anzalone,D. Bonacorsi",0,34,0
"de5ebf2ed4433eac7bceb16484d33f66e6b5b580","https://www.semanticscholar.org/paper/de5ebf2ed4433eac7bceb16484d33f66e6b5b580",7,"Cooperative and competitive multi-agent deep reinforcement learning","This article mostly focuses on recent papers on Multi-agent deep reinforcement learning (MADRL), and key ideas and main techniques in each work are discussed.","Other Conferences",2022,"Ruizhi Chen",0,77,0
"af502f64a48b1551c4beb0649a887f98776fca2c","https://www.semanticscholar.org/paper/af502f64a48b1551c4beb0649a887f98776fca2c",7,"A Critical Review of Traffic Signal Control and A Novel Unified View of Reinforcement Learning and Model Predictive Control Approaches for Adaptive Traffic Signal Control","A novel unified view of modern ATSCs is proposed to identify common ground as well as differences and shortcomings of existing methodologies with the ultimate goal to facilitate cross-fertilization and advance the state-of-the-art.","ArXiv",2022,"Xiaoyu Wang,S. Sanner,B. Abdulhai",0,107,0
"f18c3f40f62596337ce79d3d103160d3236498f2","https://www.semanticscholar.org/paper/f18c3f40f62596337ce79d3d103160d3236498f2",7,"Reinforcement Learning for Quantitative Trading","A taxonomy of RL-based QT models is devised, along with a comprehensive summary of the state of the art, and current challenges and proposed future research directions in this exciting field are discussed.","ACM Transactions on Intelligent Systems and Technology",2021,"Shuo Sun,R. Wang,Bo An",8,166,0
"6d4a9f1c41b078846901362ba0dce8295dd6a2a8","https://www.semanticscholar.org/paper/6d4a9f1c41b078846901362ba0dce8295dd6a2a8",7,"End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering","An end-to-end differentiable training method for retrieval-augmented open-domain question answering systems that combine information from multiple retrieved documents when generating answers and demonstrates the feasibility of learning to retrieve to improve answer generation without explicit supervision of retrieval decisions.","Neural Information Processing Systems",2021,"Devendra Singh Sachan,Siva Reddy,William Hamilton,Chris Dyer,Dani Yogatama",48,56,12
"25fa3de9227cce01568fe7273169195df9342d4b","https://www.semanticscholar.org/paper/25fa3de9227cce01568fe7273169195df9342d4b",7,"Mutually improved dense retriever and GNN-based reader for arbitrary-hop open-domain question answering","This paper investigates the mutual promotion of dense retrievers and Graph Neural Network-based readers to improve OpenQA and introduces an alternate training strategy where the scores of the dense retriever and the GNN-based reader are used as correction weights to enhance the performance of each other.","Neural computing & applications (Print)",2022,"Ronghan Li,Lifang Wang,Zejun Jiang,Zhongtian Hu,Meng Zhao,Xinyu Lu",0,71,0
"63ddd417f4bb3b5b736542494ec8e99d5d4227a0","https://www.semanticscholar.org/paper/63ddd417f4bb3b5b736542494ec8e99d5d4227a0",7,"Detecting Frozen Phrases in Open-Domain Question Answering","The experiments reveal that detecting frozen phrases whose presence in answer documents are highly plausible yields significant improvements in retrievals as well as in the end-to-end accuracy of open-domain QA models.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2022,"Mostafa Yadegari,Ehsan Kamalloo,Davood Rafiei",0,47,0
"c00448c8097b043004bb8010186215e2c15b70c0","https://www.semanticscholar.org/paper/c00448c8097b043004bb8010186215e2c15b70c0",7,"Towards Intrinsic Interactive Reinforcement Learning","A tutorial and review of intrinsic IRL so far with an emphasis on its parent field of feedback-driven IRL along with discussions concerning validity, challenges, and open problems is provided.","",2021,"Ben Poole,Minwoo Lee",2,131,1
"c512d35fd20fbe4612f2bce2b6f5409c8b0a73e1","https://www.semanticscholar.org/paper/c512d35fd20fbe4612f2bce2b6f5409c8b0a73e1",7,"Automated Reinforcement Learning (AutoRL): A Survey and Open Problems","This survey seeks to unify the field of AutoRL, provide a common taxonomy, discuss each area in detail and pose open problems of interest to researchers going forward.","Journal of Artificial Intelligence Research",2022,"Jack Parker-Holder,Raghunandan Rajan,Xingyou Song,André Biedenkapp,Yingjie Miao,Theresa Eimer,Baohe Zhang,V. Nguyen,R. Calandra,Aleksandra Faust,F. Hutter,M. Lindauer",28,284,2
"f7374cc79d56dd683b965a91dcff7a7b2d5ceaeb","https://www.semanticscholar.org/paper/f7374cc79d56dd683b965a91dcff7a7b2d5ceaeb",7,"Optimizing communication in deep reinforcement learning with XingTian","XingTian is a novel DRL framework that co-designs the management of communication and computation in DRL algorithms in a decentralized way and provides an asynchronous communication channel that maintains high communication efficiency under different scale deployments.","Proceedings of the 23rd ACM/IFIP International Middleware Conference",2022,"Lichen Pan,Jun Qian,Wei Xia,Hangyu Mao,Jun Yao,Pengze Li,Zhen Xiao",0,56,0
"8632fc7c21c7f2cac630f2c989cb4f3d2e6cc86b","https://www.semanticscholar.org/paper/8632fc7c21c7f2cac630f2c989cb4f3d2e6cc86b",7,"High-Accuracy Model-Based Reinforcement Learning, a Survey","This paper surveys model-based reinforcement learning methods, explaining in detail how they work and what their strengths and weaknesses are, and concludes with a research agenda for future work to make the methods more robust and more widely applicable to other applications.","Artificial Intelligence Review",2021,"A. Plaat,W. Kosters,M. Preuss",3,117,0
"e7688af964a3e7eba2d11afa1fe0aab14afe3c15","https://www.semanticscholar.org/paper/e7688af964a3e7eba2d11afa1fe0aab14afe3c15",7,"PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question Answering Research and Development","P RIME QA is introduced: a one-stop and open-source QA repository with an aim to democratize QA research and facilitate easy replication of state-of-the-art (SOTA) QA methods.","ArXiv",2023,"Avirup Sil,Jaydeep Sen,Bhavani Iyer,M. Franz,Kshitij P. Fadnis,Mihaela A. Bornea,Sara Rosenthal,Scott McCarley,Rong Zhang,Vishwajeet Kumar,Yulong Li,Md Arafat Sultan,Riyaz Ahmad Bhat,Radu Florian,S. Roukos",0,51,0
"894188a2fa6825722f946eece9490d70998aa0b7","https://www.semanticscholar.org/paper/894188a2fa6825722f946eece9490d70998aa0b7",7,"Towards automating Codenames spymasters with deep reinforcement learning","Codenames is a good benchmark for both humanAI co-operation and text-based reinforcement learning, which are both several important areas of AI research.","ArXiv",2022,"Sherman Siu",0,39,0
"b18f32e6cdef86680ebd9a6cc82826127e2cff1a","https://www.semanticscholar.org/paper/b18f32e6cdef86680ebd9a6cc82826127e2cff1a",7,"A Survey on Transformers in Reinforcement Learning","This paper seeks to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-ﬁeld, and summarize future prospects.","ArXiv",2023,"Wenzhe Li,Hao Luo,Zichuan Lin,Chongjie Zhang,Zongqing Lu,Deheng Ye",0,90,0
"05a2c3bdd1eeaeef226f56be4545bfadc9eb68f5","https://www.semanticscholar.org/paper/05a2c3bdd1eeaeef226f56be4545bfadc9eb68f5",7,"Rewards Encoding Environment Dynamics Improves Preference-based Reinforcement Learning","It is demonstrated that encoding environment dynamics in the reward function (REED) dramatically reduces the number of preference labels required in state-of-the-art preference-based RL frameworks, and it is hypothesized that REED-based methods better partition the state- action space and facilitate generalization to state-action pairs not included in the preference dataset.","ArXiv",2022,"Katherine Metcalf,Miguel Sarabia,B. Theobald",0,47,0
"27ad3c82903fbf78491d707f97235ef3e8b4580f","https://www.semanticscholar.org/paper/27ad3c82903fbf78491d707f97235ef3e8b4580f",7,"(QA)2: Question Answering with Questionable Assumptions","(QA) 2 (Question Answering with Questionable Assumptions), an open-domain evaluation dataset consisting of naturally-occurring search engine queries that may or may not contain questionable assumptions, is proposed.","ArXiv",2022,"Najoung Kim,Phu Mon Htut,Sam Bowman,Jackson Owen Petty",0,39,0
"7e38476342ce1fcc8ef0dcd23686539395961769","https://www.semanticscholar.org/paper/7e38476342ce1fcc8ef0dcd23686539395961769",7,"Inductive biases for deep learning of higher-level cognition","This work considers a larger list of inductive biases that humans and animals exploit, focusing on those which concern mostly higher-level and sequential conscious processing, to help build AI systems benefiting from humans’ abilities in terms of flexible out-of-distribution and systematic generalization.","Proceedings of the Royal Society A",2020,"Anirudh Goyal,Yoshua Bengio",119,260,7
"a81a09b2a4ce36ae5c847fc4e3558c523d301179","https://www.semanticscholar.org/paper/a81a09b2a4ce36ae5c847fc4e3558c523d301179",7,"Evidentiality-guided Generation for Knowledge-Intensive NLP Tasks","This work introduces a method to incorporate evidentiality of passages—whether a passage contains correct evidence to support the output—into training the generator, and introduces a multi-task learning framework to jointly generate the final output and predict the evidentialsity of each passage.","North American Chapter of the Association for Computational Linguistics",2021,"Akari Asai,Matt Gardner,Hannaneh Hajishirzi",7,66,1
"032dc764cac41dea93680131d9a49284f2ae479f","https://www.semanticscholar.org/paper/032dc764cac41dea93680131d9a49284f2ae479f",7,"You can't pick your neighbors, or can you? When and how to rely on retrieval in the $k$NN-LM","A new formulation of the k NN-LM that uses retrieval quality to assign the interpolation coefﬁcient and empirically measures the effectiveness of the approach on two English language modeling datasets, Wikitext-103 and PG-19.","",2022,"Andrew Drozdov,Shufan Wang,Razieh Rahimi,A. McCallum,Hamed Zamani,Mohit Iyyer",0,41,0
"4ce987d4f8ae0f4680808c318980d42a82b9aa89","https://www.semanticscholar.org/paper/4ce987d4f8ae0f4680808c318980d42a82b9aa89",7,"Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers","FLTs are the first Transformers architectures providing RPE-enhanced linear attention and provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling.","ArXiv",2023,"K. Choromanski,Shanda Li,Valerii Likhosherstov,Kumar Avinava Dubey,Shengjie Luo,Di He,Yiming Yang,Tamás Sarlós,Thomas Weingarten,Adrian Weller",0,56,0
"cd471b5ef162906ef3d9a84398b3f98e9ee4bf56","https://www.semanticscholar.org/paper/cd471b5ef162906ef3d9a84398b3f98e9ee4bf56",7,"A Review on Language Models as Knowledge Bases","This paper presents a set of aspects that it is deemed an LM should have to fully act as a KB, and reviews the recent literature with respect to those aspects.","ArXiv",2022,"Badr AlKhamissi,Millicent Li,Asli Celikyilmaz,Mona T. Diab,Marjan Ghazvininejad",15,167,5
"1c1ca2392155ddf30408a442e6b504b5d60d4f2a","https://www.semanticscholar.org/paper/1c1ca2392155ddf30408a442e6b504b5d60d4f2a",7,"When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment","This paper presents a novel challenge set consisting of rule-breaking question answering (RBQA) of cases that involve potentially permissible rule- Breaking – inspired by recent moral psychology studies and proposes a novel moral chain of thought prompting strategy that combines the strengths of LLMs with theories of moral reasoning developed in cognitive science to predict human moral judgments.","ArXiv",2022,"Zhijing Jin,Sydney Levine,Fernando Gonzalez,Ojasv Kamal,Maarten Sap,Mrinmaya Sachan,Rada Mihalcea,J. Tenenbaum,B. Schölkopf",1,78,0
"dda0f7f086fc875d583604f8b0cf4a8678bc4de4","https://www.semanticscholar.org/paper/dda0f7f086fc875d583604f8b0cf4a8678bc4de4",7,"Bootstrapping Multilingual Semantic Parsers using Large Language Models","The effectiveness and flexibility offered by large language models (LLMs) for translating English datasets into several languages via few-shot prompting are demonstrated and it is shown that the method of translating data using LLMs outperforms a strong translate-train baseline on 41 out of 50 languages.","ArXiv",2022,"Abhijeet Awasthi,Nitish Gupta,Bidisha Samanta,Shachi Dave,Sunita Sarawagi,P. Talukdar",0,51,0
"4c0f95df93ac75f9ab06b0104e4196a6e8fda25e","https://www.semanticscholar.org/paper/4c0f95df93ac75f9ab06b0104e4196a6e8fda25e",7,"Can GPT-3 Perform Statutory Reasoning?","This paper explores the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset called SARA, and considers a variety of approaches, including dynamic few-shot prompting, chain-of-thought prompting, and zero- shot prompting.","ArXiv",2023,"Andrew Blair-Stanek,Nils Holzenberger,Benjamin Van Durme",0,26,0
"0180d35b85dd4daead90e0652b64b1339e754684","https://www.semanticscholar.org/paper/0180d35b85dd4daead90e0652b64b1339e754684",7,"Assistance with large language models","A behavioral cloning approach is applied to GPT-3 such that it can respond to clear input questions directly, clarify the intent behind vague input questions, and respond based on the clarification it receives, and this approach leads to quantitative improvements in answer accuracy compared to a baseline that cannot ask for clarifications.","",2022,"Dmitrii Krasheninnikov",2,30,0
"58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b","https://www.semanticscholar.org/paper/58aacb967cc7fc25cfc9d51b7ad3e57ac00d119b",7,"Can Foundation Models Wrangle Your Data?","It is found that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks.","Proceedings of the VLDB Endowment",2022,"A. Narayan,Ines Chami,Laurel J. Orr,Christopher R'e",7,91,1
"815c6ca281536d18ec0eb408b6e46e72a0826163","https://www.semanticscholar.org/paper/815c6ca281536d18ec0eb408b6e46e72a0826163",7,"Natural Language to Code Generation in Interactive Data Science Notebooks","P A C H - I NC O, a 62B code language model for Python computational notebooks, which outperforms public code LMs and explores few-shot prompting strategies to elicit better code with step-by-step decomposition and NL explanation, showing the potential to improve the diversity and explainability of model predictions.","ArXiv",2022,"Pengcheng Yin,Wen-Ding Li,Kefan Xiao,A. Rao,Yeming Wen,Kensen Shi,Joshua Howland,Paige Bailey,Michele Catasta,H. Michalewski,Alex Polozov,Charles Sutton",1,60,0
"49293522fe3818769f5067e360c971bd7a82e0aa","https://www.semanticscholar.org/paper/49293522fe3818769f5067e360c971bd7a82e0aa",7,"Explanation Selection Using Unlabeled Data for In-Context Learning","Across four textual reasoning tasks spanning question answering, mathematical reasoning, and natural language inference, results show that the proxy metrics correlate with ground truth accuracy and the overall method can effectively improve prompts over crowdworker annotations and naive search strategies.","ArXiv",2023,"Xi Ye,Greg Durrett",0,37,0
"bd78dab66b19958950d56262a257a1041628aaed","https://www.semanticscholar.org/paper/bd78dab66b19958950d56262a257a1041628aaed",7,"ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation","This work presents a novel zero-shot object navigation method, Exploration with Soft Commonsense constraints (ESC), that transfers commonsense knowledge in pre-trained models to open-world object navigation without any navigation experience nor any other training on the visual environments.","ArXiv",2023,"KAI-QING Zhou,Kai Zheng,Connor Pryor,Yilin Shen,Hongxia Jin,L. Getoor,X. Wang",0,45,0
"87126a964ed14d0d2207747fc732b197e2fc9493","https://www.semanticscholar.org/paper/87126a964ed14d0d2207747fc732b197e2fc9493",7,"Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer","It is demonstrated for the first time that an end-to-end trained single Transformer can achieve both competitive retrieval and QA performance on in-domain datasets, matching or even slightly outperforming state-of-the-art dense retrievers and readers.","Conference on Empirical Methods in Natural Language Processing",2022,"Zhengbao Jiang,Luyu Gao,J. Araki,Haibo Ding,Zhiruo Wang,Jamie Callan,Graham Neubig",0,50,0
"a3a241e9397fe29b37f96cb5e8f4b8bebed3d3da","https://www.semanticscholar.org/paper/a3a241e9397fe29b37f96cb5e8f4b8bebed3d3da",7,"STREET: A Multi-Task Structured Reasoning and Explanation Benchmark","STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark, is introduced to provide a way for the community to better train and test systems on multi-step reasoning and explanations in natural language.","",2023,"D. Ribeiro,Shen Wang,Xiaofei Ma,He Zhu,Rui Dong,Deguang Kong,Juliette Burger,Anjelica Ramos,William Yang Wang,Zhiheng Huang,G. Karypis,Bing Xiang,D. Roth",0,50,0
"f9838a3be5c94bb2674a0e224de349b50e18f3c4","https://www.semanticscholar.org/paper/f9838a3be5c94bb2674a0e224de349b50e18f3c4",7,"Learning To Retrieve Prompts for In-Context Learning","This work proposes an efficient method for retrieving prompts for in-context learning using annotated data and an LM, and trains an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time.","North American Chapter of the Association for Computational Linguistics",2021,"Ohad Rubin,Jonathan Herzig,Jonathan Berant",75,59,10
"6d86f08a5d936780a4785acfad92f5f3e82004ad","https://www.semanticscholar.org/paper/6d86f08a5d936780a4785acfad92f5f3e82004ad",7,"Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks","It is shown that when concatenating intermediate supervision to the input and training a sequence-to-sequence model on this modified input, unlearnable composite problems can become learnable.","ArXiv",2022,"Noam Wies,Yoav Levine,A. Shashua",3,62,0
"452cf9f8b756995363baa659976b30cb09893c89","https://www.semanticscholar.org/paper/452cf9f8b756995363baa659976b30cb09893c89",7,"Decoupled Context Processing for Context Augmented Language Modeling","It is shown that such a simple architecture for incorporating external context into language models based on decoupled Encoder-Decoder architecture achieves competitive results on auto-regressive language modeling and open domain question answering tasks.","ArXiv",2022,"Zonglin Li,Ruiqi Guo,Surinder Kumar",5,43,0
"0ef6fc10b3283e2730843e8a7cbaf342d46237e0","https://www.semanticscholar.org/paper/0ef6fc10b3283e2730843e8a7cbaf342d46237e0",7,"Context Generation Improves Open Domain Question Answering","This work proposes a two-stage, closed-book QA framework which employs a coarse-to-ﬁne approach to extract relevant knowledge and answer a question and is able to better exploit the stored knowledge in pretrained LMs without adding extra learnable parameters or needing ﬁnetuning.","ArXiv",2022,"Dan Su,M. Patwary,Shrimai Prabhumoye,Peng Xu,R. Prenger,M. Shoeybi,Pascale Fung,Anima Anandkumar,Bryan Catanzaro",0,31,0
"a8394722079c251d360fbbc53137753849a64c63","https://www.semanticscholar.org/paper/a8394722079c251d360fbbc53137753849a64c63",7,"Careful Data Curation Stabilizes In-context Learning","It is shown that curating a carefully chosen subset of training data greatly stabilizes ICL performance, and that stable subset examples are no more diverse than average, and are not outliers in terms of sequence length and perplexity.","ArXiv",2022,"Ting-Yun Chang,Robin Jia",0,45,0
"01404a50a3c0c065da3391c60dda49a0cab36251","https://www.semanticscholar.org/paper/01404a50a3c0c065da3391c60dda49a0cab36251",7,"A Review and a Taxonomy of Edge Machine Learning: Requirements, Paradigms, and Techniques","A comprehensive taxonomy and a systematic review of Edge ML techniques are provided, identifying the Edge ML requirements driven by the joint constraints and analyzing how each technique fits into Edge ML by meeting a subset of the identified requirements.","",2023,"Wenbin Li,Hakim Hacid,Ebtesam Almazrouei,M. Debbah",0,246,0
"64da659c0687762359226b4cf455520c78acd165","https://www.semanticscholar.org/paper/64da659c0687762359226b4cf455520c78acd165",7,"Neural Language Generation: Formulation, Methods, and Evaluation","There is no standard way to assess the quality of text produced by these generative models, which constitutes a serious bottleneck towards the progress of the field, so this survey will provide an informative overview of formulations, methods, and assessments of neural natural language generation.","ArXiv",2020,"Cristina Garbacea,Q. Mei",17,504,2
"9b5fb07df99b0dd65f3058701d7f017c3a70c144","https://www.semanticscholar.org/paper/9b5fb07df99b0dd65f3058701d7f017c3a70c144",7,"Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data","This work formulated four prompt designs with different structures and personas to explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably and discusses the opportunities and challenges of building chatbots with LLMs.","ArXiv",2023,"Jing Wei,Sungdong Kim,Hyunhoon Jung,Young-Ho Kim",0,102,0
"66c52c6ef45cdd77c086996bcaaf01470e82dbd2","https://www.semanticscholar.org/paper/66c52c6ef45cdd77c086996bcaaf01470e82dbd2",7,"Piloting Copilot and Codex: Hot Temperature, Cold Prompts, or Black Magic?","The results showed that varying the input parameters can significantly improve the performance of language models, however, there is a tight dependency when varying the temperature, the prompt and the number of generated solutions, making potentially hard for developers to properly control the parameters to obtain an optimal result.","ArXiv",2022,"Jean-Baptiste Döderlein,M. Acher,D. Khelladi,B. Combemale",1,46,0
"538288d24bdad73d831dfed44b706958287ed318","https://www.semanticscholar.org/paper/538288d24bdad73d831dfed44b706958287ed318",7,"Generating Sequences by Learning to Self-Correct","SELF - CORRECTION is presented, an approach that decouples an imperfect base generator from a separate corrector that learns to iteratively correct imperfect generations and improves upon the base generator in three diverse generation tasks– mathematical program synthesis, lexically-constrained generation, and toxicity control.","ArXiv",2022,"S. Welleck,Ximing Lu,Peter West,Faeze Brahman,T. Shen,Daniel Khashabi,Yejin Choi",6,39,0
"048ed70192de0232086eb32a95ffb3be8d336c76","https://www.semanticscholar.org/paper/048ed70192de0232086eb32a95ffb3be8d336c76",7,"Metaphors We Learn By","This essay relates parameter sharing (“weight sharing”) to analogy making and the school of thought of cognitive metaphor, and discusses how recurrent and auto-regressive models can be thought of as extending analogy making from static features to dynamic skills and procedures.","ArXiv",2022,"R. Memisevic",0,36,0
"c66704e04b0ca1f3664a85ad0a505c5d8f933ecd","https://www.semanticscholar.org/paper/c66704e04b0ca1f3664a85ad0a505c5d8f933ecd",7,"What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary","This work proposes to interpret the vector representations produced by dual encoders by projecting them into the model’s vocabulary space, and shows that the resulting distributions over vocabulary tokens are intuitive and contain rich semantic information.","ArXiv",2022,"Ori Ram,L. Bezalel,Adi Zicher,Yonatan Belinkov,Jonathan Berant,A. Globerson",0,55,0
"ab2aa46bbe305627113499ee57958e2e1f55bc25","https://www.semanticscholar.org/paper/ab2aa46bbe305627113499ee57958e2e1f55bc25",7,"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?","Analysis of common attributes shared by effective prompts reveals that effective prompts are topically related to the task domain and calibrate the prior probability of label words, and proposes a human readable prompt tuning method based on Langevin dynamics.","ArXiv",2022,"Weijia Shi,Xiaochuang Han,Hila Gonen,Ari Holtzman,Yulia Tsvetkov,Luke Zettlemoyer",1,34,1
"224b8cd8c31cfa86c2a84bec3a65d9ba44f38280","https://www.semanticscholar.org/paper/224b8cd8c31cfa86c2a84bec3a65d9ba44f38280",7,"iPrompt: Explaining Data Patterns in Natural Language via Interpretable Autoprompting","Inter interpretable autoprompting ( iPrompt ), an algorithm that generates a natural language string explaining the data that is human-interpretable and able to aid in scientiﬁc discovery.","",2023,"Chandan Singh,John X. Morris,J. Aneja,Alexander M. Rush,Jianfeng Gao",0,71,0
"259b7a01700c39d5669e88d1434873ea38a13528","https://www.semanticscholar.org/paper/259b7a01700c39d5669e88d1434873ea38a13528",7,"In-Context Policy Iteration","An algorithm, ICPI, that learns to perform RL tasks without expert demonstrations or gradients, and is presented as a policy-iteration method in which the prompt content is the entire locus of learning.","ArXiv",2022,"Ethan Brooks,Logan Walls,Richard L. Lewis,Satinder Singh",1,39,0
"478f85aa1731c3929f020a39cff8922071834bf7","https://www.semanticscholar.org/paper/478f85aa1731c3929f020a39cff8922071834bf7",7,"Broken Neural Scaling Laws","A smoothly broken power law functional form that accurately models and extrapolates the scaling behaviors of deep neural networks for a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings is presented.","ArXiv",2022,"Ethan Caballero,Kshitij Gupta,I. Rish,David Krueger",2,44,0
"ebd4bec684808aff360b5f255d15c0d112ba13d3","https://www.semanticscholar.org/paper/ebd4bec684808aff360b5f255d15c0d112ba13d3",7,"Explicit Knowledge Transfer for Weakly-Supervised Code Generation","This paper proposes explicit knowledge transfer (EKT), which uses the few-shot capabilities of a teacher LLM to create NL-code pairs that are filter for correctness and fine-tune the student on, and finds that EKT not only yields better performance than training with expert iteration, but also outperforms knowledge distillation, another form of knowledge transfer.","ArXiv",2022,"Zhangir Azerbayev,Ansong Ni,Hailey Schoelkopf,Dragomir R. Radev",0,29,0
"70feb009bc1e8b1cb8dff64bf9fd67789636438b","https://www.semanticscholar.org/paper/70feb009bc1e8b1cb8dff64bf9fd67789636438b",7,"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models","Img2Prompt is a plug-and-play module that provides the prompts that can bridge the aforementioned modality and task disconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end training.","ArXiv",2022,"Jiaxian Guo,Junnan Li,Dongxu Li,A. M. H. Tiong,Boyang Li,Dacheng Tao,Steven Hoi",0,68,0
"f2a68932d9238209cf870058071be6903ae945a4","https://www.semanticscholar.org/paper/f2a68932d9238209cf870058071be6903ae945a4",7,"Compositional Exemplars for In-context Learning","This work proposes CEIL (Compositional Exemplars for In-context Learning), which is instantiated by Determinantal Point Processes (DPPs) to model the interaction between the given input and in-context examples, and optimized through a carefully-designed contrastive learning objective to obtain preference from LMs.","ArXiv",2023,"Jiacheng Ye,Zhiyong Wu,Jiangtao Feng,Tao Yu,Lingpeng Kong",0,60,0
"914254fac74a2da051cccf6ca16afcaad416a079","https://www.semanticscholar.org/paper/914254fac74a2da051cccf6ca16afcaad416a079",7,"AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model","It is demonstrated that multilingual large-scale sequence-to-sequence (seq2seq) models, pre-trained on a mixture of denoising and Causal Language Modeling (CLM) tasks, are more eﬃcient few-shot learners than decoder-only models on various tasks.","ArXiv",2022,"Saleh Soltan,Shankar Ananthakrishnan,Jack G. M. FitzGerald,Rahul Gupta,Wael Hamza,Haidar Khan,Charith S. Peris,Stephen Rawls,Andrew Rosenbaum,Anna Rumshisky,Chandan Prakash,Mukund Sridhar,Fabian Triefenbach,Apurv Verma,G. Tur,Premkumar Natarajan",10,81,1
"8345d757e9127eff382d5285fef99312eaf283cd","https://www.semanticscholar.org/paper/8345d757e9127eff382d5285fef99312eaf283cd",7,"WikiWhy: Answering and Explaining Cause-and-Effect Questions","WIKIWHY is introduced, a QA dataset built around a novel auxiliary task: explaining why an answer is true in natural language, which demands rigorous explicit rationales for each answer to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized.","ArXiv",2022,"Matthew Ho,Aditya Sharma,Justin Chang,Michael Stephen Saxon,Sharon Levy,Yujie Lu,William Yang Wang",0,46,0
"12f0560f2973a56f70e5503ba260725161fc46a8","https://www.semanticscholar.org/paper/12f0560f2973a56f70e5503ba260725161fc46a8",7,"Reinforced Question Rewriting for Conversational Question Answering","Experiments show that the proposed approach can effectively improve QA performance over baselines for both extractive and retrieval QA, and human evaluation shows that the method can generate more accurate and detailed rewrites when compared to human annotations.","ArXiv",2022,"Zhiyu Chen,Jie Zhao,Anjie Fang,B. Fetahu,O. Rokhlenko,S. Malmasi",1,22,0
"fba0b0817dbc8200b41a1de22654b54b778a11e9","https://www.semanticscholar.org/paper/fba0b0817dbc8200b41a1de22654b54b778a11e9",7,"Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models","This work does the first large-scale study to evaluate the effectiveness of GPT-3.x models for helping engineers root cause and mitigate production incidents and compares several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics.","ArXiv",2023,"Toufique Ahmed,Supriyo Ghosh,Chetan Bansal,T. Zimmermann,Xuchao Zhang,S. Rajmohan",0,64,0
"9b9b292bd7814fb9c62b8609e8c28c8693a078f5","https://www.semanticscholar.org/paper/9b9b292bd7814fb9c62b8609e8c28c8693a078f5",7,"EditEval: An Instruction-Based Benchmark for Text Improvements","An instruction-based, benchmark and evaluation suite that leverages high-quality existing and new datasets for automatic evaluation of editing capabilities such as making text more cohesive and paraphrasing and un-lock future research in developing models capable of iterative and more controllable editing.","ArXiv",2022,"Jane Dwivedi-Yu,Timo Schick,Zhengbao Jiang,M. Lomeli,Patrick Lewis,Gautier Izacard,Edouard Grave,Sebastian Riedel,Fabio Petroni",0,57,0
"d9d12205007ac48b03d921225f9cdaf90f7c3fdd","https://www.semanticscholar.org/paper/d9d12205007ac48b03d921225f9cdaf90f7c3fdd",7,"Model Criticism for Long-Form Text Generation","This work proposes to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text and finds that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference.","Conference on Empirical Methods in Natural Language Processing",2022,"Yuntian Deng,Volodymyr Kuleshov,Alexander M. Rush",2,84,0
"7ebdc4ed93e37e7d3691085f4d08c495557ba71b","https://www.semanticscholar.org/paper/7ebdc4ed93e37e7d3691085f4d08c495557ba71b",7,"A survey on knowledge-enhanced multimodal learning","The current survey aims to unify the fields of VL representation learning and knowledge graphs, and provides a taxonomy and analysis of knowledge-enhanced VL models.","ArXiv",2022,"Maria Lymperaiou,G. Stamou",0,259,0
"46d0a832fada6147bceb0bd4e39928e482733246","https://www.semanticscholar.org/paper/46d0a832fada6147bceb0bd4e39928e482733246",7,"How Important are Good Method Names in Neural Code Generation? A Model Robustness Perspective","The potential of benefiting from method names to enhance the performance of PCGMs, from a model robustness perspective, is studied and a novel approach is proposed, named RADAR (neuRAl coDe generAtor Robustifier).","ArXiv",2022,"Guang Yang,Yu Zhou,Wenhua Yang,Tao Yue,Xiang Chen,Taolue Chen",0,75,0
"ef52ba73fbf41eed320a479f5736e127d3a06049","https://www.semanticscholar.org/paper/ef52ba73fbf41eed320a479f5736e127d3a06049",7,"KPT: Keyword-guided Pre-training for Grounded Dialog Generation","This work proposes KPT (Keyword-guided Pre-Training), a novel self-supervised pre-training method for grounded dialog generation without relying on extra knowledge annotation, and demonstrates that KPT consistently outperforms state-of-the-art methods on these tasks with diverse grounding knowledge.","ArXiv",2022,"Qi Zhu,Fei Mi,Zheng Zhang,Yasheng Wang,Yitong Li,Xin Jiang,Qun Liu,Xiaoyan Zhu,Minlie Huang",0,53,0
"6d4e540e1bed26679097139bf90c8652919e4e5c","https://www.semanticscholar.org/paper/6d4e540e1bed26679097139bf90c8652919e4e5c",7,"Explanation Regeneration via Information Bottleneck","This work develops an information bottleneck method EIB that regenerates the free-text explanation by polishing the single-pass output from the pretrained language model but retaining the information that supports the contents being explained.","ArXiv",2022,"Qintong Li,Zhiyong Wu,Lingpeng Kong,Wei Bi",0,57,0
"d7ea898cc97754e06d209df0fd55ab60250601f2","https://www.semanticscholar.org/paper/d7ea898cc97754e06d209df0fd55ab60250601f2",7,"Contrastive Learning Reduces Hallucination in Conversations","A novel mixed contrastive objective is proposed to explicitly optimize the implicit knowledge elicitation process of LMs, and thus reduce their hallucination in conversations, and it is shown that MixCL achieves comparable performance to state-of-the-art KB-based approaches while enjoying notable advantages in terms of efficiency and scalability.","ArXiv",2022,"Weiwei Sun,Zhengliang Shi,Shen Gao,Pengjie Ren,M. de Rijke,Z. Ren",1,60,0
"9a0ffb6156763be319a1ea39c9fac4080bc61182","https://www.semanticscholar.org/paper/9a0ffb6156763be319a1ea39c9fac4080bc61182",7,"Reinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations","","ArXiv",2022,"Valentina Pyatkin,Jena D. Hwang,Vivek Srikumar,Ximing Lu,Liwei Jiang,Yejin Choi,Chandra Bhagavatula",1,34,0
"8cd67f8671a9469037933c00f983491d1712f18e","https://www.semanticscholar.org/paper/8cd67f8671a9469037933c00f983491d1712f18e",7,"A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding","This work presents the diverse approaches to ATS guided by the mechanisms they use to generate a summary and presents an empirical exploration of these methods using the CNN Corpus dataset that provides golden summaries for extractive and abstractive methods.","ArXiv",2023,"D. O. Cajueiro,A. G. Nery,Igor Tavares,M. K. D. Melo,Silvia A. dos Reis,L. Weigang,V. R. R. Celestino",0,346,0
"1cdfa7c3465943a295f8df2d2097c4bb3e222426","https://www.semanticscholar.org/paper/1cdfa7c3465943a295f8df2d2097c4bb3e222426",7,"Rationalization for Explainable NLP: A Survey","This survey presents available methods, explainable evaluations, code, and datasets used across various NLP tasks that use rationalization, and a new subfield in Explainable AI (XAI), namely, Rational AI (RAI), is introduced to advance the current state of rationalization.","ArXiv",2023,"Sai Gurrapu,Ajay Kulkarni,Lifu Huang,Ismini Lourentzou,Laura J. Freeman,Feras A. Batarseh",1,97,0
"572e82dfdde0f72f9448caf72fdc68a233da6659","https://www.semanticscholar.org/paper/572e82dfdde0f72f9448caf72fdc68a233da6659",7,"Open Problems in Applied Deep Learning","This work formulates the machine learning mechanism as a bi-level optimization problem, and considers case specific and complex cases while increasing the level of complexity from supervised learning to semi-supervised, self-super supervised, un supervised, few-shot, federated, reinforcement, and physics-informed learning.","ArXiv",2023,"M. Raissi",1,280,0
"6a4901e3bc255dd9c14d1e0d9e76e46cdd0f0ac0","https://www.semanticscholar.org/paper/6a4901e3bc255dd9c14d1e0d9e76e46cdd0f0ac0",7,"Retrieval-augmented Image Captioning","A new approach to image captioning that generates sentences given the input image and a set of captions retrieved from a datastore, as opposed to the image alone, is presented.","",2023,"R. Ramos,Desmond Elliott,Bruno Martins",0,58,0
"6e10343767ab09dde83cf99ea3442907402a9810","https://www.semanticscholar.org/paper/6e10343767ab09dde83cf99ea3442907402a9810",7,"Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing","Limits of current techniques for effectively leveraging model scale for compositional generalization are highlighted, while the analysis also suggests promising directions for future work.","Conference on Empirical Methods in Natural Language Processing",2022,"Linlu Qiu,Peter Shaw,Panupong Pasupat,Tianze Shi,Jonathan Herzig,Emily Pitler,Fei Sha,Kristina Toutanova",10,84,2
"1be5064847c7a5e9a7e516e4c21aa8f4f8ab2eb5","https://www.semanticscholar.org/paper/1be5064847c7a5e9a7e516e4c21aa8f4f8ab2eb5",7,"Multi-Game Decision Transformers","It is shown that a single transformer-based model – with a single set of weights – trained purely ofﬂine can play a suite of up to 46 Atari games simultaneously at close-to-human performance.","ArXiv",2022,"Kuang-Huei Lee,Ofir Nachum,Mengjiao Yang,L. Lee,Daniel Freeman,Winnie Xu,S. Guadarrama,Ian S. Fischer,Eric Jang,H. Michalewski,Igor Mordatch",37,84,10
"7cf4f8cb8b4a373d869e785b79160dda7a49a250","https://www.semanticscholar.org/paper/7cf4f8cb8b4a373d869e785b79160dda7a49a250",7,"Exploring The Landscape of Distributional Robustness for Question Answering Models","This investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods, and indicates that zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models.","Conference on Empirical Methods in Natural Language Processing",2022,"Anas Awadalla,Mitchell Wortsman,Gabriel Ilharco,Sewon Min,Ian H. Magnusson,Hannaneh Hajishirzi,Ludwig Schmidt",0,78,0
"d3ec78e4eeb88d7d292a8085d5cd18b254379816","https://www.semanticscholar.org/paper/d3ec78e4eeb88d7d292a8085d5cd18b254379816",7,"Inverse scaling can become U-shaped","","ArXiv",2022,"Jason Wei,Yi Tay,Quoc V. Le",4,15,1
"b3598a2f6c4e8a9e6d89de10b46bfad8e016ab2e","https://www.semanticscholar.org/paper/b3598a2f6c4e8a9e6d89de10b46bfad8e016ab2e",7,"Astronomia ex machina: a history, primer, and outlook on neural networks in astronomy","","ArXiv",2022,"Michael J. Smith,J. Geach",0,266,0
"094a2e887a983b4891f3bb5b4cafd68500508d92","https://www.semanticscholar.org/paper/094a2e887a983b4891f3bb5b4cafd68500508d92",7,"'Rarely' a problem? Language models exhibit inverse scaling in their predictions following 'few'-type quantifiers","Not only do the models perform poorly on few -type quantiﬁers, but overall the larger the model, the worse its performance, and it is argued that decreasing performance of larger models may challenge uses of Language Models as the basis for Natural Language Systems.","ArXiv",2022,"J. Michaelov,B. Bergen",1,47,0
"ac9bd7da3331d699008444925ef1121cc7178dc3","https://www.semanticscholar.org/paper/ac9bd7da3331d699008444925ef1121cc7178dc3",7,"Rethinking the Role of Scale for In-Context Learning: An Interpretability-based Case Study at 66 Billion Scale","The hypothesis that the ability of a large language model to in-context learn-perform a task is not uniformly spread across all of its underlying components is investigated and a small set of attention heads score highly on their ability to perform primitive induction operations associated with in- context learning, namely, preﬁx matching and copying.","ArXiv",2022,"Hritik Bansal,Karthik Gopalakrishnan,Saket Dingliwal,S. Bodapati,Katrin Kirchhoff,D. Roth",1,43,0
"65043331280851b767df238fabca32f6c52f1148","https://www.semanticscholar.org/paper/65043331280851b767df238fabca32f6c52f1148",7,"Training Trajectories of Language Models Across Scales","Analyzing the intermediate training checkpoints of differently sized OPT models shows that perplexity is more predictive of model behaviors than model size or training computation.","ArXiv",2022,"M. Xia,Mikel Artetxe,Chunting Zhou,Xi Victoria Lin,Ramakanth Pasunuru,Danqi Chen,Luke Zettlemoyer,V. Stoyanov",0,38,0
"3d849136e0070f6d038dd96985ed67ead5aedb69","https://www.semanticscholar.org/paper/3d849136e0070f6d038dd96985ed67ead5aedb69",7,"Locally Typical Sampling","This work posit that the abstraction of natural language generation as a discrete stochastic process—which allows for an information-theoretic analysis—can provide new insights into the behavior of probabilistic language generators, for example, why high-probability texts can be dull or repetitive.","Transactions of the Association for Computational Linguistics",2022,"Clara Meister,Tiago Pimentel,Gian Wiher,Ryan Cotterell",10,61,6
"3b16a709a5b18e52b0b6741cbc3c0e68a03ecd8e","https://www.semanticscholar.org/paper/3b16a709a5b18e52b0b6741cbc3c0e68a03ecd8e",7,"The unreasonable effectiveness of few-shot learning for machine translation","It is shown that with only 5 examples of high-quality translation data shown at inference, a transformer decoder-only model trained solely with self-supervised learning, is able to match specialized supervised state-of-the-art models as well as more general commercial translation systems.","ArXiv",2023,"Xavier García,Yamini Bansal,Colin Cherry,George F. Foster,M. Krikun,Fan Feng,Melvin Johnson,Orhan Firat",0,57,0
"ccf15b75d3ed3287c0ac524666578ed785bff1a3","https://www.semanticscholar.org/paper/ccf15b75d3ed3287c0ac524666578ed785bff1a3",7,"Big Little Transformer Decoder","Big Little Decoder (BiLD) is proposed, a framework that can improve inference efficiency and latency for a wide range of text generation applications and is fully plug-and-play as it does not require any training or modifications to model architectures.","",2023,"Sehoon Kim,Karttikeya Mangalam,J. Malik,Michael W. Mahoney,A. Gholami,K. Keutzer",0,78,0
"9cd0cb3af7c2215eae9afdcf500a2bcd5330aae3","https://www.semanticscholar.org/paper/9cd0cb3af7c2215eae9afdcf500a2bcd5330aae3",7,"20Q: Overlap-Free World Knowledge Benchmark for Language Models","20Q is introduced, a novel benchmark using the Twenty Questions game to evaluate world knowledge and common sense of language models and shows that in-context learning is inefficient for evaluating language models’ world knowledge — fine-tuning is necessary to show their true capabilities.","IEEE Games Entertainment Media Conference",2022,"Maxime De Bruyn,Ehsan Lotfi,Jeska Buhmann,Walter Daelemans",0,36,0
"374dd173491a59a10bbb2b3519ebcfe3649f529d","https://www.semanticscholar.org/paper/374dd173491a59a10bbb2b3519ebcfe3649f529d",7,"Teaching Models to Express Their Uncertainty in Words","It is shown that a GPT-3 model can learn to express uncertainty about its own answers in natural language – without use of model logits – and is sensitive to uncertainty in its own Answers, rather than imitating human examples.","ArXiv",2022,"Stephanie C. Lin,Jacob Hilton,Owain Evans",9,35,3
"6fb0b072c4fcdc0c78218bfd1b181fd562f07cd2","https://www.semanticscholar.org/paper/6fb0b072c4fcdc0c78218bfd1b181fd562f07cd2",7,"COMPS: Conceptual Minimal Pair Sentences for testing Robust Property Knowledge and its Inheritance in Pre-trained Language Models","It is found that PLMs can demonstrate behavior consistent with property inheritance to a great extent, but fail in the presence of distracting information, which decreases the performance of many models, sometimes even below chance.","",2022,"Kanishka Misra,J. Rayz,Allyson Ettinger",0,87,0
"be09ed6cd73654a23f78416433a1b23ea623ea79","https://www.semanticscholar.org/paper/be09ed6cd73654a23f78416433a1b23ea623ea79",7,"Symbolic Behaviour in Artificial Intelligence","This work argues that the path towards symbolically fluent artificial intelligence (AI) begins with a reinterpretation of what symbols are, how they come to exist, and how a system behaves when it uses them, and suggests that AI research explore social and cultural engagement as a tool to develop the cognitive machinery necessary for symbolic behaviour to emerge.","ArXiv",2021,"Adam Santoro,Andrew Kyle Lampinen,K. Mathewson,T. Lillicrap,David Raposo",19,139,0
"7fa273f450251523e6b7fcc2eb3fdbdfd4a30493","https://www.semanticscholar.org/paper/7fa273f450251523e6b7fcc2eb3fdbdfd4a30493",7,"CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in NLP","This paper presents the NLP Few-shot Gym, a repository of 160 diverse few-shot NLP tasks created from open-access NLP datasets and converted to a unified text-to-text format, and reveals that the few- shot learning ability on unseen tasks can be improved via an upstream learning stage using a set of seen tasks.","Conference on Empirical Methods in Natural Language Processing",2021,"Qinyuan Ye,Bill Yuchen Lin,Xiang Ren",68,172,18
"d83c7aa12420d5d035f43d7737bfa6893e9e2c61","https://www.semanticscholar.org/paper/d83c7aa12420d5d035f43d7737bfa6893e9e2c61",7,"Exploring Universal Intrinsic Task Subspace via Prompt Tuning","Evidence is shown indicating that the adaptations of PLMs to various few-shot tasks can be reparameterized as optimizing only a few free parameters in a low-dimensional intrinsic task subspace, which may help to understand why PLMs could easily adapt to various NLP tasks with small-scale data.","",2021,"Yujia Qin,Xiaozhi Wang,Yusheng Su,Yankai Lin,Ning Ding,Jing Yi,Weize Chen,Zhiyuan Liu,Juanzi Li,Lei Hou,Peng Li,Maosong Sun,Jie Zhou",3,125,0
"3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e","https://www.semanticscholar.org/paper/3dc7dc1bea9a4f70c02b6759a0bda7aca0005a9e",7,"A General Language Assistant as a Laboratory for Alignment","A ‘preference model pre-training’ stage of training is studied, with the goal of improving sample efﬁciency when ﬁnetuning on human preferences, and investigating scaling trends for several training objectives relevant to alignment.","ArXiv",2021,"Amanda Askell,Yuntao Bai,Anna Chen,Dawn Drain,Deep Ganguli,T. Henighan,Andy Jones,Nicholas Joseph,Benjamin Mann,Nova DasSarma,Nelson Elhage,Zac Hatfield-Dodds,Danny Hernandez,John Kernion,Kamal Ndousse,Catherine Olsson,Dario Amodei,Tom B. Brown,Jack Clark,Sam McCandlish,C. Olah,Jared Kaplan",57,52,3
"2a83a92b08e0f3873d07162c73c67e533321112e","https://www.semanticscholar.org/paper/2a83a92b08e0f3873d07162c73c67e533321112e",7,"Aligning Generative Language Models with Human Values","S ENSEI is a new reinforcement learning based method that can embed human values judgements into each step of language generation and achieves higher alignment performance in terms of both automatic and human evaluations, but also shows improvements on robustness and transfer learning on unseen human values.","NAACL-HLT",2022,"Ruibo Liu,Ge Zhang,Xinyu Feng,Soroush Vosoughi",1,58,0
"47df3fd32d00220c85c2c51a571254fd99b2ecc7","https://www.semanticscholar.org/paper/47df3fd32d00220c85c2c51a571254fd99b2ecc7",7,"MetaICL: Learning to Learn In Context","This work introduces MetaICL (Meta-training for In-Context Learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learning on a large set of training tasks.","North American Chapter of the Association for Computational Linguistics",2021,"Sewon Min,M. Lewis,Luke Zettlemoyer,Hannaneh Hajishirzi",77,136,18
"605c32428861eb26b8631617b8f6c97a850d6a04","https://www.semanticscholar.org/paper/605c32428861eb26b8631617b8f6c97a850d6a04",7,"True Few-Shot Learning with Prompts—A Real-World Perspective","An extensive study of Pet, a method that combines textual instructions with example-based finetuning, shows that, if correctly configured, Pet performs strongly in true few-shot settings without a dev set and underpin the belief that learning from instructions will play an important role on the path towards human-like few- shot learning capabilities.","Transactions of the Association for Computational Linguistics",2021,"Timo Schick,Hinrich Schütze",13,86,2
"9cbc044e315cdefe9a255119037ac7c23e9abdd5","https://www.semanticscholar.org/paper/9cbc044e315cdefe9a255119037ac7c23e9abdd5",7,"Predictability and Surprise in Large Generative Models","This paper highlights a counterintuitive property of large-scale generative models, which have a paradoxical combination of predictable loss on a broad training distribution, and unpredictable specific capabilities, inputs, and outputs, and analyzed how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment.","Conference on Fairness, Accountability and Transparency",2022,"Deep Ganguli,Danny Hernandez,Liane Lovitt,Nova DasSarma,T. Henighan,Andy Jones,Nicholas Joseph,John Kernion,Benjamin Mann,Amanda Askell,Yuntao Bai,Anna Chen,Tom Conerly,Dawn Drain,Nelson Elhage,Sheer El Showk,Stanislav Fort,Zac Hatfield-Dodds,Scott Johnston,S. Kravec,Neel Nanda,Kamal Ndousse,Catherine Olsson,Daniela Amodei,Dario Amodei,Tom B. Brown,Jared Kaplan,Sam McCandlish,C. Olah,Jack Clark",29,92,2
"2145fcceeb69385e108bf1796d52f974854d4c0b","https://www.semanticscholar.org/paper/2145fcceeb69385e108bf1796d52f974854d4c0b",7,"ZeroGen: Efficient Zero-shot Learning via Dataset Generation","It is argued that ZeroGen can also provide useful insights from the perspective of data-free model-agnostic knowledge distillation, and unreferenced text generation evaluation.","Conference on Empirical Methods in Natural Language Processing",2022,"Jiacheng Ye,Jiahui Gao,Qintong Li,Hang Xu,Jiangtao Feng,Zhiyong Wu,Tao Yu,Lingpeng Kong",18,82,1
"1fafaccebc4a74898a74c606f846318c4c2c7536","https://www.semanticscholar.org/paper/1fafaccebc4a74898a74c606f846318c4c2c7536",7,"On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model","This in-depth investigation of the effects of the source and size of the pretraining corpus on in-context learning in HyperCLOVA, a Korean-centric GPT-3 model finds that in- context learning performance heavily depends on the corpus domain source.","North American Chapter of the Association for Computational Linguistics",2022,"Seongjin Shin,Sang-Woo Lee,Hwijeen Ahn,Sungdong Kim,Hyoungseok Kim,Boseop Kim,Kyunghyun Cho,Gichang Lee,W. Park,Jung-Woo Ha,Nako Sung",13,31,1
"08c43a7b09cead543bca41d2f4f64260f3b9d574","https://www.semanticscholar.org/paper/08c43a7b09cead543bca41d2f4f64260f3b9d574",7,"Language Models in the Loop: Incorporating Prompting into Weak Supervision","The experimental evaluation shows that prompting large language models within a weak supervision framework can provide gains in accuracy, and that this approach produces classiﬁers with comparable or superior accuracy to those trained from hand-engineered rules.","ArXiv",2022,"Ryan Smith,Jason Alan Fries,Braden Hancock,Stephen H. Bach",6,71,0
"99752e255a866484291866a5ff5cf94e96d6bdc4","https://www.semanticscholar.org/paper/99752e255a866484291866a5ff5cf94e96d6bdc4",7,"Is a Question Decomposition Unit All We Need?","The findings indicate that Human-in-the-loop Question Decomposition (HQD) can potentially provide an alternate path to building large LMs and provides a viable option to involve people in NLP research in a meaningful way.","Conference on Empirical Methods in Natural Language Processing",2022,"Pruthvi H. Patel,Swaroop Mishra,Mihir Parmar,Chitta Baral",8,40,1
"096c2791c3dd4b123333e324ce88cd97661ffd3f","https://www.semanticscholar.org/paper/096c2791c3dd4b123333e324ce88cd97661ffd3f",7,"Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning","This work develops R ETRO P ROMPT with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization, which can reduce the reliance of language models on memorization and improve generalization for downstream tasks.","ArXiv",2022,"Xiang Chen,Lei Li,Ningyu Zhang,Xiaozhuan Liang,Shumin Deng,Chuanqi Tan,Fei Huang,Luo Si,Huajun Chen",7,76,0
"4bc51cb3ba793de7c06bb77770f2f9a91ff809f7","https://www.semanticscholar.org/paper/4bc51cb3ba793de7c06bb77770f2f9a91ff809f7",7,"MVP: Multi-task Supervised Pre-training for Natural Language Generation","This work collects a large-scale natural language generation corpus, MVPCorpus, from 77 datasets over 11 diverse NLG tasks, and unifies these examples into a general text-to-text format to pre-train the text generation model MVP in a supervised manner.","ArXiv",2022,"Tianyi Tang,Junyi Li,Wayne Xin Zhao,Ji-rong Wen",3,187,0
"2c676ecdc954ec24e1907c76accb1e8ac06deec0","https://www.semanticscholar.org/paper/2c676ecdc954ec24e1907c76accb1e8ac06deec0",7,"Data-Efficiency with a Single GPU: An Exploration of Transfer Methods for Small Language Models","It is demonstrated that instruction tuning provides a modest 2% performance improvement for small models, contrary to prior works on large models.","ArXiv",2022,"Alon Albalak,Akshat Shrivastava,Chinnadhurai Sankar,Adithya Sagar,Mike Ross",0,16,0
"6494c6149e5036c09ee92da9fd67cbecc998a52f","https://www.semanticscholar.org/paper/6494c6149e5036c09ee92da9fd67cbecc998a52f",7,"PCFG-based Natural Language Interface Improves Generalization for Controlled Text Generation","This work proposes a natural language (NL) interface, where a PCFG isCrafted to embed the control attributes into natural language commands, and proposes variants of existing CTG models that take commands as input.","ArXiv",2022,"Jingyu Zhang,James R. Glass,Tianxing He",0,29,0
"bb15f3727f827a3cb88b5d3ca48415c09b40a88f","https://www.semanticscholar.org/paper/bb15f3727f827a3cb88b5d3ca48415c09b40a88f",7,"What Language Model to Train if You Have One Million GPU Hours?","An ablation study at the billion-parameter scale comparing different modeling practices and their impact on zero-shot generalization is performed, and the scaling behaviour of Transformers is considered to choose the target model size, shape, and training setup.","Conference on Empirical Methods in Natural Language Processing",2022,"Teven Le Scao,Thomas Wang,Daniel Hesslow,Lucile Saulnier,Stas Bekman,Saiful Bari,Stella Rose Biderman,Hady ElSahar,Niklas Muennighoff,Jason Phang,Ofir Press,Colin Raffel,Victor Sanh,Sheng Shen,Lintang Sutawika,Jaesung Tae,Zheng Xin Yong,Julien Launay,Iz Beltagy",15,80,1
"68e401c6f90ce421d46b0899458f3c103b4aa29a","https://www.semanticscholar.org/paper/68e401c6f90ce421d46b0899458f3c103b4aa29a",7,"Solving Math Word Problem via Cooperative Reasoning induced Language Models","A cooperative reasoning-induced PLM for solving MWPs is developed, resulting in a human-like reasoning architecture with system 1 as the generator and system 2 as the veriﬁer, and decent improvement over state-of-the-art methods, up to 9.8% increase over best baselines.","ArXiv",2022,"Xinyu Zhu,Junjie Wang,Lin Zhang,Yuxiang Zhang,Ruyi Gan,Jiaxing Zhang,Yujiu Yang",1,26,0
"5de4860323ffaba9b7f5aefeedc2d8db2a529a96","https://www.semanticscholar.org/paper/5de4860323ffaba9b7f5aefeedc2d8db2a529a96",7,"Zero-Label Prompt Selection","A Zero-Label Prompt Selection (ZPS) method that selects prompts without any labeled data or gradient update is proposed that improves over prior methods by a sizeable margin in zero-label performance.","ArXiv",2022,"Chonghua Liao,Yanan Zheng,Zhilin Yang",0,50,0
"2a0953e6aa8a8c4b88928957338e93f8636ebe84","https://www.semanticscholar.org/paper/2a0953e6aa8a8c4b88928957338e93f8636ebe84",7,"Reasoning Circuits: Few-shot Multihop Question Generation with Structured Rationales","A new framework for applying chain-of-thought inspired structured rationale generation to multi-hop question generation under a very low supervision regime is introduced, treating each reasoning step as a separate task to be performed by a generative language model.","ArXiv",2022,"Saurabh Kulshreshtha,Anna Rumshisky",0,38,0
"075129a9380730f985beedd5fe7c78ff8e35cb9b","https://www.semanticscholar.org/paper/075129a9380730f985beedd5fe7c78ff8e35cb9b",7,"Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints","This work proposes sparse upcycling -- a simple way to reuse sunk training costs by initializing a sparsely activated Mixture-of-Experts model from a dense checkpoint, and shows that sparsely upcycled T5 Base, Large, and XL language models and Vision Transformer Base and Large models, respectively, significantly outperform their dense counterparts on SuperGLUE and ImageNet.","ArXiv",2022,"Aran Komatsuzaki,J. Puigcerver,J. Lee-Thorp,Carlos Riquelme Ruiz,Basil Mustafa,J. Ainslie,Yi Tay,M. Dehghani,N. Houlsby",0,56,0
"9f61d366b9d00becb25f7823997c626c6b1d5c16","https://www.semanticscholar.org/paper/9f61d366b9d00becb25f7823997c626c6b1d5c16",7,"One Embedder, Any Task: Instruction-Finetuned Text Embeddings","I NSTRUCT OR is a single embedder that can generate text embeddings tailored to different downstream tasks and domains, without any further training, and achieves state-of-the-art performance on diverse datasets.","ArXiv",2022,"Hongjin Su,Weijia Shi,Jungo Kasai,Yizhong Wang,Yushi Hu,Mari Ostendorf,Wen-tau Yih,Noah A. Smith,Luke Zettlemoyer,Tao Yu",2,78,0
"397e0e0d20f00d8fbfecd2fd36b14f13e2181d0e","https://www.semanticscholar.org/paper/397e0e0d20f00d8fbfecd2fd36b14f13e2181d0e",7,"Layer Norm Attention Layer Norm Router from scratch MLP 1 MLP 2 MLP","This work proposes sparse upcycling – a simple way to reuse sunk training costs by initializing a sparsely activated Mixture-of-Experts model from a dense checkpoint, and shows that sparsely upcycled T5 Base, Large, and XL language models and Vision Transformer Base and Large models, respectively, significantly outperform their dense counterparts on SuperGLUE and ImageNet.","",2023,"C. Riquelme,Basil Mustafa,J. Ainslie",0,55,0
"c879413103f8950bdd414c7f60a39bd7748c9be8","https://www.semanticscholar.org/paper/c879413103f8950bdd414c7f60a39bd7748c9be8",7,"Prompting Large Language Model for Machine Translation: A Case Study","A systematic study on prompting strategies for translation, examining various factors for prompt template and demonstration example selection, and exploring the use of monolingual data and the feasibility of cross-lingual, cross-domain, and sentence-to-document transfer learning in prompting.","ArXiv",2023,"Biao Zhang,B. Haddow,Alexandra Birch",1,38,0
"0e3d1457a66e442fae46c8f96886dc76aef3b085","https://www.semanticscholar.org/paper/0e3d1457a66e442fae46c8f96886dc76aef3b085",7,"Offsite-Tuning: Transfer Learning without Full Model","Offsite-tuning can achieve comparable accuracy as full model fine- Tuning while being privacy-preserving and efficient, achieving 6.5x speedup and 5.6x memory reduction.","ArXiv",2023,"Guangxuan Xiao,Ji Lin,Song Han",1,56,0
"0cf694b8f85ab2e11d45595de211a15cfbadcd22","https://www.semanticscholar.org/paper/0cf694b8f85ab2e11d45595de211a15cfbadcd22",7,"Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks","It is shown that instruction-following large language models can produce targeted malicious content, including hate speech and scams, bypassing in-the-wild defenses implemented by LLM API vendors.","ArXiv",2023,"Daniel Kang,Xuechen Li,I. Stoica,Carlos Guestrin,M. Zaharia,Tatsunori Hashimoto",0,49,0
"04407b388432e957031cebd1859e868c96006522","https://www.semanticscholar.org/paper/04407b388432e957031cebd1859e868c96006522",7,"Artefact Retrieval: Overview of NLP Models with Knowledge Base Access","This paper systematically describes the typology of artefacts, retrieval mechanisms and the way these artefacts are fused into the model to uncover combinations of design decisions that had not yet been tried in NLP systems.","ArXiv",2022,"Vilém Zouhar,Marius Mosbach,Debanjali Biswas,D. Klakow",3,88,0
"32c9b3859086d15184989454eb878638659e64c6","https://www.semanticscholar.org/paper/32c9b3859086d15184989454eb878638659e64c6",7,"MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge","This work introduces M INE D OJO, a new framework built on the popular Minecraft game that features a simulation suite with thousands of diverse open-ended tasks and an internet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and forum discussions and proposes a novel agent learning algorithm that leverages large pre-trained video-language models as a learned reward function.","ArXiv",2022,"Linxi (Jim) Fan,Guanzhi Wang,Yunfan Jiang,Ajay Mandlekar,Yuncong Yang,Haoyi Zhu,Andrew Tang,De-An Huang,Yuke Zhu,Anima Anandkumar",28,131,6
"e3a9af420cd2c0c8241856da92374027fefb87be","https://www.semanticscholar.org/paper/e3a9af420cd2c0c8241856da92374027fefb87be",7,"Language Model Cascades","Existing techniques from probabilistic programming, including scratchpads / chain of thought, veriﬁers, STaR, selection-inference, and tool use are formalized and referred to as language model cascades.","ArXiv",2022,"David Dohan,Winnie Xu,Aitor Lewkowycz,Jacob Austin,David Bieber,Raphael Gontijo Lopes,Yuhuai Wu,H. Michalewski,R. Saurous,Jascha Narain Sohl-Dickstein,Kevin Murphy,Charles Sutton",27,30,3
"35f5483fa6c1816739b604a5bb57719fadd79249","https://www.semanticscholar.org/paper/35f5483fa6c1816739b604a5bb57719fadd79249",7,"Affective Faces for Goal-Driven Dyadic Communication","A video framework for modeling the association between verbal and non-verbal communication during dyadic conversation and is able to output listeners that are significantly more socially appropriate than baselines is introduced.","ArXiv",2023,"Scott Geng,Revant Teotia,Purva Tendulkar,Sachit Menon,Carl Vondrick",0,56,0
"5a87204ba586f81c7a0d9f02a3af572a710ae24e","https://www.semanticscholar.org/paper/5a87204ba586f81c7a0d9f02a3af572a710ae24e",7,"IC3: Image Captioning by Committee Consensus","This work introduces a simple, yet novel, method, designed to generate a single caption that captures high-level details from several viewpoints, that can improve the performance of SOTA automated recall systems by up to 84%, indicating significant material improvements over existing SOTA approaches for visual description.","ArXiv",2023,"David Chan,Austin Myers,Sudheendra Vijayanarasimhan,David A. Ross,J. Canny",0,62,0
"4168325b82e9d296f11e71c8f56b3107ee297cc2","https://www.semanticscholar.org/paper/4168325b82e9d296f11e71c8f56b3107ee297cc2",7,"Distilling Internet-Scale Vision-Language Models into Embodied Agents","This work outlines a new and effective way to use internet-scale VLMs, repur-posing the generic language grounding acquired by such models to teach task-relevant groundings to embodied agents.","ArXiv",2023,"T. Sumers,Kenneth Marino,Arun Ahuja,R. Fergus,I. Dasgupta",0,63,0
"62ddfa4d7e85ef390052aced081514c78a0a42b3","https://www.semanticscholar.org/paper/62ddfa4d7e85ef390052aced081514c78a0a42b3",7,"DePlot: One-shot visual language reasoning by plot-to-table translation","The key in this method is a modality conversion module, named as D E P LOT, which translates the image of a plot or chart to a linearized table, and can be used off-the-shelf to-gether with LLMs in a plug-and-play fashion.","ArXiv",2022,"Fangyu Liu,Julian Martin Eisenschlos,Francesco Piccinno,Syrine Krichene,Chenxi Pang,Kenton Lee,Mandar Joshi,Wenhu Chen,N. Collier,Y. Altun",0,30,0
"6d269364de402d4a72ac30b0c8d81324f6849807","https://www.semanticscholar.org/paper/6d269364de402d4a72ac30b0c8d81324f6849807",7,"LEVER: Learning to Verify Language-to-Code Generation with Execution","This work proposes LEVER, a simple approach to improve language-to-code generation by learning to verify the generated programs with their execution results, which consistently improves over the base CodeLMs and achieves new state-of-the-art results on all of them.","",2023,"Ansong Ni,Srini Iyer,Dragomir R. Radev,V. Stoyanov,Wen-tau Yih,Sida I. Wang,Xi Victoria Lin",0,58,0
"7de648a460947ba0516eb88f83c33c50bbee2f15","https://www.semanticscholar.org/paper/7de648a460947ba0516eb88f83c33c50bbee2f15",6,"Distributed Deep Reinforcement Learning: A Survey and A Multi-Player Multi-Agent Learning Toolbox","A multi-player multi-agent distributed deep reinforcement learning toolbox is developed and released, and validated on Wargame, a complex environment, showing usability of the proposed toolbox for multiple players and multiple agents distributedDeep reinforcement learning under complex games.","ArXiv",2022,"Qiyue Yin,Tongtong Yu,Shengqi Shen,Jun Yang,Meijing Zhao,Kaiqi Huang,Bin Liang,Liangsheng Wang",0,59,0
"a087581d07ff739e4ee0fed06f40385a4b6a69c8","https://www.semanticscholar.org/paper/a087581d07ff739e4ee0fed06f40385a4b6a69c8",6,"Toward the third generation artificial intelligence","This paper looks toward developing a third generation artificial intelligence by combining the current paradigms, and considers symbolism as the first generation of AI and connectionism as the second generation.","Science China Information Sciences",2020,"Jun Zhu,Hang Su,Bo Zhang",14,93,2
"269b4349158ace9b7e411a67670a99928fdd3a00","https://www.semanticscholar.org/paper/269b4349158ace9b7e411a67670a99928fdd3a00",6,"Open Problems and Modern Solutions for Deep Reinforcement Learning","Two publications that investigate the issues of DRL and propose effective solutions are reviewed, one designs the reward for human-robot collaboration by combining the manually designed extrinsic reward with a parameterized intrinsic reward function via the deterministic policy gradient, which improves the task performance and guarantees a stronger obstacle avoidance.","ArXiv",2023,"Weiqin Chen",0,33,0
"3684491d62db5c3e5602375271e4b339bbf416ee","https://www.semanticscholar.org/paper/3684491d62db5c3e5602375271e4b339bbf416ee",6,"Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval","This work proposes a simple and efficient multi-hop dense retrieval approach for answering complex open-domain questions, which achieves state-of-the-art performance on twoMulti-hop datasets, HotpotQA and multi-evidence FEVER, and can be applied to any unstructured text corpus.","International Conference on Learning Representations",2020,"Wenhan Xiong,Xiang Lorraine Li,Srini Iyer,Jingfei Du,Patrick Lewis,William Yang Wang,Yashar Mehdad,Wen-tau Yih,Sebastian Riedel,Douwe Kiela,Barlas Oğuz",93,63,28
"3912c7224da9b0a999d57a0df33c44a24c6f751b","https://www.semanticscholar.org/paper/3912c7224da9b0a999d57a0df33c44a24c6f751b",6,"Phrase Retrieval Learns Passage Retrieval, Too","This work follows the intuition that retrieving phrases naturally entails retrieving larger text blocks and study whether phrase retrieval can serve as the basis for coarse-level retrieval including passages and documents, and demonstrates how phrase filtering and vector quantization can reduce the size of the index by 4-10x, making dense phrase retrieval a practical and versatile solution in multi-granularity retrieval.","Conference on Empirical Methods in Natural Language Processing",2021,"Jinhyuk Lee,Alexander Wettig,Danqi Chen",23,41,3
"4f4a409f701f7552d45c46a5b0fea69dca6f8e84","https://www.semanticscholar.org/paper/4f4a409f701f7552d45c46a5b0fea69dca6f8e84",6,"Unsupervised Dense Information Retrieval with Contrastive Learning","This work explores the limits of contrastive learning as a way to train unsupervised dense retrievers and shows that it leads to strong performance in various retrieval settings and performs cross-lingual retrieval between scripts, which would not be possible with term matching methods.","",2021,"Gautier Izacard,Mathilde Caron,Lucas Hosseini,Sebastian Riedel,Piotr Bojanowski,Armand Joulin,Edouard Grave",37,68,13
"00ef52092ef3f109a09b66037707cd3227accb42","https://www.semanticscholar.org/paper/00ef52092ef3f109a09b66037707cd3227accb42",6,"Challenges in Generalization in Open Domain Question Answering","This work introduces and annotates questions according to three categories that measure different lev- 010 els and kinds of generalization and shows that key questionulty factors are cascading errors from the retrieval, frequency of question pattern, and fre- 028 quency of the entity.","NAACL-HLT",2021,"Linqing Liu,Patrick Lewis,S. Riedel,Pontus Stenetorp",21,67,2
"e4a052055cc293753983c0f0b74f82a73b3002d3","https://www.semanticscholar.org/paper/e4a052055cc293753983c0f0b74f82a73b3002d3",6,"Dynamic Collaborative Multi-Agent Reinforcement Learning Communication for Autonomous Drone Reforestation","Results show how communication enables collaboration and increases collective performance, planting precision and the risk-taking propensity of individual agents.","ArXiv",2022,"P. D. Siedler",0,83,0
"c7b4b6d0d95c4e42e8573d2e46047df5e7d70a22","https://www.semanticscholar.org/paper/c7b4b6d0d95c4e42e8573d2e46047df5e7d70a22",6,"Towards Intrinsic Interactive Reinforcement Learning: A Survey","A review of intrinsic IRL with an emphasis on its parent field of feedback-driven IRL while also providing discussions concerning the validity, challenges, and future research directions is provided.","ArXiv",2021,"Ben Poole,Minwoo Lee",1,132,0
"599595541456ef35dd0ed4c9e1325a2173f0ea75","https://www.semanticscholar.org/paper/599595541456ef35dd0ed4c9e1325a2173f0ea75",6,"Monte Carlo Tree Search based Hybrid Optimization of Variational Quantum Circuits","A new algorithm called MCTS-QAOA is proposed, which combines a Monte Carlo tree search method with an improved natural policy gradient solver to optimize the discrete and continuous variables in the quantum circuit, respectively.","ArXiv",2022,"Jiahao Yao,Haoya Li,M. Bukov,Lin Lin,Lexing Ying",3,94,0
"8c1729752f45181b25f4ec9f2afad6b66224fc95","https://www.semanticscholar.org/paper/8c1729752f45181b25f4ec9f2afad6b66224fc95",6,"MSRL: Distributed Reinforcement Learning with Dataflow Fragments","MindSpore Reinforcement Learning is described, a distributed RL training system that supports distribution policies that govern how RL training computation is parallelised and distributed on cluster resources, without requiring changes to the algorithm implementation.","ArXiv",2022,"Huanzhou Zhu,Bo Zhao,Gang Chen,Weifeng Chen,Yijie Chen,Liang Shi,Yaodong Yang,P. Pietzuch,Lei Chen",0,51,0
"45eeeacc0ca2b193a9762ebeedba28fb8a8e8513","https://www.semanticscholar.org/paper/45eeeacc0ca2b193a9762ebeedba28fb8a8e8513",6,"Maneuver Decision-Making for Autonomous Air Combat Based on FRE-PPO","","Applied Sciences",2022,"Hongpeng Zhang,Yujie Wei,Huan Zhou,Changqiang Huang",0,38,0
"b5dbf1e8065480bc0c57829f1dfd5e29987bf6d4","https://www.semanticscholar.org/paper/b5dbf1e8065480bc0c57829f1dfd5e29987bf6d4",6,"Probing Transfer in Deep Reinforcement Learning without Task Engineering","It is argued that Atari game curricula offer a challenging benchmark for transfer learning in RL, that can help the community better understand the generalisation capabilities of RL agents along dimensions which meaningfully impact human generalisation performance.","CoLLAs",2022,"Andrei A. Rusu,Sebastian Flennerhag,Dushyant Rao,Razvan Pascanu,R. Hadsell",1,63,1
"da22226379401577bb76ac2582f2a43b89e1f8a0","https://www.semanticscholar.org/paper/da22226379401577bb76ac2582f2a43b89e1f8a0",6,"Learning to design without prior data: Discovering generalizable design strategies using deep learning and tree search","This paper presents a methodology to self-learn high-performing and generalizable problem-solving behavior in an arbitrary problem space, circumventing the needs for expert data, existing solutions, and problem-specific learning.","Journal of Mechanical Design",2022,"A. Raina,J. Cagan,Christopher McComb",0,71,0
"3659a48a7c7d2e9a3285d8c47206a1c7f7c783dd","https://www.semanticscholar.org/paper/3659a48a7c7d2e9a3285d8c47206a1c7f7c783dd",6,"Importance of prefrontal meta control in human-like reinforcement learning","","Frontiers in Computational Neuroscience",2022,"J. Lee,Joel Z. Leibo,S. An,Sang Wan Lee",0,142,0
"a8755cbdaca0ea9723fb81a06589a7837ea44619","https://www.semanticscholar.org/paper/a8755cbdaca0ea9723fb81a06589a7837ea44619",6,"A Survey of Zero-shot Generalisation in Deep Reinforcement Learning","It is argued that taking a purely procedural content generation approach to benchmark design is not conducive to progress in ZSG, and it is suggested fast online adaptation and tackling RL-specific problems as some areas for future work on methods for ZSG.","Journal of Artificial Intelligence Research",2021,"Robert Kirk,Amy Zhang,Edward Grefenstette,Tim Rocktäschel",0,211,0
"01516fcd4220b195242dda3cd74dfae165aef25e","https://www.semanticscholar.org/paper/01516fcd4220b195242dda3cd74dfae165aef25e",6,"Replay and compositional computation","A new hypothesis is proposed: that replay is able to implement a form of compositional computation where entities are assembled into relationally bound structures to derive qualitatively new knowledge.","Neuron",2022,"Z. Kurth-Nelson,T. Behrens,Greg Wayne,Kevin J. Miller,Lennart Luettgau,Raymond Dolan,Yunzhe Liu,P. Schwartenbeck",0,169,0
"f2d952a183dfb0a1e031b8a3f535d9f8423d7a6e","https://www.semanticscholar.org/paper/f2d952a183dfb0a1e031b8a3f535d9f8423d7a6e",6,"Mastering Diverse Domains through World Models","This work presents DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches across a wide range of domains with hyperparameters.","ArXiv",2023,"Danijar Hafner,J. Pašukonis,Jimmy Ba,T. Lillicrap",7,68,2
"6f8ffdf8493323baadb2eb4b8c70f2d7084474f8","https://www.semanticscholar.org/paper/6f8ffdf8493323baadb2eb4b8c70f2d7084474f8",6,"Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA","This work introduces an optimized OpenQA Table-Text Retriever (OTTeR) to jointly retrieve tabular and textual evidences and proposes to enhance mixed-modality representation learning via two mechanisms: modality-enhanced representation and mixed- modality negative sampling strategy.","Conference on Empirical Methods in Natural Language Processing",2022,"Junjie Huang,Wanjun Zhong,Qianchu Liu,Ming Gong,Daxin Jiang,Nan Duan",1,56,0
"4d1e6c441a0b6aa2b9ec500a5064dc307d797b0c","https://www.semanticscholar.org/paper/4d1e6c441a0b6aa2b9ec500a5064dc307d797b0c",6,"Relational Memory-Augmented Language Models","A memory-augmented approach to condition an autoregressive language model on a knowledge graph that represents the graph as a collection of relation triples and retrieve relevant relations for a given context to improve text generation.","International Conference on Topology, Algebra and Categories in Logic",2022,"Qi Liu,Dani Yogatama,P. Blunsom",8,92,1
"58ed1fbaabe027345f7bb3a6312d41c5aac63e22","https://www.semanticscholar.org/paper/58ed1fbaabe027345f7bb3a6312d41c5aac63e22",6,"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks","A general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation, and finds that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.","Neural Information Processing Systems",2020,"Patrick Lewis,Ethan Perez,Aleksandara Piktus,Fabio Petroni,Vladimir Karpukhin,Naman Goyal,Heinrich Kuttler,M. Lewis,Wen-tau Yih,Tim Rocktäschel,Sebastian Riedel,Douwe Kiela",532,65,94
"db9296eaa252231e24d066e8413bf29fb058ee45","https://www.semanticscholar.org/paper/db9296eaa252231e24d066e8413bf29fb058ee45",6,"Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering","This work reviews the latest research trends in OpenQA, with particular attention to systems that incorporate neural MRC techniques, and revisiting the origin and development of Open QA systems.","ArXiv",2021,"Fengbin Zhu,Wenqiang Lei,Chao Wang,Jianming Zheng,Soujanya Poria,Tat-Seng Chua",86,156,5
"76224711646c27576e5f1e71249f7dd2a3450df0","https://www.semanticscholar.org/paper/76224711646c27576e5f1e71249f7dd2a3450df0",6,"CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks","This work proposes to replace the traditional multi-step search pipeline with a novel single-step generative model, which can dramatically simplify the search process and be optimized in an end-to-end manner, and names the pre-trained generative retrieval model as CorpusBrain as all information about the corpus is encoded in its parameters without the need of constructing additional index.","International Conference on Information and Knowledge Management",2022,"Jiangui Chen,Ruqing Zhang,J. Guo,Y. Liu,Yixing Fan,Xueqi Cheng",2,53,0
"f61b04277662741222cf8af74fc8660f4c82c8e3","https://www.semanticscholar.org/paper/f61b04277662741222cf8af74fc8660f4c82c8e3",6,"Time-Efficient Reward Learning via Visually Assisted Cluster Ranking","Across some simple Mujoco tasks, it is shown that this high-level approach to batching comparisons together holds promise and is able to greatly increase the performance of the resulting agents, provided the same amount of human labeling time.","ArXiv",2022,"David W. Zhang,Micah Carroll,Andreea Bobu,A. Dragan",0,46,0
"535708777863633f7cc7fd6f4a716b1483c7100f","https://www.semanticscholar.org/paper/535708777863633f7cc7fd6f4a716b1483c7100f",6,"Reinforcement Learning from Diverse Human Preferences","The proposed method is tested on a variety of tasks in DMcontrol and Meta-world and has shown consistent and signiﬁcant improvements over existing preference-based RL algorithms when learning from diverse feedback, paving the way for real-world applications of RL methods.","ArXiv",2023,"Wanqi Xue,Bo An,Shuicheng Yan,Zhongwen Xu",0,26,0
"3a2aa950971a46167b6da9431098b02facffe342","https://www.semanticscholar.org/paper/3a2aa950971a46167b6da9431098b02facffe342",6,"Questions Are All You Need to Train a Dense Passage Retriever","ART is introduced, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data and removes the need for labeled data and task-speciﬁc losses.","ArXiv",2022,"Devendra Singh Sachan,M. Lewis,Dani Yogatama,Luke Zettlemoyer,J. Pineau,M. Zaheer",6,51,2
"4596139b28c3ceacbd7e3c34dc0df079dbf4e96b","https://www.semanticscholar.org/paper/4596139b28c3ceacbd7e3c34dc0df079dbf4e96b",6,"Language Models as Agent Models","","Conference on Empirical Methods in Natural Language Processing",2022,"Jacob Andreas",5,41,0
"d3bc7ba19e274bb6fb5e055a3f1b62924c731432","https://www.semanticscholar.org/paper/d3bc7ba19e274bb6fb5e055a3f1b62924c731432",6,"Language Quantized AutoEncoders: Towards Unsupervised Text-Image Alignment","This work is the first work that uses unaligned images for multimodal tasks by leveraging the power of pretrained language models, and enables few-shot image classification with large language models (e.g., GPT-3) as well as linear classification of images based on BERT text features.","ArXiv",2023,"Hao Liu,Wilson Yan,P. Abbeel",0,36,0
"cc99dc93dcbc61f2c17698ce446a60ab1fd22ae8","https://www.semanticscholar.org/paper/cc99dc93dcbc61f2c17698ce446a60ab1fd22ae8",6,"MPI: Evaluating and Inducing Personality in Pre-trained Language Models","","ArXiv",2022,"Guangyuan Jiang,Manjie Xu,Song-Chun Zhu,Wenjuan Han,Chi Zhang,Yixin Zhu",3,64,0
"adbac4afd1e788753be72f455259a7b6c7d69d69","https://www.semanticscholar.org/paper/adbac4afd1e788753be72f455259a7b6c7d69d69",6,"Generating Executable Action Plans with Environmentally-Aware Language Models","This paper proposes an approach to generate environmentally-aware action plans that can be directly mapped to executable agent actions, integrating environmental objects and object relations as additional inputs into LLM action plan generation to provide the system with an awareness of its surroundings.","ArXiv",2022,"Maitrey Gramopadhye,D. Szafir",0,72,0
"51965de80f86432d42749427db1e5bb0fa1e204c","https://www.semanticscholar.org/paper/51965de80f86432d42749427db1e5bb0fa1e204c",6,"B-Pref: Benchmarking Preference-Based Reinforcement Learning","This paper introduces B-Pref: a benchmark specially designed for preference-based RL, and showcases the utility of the benchmark by using it to analyze algorithmic design choices, such as selecting informative queries, for state-of-the-art preferencebased RL algorithms.","NeurIPS Datasets and Benchmarks",2021,"Kimin Lee,Laura Smith,A. Dragan,P. Abbeel",19,88,5
"b0bd491191e57bc4059e4fee4c2d4ed41a61f470","https://www.semanticscholar.org/paper/b0bd491191e57bc4059e4fee4c2d4ed41a61f470",6,"Conditioning Predictive Models: Risks and Strategies","It is thought that conditioning approaches for predictive models represent the safest known way of eliciting human-level and slightly superhuman capabilities from large language models and other similar future models.","ArXiv",2023,"Evan Hubinger,A. Jermyn,Johannes Treutlein,Rubi Hudson,Kate Woolverton",0,57,0
"9fc3a0e96f2fa6bc7a92a96d61c68f7cb09f0a8f","https://www.semanticscholar.org/paper/9fc3a0e96f2fa6bc7a92a96d61c68f7cb09f0a8f",6,"Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering","A new QA system which aug-ments a text-to-text model with a large memory of question-answer pairs, and a new pre-training task for the latent step of question retrieval, which greatly improves performance on smaller QA benchmarks.","ArXiv",2022,"Wenhu Chen,Pat Verga,Michiel de Jong,J. Wieting,W. Cohen",10,49,1
"d267ffcf1b0720d156aa2d9b80c921eddb70113e","https://www.semanticscholar.org/paper/d267ffcf1b0720d156aa2d9b80c921eddb70113e",6,"Retrieval-Enhanced Machine Learning","A generic retrieval-enhanced machine learning (REML) framework is described, which includes a number of existing models as special cases and lays a foundation for a new style of information access research and paves a path towards advancing machine learning and artificial intelligence.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2022,"Hamed Zamani,Fernando Diaz,M. Dehghani,Donald Metzler,Michael Bendersky",6,75,0
"6fcdad7b8d6b60b23bc51859e736c29f913b249a","https://www.semanticscholar.org/paper/6fcdad7b8d6b60b23bc51859e736c29f913b249a",6,"Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering","This work proposes RAG-end2end, an extension to RAG that can adapt to a domain- specific knowledge base by updating all components of the external knowledge base during training and introduces an auxiliary training signal to inject more domain-specific knowledge.","Transactions of the Association for Computational Linguistics",2022,"Shamane Siriwardhana,Rivindu Weerasekera,Elliott Wen,Tharindu Kaluarachchi,R. Rana,Suranga Nanayakkara",1,44,0
"421c19183033288e0bfd5df1451083d8b3cb8007","https://www.semanticscholar.org/paper/421c19183033288e0bfd5df1451083d8b3cb8007",6,"Language Modeling with Latent Situations","A family of approaches for improving coherence in LMs by training them to construct and condition on explicit representations of entities and their states, showing that standard LMs can be sample-efﬁciently trained to model not just language but the situations it describes.","ArXiv",2022,"Belinda Z. Li,Maxwell Nye,Jacob Andreas",1,27,0
"3cb4a3ebaf027852e5d185ccedc70990781bff72","https://www.semanticscholar.org/paper/3cb4a3ebaf027852e5d185ccedc70990781bff72",6,"Empirical Investigation of Neural Symbolic Reasoning Strategies","This work decomposes the reasoning strategy w.r.t. step granularity and chaining strategy and finds that certain configurations lead to nearly perfect performance, even in the case of length extrapolation.","",2023,"Y. Aoki,Keito Kudo,Tatsuki Kuribayashi,Ana Brassard,Masashi Yoshikawa,Keisuke Sakaguchi,Kentaro Inui",0,31,0
"9e8f0d9ba4e7af673c8b214b3764e020706dd1f3","https://www.semanticscholar.org/paper/9e8f0d9ba4e7af673c8b214b3764e020706dd1f3",6,"Don't Generate, Discriminate: A Proposal for Grounding Language Models to Real-World Environments","Pangu is proposed, a generic framework for grounded language understanding that capitalizes on the discriminative ability of LMs instead of their generative ability, and enables, for the first time, effective few-shot in-context learning for KBQA with large LMs such as Codex.","ArXiv",2022,"Yu Gu,Xiang Deng,Yu Su",0,66,0
"7195ed3c7f11220f29634cecb68b1d39db2e36d9","https://www.semanticscholar.org/paper/7195ed3c7f11220f29634cecb68b1d39db2e36d9",6,"Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness","A comprehensive robustness benchmark 1 based on Spider, a cross-domain text-to-SQL benchmark, is proposed to diagnose the model robustness and a diagnostic study of the state-of-the-art models on the robustness set is conducted.","ArXiv",2023,"Shuaichen Chang,J. Wang,Mingwen Dong,Lin Pan,Henghui Zhu,A. Li,Wuwei Lan,Shenmin Zhang,Jiarong Jiang,Joseph Lilien,Stephen M. Ash,William Yang Wang,Zhiguo Wang,Vittorio Castelli,Patrick Ng,Bing Xiang",0,56,0
"1d34b6cffe67077cdd4df41950b1195f09ae0cb8","https://www.semanticscholar.org/paper/1d34b6cffe67077cdd4df41950b1195f09ae0cb8",6,"Hierarchical Programmatic Reinforcement Learning via Learning to Compose Programs","This work proposes to learn a meta-policy that composes a series of programs sampled from the learned program embedding space that can produce program policies that describe out-of-distributionally complex behaviors and directly assign credits to programs that induce desired behaviors.","ArXiv",2023,"Guanhui. Liu,En-Pei Hu,Pu-Jen Cheng,Hung-yi Lee,Shao-Hua Sun",0,51,0
"ca35e54176d0c0e540fc99d6aabf69a72ed64412","https://www.semanticscholar.org/paper/ca35e54176d0c0e540fc99d6aabf69a72ed64412",6,"FiDO: Fusion-in-Decoder optimized for stronger performance and faster inference","This work shows that the majority of inference time results from memory bandwidth constraints in the decoder, and proposes two simple changes to the FiD architecture to speed up inference by 7x, and indicates that the faster decoder inference then allows for a much larger decoder.","ArXiv",2022,"Michiel de Jong,Yury Zemlyanskiy,J. Ainslie,Nicholas FitzGerald,Sumit K. Sanghai,Fei Sha,W. Cohen",2,41,0
"655e0fdfe5f92c3a6de43f9beab8a745ee5d7653","https://www.semanticscholar.org/paper/655e0fdfe5f92c3a6de43f9beab8a745ee5d7653",6,"Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute","It is shown that LUMEN outperforms pure memory on multiple question-answering tasks while being much cheaper than FiD, and outperforms both for any given compute budget, and the advantage of LUMen over FiD increases with model size.","ArXiv",2023,"Michiel de Jong,Yury Zemlyanskiy,Nicholas FitzGerald,J. Ainslie,Sumit K. Sanghai,Fei Sha,W. Cohen",1,37,0
"4b516216d7d150a081fd74993bddf36b6b22c118","https://www.semanticscholar.org/paper/4b516216d7d150a081fd74993bddf36b6b22c118",6,"Chain of Thought Imitation with Procedure Cloning","Through empirical analysis on navigation, simulated robotic manipulation, and game-playing environments, it is shown that imitating the intermediate computations of an expert’s behavior enables procedure cloning to learn policies exhibiting generalization to unseen environment conﬁgurations, including those for which running the expert's procedure directly is infeasible.","ArXiv",2022,"Mengjiao Yang,D. Schuurmans,P. Abbeel,Ofir Nachum",2,92,0
"9574d10f55e77d432f923ee71e3205fc64a3104a","https://www.semanticscholar.org/paper/9574d10f55e77d432f923ee71e3205fc64a3104a",6,"Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?","Meta prompt tuning is studied to systematically explore how meta-learning can help improve (if it can) cross-task generalization in PT through learning to initialize the prompt embeddings from other relevant tasks and an in-depth analysis from the perspective of task similarity.","",2023,"Chengwei Qin,Shafiq R. Joty,Q. Li,Ruochen Zhao",0,161,0
"706c6b3781374b0b11f98f204a4ddd05b26ed009","https://www.semanticscholar.org/paper/706c6b3781374b0b11f98f204a4ddd05b26ed009",6,"Knowledge Infused Decoding","Knowledge Infused Decoding (KID)—a novel decoding algorithm for generative LMs, which dynamically infuses external knowledge into each step of the LM decoding, which maintains a local knowledge memory based on the current context, interacting with a dynamically created external knowledge trie, and continuously update the local memory as a knowledge-aware constraint to guide decoding via reinforcement learning.","International Conference on Learning Representations",2022,"Ruibo Liu,Guoqing Zheng,Shashank Gupta,Radhika Gaonkar,Chongyang Gao,Soroush Vosoughi,Milad Shokouhi,A. Awadallah",6,98,1
"49b499598a8864eee55ab264fc16a5bf8d2f87ef","https://www.semanticscholar.org/paper/49b499598a8864eee55ab264fc16a5bf8d2f87ef",6,"Social Simulacra: Creating Populated Prototypes for Social Computing Systems","It is demonstrated that social simulacra shift the behaviors that they generate appropriately in response to design changes, and that they enable exploration of “what if?” scenarios where community members or moderators intervene.","ACM Symposium on User Interface Software and Technology",2022,"J. Park,Lindsay Popowski,Carrie J. Cai,M. Morris,Percy Liang,Michael S. Bernstein",5,87,0
"a609b4142feb8a00e0e9ae94c48d999f46ed80dd","https://www.semanticscholar.org/paper/a609b4142feb8a00e0e9ae94c48d999f46ed80dd",6,"Argumentative Reward Learning: Reasoning About Human Preferences","A novel neuro-symbolic framework, argumentative reward learning, is presented, which combines preference-based argumentation with existing approaches to reinforcement learning from human feedback and improves prior work by generalising human preferences, reducing the bur-den on the user and increasing the robustness of the reward model.","ArXiv",2022,"Francis Rhys Ward,F. Belardinelli,F. Toni",1,26,0
"7d6f17706cbcfcca55f08485bcbf8c82e00c9279","https://www.semanticscholar.org/paper/7d6f17706cbcfcca55f08485bcbf8c82e00c9279",6,"Goal Misgeneralization: Why Correct Specifications Aren't Enough For Correct Goals","It is demonstrated that goal misgeneralization can occur in practical systems by providing several examples in deep learning systems across a variety of domains and suggesting several research directions that could reduce the risk of goal mis generalization for future systems.","ArXiv",2022,"Rohin Shah,Vikrant Varma,Ramana Kumar,Mary Phuong,Victoria Krakovna,J. Uesato,Z. Kenton",2,55,0
"eecb45aa040064cbc0b37fd100706c02e7dc880e","https://www.semanticscholar.org/paper/eecb45aa040064cbc0b37fd100706c02e7dc880e",6,"Structured Prompting: Scaling In-Context Learning to 1, 000 Examples","Experimental results on a diverse set of tasks show that the structured prompting approach improves end-task performance and reduces evaluation variance over conventional in-context learning as the number of demonstration examples increases.","ArXiv",2022,"Y. Hao,Yutao Sun,Li Dong,Zhixiong Han,Yuxian Gu,Furu Wei",2,39,0
"da345b189e4faaaa489f7319640868a37a3932a1","https://www.semanticscholar.org/paper/da345b189e4faaaa489f7319640868a37a3932a1",6,"Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning?","A skill tree on compositionality in arithmetic symbolic reasoning that defines the hierarchical levels of complexity along with three compositionality dimensions: systematicity, productivity, and substitutivity is introduced.","",2023,"Keito Kudo,Y. Aoki,Tatsuki Kuribayashi,Ana Brassard,Masashi Yoshikawa,Keisuke Sakaguchi,Kentaro Inui",0,22,0
"023edab4738690444e3924e224c2641017a0d794","https://www.semanticscholar.org/paper/023edab4738690444e3924e224c2641017a0d794",6,"Quark: Controllable Text Generation with Reinforced Unlearning","Quantized Reward Konditioning ( Quark) is introduced, an algorithm for optimizing a reward function that quantiﬁes an (un)wanted property, while not straying too far from the original model.","ArXiv",2022,"Ximing Lu,S. Welleck,Liwei Jiang,Jack Hessel,Lianhui Qin,Peter West,Prithviraj Ammanabrolu,Yejin Choi",13,90,4
"4c2534f9b03ac2f3810c07abc398a11bcf47258e","https://www.semanticscholar.org/paper/4c2534f9b03ac2f3810c07abc398a11bcf47258e",6,"Transformers Learn Shortcuts to Automata","The theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only o(T ) layers can exactly replicate the computation of an automaton on an input sequence of length T .","ArXiv",2022,"Bingbin Liu,J. Ash,Surbhi Goel,A. Krishnamurthy,Cyril Zhang",4,104,0
"fff24425c8eaa3af4422261b9e108374ded678f0","https://www.semanticscholar.org/paper/fff24425c8eaa3af4422261b9e108374ded678f0",6,"Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge","This work proposes a novel open-domain question answering (ODQA) framework for answering single/multi-hop questions across heterogeneous knowledge sources and substantially outperforms the previous state-of-the-art on OTT-QA with an exact match score of 47.3.","Conference on Empirical Methods in Natural Language Processing",2022,"Kaixin Ma,Hao Cheng,Xiaodong Liu,Eric Nyberg,Jianfeng Gao",1,48,0
"0040dac7a1bf7a1eeb01c86ddb993f331f35b158","https://www.semanticscholar.org/paper/0040dac7a1bf7a1eeb01c86ddb993f331f35b158",6,"Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations","This work collects human-written explanations in the form of generalizable commonsense rules and finds that for hard examples, human explanations are significantly better than GPT-3 explanations both in terms of label-supportiveness and generalizability judgements.","Conference on Empirical Methods in Natural Language Processing",2022,"Swarnadeep Saha,Peter Hase,Nazneen Rajani,Mohit Bansal",0,41,0
"8745c5b9522c11818418f64fdc880894faeaed16","https://www.semanticscholar.org/paper/8745c5b9522c11818418f64fdc880894faeaed16",6,"A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation","This work explores a method for learning a single policy that manipulates various forms of agents to solve various tasks by distilling a large amount of proficient behavioral data and suggests large diverse offline datasets, unified IO representation, and policy representation and architecture selection through supervised learning form a promising approach for studying and advancing morphology-task generalization.","ArXiv",2022,"Hiroki Furuta,Yusuke Iwasawa,Yutaka Matsuo,S. Gu",0,115,0
"ae441f7305dc2cd58c708528b3ecee3501cc5c46","https://www.semanticscholar.org/paper/ae441f7305dc2cd58c708528b3ecee3501cc5c46",6,"Plansformer: Generating Symbolic Plans using Transformers","The use of LLMs for automated planning - a branch of AI concerned with the realization of action sequences (plans) to achieve a goal, typically executed by intelligent agents, autonomous robots, and unmanned vehicles are explored.","ArXiv",2022,"Vishal Pallagani,Bharath Muppasani,K. Murugesan,F. Rossi,L. Horesh,Biplav Srivastava,F. Fabiano,Andrea Loreggia",1,36,0
"9cffc161896ce2b8d1a3083ab4f293bc166134ce","https://www.semanticscholar.org/paper/9cffc161896ce2b8d1a3083ab4f293bc166134ce",6,"Language model acceptability judgements are not always robust to context","This paper investigates the stability of language models’ performance on targeted syntactic evaluations as they vary properties of the input context: the length of the context, the types of syntactic phenomena it contains, and whether or not there are violations of grammaticality.","ArXiv",2022,"Koustuv Sinha,Jon Gauthier,Aaron Mueller,Kanishka Misra,Keren Fuentes,R. Levy,Adina Williams",1,41,0
"7897e693726b3ddf6efab786fcf731fca8bd72ca","https://www.semanticscholar.org/paper/7897e693726b3ddf6efab786fcf731fca8bd72ca",6,"Does unsupervised grammar induction need pixels?","The results challenge the notion that extralinguistic signals such as image pixels are needed for unsupervised grammar induction, and point to the need for better text-only baselines in evaluating the need of multi-modality for the task.","ArXiv",2022,"Boyi Li,Rodolfo Corona,Karttikeya Mangalam,Catherine Chen,Daniel Flaherty,S. Belongie,Kilian Q. Weinberger,J. Malik,Trevor Darrell,D. Klein",0,46,0
"434250ed6b9fb5f1ad871709fb3cf0a6635ff5ce","https://www.semanticscholar.org/paper/434250ed6b9fb5f1ad871709fb3cf0a6635ff5ce",6,"ORCA: A Challenging Benchmark for Arabic Language Understanding","To measure current progress in Arabic NLU, ORCA is used to offer a comprehensive comparison between 18 multilingual and Arabic language models and to provide a public leaderboard with a single-number evaluation metric ( ORCA score) to facilitate future research.","ArXiv",2022,"AbdelRahim Elmadany,E. Nagoudi,M. Abdul-Mageed",0,111,0
"5278b81db686b4d36143941bff1c683bea963a63","https://www.semanticscholar.org/paper/5278b81db686b4d36143941bff1c683bea963a63",6,"SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient","This work considers alternative setups for training large models: using cheap “preemptible” instances or pooling existing resources from multiple regions, and proposes SWARM parallelism, a model-parallel training algorithm designed for poorly connected, heterogeneous and unreliable devices.","ArXiv",2023,"Max Ryabinin,Tim Dettmers,Michael Diskin,Alexander Borzunov",1,113,0
"a2bcacc8fefb859c94c69d524b2368bb4792f9b1","https://www.semanticscholar.org/paper/a2bcacc8fefb859c94c69d524b2368bb4792f9b1",6,"Adversarial Prompting for Black Box Foundation Models","A black-box framework for generating adversarial prompts for unstructured image and text generation and induce specific behaviors into the generative process, such as generating images of a particular object or biasing the frequency of specific letters in the generated text.","ArXiv",2023,"N. Maus,Patrick Chao,Eric Wong,Jacob R. Gardner",0,63,0
"3f4d11971f2c64be9125a7fe99c019588bbebf16","https://www.semanticscholar.org/paper/3f4d11971f2c64be9125a7fe99c019588bbebf16",6,"Iteratively Prompt Pre-trained Language Models for Chain of Thought","An iterative prompting framework is explored, a new prompting paradigm which progressively elicits relevant knowledge from PLMs for multi-step inference by learning to dynamically synthesize prompts conditioned on the current step’s contexts.","Conference on Empirical Methods in Natural Language Processing",2022,"Boshi Wang,Xiang Deng,Huan Sun",5,48,3
"b8bd29a6104d26a16687400049a4e7e026ae6258","https://www.semanticscholar.org/paper/b8bd29a6104d26a16687400049a4e7e026ae6258",6,"Active Example Selection for In-Context Learning","It is demonstrated that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information.","Conference on Empirical Methods in Natural Language Processing",2022,"Yiming Zhang,Shi Feng,Chenhao Tan",4,43,1
"52136f813243ac3de8e277906112a41590a376d4","https://www.semanticscholar.org/paper/52136f813243ac3de8e277906112a41590a376d4",6,"What do LLMs Know about Financial Markets? A Case Study on Reddit Market Sentiment Analysis","This model generates weak financial sentiment labels for Reddit posts with an LLM and then uses that data to train a small model that can be served in production and finds that prompting the LLM to produce Chain-of-Thought summaries and forcing it through sev-eral reasoning paths helps generate more stable and accurate labels.","ArXiv",2022,"Xiang Deng,Vasilisa Bashlovkina,Feng Han,Simon Baumgartner,Michael Bendersky",0,24,0
"c9ad9d69d7568110dd5527598a92c7f8b335eef4","https://www.semanticscholar.org/paper/c9ad9d69d7568110dd5527598a92c7f8b335eef4",6,"Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations","This report lays out possible changes to the actors, behaviors, and content of online influence operations, and provides a framework for stages of the language model-to-influence operations pipeline that mitigations could target.","ArXiv",2023,"Josh A. Goldstein,Girish Sastry,Micah Musser,Renée DiResta,Matthew Gentzel,Katerina Sedova",4,200,0
"feea0452e03b78f7c85f40e5daa1bd08b61bb44b","https://www.semanticscholar.org/paper/feea0452e03b78f7c85f40e5daa1bd08b61bb44b",6,"Revisiting Offline Compression: Going Beyond Factorization-based Methods for Transformer Language Models","This paper explores offline compression methods, meaning computationally-cheap approaches that do not require further fine-tuning of the compressed model, and challenges the classical matrix factorization methods by proposing a novel, better-performing autoencoder-based framework.","ArXiv",2023,"M. Banaei,Klaudia Balazy,A. Kasymov,R. Lebret,J. Tabor,K. Aberer",0,46,0
"6d994b4f5a46cd14e8f09f1e9e49120546b15e31","https://www.semanticscholar.org/paper/6d994b4f5a46cd14e8f09f1e9e49120546b15e31",6,"CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning","This work proposes “CodeRL”, a new framework for program synthesis tasks through pretrained LMs and deep reinforcement learning (RL), and treats the code-generating LM as an actor network, and introduces a critic network that is trained to predict the functional correctness of generated programs and provide dense feedback signals to the actor.","ArXiv",2022,"Hung Le,Yue Wang,Akhilesh Deepak Gotmare,S. Savarese,S. Hoi",12,77,2
"a328907b45724b61aafbad746d490f00fe0fd761","https://www.semanticscholar.org/paper/a328907b45724b61aafbad746d490f00fe0fd761",6,"Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees","An interpretable modular framework consisting of an (ordered) list of binary trees, each encoding the step-by-step generative process of an abstractive summary sentence from the source document, and demonstrates that SP-S EARCH effectively represents theGenerative process behind human summaries using modules that are typically faithful to their intended behavior.","ArXiv",2022,"Swarnadeep Saha,Shiyue Zhang,Peter Hase,Mohit Bansal",3,62,1
"f4913994ce936cc79ebcbeea51a63f6d2005e978","https://www.semanticscholar.org/paper/f4913994ce936cc79ebcbeea51a63f6d2005e978",6,"Document-Level Abstractive Summarization","This work proposes a novel retrieval-enhanced approach based on the architecture which reduces the cost of generating a summary of the entire document by processing smaller chunks, and suggests a more efﬁcient memory a consumption and truthfulness.","ArXiv",2022,"Gonçalo Raposo,Afonso Raposo,Ana Sofia Carmo",0,38,0
"533fe3da3518244d0e21b7bec7fa35647b5fa345","https://www.semanticscholar.org/paper/533fe3da3518244d0e21b7bec7fa35647b5fa345",6,"Teacher Forcing Recovers Reward Functions for Text Generation","This work proposes a task-agnostic approach that derives a step-wise reward function directly from a model trained with teacher forcing, and proposes a simple modi-cation to stabilize the RL training on non-parallel datasets with the authors' induced reward function.","ArXiv",2022,"Yongchang Hao,Yuxin Liu,Lili Mou",1,69,0
"d4f77cdb04d7ae02860415877cc4c463e93595a1","https://www.semanticscholar.org/paper/d4f77cdb04d7ae02860415877cc4c463e93595a1",6,"Retrieval Augmentation for Commonsense Reasoning: A Unified Approach","A unified framework of retrieval-augmented commonsense reasoning (called RACo), including a newly constructed commonsense corpus with over 20 million documents and novel strategies for training a commonsense retriever is proposed.","Conference on Empirical Methods in Natural Language Processing",2022,"W. Yu,Chenguang Zhu,Zhihan Zhang,Shuohang Wang,Zhuosheng Zhang,Yuwei Fang,Meng Jiang",1,68,0
"bfdbe107413a02a1ce6f233848b6d934979638cb","https://www.semanticscholar.org/paper/bfdbe107413a02a1ce6f233848b6d934979638cb",6,"Revision for Concision: A Constrained Paraphrase Generation Task","This work introduces and formulate revising for concision as a natural language processing task at the sentence level, which requires algorithms to use only necessary words to rewrite a sentence while preserving its meaning.","TSAR",2022,"Wenchuan Mu,Kwanin Lim",1,69,0
"7633c8b7cd4209222d02c453184b480533a0e139","https://www.semanticscholar.org/paper/7633c8b7cd4209222d02c453184b480533a0e139",6,"Analyzing Multi-Task Learning for Abstractive Text Summarization","This work analyzes the influence of multi-task learning strategies using task families for the English abstractive text summarization task, and finds that certain combinations of task families positively impact downstream performance.","IEEE Games Entertainment Media Conference",2022,"Frederic Kirstein,Jan Philip Wahle,Terry Ruas,Bela Gipp",0,103,0
"9b32f1b56da9b31816e237e17324beca35c15cce","https://www.semanticscholar.org/paper/9b32f1b56da9b31816e237e17324beca35c15cce",6,"ED-FAITH: Evaluating Dialogue Summarization on Faithfulness","Inspired by the strong zero-shot performance of the T0 language model, T0-Score is proposed – a new metric for faithfulness evaluation, which shows consistent improvement against baseline metrics across multiple domains.","ArXiv",2022,"Sicong Huang,Asli Celikyilmaz,Haoran Li",0,30,0
"a9a53c28f3b964cf561c05bf204b4c06f6454eec","https://www.semanticscholar.org/paper/a9a53c28f3b964cf561c05bf204b4c06f6454eec",6,"Bipartite-play Dialogue Collection for Practical Automatic Evaluation of Dialogue Systems","Experimental results show that the automatic evaluation using the bipartite-play method mitigates these two drawbacks and correlates as strongly with human subjectivity as existing methods.","AACL",2022,"Shiki Sato,Yosuke Kishinami,Hiroaki Sugiyama,Reina Akama,Ryoko Tokuhisa,Jun Suzuki",0,41,0
"aa4005a80379db297b81c01122a4cff969677b5f","https://www.semanticscholar.org/paper/aa4005a80379db297b81c01122a4cff969677b5f",6,"CE-BART: Cause-and-Effect BART for Visual Commonsense Generation","Cause-and-Effect BART (CE-BART) is proposed, which is based on a structured graph reasoner that captures intra- and inter-modality relationships among visual and textual representations and a cause-And-effect generator that generates cause- and-effect captions by considering the causal relations among inferences.","Italian National Conference on Sensors",2022,"Junyeong Kim,Jiajing Hong,Sunjae Yoon,Chang D. Yoo",0,34,0
"9b4055674cd9849f8595240695bed69cd02492bc","https://www.semanticscholar.org/paper/9b4055674cd9849f8595240695bed69cd02492bc",6,"A Survey on Natural Language Processing for Programming","This paper comprehensively investigates existing work in natural language processing for programming, rang-ing from early deductive models to the latest competition-level models.","ArXiv",2022,"Qingfu Zhu,Xianzhen Luo,Fang Liu,Cuiyun Gao,Wanxiang Che",0,79,0
"2bff7efafc7a07cc6c8402c595cb469bb90fea3d","https://www.semanticscholar.org/paper/2bff7efafc7a07cc6c8402c595cb469bb90fea3d",6,"Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation","A modiﬁed summarization salience protocol, Atomic Content Units (ACUs), which relies onained semantic units and al-lows for high inter-annotator agreement is proposed, which has important implications for evaluating large language models (LLMs), as it shows that LLMs adjusted by human feedback may over-strained human evaluation.","ArXiv",2022,"Yixin Liu,Alexander R. Fabbri,Pengfei Liu,Yilun Zhao,Linyong Nan,Ruilin Han,Simeng Han,Shafiq R. Joty,Chien-Sheng Wu,Caiming Xiong,Dragomir R. Radev",4,90,1
"690c210564226c9307b3bab977cdc07a6a45863a","https://www.semanticscholar.org/paper/690c210564226c9307b3bab977cdc07a6a45863a",6,"Execution-Based Evaluation for Open-Domain Code Generation","ODEX corroborates the mer-its of execution-based evaluation over metrics without execution but also unveils their complementary effects, and is released to facilitate research into open-domain problems for the code generation community.","ArXiv",2022,"Zhiruo Wang,Shuyan Zhou,Daniel Fried,Graham Neubig",1,30,0
"b1a3527466abbebe7d2baa75f3923c6fdc85d3d6","https://www.semanticscholar.org/paper/b1a3527466abbebe7d2baa75f3923c6fdc85d3d6",6,"On the Blind Spots of Model-Based Evaluation Metrics for Text Generation","This work design and synthesize a wide range of potential errors and check whether they result in a drop in the metric scores, and investigates the reasons behind these blind spots and suggests practical workarounds for a more reliable evaluation of text generation.","ArXiv",2022,"Tianxing He,Jingyu Zhang,Tianle Wang,Sachin Kumar,Kyunghyun Cho,James R. Glass,Yulia Tsvetkov",1,70,0
"c4b0ce9321c0c0ac8f8221aefda3281cbb566058","https://www.semanticscholar.org/paper/c4b0ce9321c0c0ac8f8221aefda3281cbb566058",6,"A Survey of Natural Language Generation","This survey aims to give the latest synthesis of deep learning research on the NLG core tasks, as well as the architectures adopted in the field, and detail meticulously and comprehensively various NLG tasks and datasets.","ACM Computing Surveys",2021,"Chenhe Dong,Yinghui Li,Haifan Gong,M. Chen,Junxin Li,Ying Shen,Min Yang",4,165,0
"25c1dd5c0276fdb3c46868f91b604049f5182723","https://www.semanticscholar.org/paper/25c1dd5c0276fdb3c46868f91b604049f5182723",6,"A Cognitive Evaluation of Instruction Generation Agents tl;dr They Need Better Theory-of-Mind Capabilities","The results indicate that neural-network-based instruction generation agents, while capable of effectively narrowing the search space, poorly predict the listener’s interpretations of their instructions and thus often fail to select the best instructions even from a small candidate set.","ArXiv",2022,"Lingjun Zhao,Khanh Nguyen,Hal Daum'e",0,69,0
"0645c86da0f6329f13489654210eaaca87be2e22","https://www.semanticscholar.org/paper/0645c86da0f6329f13489654210eaaca87be2e22",6,"You Truly Understand What I Need: Intellectual and Friendly Dialogue Agents grounding Knowledge and Persona","This work proposes an effective dialogue agent that grounds external knowledge and persona simultaneously, and shows the retriever’s effectiveness in extracting relevant documents compared to the other previous retrievers, along with the comparison of multiple candidate scoring methods.","ArXiv",2023,"J. Lim,Myunghoon Kang,Yuna Hur,Seung-Ju Jung,Jinsung Kim,Yoonna Jang,Dongyub Lee,Hyesung Ji,Donghoon Shin,Seung Wook Kim,Heu-Jeoung Lim",0,39,0
"c7ce496c49da196dc632533afae8da587bd3c338","https://www.semanticscholar.org/paper/c7ce496c49da196dc632533afae8da587bd3c338",6,"HeroNet: A Hybrid Retrieval-Generation Network for Conversational Bots","A hybrid retrieval-generation network (HeroNet) with the three-fold ideas to produce high-quality sentence representations, which is able to solve both retrieval and generation tasks simultaneously while maximizing performance of each other.","ArXiv",2023,"Bolin Zhang,Yunzhe Xu,Zhiying Tu,Dianhui Chu",0,31,0
"83a5b5c4cf762fd9b8b4e6d8e607de52b7ecaa77","https://www.semanticscholar.org/paper/83a5b5c4cf762fd9b8b4e6d8e607de52b7ecaa77",6,"Automatic question generation: a review of methodologies, datasets, evaluation metrics, and applications","This review provides an overview of the research progress in automatic question generation and presents a comprehensive literature review covering the classification of Question Generation systems by categorizing them into three broad use-cases, namely standalone question generation, visual questiongeneration, and conversational question generation.","Progress in Artificial Intelligence",2023,"Nikahat Mulla,P. Gharpure",0,150,0
"79588eb402572fb37fe20d4cfc516ace8a661603","https://www.semanticscholar.org/paper/79588eb402572fb37fe20d4cfc516ace8a661603",6,"Coherence and Diversity through Noise: Self-Supervised Paraphrase Generation via Structure-Aware Denoising","SCANING considerably improves performance in terms of both semantic preservation and producing diverse paraphrases through extensive automated and manual evaluation across 4 datasets.","ArXiv",2023,"Rishabh Gupta,V. Venktesh,M. Mohania,Vikram Goyal",0,35,0
"13a66fc8689724e295548ceac9e5425fc46cc093","https://www.semanticscholar.org/paper/13a66fc8689724e295548ceac9e5425fc46cc093",6,"SkCoder: A Sketch-based Approach for Automatic Code Generation","This paper proposes a sketch-based code generation approach named SkCoder to mimic developers' code reuse behavior, which retrieves a similar code snippet, extracts relevant parts as a code sketch, and edits the sketch into the desired code.","",2023,"Jia Li,Yongming Li,Ge Li,Zhi Jin,Yiyang Hao,Xing Hu",0,38,0
"5ef821267fa68d3231ed8135ff8ec09f25bb1398","https://www.semanticscholar.org/paper/5ef821267fa68d3231ed8135ff8ec09f25bb1398",6,"ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models","The goal is to merge the strengths of LLMs' medical domain knowledge and logical reasoning with the vision understanding capability of existing medical-image CAD models to create a more user-friendly and understandable system for patients compared to conventional CAD systems.","",2023,"Sheng Wang,Zihao Zhao,Xi Ouyang,Qian Wang,Dinggang Shen",0,33,0
"ca086f4c09cf8de705830ac2b70951737fab93ca","https://www.semanticscholar.org/paper/ca086f4c09cf8de705830ac2b70951737fab93ca",6,"A Review of Sparse Expert Models in Deep Learning","The concept of sparse expert models is reviewed, a basic description of the common algorithms is provided, the advances in the deep learning era are contextualized, and areas for future work are highlighted.","ArXiv",2022,"W. Fedus,J. Dean,Barret Zoph",14,87,1
"dcff38de0e5fb47bdb31d472c21b0c2d88cbc4fc","https://www.semanticscholar.org/paper/dcff38de0e5fb47bdb31d472c21b0c2d88cbc4fc",6,"AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models","It is demonstrated that AlphaTuning, when applied to GPT-2 and OPT, performs competitively with full fine-tuning on a variety of downstream tasks while achieving>10x compression ratio under 4-bit quantization and>1,000x reduction in the number of trainable parameters.","Conference on Empirical Methods in Natural Language Processing",2022,"Se Jung Kwon,Jeonghoon Kim,Jeongin Bae,Kang Min Yoo,Jin-Hwa Kim,Baeseong Park,Byeongwook Kim,Jung-Woo Ha,Nako Sung,Dongsoo Lee",1,64,0
"9eccd7b1d184ceb9268da754f35e399bc161ed3c","https://www.semanticscholar.org/paper/9eccd7b1d184ceb9268da754f35e399bc161ed3c",6,"Understanding BLOOM: An empirical study on diverse NLP tasks","An evaluation of smaller BLOOM model variants on various natural language processing tasks, including GLUE language understanding, prompt-based zero-shot and few-shot text classification and extraction, question answering, Prompt-based text generation, and multi-lingual text classification to understand model strengths/weaknesses and behavior shows that BLOoms under-perform on all GLUE tasks, question-answering, and text generation.","ArXiv",2022,"Parag Dakle,Sai Krishna Rallabandi,Preethi Raghavan",0,63,0
"93fdf5cf598aefb0335f001039e83494dc721c3a","https://www.semanticscholar.org/paper/93fdf5cf598aefb0335f001039e83494dc721c3a",6,"General-Purpose In-Context Learning by Meta-Learning Transformers","This paper shows that Transformers and other black-box models can be meta-trained to act as general-purpose in-context learners, and describes phase transitions between algorithms that generalize, algorithms that memorize, and algorithms that fail to meta-train at all, induced by changes in model size, number of tasks, and meta-optimization.","ArXiv",2022,"Louis Kirsch,James Harrison,Jascha Narain Sohl-Dickstein,Luke Metz",3,60,0
"bfe6fd05f09647b001c7eb6e333a95c881c88344","https://www.semanticscholar.org/paper/bfe6fd05f09647b001c7eb6e333a95c881c88344",6,"Human-Timescale Adaptation in an Open-Ended Task Space","It is demonstrated that training an RL agent at scale leads to a general in-context learning algorithm that can adapt to open-ended novel embodied 3D problems as quickly as humans.","ArXiv",2023,"Adaptive Agent Team,Jakob Bauer,Kate Baumli,Satinder Baveja,Feryal M. P. Behbahani,Avishkar Bhoopchand,N. Bradley-Schmieg,Michael Chang,Natalie Clay,Adrian Collister,Vibhavari Dasagi,Lucy Gonzalez,Karol Gregor,Edward Hughes,Sheleem Kashem,Maria Loks-Thompson,Hannah Openshaw,Jack Parker-Holder,Shreyaan Pathak,Nicolas Perez Nieves,Nemanja Rakicevic,Tim Rocktäschel,Yannick Schroecker,Jakub Sygnowski,K. Tuyls,Sarah York,Alexander Zacherl,Lei M. Zhang",1,129,0
"0545ec3a4e3eeaec924847d5bd9b3436bcc136d8","https://www.semanticscholar.org/paper/0545ec3a4e3eeaec924847d5bd9b3436bcc136d8",6,"Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning","This study systematically explore how the ability to detect out-of-distribution (OOD) changes as the size of the PLM grows or the transfer methods are altered.","ArXiv",2023,"Hyunsoo Cho,Choonghyun Park,Junyeop Kim,Hyuhng Joon Kim,Kang Min Yoo,Sang-goo Lee",0,52,0
"94d84d1403a23a8a8486a151f52a126beb16875c","https://www.semanticscholar.org/paper/94d84d1403a23a8a8486a151f52a126beb16875c",6,"Partitioning Distributed Compute Jobs with Reinforcement Learning and Graph Neural Networks","It is shown that maximum parallelisation is sub-optimal in relation to user-critical metrics such as throughput and blocking rate, and a proposed PAC-ML (partitioning for asynchronous computing with machine learning) is proposed.","ArXiv",2023,"Christopher W. F. Parsonson,Z. Shabka,A. Ottino,G. Zervas",0,92,0
"da2fe6cd385194b0274d04d04ee72e8caf3854d4","https://www.semanticscholar.org/paper/da2fe6cd385194b0274d04d04ee72e8caf3854d4",6,"Learning Universal Policies via Text-Guided Video Generation","This work casts the sequential decision making problem as a text-conditioned video generation problem, where a planner synthesizes a set of future frames depicting its planned actions in the future, after which control actions are extracted from the generated video.","ArXiv",2023,"Yilun Du,Mengjiao Yang,Bo Dai,H. Dai,Ofir Nachum,J. Tenenbaum,D. Schuurmans,P. Abbeel",0,48,0
"95fa2b27ab7eb84738441ee16da97323538938f9","https://www.semanticscholar.org/paper/95fa2b27ab7eb84738441ee16da97323538938f9",6,"I Speak, You Verify: Toward Trustworthy Neural Program Synthesis","An approach for improving the trustworthiness and overall accuracy of program synthesizers based on large language models for source code by analyzing the agreement between programs and predicates to judge both which program is most likely to be correct and whether the language model is able to solve the programming problem in the first place.","ArXiv",2022,"Darren Key,Wen-Ding Li,Kevin Ellis",0,34,0
"47a541269d4ef70f37f0d3a57483312c4c6c2ad5","https://www.semanticscholar.org/paper/47a541269d4ef70f37f0d3a57483312c4c6c2ad5",6,"Crawling the Internal Knowledge-Base of Language Models","The crawling procedure is decomposed into sub-tasks, realized through specially designed prompts that control for both precision and recall, and yields high precision graphs, while emit-ting a reasonable number of facts per entity.","ArXiv",2023,"Roi Cohen,Mor Geva,Jonathan Berant,A. Globerson",0,26,0
"5581bf85386737bd3378eec68189759a05280bea","https://www.semanticscholar.org/paper/5581bf85386737bd3378eec68189759a05280bea",6,"FOLIO: Natural Language Reasoning with First-Order Logic","The results show that one of the most capable Large Language Model (LLM) publicly available, GPT-3 davinci, achieves only slightly better than random results with few-shot prompting on a subset of FOLIO, and the model is especially bad at predicting the correct truth values for False and Unknown conclusions.","ArXiv",2022,"Simeng Han,Hailey Schoelkopf,Yilun Zhao,Zhenting Qi,Martin Riddell,Luke Benson,Lucy Sun,E. Zubova,Yujie Qiao,Matthew Burtell,David Peng,Jonathan Fan,Yixin Liu,Brian Wong,Malcolm Sailor,Ansong Ni,Linyong Nan,Jungo Kasai,Tao Yu,Rui Zhang,Shafiq R. Joty,Alexander R. Fabbri,Wojciech Kryscinski,Xi Victoria Lin,Caiming Xiong,Dragomir R. Radev",4,80,1
"c43a6f12b062a50617244611af180a8146e792de","https://www.semanticscholar.org/paper/c43a6f12b062a50617244611af180a8146e792de",6,"Learning from Natural Language Feedback","This work proposes to learn from natural language feedback, which conveys more information per human evaluation, using a three-step learning algorithm that fine-tunes a GPT-3 model to roughly human-level summarization ability.","ArXiv",2022,"J. Scheurer,Jon Ander Campos,Jun Shern Chan,Angelica Chen,Kyunghyun Cho,Ethan Perez",1,34,1
"2aec574791fd33e9be32fd5191a66734f805a6a1","https://www.semanticscholar.org/paper/2aec574791fd33e9be32fd5191a66734f805a6a1",6,"Training Language Models with Natural Language Feedback","This work proposes to learn from natural language feedback, which conveys more information per human evaluation, from a GPT-3 model to roughly human-level summarization ability using a three-step learning algorithm.","",2022,"J. Scheurer,Jon Ander Campos,Jun Shern Chan,Angelica Chen,Kyunghyun Cho,Ethan Perez",5,35,1
"c8d4c5907ddce4f42b20662324a2ccff7bf9d6c9","https://www.semanticscholar.org/paper/c8d4c5907ddce4f42b20662324a2ccff7bf9d6c9",6,"Nearest Neighbor Zero-Shot Inference","KNN-Prompt is introduced, a simple and effective kNN-LM with automatically expanded fuzzy verbalizers that is effective for domain adaptation with no further training, and gains increase with the size of the retrieval model.","Conference on Empirical Methods in Natural Language Processing",2022,"Weijia Shi,Julian Michael,Suchin Gururangan,Luke Zettlemoyer",5,37,0
"3ac5aa6ac59253611ef3cb72a95cbe21ef5dda1b","https://www.semanticscholar.org/paper/3ac5aa6ac59253611ef3cb72a95cbe21ef5dda1b",6,"Reframing Instructional Prompts to GPTk’s Language","This work studies several classes of reframing techniques for manual reformulation of prompts into more effective ones, and hopes these empirically-driven techniques will pave the way towards more effective future prompting algorithms.","Findings",2021,"Swaroop Mishra,Daniel Khashabi,Chitta Baral,Yejin Choi,Hannaneh Hajishirzi",55,44,6
"53c0abe83fe9b4fdaf2208295d8504fcf5241694","https://www.semanticscholar.org/paper/53c0abe83fe9b4fdaf2208295d8504fcf5241694",6,"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models","The UnifiedSKG framework is proposed, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset.","Conference on Empirical Methods in Natural Language Processing",2022,"Tianbao Xie,Chen Henry Wu,Peng Shi,Ruiqi Zhong,Torsten Scholak,Michihiro Yasunaga,Chien-Sheng Wu,Ming Zhong,Pengcheng Yin,Sida I. Wang,Victor Zhong,Bailin Wang,Chengzu Li,Connor Boyle,Ansong Ni,Ziyu Yao,Dragomir R. Radev,Caiming Xiong,Lingpeng Kong,Rui Zhang,Noah A. Smith,Luke Zettlemoyer,Tao Yu",92,118,13
"41f44979cf1cd3f4cbd615dc130bc33721f5281b","https://www.semanticscholar.org/paper/41f44979cf1cd3f4cbd615dc130bc33721f5281b",6,"MemPrompt: Memory-assisted Prompt Editing with User Feedback","It is shown how a (simulated) user can interac-tively teach a deployed GPT -3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT 3, a step towards the low-cost utility enhancement for very large pre-trained LMs.","",2022,"Aman Madaan,Niket Tandon,Peter Clark,Yiming Yang",1,41,0
"31e396eab8edb44f79e3158eeefc3280afb404f4","https://www.semanticscholar.org/paper/31e396eab8edb44f79e3158eeefc3280afb404f4",6,"How Many Data Samples is an Additional Instruction Worth?","A subset of tasks in the expanded version of NATURAL INSTRUCTIONS is augmented with additional instructions and it significantly improves model performance (up to 35%), especially in the low-data regime.","ArXiv",2022,"Ravsehaj Singh Puri,Swaroop Mishra,Mihir Parmar,Chitta Baral",8,57,0
"85b50df702604d738650d100a2dd6da40a8a6e4c","https://www.semanticscholar.org/paper/85b50df702604d738650d100a2dd6da40a8a6e4c",6,"Match-Prompt: Improving Multi-task Generalization Ability for Neural Text Matching via Prompt Learning","Experimental results on eighteen public datasets show that Match-Prompt can improve multi- Task generalization capability of PLMs in text matching and yield better in-domain multi-task, out-of-domainmulti-task and new task adaptation performance than multi- task and task-specific models trained by previous fine-tuning paradigm.","International Conference on Information and Knowledge Management",2022,"Shicheng Xu,Liang Pang,Huawei Shen,Xueqi Cheng",1,71,0
"a8fc183c089bd596ccc48b3d666f8814e1b41e55","https://www.semanticscholar.org/paper/a8fc183c089bd596ccc48b3d666f8814e1b41e55",6,"InCoder: A Generative Model for Code Infilling and Synthesis","INCODER is introduced, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via infilling) and the ability to condition on bidirectional context substantially improves performance on challenging tasks such as type inference, comment generation, and variable re-naming.","ArXiv",2022,"Daniel Fried,Armen Aghajanyan,Jessy Lin,Sida I. Wang,Eric Wallace,Freda Shi,Ruiqi Zhong,Wen-tau Yih,Luke Zettlemoyer,M. Lewis",59,77,18
"15190e8b459bd85d546286f7d7da61b4f4f3f58a","https://www.semanticscholar.org/paper/15190e8b459bd85d546286f7d7da61b4f4f3f58a",6,"What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization?","A large-scale evaluation of modeling choices and their impact on zero-shot generalization of large pretrained Transformer language models focuses on text-to-text models and shows that causal decoder-only models trained on an autoregressive language modeling objective exhibit the strongest zero- shot generalization after purely self-supervised pretraining.","International Conference on Machine Learning",2022,"Thomas Wang,Adam Roberts,Daniel Hesslow,Teven Le Scao,Hyung Won Chung,Iz Beltagy,Julien Launay,Colin Raffel",34,93,6
"fd7c3c8fbe8cf88bd967ead02738b43081e306a7","https://www.semanticscholar.org/paper/fd7c3c8fbe8cf88bd967ead02738b43081e306a7",6,"Training Language Models with Language Feedback","This work proposes to learn from natural language feedback, which conveys more information per human evaluation, from a GPT-3 model to roughly human-level summarization ability using a three-step learning algorithm.","",2022,"J. Scheurer,Jon Ander Campos,Jun Shern Chan,Angelica Chen,Kyunghyun Cho,Ethan Perez",7,43,2
"55a250868627de2d202d06e7cb3f6cbcd3a66f88","https://www.semanticscholar.org/paper/55a250868627de2d202d06e7cb3f6cbcd3a66f88",6,"ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts","A new multi-task, parameter-efficient language model (LM) tuning method that learns to transfer knowledge across different tasks via a mixture of soft prompts—small prefix embedding vectors pre-trained for different tasks that significantly outperforms prompt tuning and outperforms or matches fully fine-tuned or other parameter- efficient tuning approaches that use 10 times more parameters.","Conference on Empirical Methods in Natural Language Processing",2022,"Akari Asai,Mohammadreza Salehi,Matthew E. Peters,Hannaneh Hajishirzi",0,84,0
"8f926c0c3f1557a9241b7e75609082a1f207a75e","https://www.semanticscholar.org/paper/8f926c0c3f1557a9241b7e75609082a1f207a75e",6,"InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning","This work introduces InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets, and introduces novel meta-tasks to ensure that models adhere to instructions.","Conference on Empirical Methods in Natural Language Processing",2022,"Prakhar Gupta,Cathy Jiao,Yi-Ting Yeh,Shikib Mehri,M. Eskénazi,Jeffrey P. Bigham",10,124,0
"563a851106623b9f112d0e2a290d3950a871079c","https://www.semanticscholar.org/paper/563a851106623b9f112d0e2a290d3950a871079c",6,"kNN-Prompt: Nearest Neighbor Zero-Shot Inference","KNN-Prompt is introduced, a simple and effective kNN-LM with automatically expanded fuzzy verbalizers that is effective for domain adaptation with no further training, and gains increase with the size of the retrieval model.","",2022,"Weijia Shi,Julian Michael,Suchin Gururangan,Luke Zettlemoyer",0,33,0
"86d0d3855f94105e25d81cab9f3d269c6062a9c4","https://www.semanticscholar.org/paper/86d0d3855f94105e25d81cab9f3d269c6062a9c4",6,"Selective Annotation Makes Language Models Better Few-Shot Learners","It is shown that the effectiveness of vote- k is consistent with different language model sizes and domain shifts between training and test data, and will help researchers and practitioners design new natural language tasks and beyond.","ArXiv",2022,"Hongjin Su,Jungo Kasai,Chen Henry Wu,Weijia Shi,Tianlu Wang,Jiayi Xin,Rui Zhang,Mari Ostendorf,Luke Zettlemoyer,Noah A. Smith,Tao Yu",16,54,1
"b65b7f480a61d3dd31d8117b349cabc87c8ccf6c","https://www.semanticscholar.org/paper/b65b7f480a61d3dd31d8117b349cabc87c8ccf6c",6,"Bidirectional Language Models Are Also Few-shot Learners","For the first time, prompt-based learning is an emergent property of a broader class of language models, rather than only unidirectional models, and is shown to be effective on question answering and summarization.","ArXiv",2022,"Ajay Patel,Bryan Li,Mohammad Sadegh Rasooli,Noah Constant,Colin Raffel,Chris Callison-Burch",3,55,1
"0979695b5d74016e97ab8f306f632114e98bd6d9","https://www.semanticscholar.org/paper/0979695b5d74016e97ab8f306f632114e98bd6d9",6,"Task Compass: Scaling Multi-task Pre-training with Task Prefix","This work proposes a task prefix guided multi-task pre-training framework to explore the relationships among tasks and shows that the model can not only serve as the strong foundation backbone for a wide range of tasks but also be feasible as a probing tool for analyzing task relationships.","Conference on Empirical Methods in Natural Language Processing",2022,"Zhuosheng Zhang,Shuo Wang,Yichong Xu,Yuwei Fang,W. Yu,Yang Liu,H. Zhao,Chenguang Zhu,Michael Zeng",1,90,0
"82cd40e926300b6b18c34ced2edeb07e84d9d6c7","https://www.semanticscholar.org/paper/82cd40e926300b6b18c34ced2edeb07e84d9d6c7",6,"Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization","This work proposes Unlabeled Data Augmented Instruction Tuning (UDIT) to take better advantage of the instructions during IT by constructing pseudo-labeled data from unlabeled plain texts and comprehensively analyzes the key factors of UDIT to investigate how to better improve IT with unlabeling data.","Conference on Empirical Methods in Natural Language Processing",2022,"Yuxian Gu,Pei Ke,Xiaoyan Zhu,Minlie Huang",0,97,0
"77a94f6c91ee1590dd2c6fd80b4a6d8bffdb91ac","https://www.semanticscholar.org/paper/77a94f6c91ee1590dd2c6fd80b4a6d8bffdb91ac",6,"Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing","","Conference on Empirical Methods in Natural Language Processing",2022,"Tuhin Chakrabarty,Vishakh Padmakumar,Hengxing He",4,45,0
"b3d04ab5362b3fb171b5231dcf4c675c4c64ec02","https://www.semanticscholar.org/paper/b3d04ab5362b3fb171b5231dcf4c675c4c64ec02",6,"HyperTuning: Toward Adapting Large Language Models without Back-propagation","This work proposes HyperTuning, a novel approach to model adaptation that uses a hypermodel to generate task-speciﬁc parameters for a ﬁxed downstream model and shows that using hypermodel-generated parameters as initializations for further parameter-efﬂcient ﬀne-tuning improves performance.","ArXiv",2022,"Jason Phang,Yi Mao,Pengcheng He,Weizhu Chen",2,37,1
"05da1a63f448d1e4c41306d37b7a3d21a9974cef","https://www.semanticscholar.org/paper/05da1a63f448d1e4c41306d37b7a3d21a9974cef",6,"NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework","Experiments show that NIR-Prompt can improve the generalization of PLMs in NIR for both retrieval and reranking stages compared with baselines and under in- domain multi-task, out-of-domain multi- task, and new task adaptation settings.","ArXiv",2022,"Shicheng Xu,Liang Pang,Huawei Shen,Xueqi Cheng",0,80,0
"364fda684ba3063715743dfbed099c5d1b43dbfd","https://www.semanticscholar.org/paper/364fda684ba3063715743dfbed099c5d1b43dbfd",6,"Self-Play and Self-Describe: Policy Adaptation with Vision-Language Foundation Models","This work explores a new paradigm on leveraging the pre-trained foundation models with Self-PLAY and SelfDescribe with the focus on generalization on unseen objects, unseen tasks, unseen environments, and sim-to-real transfer and shows SPLAYD improves baseline in all cases.","ArXiv",2022,"Yuying Ge,Annabella Macaluso,Erran L. Li,Ping Luo,Xiaolong Wang",0,66,0
"6db13f58ff662eefa823a660fa86faf8ddf75533","https://www.semanticscholar.org/paper/6db13f58ff662eefa823a660fa86faf8ddf75533",6,"Controllable Text Generation with Language Constraints","A solution to leverage a language model’s own internal knowledge to guide generation and propose three forms of guidance (binary veriﬁer, top-k token, textual example), and employ pre-tuning approaches to distill the guidance to tackle diverse natural language constraints.","ArXiv",2022,"Howard Chen,Huihan Li,Danqi Chen,Karthik Narasimhan",0,38,0
"89184ab496b2a1ae31e068e628479b4cd8f4b9d2","https://www.semanticscholar.org/paper/89184ab496b2a1ae31e068e628479b4cd8f4b9d2",6,"Do We Still Need Clinical Language Models?","It is shown that relatively small specialized clinical models substantially outperform all in-context learning approaches, even when finetuned on limited annotated data.","",2023,"Eric P. Lehman,Evan Hernandez,Diwakar Mahajan,Jonas Wulff,Micah J. Smith,Zachary M. Ziegler,Daniel Nadler,P. Szolovits,A. Johnson,Emily Alsentzer",0,48,0
"76b547bc6c14940b262e9df2802d370cc5ef140e","https://www.semanticscholar.org/paper/76b547bc6c14940b262e9df2802d370cc5ef140e",6,"InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis","InstructABSA outperforms the previous state-of-the-art (SOTA) approaches on all three ABSA subtasks (ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x larger models.","",2023,"Kevin Scaria,Himanshu Gupta,S. Sawant,Swaroop Mishra,Chitta Baral",0,43,0
"10be7057efd37643a6aaf277ba4bfd8ab2a35775","https://www.semanticscholar.org/paper/10be7057efd37643a6aaf277ba4bfd8ab2a35775",6,"Controllable Factuality in Document-Grounded Dialog Systems Using a Noisy Channel Model","This work presents a model for document-grounded response generation in dialog that is decomposed into two components according to Bayes theorem, and outlines how introducing scaling factors between the components allows for controlling the tradeoff between factuality and fluency in the model output.","Conference on Empirical Methods in Natural Language Processing",2022,"Nico Daheim,David Thulke,C. Dugast,H. Ney",0,61,0
"25c402db512d327f1da143de3b8e797ad6fbfe5b","https://www.semanticscholar.org/paper/25c402db512d327f1da143de3b8e797ad6fbfe5b",6,"P ROG P ROMPT : Generating Situated Robot Task Plans using Large Language Models","This work presents a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks, and makes concrete recommendations about prompt structure and generation constraints through ablation experiments.","",2022,"Llm Gpt",0,39,0
"36af02a2fbce04f536dd339ccccb0434b85cfde8","https://www.semanticscholar.org/paper/36af02a2fbce04f536dd339ccccb0434b85cfde8",6,"Language and culture internalization for human-like autotelic AI","This work proposes Vygotskian autotelic agents — agents able to internalise their interactions with others and turn them into cognitive tools and focuses on language and shows how its structure and informational content may support the development of new cognitive functions in artiﬁcial agents as it does in humans.","Nature Machine Intelligence",2022,"Cédric Colas,Tristan Karch,Clément Moulin-Frier,P. Oudeyer",1,122,0
"c03fa01fbb9c77fe3d10609ba5f1dee33a723867","https://www.semanticscholar.org/paper/c03fa01fbb9c77fe3d10609ba5f1dee33a723867",6,"ProgPrompt: Generating Situated Robot Task Plans using Large Language Models","This work presents a programmatic LLM prompt structure that enables plan generation functional across situated envi- ronments, robot capabilities, and tasks, and makes concrete recommendations about prompt structure and generationaints through ablation experiments.","ArXiv",2022,"Ishika Singh,Valts Blukis,Arsalan Mousavian,Ankit Goyal,Danfei Xu,Jonathan Tremblay,D. Fox,Jesse Thomason,Animesh Garg",13,39,3
"7619b0aad6f16a0328021c5fdd3d97239e362e97","https://www.semanticscholar.org/paper/7619b0aad6f16a0328021c5fdd3d97239e362e97",6,"Visual Language Maps for Robot Navigation","VLMaps is proposed, a spatial map representation that directly fuses pretrained visual-language features with a 3D reconstruction of the physical world and enable navigation according to more complex language instructions than existing methods.","ArXiv",2022,"Chen Huang,Oier Mees,Andy Zeng,W. Burgard",4,49,0
"4bfc5b87891e95e1591e47f3ddd6eab19b616ce5","https://www.semanticscholar.org/paper/4bfc5b87891e95e1591e47f3ddd6eab19b616ce5",6,"Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training","This work first generate question-guided informative image captions, and pass the captions to a PLM as context for question answering, and achieves state-of-the-art results on zero-shot VQAv2 and GQA.","Conference on Empirical Methods in Natural Language Processing",2022,"A. M. H. Tiong,Junnan Li,Boyang Li,S. Savarese,S. Hoi",4,54,1
"f390e9d688f55d2518f0c09351a31c09ba3add88","https://www.semanticscholar.org/paper/f390e9d688f55d2518f0c09351a31c09ba3add88",6,"Manifestations of Xenophobia in AI Systems","This work ground the impact of xenophobia by first identifying distinct types of xenophobic harms, and then applying this framework across a number of prominent AI application domains, reviewing the potential interplay between AI and xenophobia on social media and recommendation systems.","ArXiv",2022,"Nenad Tomašev,J. L. Maynard,Iason Gabriel",0,339,0
"a7b060413027cbd25b6144f4a6214c3bd4fb12e3","https://www.semanticscholar.org/paper/a7b060413027cbd25b6144f4a6214c3bd4fb12e3",6,"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters","It is shown that CoT reasoning is possible even with invalid demonstrations—prompting with invalid reasoning steps can achieve over 80-90% of the performance obtained using CoT under various metrics, while still generating coherent lines of reasoning during inference.","ArXiv",2022,"Boshi Wang,Sewon Min,Xiang Deng,Jiaming Shen,You Wu,Luke Zettlemoyer,Huan Sun",2,20,1
"a07a94168608322600fd3cab54df1410b96852b6","https://www.semanticscholar.org/paper/a07a94168608322600fd3cab54df1410b96852b6",5,"Case-based Reasoning for Natural Language Queries over Knowledge Bases","A neuro-symbolic CBR approach (CBR-KBQA) for question answering over large knowledge bases that is capable of using new cases without any further training and is able to successfully generate logical forms containing unseen KB entities as well as relations.","Conference on Empirical Methods in Natural Language Processing",2021,"R. Das,M. Zaheer,Dung Ngoc Thai,Ameya Godbole,Ethan Perez,Jay Yoon Lee,Lizhen Tan,L. Polymenakos,A. McCallum",48,94,10
"de549c1592a62c129b8d49c8c0137aa6859b103f","https://www.semanticscholar.org/paper/de549c1592a62c129b8d49c8c0137aa6859b103f",5,"Internet-Augmented Dialogue Generation","An approach that learns to generate an internet search query based on the context, and then conditions on the search results to finally generate a response, a method that can employ up-to-the-minute relevant information.","Annual Meeting of the Association for Computational Linguistics",2021,"M. Komeili,Kurt Shuster,J. Weston",95,44,20
"2eb710b446570f48377b25eb279295648d05f65d","https://www.semanticscholar.org/paper/2eb710b446570f48377b25eb279295648d05f65d",5,"On sample efficiency and systematic generalization of grounded language understanding with deep learning","","",2020,"Dzmitry Bahdanau",0,173,0
"abba9a6f99d877fdd1b8412ddfcc26fdac6163dc","https://www.semanticscholar.org/paper/abba9a6f99d877fdd1b8412ddfcc26fdac6163dc",5,"SMART: Self-supervised Multi-task pretrAining with contRol Transformers","This work formulates a general pretraining-finetuning pipeline for sequential decision making, and proposes a generic pretraining framework Self-supervised Multi-task pretrAining with contRol Transformer (SMART), which significantly improves the learning efficiency among seen and unseen downstream tasks and domains under different learning scenarios.","ArXiv",2023,"Yanchao Sun,Shuang Ma,Ratnesh Madaan,Rogerio Bonatti,Furong Huang,Ashish Kapoor",0,42,0
"7cd79ad685a23e7a9acc1b7a25e15f739a6dd2a5","https://www.semanticscholar.org/paper/7cd79ad685a23e7a9acc1b7a25e15f739a6dd2a5",5,"Teachable Reinforcement Learning via Advice Distillation","In puzzle-solving, navigation, and locomotion domains, it is shown that agents that learn from advice can acquire new skills with signiﬁcantly less human supervision than standard reinforcement learning algorithms and often less than imitation learning.","Neural Information Processing Systems",2022,"Olivia Watkins,Trevor Darrell,P. Abbeel,Jacob Andreas,Abhishek Gupta",1,64,0
"e03d6414dd5a3e7fcac7fe273089ca6e5ad848dd","https://www.semanticscholar.org/paper/e03d6414dd5a3e7fcac7fe273089ca6e5ad848dd",5,"Efficient Exploration using Model-Based Quality-Diversity with Gradients","This approach optimizes all members of a population simultaneously to maintain both performance and diversity efﬁciently by leveraging the effectiveness of QD algorithms as good data generators to train deep models and maintains the divergent search capabilities of population-based approaches on tasks with deceptive rewards.","ArXiv",2022,"Bryan Lim,Manon Flageat,Antoine Cully",0,47,0
"e83478d3752ca2a3dbd5a4ff1bae2ca3c69750df","https://www.semanticscholar.org/paper/e83478d3752ca2a3dbd5a4ff1bae2ca3c69750df",5,"Actively Learning Costly Reward Functions for Reinforcement Learning","This work proposes to alleviate the problem of costly ground-truth rewards with rewards modeled by neural networks, counteracting non-stationarity of state and reward distributions during training with an active learning component, and shows that using the proposed ACRL method, it is possible to train agents in complex real-world environments orders of magnitudes faster.","ArXiv",2022,"Andr'e Eberhard,Houssam Metni,G. Fahland,Alexander Stroh,Pascal Friederich",0,46,0
"466317182e02c1cfdf5a227639778a296f48ca11","https://www.semanticscholar.org/paper/466317182e02c1cfdf5a227639778a296f48ca11",5,"Melting Pot 2.0","","ArXiv",2022,"J. Agapiou,A. Vezhnevets,Edgar A. Duéñez-Guzmán,Jayd Matyas,Yiran Mao,Peter Sunehag,R. Koster,Udari Madhushani,Kavya Kopparapu,R. Comanescu,D. Strouse,Michael Bradley Johanson,Sukhdeep Singh,Julia Haas,Igor Mordatch,D. Mobbs,Joel Z. Leibo",0,77,0
"aba015094c0f34b14a6744f63c6b5ea3cd9e0cc9","https://www.semanticscholar.org/paper/aba015094c0f34b14a6744f63c6b5ea3cd9e0cc9",5,"Towards Deadlock Handling with Machine Learning in a Simulation-Based Learning Environment","The first results show that artificial neural networks can learn to handle deadlock capable logistic systems with low complexity.","Online World Conference on Soft Computing in Industrial Applications",2022,"Marcel Müller,T. Reggelin,Iegor Kutsenko,Hartmut Zadek,L. Reyes-Rubiano",0,54,0
"63b5d00b658b5b7314676e0dd75eb61349298e8a","https://www.semanticscholar.org/paper/63b5d00b658b5b7314676e0dd75eb61349298e8a",5,"Breaking the Curse of Multiagency: Provably Efficient Decentralized Multi-Agent RL with Function Approximation","This paper presents the first line of MARL algorithms that provably resolve the curse of multiagency under function approximation, and designs a new decentralized algorithm -- V-Learning with Policy Replay, which gives the first polynomial sample complexity results for learning approximate Coarse Correlated Equilibria of Markov Games under decentralized linear function approximation.","",2023,"Yuanhao Wang,Qinghua Liu,Yunru Bai,Chi Jin",0,72,0
"31ed72a18ed8a1008786130af9f1d61761cff4f3","https://www.semanticscholar.org/paper/31ed72a18ed8a1008786130af9f1d61761cff4f3",5,"DQN-TAMER: Human-in-the-Loop Reinforcement Learning with Intractable Feedback","This work demonstrates a real-world human-in-the-loop RL application where a camera automatically recognizes a user's facial expressions as feedback to the agent while the agent explores a maze and proposes an RL method called DQN-TAMER, which efficiently uses both human feedback and distant rewards.","ArXiv",2018,"Riku Arakawa,Sosuke Kobayashi,Y. Unno,Yuta Tsuboi,S. Maeda",42,31,11
"3e425dd366e0696d5b835d8fff92add9873077da","https://www.semanticscholar.org/paper/3e425dd366e0696d5b835d8fff92add9873077da",5,"On Efficient Reinforcement Learning for Full-length Game of StarCraft II","This work investigates a set of RL techniques for the full-length game of StarCraft II and investigates a hierarchical RL approach, where the hierarchy involves two: the extracted macro-actions from experts’ demonstration trajectories and a hierarchical architecture of neural networks.","Journal of Artificial Intelligence Research",2022,"Ruo-Ze Liu,Zhen-Jia Pang,Zhou-Yu Meng,Wenhai Wang,Yang Yu,Tong Lu",2,36,0
"2f63b84461a7fe159451996d9901856f019e9277","https://www.semanticscholar.org/paper/2f63b84461a7fe159451996d9901856f019e9277",5,"Teacher-student curriculum learning for reinforcement learning","","ArXiv",2022,"Yanick Schraner",0,63,0
"a6c6e464b2ab15bb04176c26da3816d4038d5176","https://www.semanticscholar.org/paper/a6c6e464b2ab15bb04176c26da3816d4038d5176",5,"Dungeons and Data: A Large-Scale NetHack Dataset","It is shown that, while current state-of-the-art methods in ofﬂine RL and learning from demonstrations can effectively make use of the dataset, playing NetHack at human-level performance remains an open research challenge.","ArXiv",2022,"Eric Hambro,Roberta Raileanu,Dan Rothermel,Vegard Mella,Tim Rocktäschel,Heinrich Küttler,Naila Murray",0,66,0
"6fdbe62e8bedbbdb6292a37cd239208d93f2949b","https://www.semanticscholar.org/paper/6fdbe62e8bedbbdb6292a37cd239208d93f2949b",5,"Progress and summary of reinforcement learning on energy management of MPS-EV","","ArXiv",2022,"Jincheng Hu,Yang Lin,Liang Chu,Zhuoran Hou,Jihan Li,Jingjing Jiang,Yuanjian Zhang",0,139,0
"408b5fb36616f9a60b1911d148b88d6a5d6def7c","https://www.semanticscholar.org/paper/408b5fb36616f9a60b1911d148b88d6a5d6def7c",5,"Curiosity-Driven and Victim-Aware Adversarial Policies","This paper develops curiosity-driven and victim-aware adversarial policy training, a novel method that can more effectively exploit the defects of victim agents and suggests that the method is harder to defend against a commonly used defensive strategy.","Asia-Pacific Computer Systems Architecture Conference",2022,"Chen Gong,Zhou Yang,Yunru Bai,Jieke Shi,Arunesh Sinha,Bowen Xu,D. Lo,Xinwen Hou,Guoliang Fan",5,67,0
"ab4816876ef3ba7080d02b6d2cc487693ad3e5d8","https://www.semanticscholar.org/paper/ab4816876ef3ba7080d02b6d2cc487693ad3e5d8",5,"Tuning Synaptic Connections instead of Weights by Genetic Algorithm in Spiking Policy Network","Inspired by biological research that the brain forms memories by forming new synaptic connections and rewires these connections based on new experiences, the SPN mimics the sensorimotor neuron pathway of insects and communicates through event-based spikes to solve given tasks.","ArXiv",2022,"Duzhen Zhang,Tielin Zhang,Shuncheng Jia,Qing Wang,Bo Xu",0,66,0
"3cbdcec97acef3cb32f9759eb3b49ee6dafd9892","https://www.semanticscholar.org/paper/3cbdcec97acef3cb32f9759eb3b49ee6dafd9892",5,"Transformer in Transformer as Backbone for Deep Reinforcement Learning","The Transformer in Transformer (TIT) backbone is proposed, which cascades two Transformers in a very natural way: the inner one is used to process a single observation, while the outer one is responsible for processing the observation history; combining both is expected to extract spatial-temporal representations for good decision-making.","ArXiv",2022,"Hangyu Mao,Rui Zhao,Hao Chen,Jianye Hao,Yiqun Chen,Dong Li,Junge Zhang,Zhen Xiao",1,55,0
"e72f3a2e0e3b3c6939164b68dccc073e0e947436","https://www.semanticscholar.org/paper/e72f3a2e0e3b3c6939164b68dccc073e0e947436",5,"Multi-Agent Reinforcement Learning Based Actuator Control for EV HVAC Systems","","IEEE Access",2023,"Sungho Joo,Dongmin Lee,Minseop Kim,Taehoon Lee,Sanghyeok Choi,Seung-Chun Kim,Jeyeol Lee,Joo-Whan Kim,Yongsub Lim,Jeonghoon Lee",0,41,0
"222baa4e9e7ce691fdfddbc826a70e027daed70d","https://www.semanticscholar.org/paper/222baa4e9e7ce691fdfddbc826a70e027daed70d",5,"Reinforcement Learning in Healthcare: A Survey","This survey provides an extensive overview of RL applications in a variety of healthcare domains, ranging from dynamic treatment regimes in chronic diseases and critical care, automated medical diagnosis, and many other control or scheduling problems that have infiltrated every aspect of the healthcare system.","ACM Computing Surveys",2019,"Chao Yu,Jiming Liu,S. Nemati",215,373,7
"9bf040845e5d27e4de5832c032b9c8f32fcf7b82","https://www.semanticscholar.org/paper/9bf040845e5d27e4de5832c032b9c8f32fcf7b82",5,"Model-Based Transfer Reinforcement Learning Based on Graphical Model Representations","Relation Transfer is defined as explainable and transferable learning based on graphical model representations, inferring the skeleton and relations among variables in a causal view and generalizing to the target domain.","IEEE Transactions on Neural Networks and Learning Systems",2021,"Yuewen Sun,Kun Zhang,Changyin Sun",3,77,0
"3c84a3c87ee58e9dc7c0073cea5c311d466d07bb","https://www.semanticscholar.org/paper/3c84a3c87ee58e9dc7c0073cea5c311d466d07bb",5,"Challenging Machine Learning-based Clone Detectors via Semantic-preserving Code Transformations","Surprisingly, the experiments show that, despite the notable successes achieved by existing clone detectors, the ML models inside these detectors still cannot distinguish numerous clones produced by the code transformations in CloneGen.","IEEE Transactions on Software Engineering",2021,"Weiwei Zhang,Shengjian Guo,Hongyu Zhang,Yulei Sui,Yinxing Xue,Yun Xu",5,79,0
"883fa47931757e8721b3357387f7164a4da6e1fd","https://www.semanticscholar.org/paper/883fa47931757e8721b3357387f7164a4da6e1fd",5,"Proximal Policy Optimization with Adaptive Threshold for Symmetric Relative Density Ratio","A new PPO derived using relative Pearson (RPE) divergence, therefore so-called PPO-RPE, to design the threshold adaptively, to maximize the values of regularization of policy is proposed.","Results in Control and Optimization",2022,"Taisuke Kobayashi",1,36,0
"db86eddbd96424a486c3a7301767b65349dfd604","https://www.semanticscholar.org/paper/db86eddbd96424a486c3a7301767b65349dfd604",5,"Modelling fine-sliced three dimensional electron diffraction data with dynamical Bloch-wave simulations","","IUCrJ",2022,"Anton Cleverley,R. Beanland",0,21,0
"2d0fb59b1e6a8cb80ae2a0060bd35637cf4e8bbb","https://www.semanticscholar.org/paper/2d0fb59b1e6a8cb80ae2a0060bd35637cf4e8bbb",5,"Systems Theoretic Process Analysis of a Run Time Assured Neural Network Control System","This research considers the problem of identifying safety constraints and developing Run Time Assurance (RTA) for Deep Reinforcement Learning (RL) Tactical Autopilots that use neural network control systems (NNCS) and applies STAMP and STPA to an NNCS bounded by RTA.","AIAA SCITECH 2023 Forum",2022,"Kerianne L. Hobbs,Benjamin Heiner,Lillian Busse,Kyle Dunlap,Jonathan C. Rowanhill,A. Hocking,Aditya Zutshi",0,43,0
"29250e776d98d1e2b0d0222eaf167ebe890e688d","https://www.semanticscholar.org/paper/29250e776d98d1e2b0d0222eaf167ebe890e688d",5,"Distributed Multiagent Deep Reinforcement Learning for Multiline Dynamic Bus Timetable Optimization","This article considers the multiline dynamic bus timetable optimization problem as a Markov decision process model and proposes a multiagent deep reinforcement learning framework to ensure effective learning from the imperfect-information game, where the passenger demand and traffic condition are not always known in advance.","IEEE Transactions on Industrial Informatics",2023,"Haoyang Yan,Zhiyong Cui,Xinqiang Chen,Xiaolei Ma",4,30,0
"53cf80e5eadc8e4b3df358ce856cf14cb71efc18","https://www.semanticscholar.org/paper/53cf80e5eadc8e4b3df358ce856cf14cb71efc18",5,"Accelerating Policy Gradient by Estimating Value Function from Prior Computation in Deep Reinforcement Learning","This paper investigates the use of prior computation to estimate the value function to improve sample efficiency in on-policy policy gradient methods in reinforcement learning and learns a new value function for the target task while combining it with a value estimate from the prior computation.","ArXiv",2023,"Md Masudur Rahman,Yexiang Xue",0,31,0
"a19c67d9d1d416731930dff76d8c79ff5b8247c9","https://www.semanticscholar.org/paper/a19c67d9d1d416731930dff76d8c79ff5b8247c9",5,"Population-size-Aware Policy Optimization for Mean-Field Games","This work attempts to bridge the two fields of finite-agent and infinite-agent games, by studying how the optimal policies of agents evolve with the number of agents in mean-field games, an agent-centric perspective in contrast to the existing works focusing typically on the convergence of the empirical distribution of the population.","ArXiv",2023,"Pengdeng Li,Xinrun Wang,Shuxin Li,Hau Chan,Bo An",0,93,0
"8031bfd2408b9fa41e85b346b9452ebd63073076","https://www.semanticscholar.org/paper/8031bfd2408b9fa41e85b346b9452ebd63073076",5,"Distributional GFlowNets with Quantile Flows","This work adopts a distributional paradigm for GFlowNets, turning each flow function into a distribution, thus providing more informative learning signals during training, and finds that the distributional approach can achieve substantial improvement on existing benchmarks compared to prior methods.","ArXiv",2023,"Dinghuai Zhang,L. Pan,Ricky T. Q. Chen,Aaron C. Courville,Y. Bengio",0,66,0
"24c7d869f741b61dae384d97d4ca2abd4d2244f6","https://www.semanticscholar.org/paper/24c7d869f741b61dae384d97d4ca2abd4d2244f6",5,"Accelerating deep reinforcement learning via knowledge-guided policy network","A knowledge-guided policy network, a novel framework that combines suboptimal human knowledge with reinforcement learning and RL that significantly improves the learning efficiency of basic RL algorithms, even with very low-performance human prior knowledge.","Autonomous Agents and Multi-Agent Systems",2023,"Yuanqiang Yu,Peng Zhang,Kai Zhao,Yan Zheng,Jianye Hao",0,54,0
"e8787895af512169814655ba32ff0f46d0d665e4","https://www.semanticscholar.org/paper/e8787895af512169814655ba32ff0f46d0d665e4",5,"Research and Challenges of Reinforcement Learning in Cyber Defense Decision-Making for Intranet Security","This work proposes a framework that defines four modules based on the life cycle of threats: pentest, design, response, recovery, and provides a systematic view for understanding and solving decision-making problems in the application of reinforcement learning to cyber defense.","Algorithms",2022,"Wenhao Wang,Dingyuanhao Sun,Feng Jiang,Xingguo Chen,Cheng Zhu",1,131,0
"e258ac931efd168db6249f284aecda3b46c1d32d","https://www.semanticscholar.org/paper/e258ac931efd168db6249f284aecda3b46c1d32d",5,"Variance Reduction for Policy-Gradient Methods via Empirical Variance Minimization","The experiments indicate that in terms of variance reduction EV-based methods are much better than A2C and allow stronger variance reduction, and some theoretical guarantees of the actual variance reduction under very general assumptions are proved.","ArXiv",2022,"M. Kaledin,Alexander Golubev,D. Belomestny",0,33,0
"9dcc13ea4d9c988d044239497b5597f09c086e32","https://www.semanticscholar.org/paper/9dcc13ea4d9c988d044239497b5597f09c086e32",5,"Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework","Experimental results demonstrate that the proposed advisor-in-the-loop actor-critic framework, termed as Ask-AC, improves the learning efﬁciency of the agent, and achieves the performances on par with those obtained by continuous advisor monitoring.","ArXiv",2022,"Shunyu Liu,Xinchao Wang,Na Yu,Jie Song,Kaixuan Chen,Zunlei Feng,Mingli Song",0,43,0
"28cbf0c09dccea15025252e99b26eac0522eec46","https://www.semanticscholar.org/paper/28cbf0c09dccea15025252e99b26eac0522eec46",5,"Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in Edge IoT","An adaptive stochastic incremental ADMM (asI-ADMM) algorithm is proposed and applied to decentralized RL with edge-computing-empowered IoT networks and shows that the proposed algorithms outperform the state of the art in terms of communication costs and scalability and can well adapt to complex IoT environments.","IEEE Internet of Things Journal",2022,"Wanlu Lei,Yu Ye,M. Xiao,M. Skoglund,Zhu Han",1,56,0
"d7508c9354448860185a4537e4e3a052b4eb1019","https://www.semanticscholar.org/paper/d7508c9354448860185a4537e4e3a052b4eb1019",5,"Defending Smart Electrical Power Grids against Cyberattacks with Deep 
Q
-Learning","Comparison with alternative reinforcement learning methods provides further support for the general applicability of the deep-Q learning framework in ensuring secure operation of modern power grid systems.","PRX Energy",2022,"M. Moradi,Yang Weng,Y. Lai",0,48,0
"b1daf688d32c85c85dc62891d5ec8c366f477fea","https://www.semanticscholar.org/paper/b1daf688d32c85c85dc62891d5ec8c366f477fea",5,"Discrete space reinforcement learning algorithm based on twin support vector machine classification","","Pattern Recognition Letters",2022,"Wenguo Wu,Zhengchun Zhou,A. R. Adhikary,Bapi Dutta",0,37,0
"5685abf9e7bb2c16449ae1eb181051e503602a55","https://www.semanticscholar.org/paper/5685abf9e7bb2c16449ae1eb181051e503602a55",5,"Reinforcement Learning based Recommender Systems: A Survey","A survey on reinforcement learning based recommender systems (RLRSs) is presented and it is recognized and illustrated that RLRSs can be generally classified into RL- and DRL-based methods and proposed an RLRS framework with four components, i.e., state representation, policy optimization, reward formulation, and environment building.","ACM Computing Surveys",2021,"M. Afsar,T. Crump,B. Far",95,274,7
"12075ea34f5fbe32ec5582786761ab34d401209b","https://www.semanticscholar.org/paper/12075ea34f5fbe32ec5582786761ab34d401209b",5,"Exploration in Deep Reinforcement Learning: From Single-Agent to Multiagent Domain","A comprehensive survey on existing exploration methods for both single-agent and multi-agent RL, identifying several key challenges to efﬁcient exploration and point out a few future directions.","IEEE Transactions on Neural Networks and Learning Systems",2021,"Tianpei Yang,Hongyao Tang,Chenjia Bai,Jinyi Liu,Jianye Hao,Zhaopeng Meng,Peng Liu,Zhen Wang",0,235,0
"24d46159172993c67ccc83ae713d1b8dd21405b5","https://www.semanticscholar.org/paper/24d46159172993c67ccc83ae713d1b8dd21405b5",5,"Text-Driven Video Acceleration: A Weakly-Supervised Reinforcement Learning Method","A novel weakly-supervised methodology based on a reinforcement learning formulation to accelerate instructional videos using text and the Extended Visually-guided Document Attention Network (VDAN+), which can generate a highly discriminative embedding space to represent both textual and visual data.","IEEE Transactions on Pattern Analysis and Machine Intelligence",2022,"W. Ramos,M. Silva,Edson R. Araujo,Victor Moura,Keller Clayderman Martins de Oliveira,Leandro Soriano Marcolino,Erickson R. Nascimento",0,61,0
"4360de3e3303daa369515ac602c20b8f18be28bb","https://www.semanticscholar.org/paper/4360de3e3303daa369515ac602c20b8f18be28bb",5,"Comparative Study of Cooperative Platoon Merging Control Based on Reinforcement Learning","A model-free deep reinforcement learning approach is used to find the optimal driving behavior in the scenario in which two platoons are merging into one, and results show that the proposed framework can reduce the energy consumed, and the average jerk can be decreased by up to 50%, all by only changing the cooperative merge behavior.","Italian National Conference on Sensors",2023,"Ali Irshayyid,Jun Chen",0,63,0
"5f90d43e6ece5c6ee6e8186e4b57d46c85377713","https://www.semanticscholar.org/paper/5f90d43e6ece5c6ee6e8186e4b57d46c85377713",5,"DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization","DIFUSCO is introduced, a new graph-based diffusion framework for NPC combinatorial optimization that strongly outperforms the previous state-of-the-art neural solvers on the challenging SATLIB benchmark and investigates two types of diffusion models with Gaussian and Bernoulli noise, respectively.","",2023,"Zhiqing Sun,Yiming Yang",0,124,0
"d547e1781771deefcab1adb621e77f1d36d70061","https://www.semanticscholar.org/paper/d547e1781771deefcab1adb621e77f1d36d70061",5,"A Memory Efficient Baseline for Open Domain Question Answering","This paper considers three strategies to reduce the index size of dense retriever-reader systems: dimension reduction, vector quantization and passage filtering, and shows that it is possible to get competitive systems using less than 6Gb of memory.","ArXiv",2020,"Gautier Izacard,Fabio Petroni,Lucas Hosseini,Nicola De Cao,Sebastian Riedel,Edouard Grave",27,25,3
"469d92f195aebfa09e9b411ad92b3c879bcd1eba","https://www.semanticscholar.org/paper/469d92f195aebfa09e9b411ad92b3c879bcd1eba",5,"Progressively Pretrained Dense Corpus Index for Open-Domain Question Answering","This work proposes a sample-efficient method to pretrain the paragraph encoder using an existing pretrained sequence-to-sequence model to build a strong question generator that creates high-quality pretraining data and proposes a simple progressive pretraining algorithm to ensure the existence of effective negative samples in each batch.","Conference of the European Chapter of the Association for Computational Linguistics",2020,"Wenhan Xiong,Hong Wang,W. Wang",13,53,2
"7d429ad73fc311a0a29ab9d02482b4e6b059d81f","https://www.semanticscholar.org/paper/7d429ad73fc311a0a29ab9d02482b4e6b059d81f",5,"Generation-Augmented Retrieval for Open-Domain Question Answering","It is shown that generating diverse contexts for a query is beneficial as fusing their results consistently yields better retrieval accuracy, and as sparse and dense representations are often complementary, GAR can be easily combined with DPR to achieve even better performance.","Annual Meeting of the Association for Computational Linguistics",2020,"Yuning Mao,Pengcheng He,Xiaodong Liu,Yelong Shen,Jianfeng Gao,Jiawei Han,Weizhu Chen",80,44,15
"3416e5e5694855f7175125b5fe2e0b659c3cdbfa","https://www.semanticscholar.org/paper/3416e5e5694855f7175125b5fe2e0b659c3cdbfa",5,"RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering","This work proposes an optimized training approach, called RocketQA, to improving dense passage retrieval, which significantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions and demonstrates that the performance of end-to-end QA can be improved based on theRocketQA retriever.","North American Chapter of the Association for Computational Linguistics",2020,"Yingqi Qu,Yuchen Ding,Jing Liu,Kai Liu,Ruiyang Ren,Xin Zhao,Daxiang Dong,Hua Wu,Haifeng Wang",246,53,67
"93d3e45395117e21214d404c8753b578c29266d1","https://www.semanticscholar.org/paper/93d3e45395117e21214d404c8753b578c29266d1",5,"Open Question Answering over Tables and Text","This work considers for the first time open QA over both tabular and textual data and presents a new large-scale dataset Open Table-and-Text Question Answering (OTT-QA) to evaluate performance on this task.","International Conference on Learning Representations",2020,"Wenhu Chen,Ming-Wei Chang,Eva Schlinger,W. Wang,William W. Cohen",72,49,23
"c2482d0c49c2cfb1a50c24fb2177182893a9d1a0","https://www.semanticscholar.org/paper/c2482d0c49c2cfb1a50c24fb2177182893a9d1a0",5,"Answering Open-Domain Questions of Varying Reasoning Steps from Text","A unified system to answer directly from text open-domain questions that may require a varying number of retrieval steps, using a single multi-task transformer model to perform all the necessary subtasks in an iterative fashion.","Conference on Empirical Methods in Natural Language Processing",2020,"Peng Qi,Haejun Lee,OghenetegiriTGSido,Christopher D. Manning",26,51,5
"a2a7033a5a859e3a6e6f0a83018326400b4c5faa","https://www.semanticscholar.org/paper/a2a7033a5a859e3a6e6f0a83018326400b4c5faa",5,"Retrieval Augmentation Reduces Hallucination in Conversation","This work explores the use of neural-retrieval-in-the-loop architectures recently shown to be effective in open-domain QA for knowledge-grounded dialogue, a task that is arguably more challenging as it requires querying based on complex multi-turn dialogue context and generating conversationally coherent responses.","Conference on Empirical Methods in Natural Language Processing",2021,"Kurt Shuster,Spencer Poff,Moya Chen,Douwe Kiela,J. Weston",113,68,19
"9bbdcc03d872987eef9165f4a63c3878a5b05189","https://www.semanticscholar.org/paper/9bbdcc03d872987eef9165f4a63c3878a5b05189",5,"Condenser: a Pre-training Architecture for Dense Retrieval","This paper proposes to pre-train towards dense encoder with a novel Transformer architecture, Condenser, where LM prediction CONditions on DENSE Representation improves over standard LM by large margins on various text retrieval and similarity tasks.","Conference on Empirical Methods in Natural Language Processing",2021,"Luyu Gao,Jamie Callan",87,52,19
"baf34ac4080a365a7cec30b6877fa1a018eb31cf","https://www.semanticscholar.org/paper/baf34ac4080a365a7cec30b6877fa1a018eb31cf",5,"Joint Passage Ranking for Diverse Multi-Answer Retrieval","JPR is introduced, a joint passage retrieval model focusing on reranking that achieves significantly better answer coverage on three multi-answer datasets, and enables larger answer generation models since they need to consider fewer passages.","Conference on Empirical Methods in Natural Language Processing",2021,"Sewon Min,Kenton Lee,Ming-Wei Chang,Kristina Toutanova,Hannaneh Hajishirzi",14,39,3
"d82c779e316aebf0a6b08904dff9cd26ba57219b","https://www.semanticscholar.org/paper/d82c779e316aebf0a6b08904dff9cd26ba57219b",5,"R2-D2: A Modular Baseline for Open-Domain Question Answering","This work presents a novel four-stage open-domain QA pipeline R2-D2, composed of a retriever, passage reranker, extractive reader, generative reader and a mechanism that aggregates the prediction from all system’s components.","Conference on Empirical Methods in Natural Language Processing",2021,"Martin Fajcik,Martin Docekal,Karel Ondrej,P. Smrz",23,48,4
"7c5064305b8f8add57f211e185cdfeb9d68e6e31","https://www.semanticscholar.org/paper/7c5064305b8f8add57f211e185cdfeb9d68e6e31",5,"Recent Advances in Automated Question Answering In Biomedical Domain","The basic methodologies used for developing general domain QA systems are introduced, followed by a thorough investigation of different aspects of biomedicalQA systems, including benchmark datasets and several proposed approaches, both using structured databases and collection of texts.","ArXiv",2021,"K. D. Baksi",0,211,0
"5a37124345d0fb44ac1b4809dda85bf61ab79564","https://www.semanticscholar.org/paper/5a37124345d0fb44ac1b4809dda85bf61ab79564",5,"Towards Unsupervised Dense Information Retrieval with Contrastive Learning","This work explores the limits of contrastive learning as a way to train unsupervised dense retrievers, and shows that it leads to strong retrieval performance on the BEIR benchmark.","ArXiv",2021,"Gautier Izacard,Mathilde Caron,Lucas Hosseini,Sebastian Riedel,Piotr Bojanowski,Armand Joulin,Edouard Grave",50,58,17
"ca798e19f82266800f835d3b41672b385cdec0f6","https://www.semanticscholar.org/paper/ca798e19f82266800f835d3b41672b385cdec0f6",5,"Empowering Dual-Encoder with Query Generator for Cross-Lingual Dense Retrieval","This paper proposes to use a query generator as the teacher in the cross-lingual setting, which is less dependent on enough training samples and high-quality negative samples, and proposes a novel enhancement method, which uses the query generator to help the dual-encoder align queries from different languages, but does not need any additional parallel sentences.","Conference on Empirical Methods in Natural Language Processing",2022,"Houxing Ren,Linjun Shou,Ning Wu,Ming Gong,Daxin Jiang",0,54,0
"2af67c1063172c924a977d97d4b848651cc1617e","https://www.semanticscholar.org/paper/2af67c1063172c924a977d97d4b848651cc1617e",5,"A Survey on Machine Reading Comprehension Systems","It is demonstrated that the focus of research has changed in recent years from answer extraction to answer generation, from single- to multi-document reading comprehension, and from learning from scratch to using pre-trained word vectors.","Natural Language Engineering",2020,"Razieh Baradaran,Razieh Ghiasi,Hossein Amirkhani",39,241,4
"82d60ef4c9439ff24a4ebdd1b6eab59396a6a2ce","https://www.semanticscholar.org/paper/82d60ef4c9439ff24a4ebdd1b6eab59396a6a2ce",5,"TopiOCQA: Open-domain Conversational Question Answering with Topic Switching","TopiOCQA is introduced, an open-domain conversational dataset with topic switches based on Wikipedia that poses a challenging test-bed for models, where efficient retrieval is required on multiple turns of the same conversation, in conjunction with constructing valid responses using conversational history.","International Conference on Topology, Algebra and Categories in Logic",2021,"Vaibhav Adlakha,S. Dhuliawala,Kaheer Suleman,Harm de Vries,Siva Reddy",11,72,0
"8bcb1e12aa1d12221808d4e3643559077cfe7db2","https://www.semanticscholar.org/paper/8bcb1e12aa1d12221808d4e3643559077cfe7db2",5,"Open Domain Question Answering with A Unified Knowledge Interface","This work proposes a verbalizer-retriever-reader framework for ODQA over data and text where verbalized tables from Wikipedia and graphs from Wikidata are used as augmented knowledge sources and shows that the Unified Data and Text QA, UDT-QA, can effectively benefit from the expanded knowledge index, leading to large gains over text-only baselines.","Annual Meeting of the Association for Computational Linguistics",2021,"Kaixin Ma,Hao Cheng,Xiaodong Liu,Eric Nyberg,Jianfeng Gao",8,53,1
"c2b86e6dee44dd1dc711425e13eadcf04444dea9","https://www.semanticscholar.org/paper/c2b86e6dee44dd1dc711425e13eadcf04444dea9",5,"You Only Need One Model for Open-domain Question Answering","This work proposes casting the retriever and the reranker as internal passage-wise attention mechanisms applied sequentially within the transformer architecture and feeding computed representations to the reader, with the hidden representations progressively refined at each stage.","Conference on Empirical Methods in Natural Language Processing",2021,"Haejun Lee,Akhil Kedia,Jongwon Lee,Ashwin Paranjape,Christopher D. Manning,Kyoung-Gu Woo",6,62,3
"196c925eb2d0be235d85b3944e013330d101901c","https://www.semanticscholar.org/paper/196c925eb2d0be235d85b3944e013330d101901c",5,"A Thousand Words Are Worth More Than a Picture: Natural Language-Centric Outside-Knowledge Visual Question Answering","A Transform-Retrieve-Generate framework (TRiG) framework is proposed, which can be plug-and-played with alternative image-to-text models and textual knowledge bases, and outperforms all state-of-the-art supervised methods by at least 11.1% absolute margin.","",2022,"Feng Gao,Q. Ping,G. Thattai,Aishwarya N. Reganti,Yingting Wu,Premkumar Natarajan",5,66,1
"c2f9a27ab32bff87573e31594c97742af90f11b2","https://www.semanticscholar.org/paper/c2f9a27ab32bff87573e31594c97742af90f11b2",5,"Saving Dense Retriever from Shortcut Dependency in Conversational Search","This paper demonstrates the existence of a retrieval shortcut in CS, which causes models to retrieve passages solely relying on partial history while disregarding the latest question, and explores various hard negative mining strategies to build more robust models against shortcut dependency.","Conference on Empirical Methods in Natural Language Processing",2022,"Sungdong Kim,Gangwoo Kim",4,69,0
"c1b68e138ef3352e5010eacf1211a4d0e43b1ef0","https://www.semanticscholar.org/paper/c1b68e138ef3352e5010eacf1211a4d0e43b1ef0",5,"Generative Retrieval for Long Sequences","This paper uses an encoder-decoder model to memorize the target corpus in a generative manner and then uses it on query-to-passage generation, conjecture that generative retrieval is complementary to traditional retrieval, as it is conjecture that an ensemble of both outperforms homogeneous ensembles.","ArXiv",2022,"Hyunji Lee,Sohee Yang,Hanseok Oh,Minjoon Seo",0,34,0
"65ff0735438cf12bbad87d92ce466f55dafd4eda","https://www.semanticscholar.org/paper/65ff0735438cf12bbad87d92ce466f55dafd4eda",5,"QAMPARI: : An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs","QQA models from the retrieve-and-read family are trained, showing that QAMP AR I is challenging in terms of both passage retrieval and answer generation, reaching an F 1 score of 26.6 at best.","ArXiv",2022,"Samuel Joseph Amouyal,Ori Yoran,Tomer Wolfson,Jonathan Herzig,Jonathan Berant",2,37,1
"26217a04c8a2ce36e1d027cca7b35bf83cab957b","https://www.semanticscholar.org/paper/26217a04c8a2ce36e1d027cca7b35bf83cab957b",5,"ZusammenQA: Data Augmentation with Specialized Models for Cross-lingual Open-retrieval Question Answering System","The proposed system for the MIA Shared Task on Cross-lingual Openretrieval Question Answering (COQA) is introduced, showing that language- and domain-specialization as well as data augmentation help, especially for low-resource languages.","MIA",2022,"Chia-Chien Hung,Tommaso Green,Robert Litschko,Tornike Tsereteli,Sotaro Takeshita,Marco Bombieri,Goran Glavavs,Simone Paolo Ponzetto",1,55,0
"02720ba7a4c0c70506ef63e039387c10b227d8e3","https://www.semanticscholar.org/paper/02720ba7a4c0c70506ef63e039387c10b227d8e3",5,"Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering","This paper calls for an alternative paradigm for the OK-VQA task, which transforms the image into plain text, so that it can enable knowledge passage retrieval, and generative question-answering in the natural language space.","Computer Vision and Pattern Recognition",2022,"Feng Gao,Q. Ping,G. Thattai,Aishwarya N. Reganti,Yingting Wu,Premkumar Natarajan",2,67,2
"5aaaf17b9bc115e6a6ff7a2b0d11b3997647b969","https://www.semanticscholar.org/paper/5aaaf17b9bc115e6a6ff7a2b0d11b3997647b969",5,"Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader Models","A learnable passage mask mechanism is introduced which desensitizes the impact from the top-rank retrieval passages and prevents the model from overfitting and enforces the answer generation to focus on the entire retrieval passages.","Conference on Empirical Methods in Natural Language Processing",2022,"Shujian Zhang,Chengyue Gong,Xingchao Liu",0,61,0
"56ac515d27cc7e1e471fe883d12cf5fd841114ee","https://www.semanticscholar.org/paper/56ac515d27cc7e1e471fe883d12cf5fd841114ee",5,"Data Discovery using Natural Language Questions via a Self-Supervised Approach","A self-supervised approach to assemble training datasets and train learned discovery systems without human intervention is introduced, and the new techniques outperform state-of-the-art approaches on well-known benchmarks.","ArXiv",2023,"Qiming Wang,R. Fernandez",0,44,0
"1bb82660573bbaf01572041da16842ee2398ae39","https://www.semanticscholar.org/paper/1bb82660573bbaf01572041da16842ee2398ae39",5,"Learning Robust Real-Time Cultural Transmission without Human Data","","ArXiv",2022,"Avishkar Bhoopchand,Bethanie Brownfield,Adrian Collister,Agustin Dal Lago,Ashley D. Edwards,Richard Everett,Alexandre Frechette,Y. Oliveira,Edward Hughes,K. Mathewson,Piermaria Mendolicchio,Julia Pawar,Miruna Pislar,A. Platonov,Evan Senter,Sukhdeep Singh,Alexander Zacherl,Lei M. Zhang",4,161,1
"05c522667f9dee976764f805a2e509f7c05ca80e","https://www.semanticscholar.org/paper/05c522667f9dee976764f805a2e509f7c05ca80e",5,"RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning","This work proposes a simple yet effective method, ranked policy memory (RPM), to collect diverse multi-agent trajectories for training MARL policies with good generalizability, and implements RPM on top of MARL algorithms and conducts extensive experiments on Melting Pot.","ArXiv",2022,"Wei Qiu,Xiao Ma,Bo An,S. Obraztsova,Shuicheng Yan,Zhongwen Xu",0,70,0
"cc3cb6b0ea04eb35c1907e3917a4db4b435c95b1","https://www.semanticscholar.org/paper/cc3cb6b0ea04eb35c1907e3917a4db4b435c95b1",5,"FinRL-Meta: Market Environments and Benchmarks for Data-Driven Financial Reinforcement Learning","This paper presents an openly accessible FinRL-Meta library that has been actively maintained by the FinRL community and provides hundreds of market environments through an automatic pipeline that collects dynamic datasets from real-world markets and processes them into standard gym-style market environments.","SSRN Electronic Journal",2022,"Xiao-Yang Liu,Ziyi Xia,Jingyang Rui,Jiechao Gao,Hongyang Yang,Ming Zhu,Chris Wang,Zhaoran Wang,Jian Guo",2,78,0
"82866d7a806dd20ae397dd5e544d2e2240fe0949","https://www.semanticscholar.org/paper/82866d7a806dd20ae397dd5e544d2e2240fe0949",5,"Open-World Multi-Task Control Through Goal-Aware Representation Learning and Adaptive Horizon Prediction","This work proposes Goal-Sensitive Backbone (GSB) for the policy to encourage the emergence of goal-relevant visual state representations in Minecraft and proposes an adaptive horizon prediction module that helps alleviate the learning uncertainty brought by the non-stationary dynamics.","ArXiv",2023,"Shaofei Cai,Zihao Wang,Xiaojian Ma,Anji Liu,Yitao Liang",1,49,1
"0e1d82d24d58433ce9e211551605a0bfd296624f","https://www.semanticscholar.org/paper/0e1d82d24d58433ce9e211551605a0bfd296624f",5,"Text Modular Networks: Learning to Decompose Tasks in the Language of Existing Models","ModularQA is more versatile than existing explainable systems for DROP and HotpotQA datasets, is more robust than state-of-the-art blackbox (uninterpretable) systems, and generates more understandable and trustworthy explanations compared to prior work.","North American Chapter of the Association for Computational Linguistics",2021,"Tushar Khot,Daniel Khashabi,Kyle Richardson,Peter Clark,Ashish Sabharwal",42,66,3
"32ccd0f725fc5f7c81b57cad7787dc15b99151d0","https://www.semanticscholar.org/paper/32ccd0f725fc5f7c81b57cad7787dc15b99151d0",5,"Neural methods for effective, efficient, and exposure-aware information retrieval","This thesis presents novel neural architectures and methods motivated by the specific needs and challenges of IR tasks, and develops a framework to incorporate query term independence into any arbitrary deep model that enables large-scale precomputation and the use of inverted index for fast retrieval.","SIGIR Forum",2020,"Bhaskar Mitra",2,470,0
"2e1214b4a59b5931131b6c58e19b0eb16f1b365c","https://www.semanticscholar.org/paper/2e1214b4a59b5931131b6c58e19b0eb16f1b365c",5,"Can Question Rewriting Help Conversational Question Answering?","A reinforcement learning approach is investigated that integrates QR and CQA tasks and does not require corresponding QR datasets for targeted CZA and finds that the RL method is on par with the end-to-end baseline.","First Workshop on Insights from Negative Results in NLP",2022,"Etsuko Ishii,Yan Xu,Samuel Cahyawijaya,Bryan Wilie",3,39,0
"3d5a107d0f9803e450bee409491b5a54f25b0d7a","https://www.semanticscholar.org/paper/3d5a107d0f9803e450bee409491b5a54f25b0d7a",5,"Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel Test Environments","The Brick Tic-Tac-Toe (BTTT) test bed is introduced, where the brick position in the test environment is different from that in the training environment, and it is shown that traditional RL state-search approaches such as Monte Carlo Tree Search and Minimax are more generalizable to novel test environments than AlphaZero is.","ArXiv",2022,"John Tan Chong Min,M. Motani",0,31,0
"08b2b38cd8f03def99059fd32d5563580933e81b","https://www.semanticscholar.org/paper/08b2b38cd8f03def99059fd32d5563580933e81b",5,"Robust Searching-based Gradient Collaborative Management in Intelligent Transportation System","Robust Searching-based Gradient Collaborative Management in Intelligent Transportation System (RSGCM) is proposed, a practical ring-based gradient managing algorithm for communication schedules across devices to deal with ITS malfunction and increases the robustness of ITS.","ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)",2022,"Hong Shi,Hao Wang,Ruhui Ma,Yang Hua,Tao Song,Honghao Gao,Haibing Guan",0,43,0
"cc0f7a7742f05b18af1405dfa7e15cce4584e44e","https://www.semanticscholar.org/paper/cc0f7a7742f05b18af1405dfa7e15cce4584e44e",5,"A Survey on Reinforcement Learning in Aviation Applications","This survey paper first describes standard RL formulations and solutions, then surveys the landscape of existing RL-based applications in aviation, and suggests future directions of RL research in aviation.","ArXiv",2022,"Pouria Razzaghi,Amin Tabrizian,Wei Guo,Shulu Chen,Abenezer G. Taye,Ellis E. Thompson,Alexis Bregeon,A. Baheri,Peng Wei",0,137,0
"1c6435cb353271f3cb87b27ccc6df5b727d55f26","https://www.semanticscholar.org/paper/1c6435cb353271f3cb87b27ccc6df5b727d55f26",5,"Model-based Reinforcement Learning: A Survey","A survey of the integration of model-based reinforcement learning and planning, better known as model- based reinforcement learning, and a broad conceptual overview of planning-learning combinations for MDP optimization are presented.","Found. Trends Mach. Learn.",2020,"T. Moerland,J. Broekens,C. Jonker",19,327,0
"75135f01f1ba144b87902a0603c754924a1b394f","https://www.semanticscholar.org/paper/75135f01f1ba144b87902a0603c754924a1b394f",5,"A Succinct Summary of Reinforcement Learning","","ArXiv",2023,"S. Ahilan",0,25,0
"0f99ec01472af668be23cf14b0f6953f170082ad","https://www.semanticscholar.org/paper/0f99ec01472af668be23cf14b0f6953f170082ad",5,"Knowledge-integrated machine learning for materials: lessons from gameplaying and robotics","","Nature Reviews Materials",2023,"K. Hippalgaonkar,Qianxiao Li,Xiaonan Wang,John Fisher,J. Kirkpatrick,T. Buonassisi",0,152,0
"7758711c910bafcd5976d35eeabd69e0a1264156","https://www.semanticscholar.org/paper/7758711c910bafcd5976d35eeabd69e0a1264156",5,"Policy Expansion for Bridging Offline-to-Online Reinforcement Learning","A policy expansion scheme that ensures that the policy previously learned offline is fully retained during online learning, thus mitigating the potential issues such as destroying the useful behaviors of the offline policy in the initial stage of online learning while allowing the offline Policy to participate in the exploration naturally in an adaptive manner.","ArXiv",2023,"Haichao Zhang,We Xu,Haonan Yu",0,66,0
"754fad16ccde2328b302162571650254acd38203","https://www.semanticscholar.org/paper/754fad16ccde2328b302162571650254acd38203",5,"Query Expansion Using Contextual Clue Sampling with Language Models","This work argues that expansion terms from language models to generate query-related contexts should balance two key aspects: diversity and relevance, and proposes a combination of an effective filtering strategy and fusion of the retrieved documents based on the generation probability of each context.","ArXiv",2022,"Linqing Liu,Minghan Li,Jimmy Lin,Sebastian Riedel,Pontus Stenetorp",0,31,0
"bdeef928a5ed19315a4eb8e776794cfa9d3119e7","https://www.semanticscholar.org/paper/bdeef928a5ed19315a4eb8e776794cfa9d3119e7",5,"Disentangled Retrieval and Reasoning for Implicit Question Answering.","This article proposes a systematic solution denoted as DisentangledQA, which disentangles topic, attribute, and reasoning strategy from the implicit question to guide the retrieval and reasoning of evidence retrieval and answer reasoning.","IEEE Transactions on Neural Networks and Learning Systems",2022,"Qiang Liu,Xiubo Geng,Yu Wang,E. Cambria,Daxin Jiang",0,58,0
"00675f1591392622b0db2d9cd37a8a1f32e37aa8","https://www.semanticscholar.org/paper/00675f1591392622b0db2d9cd37a8a1f32e37aa8",5,"Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks","It is shown that, with consistent tokenization, the model performs better in both in-domain and out-of-domain datasets, with a notable average of +1.7 F 1 gain when a BART model is trained on SQuAD and evaluated on 8 QA datasets.","ArXiv",2022,"Kaiser Sun,Peng Qi,Yuhao Zhang,Lan Liu,William Yang Wang,Zhiheng Huang",0,29,0
"7138b55809694d052a9cc9bab77c880d87872616","https://www.semanticscholar.org/paper/7138b55809694d052a9cc9bab77c880d87872616",5,"EmbedDistill: A Geometric Knowledge Distillation for Information Retrieval","The proposed distillation approach supports both retrieval and re-ranking stages and crucially leverages the relative geometry among queries and documents learned by the large teacher model to provide stronger signals about local geometry via embedding matching and attaining better coverage of data manifold globally via query generation.","ArXiv",2023,"Seungyeon Kim,A. Rawat,M. Zaheer,Sadeep Jayasumana,Veeranjaneyulu Sadhanala,Wittawat Jitkrittum,A. Menon,R. Fergus,Surinder Kumar",0,62,0
"a23b8f072625d6481ead4c8b6193f01cdddd7fe0","https://www.semanticscholar.org/paper/a23b8f072625d6481ead4c8b6193f01cdddd7fe0",5,"Symbolic Discovery of Optimization Algorithms","The method discovers a simple and effective optimization algorithm, Lion, which is more memory-efficient than Adam and requires a smaller learning rate than Adam due to the larger norm of the update produced by the sign function.","",2023,"Xiangning Chen,Chen Liang,Da Huang,Esteban Real,Kaiyuan Wang,Yao Liu,Hieu Pham,Xuanyi Dong,Thang Luong,Cho-Jui Hsieh,Yifeng Lu,Quoc V. Le",0,104,0
"b97369cf35c58d7c518e7364dff54535d344c94c","https://www.semanticscholar.org/paper/b97369cf35c58d7c518e7364dff54535d344c94c",5,"Learning a model is paramount for sample efficiency in reinforcement learning control of PDEs","It is demonstrated that learning an actuated model in parallel to training the RL agent significantly reduces the total amount of required data sampled from the real system, and that iteratively updating the model is of major importance to avoid biases in the RL training.","",2023,"Stefan Werner,Sebastian Peitz",0,75,0
"12bc45e2268a5742d21a8a37109f8793417cefcc","https://www.semanticscholar.org/paper/12bc45e2268a5742d21a8a37109f8793417cefcc",5,"More Than Reading Comprehension: A Survey on Datasets and Metrics of Textual Question Answering","A survey of 47 recent textual QA benchmark datasets and a new taxonomy from an application point of view is proposed, which summarizes 8 evaluation metrics oftextual QA tasks and suggests directions for future work.","ArXiv",2021,"Yang Bai,D. Wang",4,74,2
"e02a757617c2c42eb62889cc4d4aee3765928303","https://www.semanticscholar.org/paper/e02a757617c2c42eb62889cc4d4aee3765928303",5,"The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large Web Corpus","It is observed that while a dense index can outperform a sparse BM25 baseline on Wikipedia, on S PHERE this is not yet possible, and to facilitate further research and minimise the community’s reliance on propri-etary, black-box search engines, the indices, evaluation metrics and infrastructure are shared.","ArXiv",2021,"Aleksandra Piktus,Fabio Petroni,Vladimir Karpukhin,Dmytro Okhonko,Samuel Broscheit,Gautier Izacard,Patrick Lewis,Barlas Ouguz,Edouard Grave,Wen-tau Yih,Sebastian Riedel",21,68,0
"60dfb269f6ec44ccf993c52ba688481bc32f2b31","https://www.semanticscholar.org/paper/60dfb269f6ec44ccf993c52ba688481bc32f2b31",5,"M3: A Multi-View Fusion and Multi-Decoding Network for Multi-Document Reading Comprehension","This work proposes a novel method that tries to employ a multi-view fusion and multi-decoding mechanism to achieve fine-grained fusion of evidence clues from different documents in the encoder and decoder concurrently.","Conference on Empirical Methods in Natural Language Processing",2022,"Liang Wen,Houfeng Wang,Yingwei Luo,Xiaolin Wang",0,40,0
"5aec43e6d48c1b187778ee3beb6e8e3d41267077","https://www.semanticscholar.org/paper/5aec43e6d48c1b187778ee3beb6e8e3d41267077",5,"CCQA: A New Web-Scale Question Answering Dataset for Model Pre-Training","A novel open-domain question-answering dataset based on the Common Crawl project that achieves promising results in zero-shot, low resource, and tuned settings across multiple tasks, models and benchmarks is proposed.","NAACL-HLT",2021,"Patrick Huber,A. Aghajanyan,Barlas Oğuz,Dmytro Okhonko,Wen-tau Yih,Sonal Gupta,Xilun Chen",6,31,1
"b4c793fc05644979b405e79d9a6112dcbf85b11c","https://www.semanticscholar.org/paper/b4c793fc05644979b405e79d9a6112dcbf85b11c",5,"TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval","TABi is introduced, a method to jointly train bi-encoders on knowledge graph types and unstructured text for entity retrieval for open-domain tasks and leverages a type-enforced contrastive loss to encourage entities and queries of similar types to be close in the embedding space.","Findings",2022,"Megan Leszczynski,Daniel Y. Fu,Mayee F. Chen,Christopher R'e",5,52,0
"39a26d50587e2e3e17e53b10ad3a7c0dce88f608","https://www.semanticscholar.org/paper/39a26d50587e2e3e17e53b10ad3a7c0dce88f608",5,"Modeling Multi-hop Question Answering as Single Sequence Prediction","This work proposes a simple generative approach (PathFid) that extends the task beyond just answer generation by explicitly modeling the reasoning process to resolve the answer for multi-hop questions by linearizing the hierarchical reasoning path of supporting passages, their key sentences, and finally the factoid answer.","Annual Meeting of the Association for Computational Linguistics",2022,"Semih Yavuz,Kazuma Hashimoto,Yingbo Zhou,N. Keskar,Caiming Xiong",5,52,0
"2f3efe44083af91cef562c1a3451eee2f8601d22","https://www.semanticscholar.org/paper/2f3efe44083af91cef562c1a3451eee2f8601d22",5,"WebGPT: Browser-assisted question-answering with human feedback","GPT-3 is tuned to answer long-form questions using a text-based web-browsing environment, which allows the model to search and navigate the web, and the best model is obtained by using behavior cloning, and then performing rejection sampling against a reward model trained to predict human preferences.","ArXiv",2021,"Reiichiro Nakano,Jacob Hilton,S. Balaji,Jeff Wu,Long Ouyang,Christina Kim,Christopher Hesse,Shantanu Jain,V. Kosaraju,W. Saunders,Xu Jiang,Karl Cobbe,Tyna Eloundou,Gretchen Krueger,Kevin Button,Matthew Knight,Benjamin Chess,J. Schulman",113,42,22
"bb775023683e0909a47f680850bb04a8cabf962f","https://www.semanticscholar.org/paper/bb775023683e0909a47f680850bb04a8cabf962f",5,"Integrating Question Rewrites in Conversational Question Answering: A Reinforcement Learning Approach","A reinforcement learning approach that integrates QR and CQA tasks without corresponding labeled QR datasets is proposed and the experimental results show that this approach can bring improvement over the pipeline approaches.","Annual Meeting of the Association for Computational Linguistics",2022,"Etsuko Ishii,Bryan Wilie,Yan Xu,Samuel Cahyawijaya,Pascale Fung",0,64,0
"203636315f7c9526189d88c541bedf623d63ea7c","https://www.semanticscholar.org/paper/203636315f7c9526189d88c541bedf623d63ea7c",5,"ASQA: Factoid Questions Meet Long-Form Answers","A novel dataset and a task that is called ASQA (Answer Summaries for Questions which are Ambiguous) are released and an agreement between this metric and human judgments are demonstrated, and a considerable gap between human performance and strong baselines is revealed.","Conference on Empirical Methods in Natural Language Processing",2022,"Ivan Stelmakh,Yi Luan,Bhuwan Dhingra,Ming-Wei Chang",1,40,0
"72c47862e2eee0e65bc25b6cd6baeb2a50ef4bc7","https://www.semanticscholar.org/paper/72c47862e2eee0e65bc25b6cd6baeb2a50ef4bc7",5,"tasksource: Structured Dataset Preprocessing Annotations for Frictionless Extreme Multi-Task Learning and Evaluation","This work identifies patterns across previous preprocessings, e.g. mapping of column names, and extraction of a specific sub-field from structured data in a column, and proposes a structured annotation framework that makes the authors' annotations fully exposed and not buried in unstructured code.","ArXiv",2023,"Damien Sileo",0,145,0
"f057ffb46bf799ae83b2d20e784103b9252b0596","https://www.semanticscholar.org/paper/f057ffb46bf799ae83b2d20e784103b9252b0596",5,"Do BERTs Learn to Use Browser User Interface? Exploring Multi-Step Tasks with Unified Vision-and-Language BERTs","It is suggested that although room for improvement exists, BERTs to multi-step tasks, such as 025 using graphical user interfaces, can be transferred using graphicaluser interfaces.","ArXiv",2022,"Taichi Iki,Akiko Aizawa",0,62,0
"15df0e2c602ae8ccedcf50accea080c4ba76f8ba","https://www.semanticscholar.org/paper/15df0e2c602ae8ccedcf50accea080c4ba76f8ba",5,"End-to-End Training of Neural Retrievers for Open-Domain Question Answering","An approach of unsupervised pre-training with the Inverse Cloze Task and masked salient spans, followed by supervised finetuning using question-context pairs leads to absolute gains over the previous best result in the top-20 retrieval accuracy on Natural Questions and TriviaQA datasets.","Annual Meeting of the Association for Computational Linguistics",2021,"Devendra Singh Sachan,M. Patwary,M. Shoeybi,Neel Kant,Wei Ping,William L. Hamilton,Bryan Catanzaro",47,37,10
"9b23fb9c472c202fd53aba9d0fcaf6ae469260b4","https://www.semanticscholar.org/paper/9b23fb9c472c202fd53aba9d0fcaf6ae469260b4",5,"Calibration of Machine Reading Systems at Scale","It is shown that calibrating such complex systems which contain discrete retrieval and deep reading components is challenging and current calibration techniques fail to scale to these settings, and proposes simple extensions to existing calibration approaches that allows them to adapt them toThese settings.","Findings",2022,"S. Dhuliawala,Leonard Adolphs,R. Das,Mrinmaya Sachan",2,42,0
"515cf674fcdced5a7d5bb156dd5fcc1f5290e79b","https://www.semanticscholar.org/paper/515cf674fcdced5a7d5bb156dd5fcc1f5290e79b",5,"In-context Examples Selection for Machine Translation","It is shown that the translation quality and the domain of the in-context examples matter and that 1-shot noisy unrelated example can have a catastrophic impact on output quality.","ArXiv",2022,"Sweta Agrawal,Chunting Zhou,M. Lewis,Luke Zettlemoyer,Marjan Ghazvininejad",8,42,2
"5aa4e5b90827f1c16bed100982e2a1871925d445","https://www.semanticscholar.org/paper/5aa4e5b90827f1c16bed100982e2a1871925d445",5,"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition","The proposed prompt tuning methods of Deep Neural Networks for speaker-adaptive VSR are proposed and it is shown that the performance of the pre-trained VSR model on unseen speakers can be largely improved by using a small amount of adaptation data, even if thePre-trained model is already developed with large speaker variations.","",2023,"Minsu Kim,Hyungil Kim,Y. Ro",0,101,0
"884c0b6db564208d99cadf2548f0aa96dee5f859","https://www.semanticscholar.org/paper/884c0b6db564208d99cadf2548f0aa96dee5f859",5,"Commonsense Reasoning with Implicit Knowledge in Natural Language","This work takes a middle ground where it uses smaller language models together with a relatively smaller but targeted natural language text corpora and proposes four methods competitive to state-of-the-art methods to reason with implicit commonsense.","Conference on Automated Knowledge Base Construction",2021,"Pratyay Banerjee,Swaroop Mishra",2,73,0
"9ba50f992ccd92f428503ea6246157260a26cd77","https://www.semanticscholar.org/paper/9ba50f992ccd92f428503ea6246157260a26cd77",5,"Do Prompt-Based Models Really Understand the Meaning of Their Prompts?","It is found that models can learn just as fast with many prompts that are intentionally irrelevant or even pathologically misleading as they do with instructively “good” prompts, and instruction-tuned models often produce good predictions with irrelevant and misleading prompts even at zero shots.","North American Chapter of the Association for Computational Linguistics",2021,"Albert Webson,Ellie Pavlick",64,67,9
"8c8868d75f5fc7a055fdbc8610ab20b0a4304829","https://www.semanticscholar.org/paper/8c8868d75f5fc7a055fdbc8610ab20b0a4304829",5,"Deep Reinforcement Learning: Opportunities and Challenges","In this article, a brief introduction to reinforcement learning (RL), and its relationship with deep learning, machine learning and AI is given, and a discussion is attempted, attempting to answer: “Why has RL not been widely adopted in practice yet?” and “When is RL helpful?’.","ArXiv",2022,"Yuxi Li",1,324,0
"21dfd2731fd26612dce5f6a4025a51185bed9520","https://www.semanticscholar.org/paper/21dfd2731fd26612dce5f6a4025a51185bed9520",5,"Relative Behavioral Attributes: Filling the Gap between Symbolic Goal Specification and Reward Learning from Human Preferences","This work proposes two practical methods that can learn to model any kind of behavioral attributes from ordered behavior clips, and demonstrates the effectiveness of the methods on four tasks with nine different behavioral attributes, showing that once the attributes are learned, end users can produce desirable agent behaviors relatively effortlessly, by providing feedback just around ten times.","ArXiv",2022,"L. Guan,Karthik Valmeekam,Subbarao Kambhampati",0,60,0
"f43138cf1e9fb0d9c073a3ba6db2506d4e9533a3","https://www.semanticscholar.org/paper/f43138cf1e9fb0d9c073a3ba6db2506d4e9533a3",5,"Conversation Regression Testing: A Design Technique for Prototyping Generalizable Prompt Strategies for Pre-trained Language Models","This work embodies the concept of regression testing in an interactive design tool, BotDesigner, that lets designers identify archetypal errors across multiple conversations; shows common threads of conversation using a graph visualization; and highlights the effects of prompt changes across bot design iterations.","ArXiv",2023,"J. D. Zamfirescu-Pereira,Bjoern Hartmann,Qiang Yang",0,44,0
"95c3cdcf0fae3a3427a375244088b74879b4d972","https://www.semanticscholar.org/paper/95c3cdcf0fae3a3427a375244088b74879b4d972",5,"Vygotskian Autotelic Artificial Intelligence: Language and Culture Internalization for Human-Like AI","","ArXiv",2022,"Cédric Colas,Tristan Karch,Clément Moulin-Frier,P. Oudeyer",3,128,0
"e8770b45ddfd9529b4f5a70658affc001bb0b287","https://www.semanticscholar.org/paper/e8770b45ddfd9529b4f5a70658affc001bb0b287",5,"MAQA: A Multimodal QA Benchmark for Negation","This study presents a new multimodal question answering (QA) benchmark adapted from labeled music videos in AudioSet and demonstrates that augmenting the original training task distributions with negated QA examples allow the model to reliably reason with negation.","ArXiv",2023,"Judith Yue Li",1,35,0
"ef12cbed0377de452351552bc1d41a5fd6638cab","https://www.semanticscholar.org/paper/ef12cbed0377de452351552bc1d41a5fd6638cab",5,"Policy-Induced Self-Supervision Improves Representation Finetuning in Visual RL","A self-supervised objective is proposed that clusters representations according to the policy they induce, as opposed to traditional representation similarity measures which are policy-agnostic (e.g. Euclidean norm, cosine similarity).","ArXiv",2023,"Sébastien M. R. Arnold,Fei Sha",0,68,0
"6059e073b11b96af7566efddd1d4ee0e25046c54","https://www.semanticscholar.org/paper/6059e073b11b96af7566efddd1d4ee0e25046c54",5,"Forecasting Future World Events with Neural Networks","Autocast is introduced, a dataset containing thousands of forecasting questions and an accompanying news corpus that poses a novel challenge for large language models and improved performance could bring large practical beneﬁts.","ArXiv",2022,"Andy Zou,Tristan Xiao,Ryan Jia,Joe Kwon,Mantas Mazeika,Richard Li,Dawn Song,J. Steinhardt,Owain Evans,Dan Hendrycks",2,58,0
"f7d2c630cf62a88ffbff2c62a0ad94536d46224d","https://www.semanticscholar.org/paper/f7d2c630cf62a88ffbff2c62a0ad94536d46224d",5,"Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling","The method of hypothesizing an AWM with LLMs and then verifying the AWM based on agent experience not only increases sample efﬁciency over contemporary methods by an order of magnitude but is also robust to and corrects errors in the LLM—successfully blending noisy internet-scale information from LLMs with knowledge grounded in environment dynamics.","ArXiv",2023,"Kolby Nottingham,Prithviraj Ammanabrolu,Alane Suhr,Yejin Choi,Hanna Hajishirzi,Sameer Singh,Roy Fox",0,45,0
"50b0c6ee2b3d53ba5af69d6c00b5d60888a9026f","https://www.semanticscholar.org/paper/50b0c6ee2b3d53ba5af69d6c00b5d60888a9026f",5,"Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations","Maieutic Prompting is developed, which aims to infer a correct answer to a question even from the unreliable generations of LM, and achieves up to 20% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models.","Conference on Empirical Methods in Natural Language Processing",2022,"Jaehun Jung,Lianhui Qin,S. Welleck,Faeze Brahman,Chandra Bhagavatula,Ronan Le Bras,Yejin Choi",22,53,3
"4217467e747182b9ad8035e8a2d657d2ce80af07","https://www.semanticscholar.org/paper/4217467e747182b9ad8035e8a2d657d2ce80af07",5,"On Reality and the Limits of Language Data","The objective of this work is to explore how far can language data alone enable computers to understand the necessary truth about the physical world using a novel and tightly controlled reasoning test and to highlight what models might learn directly from pure linguistic data.","ArXiv",2022,"N. Collier,Fangyu Liu,Ehsan Shareghi",1,82,0
"fadc0a6bcf968ed2ac71f567a48cd302dd62adde","https://www.semanticscholar.org/paper/fadc0a6bcf968ed2ac71f567a48cd302dd62adde",5,"RLET: A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees","RLET is proposed, a Reinforcement Learning based Entailment Tree generation framework, which is trained utilising the cumulative signals across the whole tree, and is the first to introduce RL into the entailment tree generation task.","Conference on Empirical Methods in Natural Language Processing",2022,"Tengxiao Liu,Qipeng Guo,Xiangkun Hu,Yuechen Zhang,Xipeng Qiu,Zheng Zhang",1,38,0
"ca2ea26b851fea6914a65b233b7daf8f32e38073","https://www.semanticscholar.org/paper/ca2ea26b851fea6914a65b233b7daf8f32e38073",5,"CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation","CONDAQA is presented, the first English reading comprehension dataset which requires reasoning about the implications of negated statements in paragraphs, and is challenging for current state-of-the-art models.","Conference on Empirical Methods in Natural Language Processing",2022,"Abhilasha Ravichander,Matt Gardner,Ana Marasović",2,84,0
"624ea7bdaf7e8e3f7bd76f72aa665b562f0dd70a","https://www.semanticscholar.org/paper/624ea7bdaf7e8e3f7bd76f72aa665b562f0dd70a",5,"When Do Decompositions Help for Machine Reading?","It is shown that decompositions can be helpful in the few-shot case, giving several points of improvement in exact match, but it is also shown that when models are given access to around a few hundred or more examples, decomposition are not helpful (and can actually be detrimental).","ArXiv",2022,"Kangda Wei,Dawn J Lawrie,Benjamin Van Durme,Yunmo Chen,Orion Weller",0,24,0
"1e0ae8f7c12c64824040624634dbae49428ce10f","https://www.semanticscholar.org/paper/1e0ae8f7c12c64824040624634dbae49428ce10f",5,"Contrast with Reconstruct: Contrastive 3D Representation Learning Guided by Generative Pretraining","This paper proposes contrast with reconstruct (ReCon) that unifies these two paradigms, and achieves a new state-of-the-art in 3D representation learning, e.g., 91.26% accuracy on ScanObjectNN.","ArXiv",2023,"Zekun Qi,Runpei Dong,Guo Fan,Zheng Ge,Xiangyu Zhang,Kaisheng Ma,Li Yi",0,99,0
"f2a2401a35b6b892d43642b31700e83e88b2ebb8","https://www.semanticscholar.org/paper/f2a2401a35b6b892d43642b31700e83e88b2ebb8",5,"SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning","SURF is presented, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation and improves the feedback-efficiency of the state-ofthe-art preference-based method on a variety of locomotion and robotic manipulation tasks.","International Conference on Learning Representations",2022,"Jongjin Park,Younggyo Seo,Jinwoo Shin,Honglak Lee,P. Abbeel,Kimin Lee",13,56,5
"0bec67b22a85cc4344bbbeb837f369afde091288","https://www.semanticscholar.org/paper/0bec67b22a85cc4344bbbeb837f369afde091288",5,"The Expertise Problem: Learning from Specialized Feedback","This work formalizes the expertise problem of RLHF algorithms that learn from multiple teachers, implements it as an extension of an existing RLHF benchmark, evaluates the performance of a state-of-the-art RLHF algorithm, and explores techniques to improve query and teacher selection.","ArXiv",2022,"Oliver Daniels-Koch,Rachel Freedman",1,29,0
"c3349d0493a56f76c27d74c5056ab039f665b7b4","https://www.semanticscholar.org/paper/c3349d0493a56f76c27d74c5056ab039f665b7b4",5,"Synthesizing Human Gaze Feedback for Improved NLP Performance","ScanTextGAN, a novel model for generating human scanpaths over text, is proposed and it is shown that ScanTextGAN-generated scan Paths can approximate meaningful cognitive signals in human gaze patterns and improve the performance of all downstream NLP tasks.","ArXiv",2023,"Varun Khurana,Yaman Kumar Singla,Nora Hollenstein,Rajesh Kumar,Balaji Krishnamurthy",0,55,0
"95f78c60698a1e7deb6a4ff8fcbdc3485c829dc6","https://www.semanticscholar.org/paper/95f78c60698a1e7deb6a4ff8fcbdc3485c829dc6",5,"UGIF: UI Grounded Instruction Following","This work proposes a natural language based instruction following agent that operates over the UI and shows the user how to perform various tasks on the smartphone and analyzes the common failure modes of existing models on this task and point out areas for improvement.","ArXiv",2022,"S. Venkatesh,Partha P. Talukdar,S. Narayanan",0,26,0
"44772fe1c3fa422a3da7e25092db2544893d6bfb","https://www.semanticscholar.org/paper/44772fe1c3fa422a3da7e25092db2544893d6bfb",5,"Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming","DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion and leads to improved logical reasoning of pre-trained LMs.","",2022,"Hanlin Zhang,Jian-Hui Huang,Ziyang Li,M. Naik,Eric Xing",3,43,1
"76aa6eb43db7f0684a5fc4619bd41c384a699c5d","https://www.semanticscholar.org/paper/76aa6eb43db7f0684a5fc4619bd41c384a699c5d",5,"Dynamic Generation of Interpretable Inference Rules in a Neuro-Symbolic Expert System","This novel reasoning engine, N ELLIE, dynamically instantiates interpretable inference rules that capture and score entailment (de)compositions over natural language statements that provide competitive performance on scientiﬁc QA datasets requiring structured explanations over multiple facts.","ArXiv",2022,"Nathaniel Weir,Benjamin Van Durme",2,70,0
"b1054e448186822bfe9445bb6f4533d157e3da5e","https://www.semanticscholar.org/paper/b1054e448186822bfe9445bb6f4533d157e3da5e",5,"True Detective: A Challenging Benchmark for Deep Abductive Reasoning in Foundation Models","The results show that state-of-the-art GPT models perform significantly worse than human solvers on this benchmark, indicating that there is still a signiﬁcant gap in the abductive reasoning abilities of LLMs and highlights the need for further research in this area.","ArXiv",2022,"Maksym Del,Mark Fishel",0,10,0
"934733a641c6f46cec4ba74213c82fc76127eece","https://www.semanticscholar.org/paper/934733a641c6f46cec4ba74213c82fc76127eece",5,"A Categorical Archive of ChatGPT Failures","","ArXiv",2023,"A. Borji",1,45,0
"efa06fe7c6a4abbe465dbea4f7130f45720ac6f0","https://www.semanticscholar.org/paper/efa06fe7c6a4abbe465dbea4f7130f45720ac6f0",5,"Tuning computer vision models with task rewards","This work adopts a reinforcement learning approach and shows its surprising effectiveness across multiple computer vision tasks, such as object detection, panoptic segmentation, colorization and image captioning.","",2023,"André Susano Pinto,Alexander Kolesnikov,Yuge Shi,L. Beyer,Xiaohua Zhai",0,43,0
"83f5f43ec419470508ce14355b0ecf0e9036dc0f","https://www.semanticscholar.org/paper/83f5f43ec419470508ce14355b0ecf0e9036dc0f",5,"Huge Frozen Language Models as Readers for Open-Domain Question Answering","","",2022,"Yoav Levine,Ori Ram,Daniel Jannai,Barak Lenz,S. Shalev-Shwartz,A. Shashua,K. Leyton-Brown,Y. Shoham",2,14,0
"361b3c2d78c4ed44d0e11b8e16600b29fc27479d","https://www.semanticscholar.org/paper/361b3c2d78c4ed44d0e11b8e16600b29fc27479d",5,"Reasoning over Public and Private Data in Retrieval-Based Systems","This work defines the PUBLIC-PRIVATE AUTOREGRESSIVE INFORMATION RETRIEVAL (PAIR) privacy framework for the novel retrieval setting over multiple privacy scopes and argues that an adequate benchmark is missing to study PAIR since existing textual benchmarks require retrieving from a single data distribution.","ArXiv",2022,"Simran Arora,Patrick Lewis,Angela Fan,Jacob Kahn,Christopher R'e",2,80,0
"5a3b1fe3073d4ab6043542537c24b17f602eaf92","https://www.semanticscholar.org/paper/5a3b1fe3073d4ab6043542537c24b17f602eaf92",5,"Asking for Knowledge: Training RL Agents to Query External Knowledge Using Language","The AFK agent is proposed, which learns to generate language commands to query for meaningful knowledge that helps solve the tasks and outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld environments.","International Conference on Machine Learning",2022,"Iou-Jen Liu,Xingdi Yuan,Marc-Alexandre Côté,P. Oudeyer,A. Schwing",4,66,0
"64b0c2f0e89f56f3fb64a21fe699560316e56ef5","https://www.semanticscholar.org/paper/64b0c2f0e89f56f3fb64a21fe699560316e56ef5",5,"Contextualized Generative Retrieval","The embeddings parametric generative retrieval generative vocab embeddins decoding generative and the embeddments parametric Generative embedding space bottleneck parametric space are presented.","ArXiv",2022,"Hyunji Lee,Jaeyoung Kim,Hoyeon Chang,Hanseok Oh,Sohee Yang,Vladimir Karpukhin,Yi Lu,Minjoon Seo",0,28,0
"eebe62c685bffd1c8880fb3ce70e3b6d42b4b9e9","https://www.semanticscholar.org/paper/eebe62c685bffd1c8880fb3ce70e3b6d42b4b9e9",5,"DSI++: Updating Transformer Memory with New Documents","This work introduces DSI++, a continual learning challenge for DSI to incrementally index new documents while being able to answer queries related to both previously and newly indexed documents, and introduces a generative memory to sample pseudo-queries for documents and supplement them during continual indexing to prevent forgetting for the retrieval task.","ArXiv",2022,"Sanket Vaibhav Mehta,Jai Gupta,Yi Tay,M. Dehghani,V. Tran,J. Rao,Marc-Alexander Najork,Emma Strubell,Donald Metzler",0,52,0
"714beceee04a4ab07a971ff69961972b2e740eb5","https://www.semanticscholar.org/paper/714beceee04a4ab07a971ff69961972b2e740eb5",5,"Is GPT-3 a Psychopath? Evaluating Large Language Models from a Psychological Perspective","","ArXiv",2022,"Xingxuan Li,Yutong Li,Linlin Liu,Lidong Bing,Shafiq R. Joty",1,62,0
"36589346063ff26506330451976280011273b935","https://www.semanticscholar.org/paper/36589346063ff26506330451976280011273b935",5,"Towards Teachable Reasoning Systems","Generated chains of reasoning show how answers are implied by the system’s own internal beliefs, and are both faithful and truthful, which suggests new opportunities for using language models in an interactive setting where users can inspect, debug, correct, and improve a system‘s performance over time.","ArXiv",2022,"Bhavana Dalvi,Oyvind Tafjord,Peter Clark",10,40,3
"7865ae1c4d7ba0e3ba48aef54270c3fdf61ec11d","https://www.semanticscholar.org/paper/7865ae1c4d7ba0e3ba48aef54270c3fdf61ec11d",5,"Symbolic Data Augmentation for Assisted Neural Reasoning","It is demonstrated that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters, and establish the state-of-the-art single model performance on OPENBOOKQA.","",2022,"Muhan Li",0,82,0
"7b9c43ee43b7e21af079ff0c098b2b17cefe461f","https://www.semanticscholar.org/paper/7b9c43ee43b7e21af079ff0c098b2b17cefe461f",5,"DREAM: Improving Situational QA by First Elaborating the Situation","Adding focused elaborations about a situation can improve a system’s reasoning about it, and may serve as an effective way of injecting new scenario-based knowledge into QA models.","North American Chapter of the Association for Computational Linguistics",2021,"Yuling Gu,Bhavana Dalvi,Peter Clark",7,49,2
"9ffefdf1fcd780cb71450b0a7a29247c66aa87be","https://www.semanticscholar.org/paper/9ffefdf1fcd780cb71450b0a7a29247c66aa87be",5,"The Unreliability of Explanations in Few-shot Prompting for Textual Reasoning","Analysis in three settings shows that explanations judged by humans to be good—logically consistent with the input and the prediction—more likely cooccur with accurate predictions, and trains calibrators using automatically extracted scores that assess the reliability of explanations to improve performance post-hoc.","",2022,"Xi Ye,Greg Durrett",8,69,0
"d400a649f0f0a3de22b89a268f48aff2dcb06a09","https://www.semanticscholar.org/paper/d400a649f0f0a3de22b89a268f48aff2dcb06a09",5,"Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning","This work recursively combines a trained backward-chaining model, capable of generating a set of premises entailing an answer hypothesis, with a verifier that checks that the model itself believes those premises (and the entailment itself) through self-querying.","Conference on Empirical Methods in Natural Language Processing",2022,"Oyvind Tafjord,Bhavana Dalvi,Peter Clark",3,38,0
"04db9b694280134f09af5fa787a306907edba29d","https://www.semanticscholar.org/paper/04db9b694280134f09af5fa787a306907edba29d",5,"How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN","AVEN, a suite of analyses for assessing the novelty of generated text, focusing on sequential structure (n-grams) and syntactic structure, is introduced, showing that GPT-2's novel text is usually well-formed morphologically and syntactically but has reasonably frequent semantic issues.","ArXiv",2021,"R. Thomas McCoy,P. Smolensky,Tal Linzen,Jianfeng Gao,Asli Celikyilmaz",18,81,2
"9bfda45ef365466cba27e47a9fdb98d15d78aa15","https://www.semanticscholar.org/paper/9bfda45ef365466cba27e47a9fdb98d15d78aa15",5,"Repository-Level Prompt Generation for Large Language Models of Code","This work proposes a framework called Repo-Level Prompt Generator that learns to generate example-speciﬁc prompts using prompt proposals, and demonstrates that an oracle constructed from these prompt proposals gives a remarkably high relative improvement over Codex, showing the quality of these proposals.","ArXiv",2022,"Disha Shrivastava,H. Larochelle,Daniel Tarlow",3,54,0
"f843233f76a5dff07bfa93a71a1cf13d8aa6a94a","https://www.semanticscholar.org/paper/f843233f76a5dff07bfa93a71a1cf13d8aa6a94a",5,"Exploring Length Generalization in Large Language Models","It is shown that combining pretrained large language models’ in-context learning abilities with scratchpad prompting results in a dramatic improvement in length generalization, and is run to identify common sources of mistakes that highlight opportunities in equipping language models with the ability to generalize to longer problems.","ArXiv",2022,"Cem Anil,Yuhuai Wu,Anders Andreassen,Aitor Lewkowycz,Vedant Misra,V. Ramasesh,Ambrose Slone,Guy Gur-Ari,Ethan Dyer,Behnam Neyshabur",19,32,5
"4fbe0cb0777b228e39243692bf29e2829060b8de","https://www.semanticscholar.org/paper/4fbe0cb0777b228e39243692bf29e2829060b8de",5,"When Language Model Meets Private Library","This paper investigates how to equip pre-trained language models with the ability of code generation for private libraries, and proposes a novel framework with two modules: the APIRetriever finds useful APIs, and the APICoder generates code using these APIs.","Conference on Empirical Methods in Natural Language Processing",2022,"Daoguang Zan,Bei Chen,Zeqi Lin,Bei Guan,Yongji Wang,Jian-Guang Lou",1,40,0
"95915aa592fdfc73f039c13472a21d3e4220f129","https://www.semanticscholar.org/paper/95915aa592fdfc73f039c13472a21d3e4220f129",5,"On the Compositional Generalization Gap of In-Context Learning","This work evaluates four model families, OPT, BLOOM, CodeGen and Codex on three semantic parsing datasets, CFQ, SCAN and GeoQuery with different number of exemplars, and observes a trend of decreasing relative generalization gap as models are scaled up.","BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",2022,"Arian Hosseini,A. Vani,Dzmitry Bahdanau,Alessandro Sordoni,Aaron C. Courville",1,36,0
"8bfd39e6e8f15531ffb071f2c6470e1e6e0a4aff","https://www.semanticscholar.org/paper/8bfd39e6e8f15531ffb071f2c6470e1e6e0a4aff",5,"LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models","A novel method is proposed, LLM-Planner, that harnesses the power of large language models (LLMs) such as GPT-3 to do few-shot planning for embodied agents and further proposes a simple but effective way to enhance LLMs with physical grounding to generate plans that are grounded in the current environment.","ArXiv",2022,"Chan Hee Song,Jiaman Wu,Clay Washington,Brian M. Sadler,Wei-Lun Chao,Yu Su",3,41,1
"d98fd1dd218bf522722a42b7c56f53dd6b1d20b0","https://www.semanticscholar.org/paper/d98fd1dd218bf522722a42b7c56f53dd6b1d20b0",5,"Diverse Demonstrations Improve In-context Compositional Generalization","This work proposes a method to select diverse demonstrations that aims to collectively cover all of the structures required in the output program, in order to encourage the model to generalize to new structures from these demonstrations.","ArXiv",2022,"Itay Levy,Ben Bogin,Jonathan Berant",2,44,1
"6a53eeada90d83b9508e7e451d62fdc9d2476350","https://www.semanticscholar.org/paper/6a53eeada90d83b9508e7e451d62fdc9d2476350",5,"Using cognitive psychology to understand GPT-3","Much of GPT-3's behavior is impressive: It solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multiarmed bandit task, and shows signatures of model-based reinforcement learning.","Proceedings of the National Academy of Sciences of the United States of America",2022,"Marcel Binz,Eric Schulz",14,58,0
"a20875e70a38cb053cd34e170038c4746f85dac9","https://www.semanticscholar.org/paper/a20875e70a38cb053cd34e170038c4746f85dac9",5,"A Case Study in Engineering a Conversational Programming Assistant's Persona","The Programmer’s Assistant is an experimental prototype software development environment that integrates a chatbot with a code editor that establishes a conversational interaction pattern, a set of conventions.","ArXiv",2023,"Steven I. Ross,Michael J. Muller,Fernando Martinez,Stephanie Houde,Justin D. Weisz",0,22,0
"658fbf9874c35b442ca67e3d0077682064808cbf","https://www.semanticscholar.org/paper/658fbf9874c35b442ca67e3d0077682064808cbf",5,"Norm-based Generalization Bounds for Compositionally Sparse Neural Networks","The Rademacher complexity of deep sparse neural networks is investigated and generalization bounds for multilayered sparse ReLU neural networks, including convolutional neural networks are proved, suggesting that compositional sparsity of the underlying target function is critical to the success of deep neural networks.","ArXiv",2023,"Tomer Galanti,Mengjia Xu,Liane Galanti,T. Poggio",0,53,0
"327333ba2362c48b11b76c9673475d25c076a363","https://www.semanticscholar.org/paper/327333ba2362c48b11b76c9673475d25c076a363",5,"Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming","Using OpenAI Codex significantly increased code-authoring performance while not decreasing performance on manual code-modification tasks, and learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance.","",2023,"Majeed Kazemitabaar,J. Chow,Carl Ka To Ma,Barbara J. Ericson,David Weintrop,Tovi Grossman",0,85,0
"10e8fd0de2c06056393dd1e5e16376bd83c88b42","https://www.semanticscholar.org/paper/10e8fd0de2c06056393dd1e5e16376bd83c88b42",5,"To Adapt or to Annotate: Challenges and Interventions for Domain Adaptation in Open-Domain Question Answering","It is found that not only do models fail to generalize, but high retrieval scores often still yield poor answer prediction accuracy, and several intervention methods are proposed which improve end-to-end answer F1 score by up to ∼ 24 points.","ArXiv",2022,"Dheeru Dua,Emma Strubell,Sameer Singh,Pat Verga",0,38,0
"4b256efcc9627d5f83a91de577623ee5479bc8f9","https://www.semanticscholar.org/paper/4b256efcc9627d5f83a91de577623ee5479bc8f9",5,"Generating Full Length Wikipedia Biographies: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies","A model for English text is developed that uses a retrieval mechanism to identify relevant sup-porting information on the web and a cache-based pre-trained encoder-decoder to generate long-form biographies section by section, including citation information.","ArXiv",2022,"Angela Fan,Claire Gardent",1,96,0
"816593b1abbc9b09763fcb2894ca3778db341769","https://www.semanticscholar.org/paper/816593b1abbc9b09763fcb2894ca3778db341769",5,"Generative Knowledge Graph Construction: A Review","This study summarizes the recent compelling progress in generative knowledge graph construction and presents a detailed, complete taxonomy for the generative KGC methods to provide theoretical insight and empirical analysis.","Conference on Empirical Methods in Natural Language Processing",2022,"Hongbin Ye,Ningyu Zhang,Hui Chen,Huajun Chen",1,109,0
"1338b3771c27090dee722cc5b351ace179ebae76","https://www.semanticscholar.org/paper/1338b3771c27090dee722cc5b351ace179ebae76",5,"Mathematics, word problems, common sense, and artificial intelligence","It is argued that it is not clear whether these kinds of limitations will be important in developing AI technology for pure mathematical research, but that they will beImportant in applications of mathematics, and may well beimportant in developing programs capable of reading and understanding mathematical content written by humans.","ArXiv",2023,"E. Davis",1,18,0
"eaa88d697f92739f3569564329e9d037aabbe2d7","https://www.semanticscholar.org/paper/eaa88d697f92739f3569564329e9d037aabbe2d7",5,"A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics","Models show a gap toward human-level generalization when tested with new concepts in a few-shot setting, and the results suggest that current models still struggle in extrapolation to long-range syntactic dependency and semantics.","",2021,"Qing Li,Siyuan Huang,Yining Hong,Yixin Zhu,Y. Wu,Song-Chun Zhu",1,105,1
"70f8e3c72e9178b408667e3619a87a153fd853e6","https://www.semanticscholar.org/paper/70f8e3c72e9178b408667e3619a87a153fd853e6",5,"Foundation Models of Scientific Knowledge for Chemistry: Opportunities, Challenges and Lessons Learned","This work develops large-scale general-purpose models for chemistry that can be effectively used to perform a wide range of in-domain and out-of-domain tasks and demonstrates that model size significantly contributes to the task performance when evaluated in a zero-shot setting.","BIGSCIENCE",2022,"Sameera Horawalavithana,Ellyn Ayton,Shivam Sharma,Scott Howland,Megha Subramanian,Scott Vasquez,Robin Cosbey,M. Glenski,Svitlana Volkova",4,77,0
"03488f1a193066b5ea8b9b800e119f07df5c1d9e","https://www.semanticscholar.org/paper/03488f1a193066b5ea8b9b800e119f07df5c1d9e",5,"Reasoning Like Program Executors","Experimental results on six benchmarks demonstrate that POET can significantly boost model performance in natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning.","Conference on Empirical Methods in Natural Language Processing",2022,"Xinyu Pi,Qian Liu,Bei Chen,Morteza Ziyadi,Zeqi Lin,Yan Gao,Qiang Fu,Jian-Guang Lou,Weizhu Chen",18,78,4
"5cbe278b65a81602a864184bbca37de91448a5f5","https://www.semanticscholar.org/paper/5cbe278b65a81602a864184bbca37de91448a5f5",5,"Competition-level code generation with AlphaCode","AlphaCode is introduced, a system for code generation that achieved an average ranking in the top 54.3% in simulated evaluations on recent programming competitions on the Codeforces platform, marking the first time an artificial intelligence system has performed competitively in programming competitions.","Science",2022,"Yujia Li,David H. Choi,Junyoung Chung,Nate Kushman,Julian Schrittwieser,Rémi Leblond,Tom,Eccles,James Keeling,Felix Gimeno,Agustin Dal Lago,T. Hubert,Peter Choy,Cyprien de,Masson d’Autume,I. Babuschkin,Xinyun Chen,Po-Sen Huang,Johannes Welbl,Sven Gowal,Alexey,Cherepanov,James Molloy,D. Mankowitz,Esme Sutherland Robson,Pushmeet Kohli,Nando de,Freitas,K. Kavukcuoglu,Oriol Vinyals",152,81,33
"155d712236147d90516045a71b66d5d32c03846f","https://www.semanticscholar.org/paper/155d712236147d90516045a71b66d5d32c03846f",5,"Autoregressive Search Engines: Generating Substrings as Document Identifiers","This work proposes an alternative that doesn’t force any structure in the search space: using all ngrams in a passage as its possible identiﬁer, which not only outperforms prior autoregressive approaches but also leads to an average improvement over more established retrieval solutions for passage-level retrieval on the KILT benchmark.","ArXiv",2022,"Michele Bevilacqua,G. Ottaviano,Patrick Lewis,Wen-tau Yih,Sebastian Riedel,Fabio Petroni",18,64,7
"26c9075f42ffa3e9b563c024dbf3e08f7d8df8f5","https://www.semanticscholar.org/paper/26c9075f42ffa3e9b563c024dbf3e08f7d8df8f5",5,"Factuality Enhanced Language Models for Open-Ended Text Generation","This work measures and improves the factual accuracy of large-scale LMs for open-ended text generation, and proposes a factuality-enhanced training method that uses T OPIC P REFIX for better awareness of facts and sentence completion as the training objective, which can vastly reduce the factual errors.","ArXiv",2022,"Nayeon Lee,Wei Ping,Peng Xu,M. Patwary,M. Shoeybi,Bryan Catanzaro",7,78,0
"07dc375b95aaeb748d7b0560bfa7d81f1bddc8b2","https://www.semanticscholar.org/paper/07dc375b95aaeb748d7b0560bfa7d81f1bddc8b2",5,"Predicting the Future of AI with AI: High-quality link prediction in an exponentially growing knowledge network","A new graph-based benchmark based on real-world data – the Science4Cast benchmark is developed, which aims to predict the future state of an evolving semantic network of AI.","ArXiv",2022,"M. Krenn,L. Buffoni,B. Coutinho,S. Eppel,Jacob G. Foster,Andrew Gritsevskiy,Harlin Lee,Yichao Lu,João P. Moutinho,Nima Sanjabi,Rishi Sonthalia,Ngoc M. Tran,Francisco Valente,Yangxinyu Xie,Rose Yu,Michael Kopp",1,66,0
"9f93f293fd2a188c6eb2c86aa55fd135548bb7a4","https://www.semanticscholar.org/paper/9f93f293fd2a188c6eb2c86aa55fd135548bb7a4",5,"SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models","This work proposes SmoothQuant, a training-free, accuracy-preserving, and general-purpose post-training quantization (PTQ) solution to enable 8-bit weight,8-bit activation (W8A8) quantization for LLMs, and integrates it into FasterTransformer, a state-of-the-art LLM serving framework, to achieve faster inference speed with half the number of GPUs compared to FP16.","ArXiv",2022,"Guangxuan Xiao,Ji Lin,Mickael Seznec,Julien Demouth,Song Han",7,42,2
"775b2dc88cf04993f8596332444a906bec2db807","https://www.semanticscholar.org/paper/775b2dc88cf04993f8596332444a906bec2db807",5,"Foundation models in brief: A historical, socio-technical focus","This paper contributes by crafting a crisp distinction between foundation models and prior deep learning models, providing a history of machine learning leading to foundation models, elaborating more on socio-technical aspects, i.e., organizational issues and end-user interaction, and a discussion of future research.","ArXiv",2022,"Johannes Schneider",0,62,0
"3c9ba25baca64151af4e9d50c7947de28eb2a599","https://www.semanticscholar.org/paper/3c9ba25baca64151af4e9d50c7947de28eb2a599",5,"Survey of Hallucination in Natural Language Generation","A broad overview of the research progress and challenges in the hallucination problem in NLG is provided, including task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation.","ACM Computing Surveys",2022,"Ziwei Ji,Nayeon Lee,Rita Frieske,Tiezheng Yu,D. Su,Yan Xu,Etsuko Ishii,Yejin Bang,Wenliang Dai,Andrea Madotto,Pascale Fung",61,250,4
"0f29d13896f1851422ada71eb15d31f1ab61cddf","https://www.semanticscholar.org/paper/0f29d13896f1851422ada71eb15d31f1ab61cddf",5,"Effidit: Your AI Writing Assistant","The main contents of this report include major modules of Efﬁdit, methods for implementing these modules, and evaluation results of some key methods.","ArXiv",2022,"Shuming Shi,Enbo Zhao,Duyu Tang,Yan Wang,Piji Li,Wei Bi,Haiyun Jiang,Guoping Huang,Leyang Cui,Xinting Huang,Cong Zhou,Yong Dai,Dongyang Ma",0,47,0
"366bae3f3e269ed9e1c3b6b8ef5b0984e8d5476f","https://www.semanticscholar.org/paper/366bae3f3e269ed9e1c3b6b8ef5b0984e8d5476f",5,"Attribution and Obfuscation of Neural Text Authorship: A Data Mining Perspective","A comprehensive review of recent literature on the attribution and obfuscation of neural text authorship from a Data Mining perspective, and the view on their limitations and promising research directions is shared.","ArXiv",2022,"Adaku Uchendu,Thai Le,Dongwon Lee",0,118,0
"9a523de464d0096a4f2f722ecda5ef11a42bc6eb","https://www.semanticscholar.org/paper/9a523de464d0096a4f2f722ecda5ef11a42bc6eb",5,"Robustness of Demonstration-based Learning Under Limited Data Scenario","This paper designs pathological demonstrations by gradually removing intuitively useful information from the standard ones to take a deep dive of the robustness of demonstration-based sequence labeling and shows that demonstrations composed of random tokens still make the model a better few-shot learner.","Conference on Empirical Methods in Natural Language Processing",2022,"Hongxin Zhang,Yanzhe Zhang,Ruiyi Zhang,Diyi Yang",1,40,0
"95d54e3ce577f7d91ab4b2c52c73b501245e484d","https://www.semanticscholar.org/paper/95d54e3ce577f7d91ab4b2c52c73b501245e484d",5,"ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback","A progressive zero-shot dataset generation framework, ProGen, which leverages the feedback from the task-specific model to guide the generation of new training data via in- context examples, which achieves on-par or superior performance with only 1\% synthetic dataset size compared to baseline methods without in-context feedback.","Conference on Empirical Methods in Natural Language Processing",2022,"Jiacheng Ye,Jiahui Gao,Jiangtao Feng,Zhiyong Wu,Tao Yu,Lingpeng Kong",1,53,0
"fe123b27a3ecc63c7087cb0d3a04e43790661c2d","https://www.semanticscholar.org/paper/fe123b27a3ecc63c7087cb0d3a04e43790661c2d",5,"LAD: Language Augmented Diffusion for Reinforcement Learning","This paper demonstrates the comparable performance of LAD with the state-of-the-art on the CALVIN language robotics benchmark with a much simpler architecture that contains no inductive biases special-ized to robotics, achieving an average success rate of 72% compared to the best performance of 76%.","ArXiv",2022,"Edwin Zhang,Yujie Lu,W. Wang,Amy Zhang",0,37,0
"20fae749e3d469c331731ffa2f811079db792fdc","https://www.semanticscholar.org/paper/20fae749e3d469c331731ffa2f811079db792fdc",5,"A Simple, Yet Effective Approach to Finding Biases in Code Generation","This work shows that current code generation systems exhibit biases inherited from large language model backbones, which might leak into generated code under specific circumstances, and proposes a framework that automatically removes hints and exposes various biases that these code generation models use.","ArXiv",2022,"Spyridon Mouselinos,Mateusz Malinowski,H. Michalewski",2,43,0
"066316c88c708bbc58b967a24f5dfdd4be371295","https://www.semanticscholar.org/paper/066316c88c708bbc58b967a24f5dfdd4be371295",5,"Prompting PaLM for Translation: Assessing Strategies and Performance","An in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date, and an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.","ArXiv",2022,"David Vilar,Markus Freitag,Colin Cherry,Jiaming Luo,Viresh Ratnakar,George F. Foster",4,64,0
"f318ab67ac22cb758e38a16dafdc8e486b7b9756","https://www.semanticscholar.org/paper/f318ab67ac22cb758e38a16dafdc8e486b7b9756",5,"Planning with Large Language Models via Corrective Re-prompting","This work proposes a prompting-based strategy for extracting executable plans from an LLM, which leverages a novel and readily-accessible source of information: precondition errors, and improves executability and semantic correctness of plans, while also reducing the number of re-prompts required when querying actions.","ArXiv",2022,"S. S. Raman,Vanya Cohen,Eric Rosen,Ifrah Idrees,D. Paulius,Stefanie Tellex",1,32,0
"471a49220cea2069e8b8a76821b1d2434204a732","https://www.semanticscholar.org/paper/471a49220cea2069e8b8a76821b1d2434204a732",5,"FiE: Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering","This work proposes to extend transformer encoders with the ability to fuse information from multiple passages, using global representation to provide cross-sample attention over all tokens across samples, and proposes an alternative answer span probability calculation to better aggregate answer scores in the global space of all samples.","Conference on Empirical Methods in Natural Language Processing",2022,"Akhil Kedia,Mohd Abbas Zaidi,Haejun Lee",0,43,0
"6d951d939d3f27054215f2606a0cf89ed21550e9","https://www.semanticscholar.org/paper/6d951d939d3f27054215f2606a0cf89ed21550e9",5,"Improving Few-Shot Performance of Language Models via Nearest Neighbor Calibration","Experiments on various few-shot text classiﬁcation tasks demonstrate that the proposed nearest-neighbor calibration framework for in- context learning proves in-context learning, while even achieving comparable performance with state-of-the-art tuning-based approaches in some sentiment analysis tasks.","ArXiv",2022,"Feng Nie,Meixi Chen,Zhirui Zhang,Xuan Cheng",1,42,0
"efa92d27065501981f2ade15c1cd884fdf644f44","https://www.semanticscholar.org/paper/efa92d27065501981f2ade15c1cd884fdf644f44",5,"APOLLO: An Optimized Training Approach for Long-form Numerical Reasoning","This work proposes APOLLO to improve the long-form numerical reasoning framework, and adopts a number-aware negative sampling strategy to enable the retriever to be more discriminative on key numerical facts.","ArXiv",2022,"Jia Sun,Hang Zhang,Chen Lin,Yeyun Gong,Jian Guo,Nan Duan",0,34,0
"afdf2daa43ff4415d54a4c4501a339d619a2d13b","https://www.semanticscholar.org/paper/afdf2daa43ff4415d54a4c4501a339d619a2d13b",5,"MASTER: Multi-task Pre-trained Bottlenecked Masked Autoencoders are Better Dense Retrievers","Experimental results show that the proposed approach can achieve new state-of-the-art performances in dense retrieval indatasets, e.g., MS-MARCO Passage Ranking, TREC Deep Learning Track, Natural Questions and BEIR zero-shot retrieval benchmark.","ArXiv",2022,"Kun Zhou,Xiao Liu,Yeyun Gong,Wayne Xin Zhao,Daxin Jiang,Nan Duan,Ji-rong Wen",0,62,0
"fa50f2bc03d6d53fe50f37a1978107b13af24ea7","https://www.semanticscholar.org/paper/fa50f2bc03d6d53fe50f37a1978107b13af24ea7",5,"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization","C OSMO is a generalizable conversation agent outperforming previous best-performing agents on both in- and out-of-domain datasets, and human evaluation shows that dialogues in S ODA are more consistent, speciﬁc, and (surprisingly) natural than prior human-authored datasets.","ArXiv",2022,"Hyunwoo Kim,Jack Hessel,Liwei Jiang,Ximing Lu,Youngjae Yu,Pei Zhou,Ronan Le Bras,Malihe Alikhani,Gunhee Kim,Maarten Sap,Yejin Choi",3,59,0
"8a5c9f0606b985dee71b6d8417023805f0938a9f","https://www.semanticscholar.org/paper/8a5c9f0606b985dee71b6d8417023805f0938a9f",5,"Are Deep Neural Networks SMARTer than Second Graders?","The experiments reveal that while powerful deep models offer reasonable performances on puzzles that they are trained on, they are not better than random accuracy when analyzed for generalization, and the recent ChatGPT large language model is evaluated.","ArXiv",2022,"A. Cherian,Kuan-Chuan Peng,Suhas Lohit,Kevin A. Smith,J. Tenenbaum",1,62,0
"12a4e62c43b829dabdb8afc60eee76aa80fa3f6e","https://www.semanticscholar.org/paper/12a4e62c43b829dabdb8afc60eee76aa80fa3f6e",5,"Fuzzing Deep-Learning Libraries via Large Language Models","LLMFuzz is the first automated approach to directly leveraging Large Pre-trained Language Models (LLMs) to generate input programs for fuzzing DL libraries, and is able to detect 65 bugs, with 41 already confirmed as previously unknown bugs.","ArXiv",2022,"Yinlin Deng,Chun Xia,Haoran Peng,Chenyuan Yang,Lingming Zhang",0,65,0
"5f72c4f7a0991e7035ccc87b69410f4b3e6244ce","https://www.semanticscholar.org/paper/5f72c4f7a0991e7035ccc87b69410f4b3e6244ce",5,"Masked Contrastive Representation Learning for Reinforcement Learning","This work proposes a new algorithm, i.e., masked contrastive representation learning for RL (M-CURL), which takes the correlation among consecutive inputs into consideration and achieves consistent improvements over CURL on 14 out of 16 environments from DMControl suite and 23 out of 26 environments from Atari 2600 Games.","IEEE Transactions on Pattern Analysis and Machine Intelligence",2020,"Jinhua Zhu,Yingce Xia,Lijun Wu,Jiajun Deng,Wen-gang Zhou,Tao Qin,Houqiang Li",13,63,2
"de91ff679800fbdb224b96d68f84a78c8fe629c7","https://www.semanticscholar.org/paper/de91ff679800fbdb224b96d68f84a78c8fe629c7",5,"Mind the gap: Challenges of deep learning approaches to Theory of Mind","It is argued that when studying Theory of Mind with deep learning, the research's main focus and contribution ought to be opening up the network's representations, and researchers use tools from the field of interpretability of AI to study the relationship between different network components and aspects of Theory ofMind.","Artificial Intelligence Review",2022,"J. Aru,Aqeel Labash,Oriol Corcoll,Raul Vicente",1,110,0
"c432aff446d55e72a28394a1508e760cc9a25c08","https://www.semanticscholar.org/paper/c432aff446d55e72a28394a1508e760cc9a25c08",5,"Why do Nearest Neighbor Language Models Work?","This paper identifies three main reasons why k N-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate k NN search, and the importance of softmax temperature for the k Nn distribution.","ArXiv",2023,"Frank F. Xu,Uri Alon,Graham Neubig",0,37,0
"7ec58d26c4dddb4bc3b6829fa0654a22cc26fdfe","https://www.semanticscholar.org/paper/7ec58d26c4dddb4bc3b6829fa0654a22cc26fdfe",5,"Memory Augmented Large Language Models are Computationally Universal","It is established that an existing large language model, Flan-U-PaLM 540B, can be combined with an associative read-write memory to exactly simulate the execution of a universal Turing machine, U 15 , 2.","ArXiv",2023,"Dale Schuurmans",1,23,0
"db5423d1d5737aa90c48bc121239160d24dccb36","https://www.semanticscholar.org/paper/db5423d1d5737aa90c48bc121239160d24dccb36",5,"Blind Judgement: Agent-Based Supreme Court Modelling With GPT","","ArXiv",2023,"S. Hamilton",0,26,0
"92999f7a304e866a2be7176e59c745481ed01042","https://www.semanticscholar.org/paper/92999f7a304e866a2be7176e59c745481ed01042",5,"Co-Writing with Opinionated Language Models Affects Users' Views","Whether a language-model-powered writing assistant that generates some opinions more often than others impacts what users write - and what they think is investigated.","ArXiv",2023,"Maurice Jakesch,Advait Bhat,D. Buschek,Lior Zalmanson,Mor Naaman",0,112,0
"05deb6c1862b2f129d6652a09eaedbc1f655cc8f","https://www.semanticscholar.org/paper/05deb6c1862b2f129d6652a09eaedbc1f655cc8f",5,"STEP: Learning N: M Structured Sparsity Masks from Scratch with Precondition","STEP is proposed, an Adam-aware recipe that learns N:M masks with two phases: first, STEP calculates a reliable variance estimate (precondition phase) and subsequently, the variance remains fixed and is used as a precondition to learn N: M masks (mask-learning phase).","ArXiv",2023,"Yucheng Lu,Shivani Agrawal,Suvinay Subramanian,Oleg Rybakov,Chris De Sa,A. Yazdanbakhsh",0,46,0
"d55b69a533dea69c8b2673cde8de90c6626ee789","https://www.semanticscholar.org/paper/d55b69a533dea69c8b2673cde8de90c6626ee789",5,"A Text-guided Protein Design Framework","The proposed ProteinDT is a multi-modal framework that leverages textual descriptions for protein design that consistently superior performance on four out of six protein property prediction benchmarks and promising results for zero-shot text-guided protein editing.","ArXiv",2023,"Shengchao Liu,Yutao Zhu,Jiarui Lu,Zhao Xu,Weili Nie,A. Gitter,Chaowei Xiao,Jian Tang,Hongyu Guo,Anima Anandkumar",0,102,0
"897241ffbcb7b32f15cc45599ea3f297613f0c90","https://www.semanticscholar.org/paper/897241ffbcb7b32f15cc45599ea3f297613f0c90",5,"MarioGPT: Open-Ended Text2Level Generation through Large Language Models","MarioGPT is the first text-to-level model trained to generate tile-based game levels, and it is shown that MarioGPT can not only generate diverse levels, but can be text-prompted for controllable level generation, addressing one of the key challenges of current PCG techniques.","ArXiv",2023,"Shyam Sudhakaran,Miguel Gonz'alez-Duque,Claire Glanois,M. Freiberger,Elias Najarro,S. Risi",0,46,0
"4805470c7e5abf36781bf89f6fe8743c7344ab90","https://www.semanticscholar.org/paper/4805470c7e5abf36781bf89f6fe8743c7344ab90",5,"Gradient-Based Automated Iterative Recovery for Parameter-Efficient Tuning","It is shown that G-BAIR can recover LLM performance on benchmarks after manually corrupting training labels, suggesting that influence methods like TracIn can be used to automatically perform data cleaning, and introduces the potential for interactive debugging and relabeling for PET-based transfer learning methods.","",2023,"Maximilian Mozes,Tolga Bolukbasi,Ann Yuan,Frederick Liu,Nithum Thain,Lucas Dixon",0,38,0
"4290a70025f29d7054c550c75ae6b24c38a79d12","https://www.semanticscholar.org/paper/4290a70025f29d7054c550c75ae6b24c38a79d12",5,"SE Factual Knowledge in Frozen Giant Code Model: A Study on FQN and its Retrieval","This work conducts the first systematic study on the SE factual knowledge in the state-of-the-art PCM CoPilot, focusing on APIs’ Fully Qualiﬁed Names (FQNs), the fundamental knowledge for effective code analysis, search and reuse.","ArXiv",2022,"Qing Huang,Dianshu Liao,Zhenchang Xing,Zhiqiang Yuan,Qinghua Lu,Xiwei Xu,Jiaxing Lu",0,74,0
"df239785e6d26a45e9c8e06551cfecba92d1ecad","https://www.semanticscholar.org/paper/df239785e6d26a45e9c8e06551cfecba92d1ecad",5,"Exploring AI Ethics of ChatGPT: A Diagnostic Analysis","A qualitative research method on OpenAI’s ChatGPT is performed to better understand the practical features of ethical dangers in recent LLMs, and it is found that a signiﬁcant number of ethical risks cannot be addressed by existing benchmarks, and hence illustrate them via additional case studies.","ArXiv",2023,"Terry Yue Zhuo,Yujin Huang,Chunyang Chen,Zhenchang Xing",1,93,0
"3ed1c94ec4fdd2a9235afeb2d929fde965b1d723","https://www.semanticscholar.org/paper/3ed1c94ec4fdd2a9235afeb2d929fde965b1d723",5,"Characterizing Attribution and Fluency Tradeoffs for Retrieval-Augmented Large Language Models","The relationship between fluency and attribution in LLMs prompted with retrieved evidence in knowledge-heavy dialog settings is examined and a recipe is proposed that could allow smaller models to both close the gap with larger models and preserve the benefits of top-k retrieval while avoiding its drawbacks.","ArXiv",2023,"Renat Aksitov,Chung-Ching Chang,D. Reitter,Siamak Shakeri,Yun-Hsuan Sung",0,17,0
"8a13d58ce02734f92dcc787272afbea4bbc7f09f","https://www.semanticscholar.org/paper/8a13d58ce02734f92dcc787272afbea4bbc7f09f",5,"Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models","Six ways of characterizing harmful text which merit explicit consideration when designing new benchmarks are outlined and applied in a case study of the Perspective API, a toxicity classiﬁer that is widely used in harm benchmarks.","ArXiv",2022,"M. Rauh,John F. J. Mellor,J. Uesato,Po-Sen Huang,Johannes Welbl,Laura Weidinger,Sumanth Dathathri,A. Glaese,Geoffrey Irving,Iason Gabriel,William S. Isaac,Lisa Anne Hendricks",6,107,0
"67b4e3822405cb3d7f6bc75c3dfa49832dfac9c0","https://www.semanticscholar.org/paper/67b4e3822405cb3d7f6bc75c3dfa49832dfac9c0",5,"Re2G: Retrieve, Rerank, Generate","This work proposes Re2G, which combines both neural initial retrieval and reranking into a BART-based sequence-to-sequence generation, and introduces a novel variation of knowledge distillation to train the initial retrieval, reranker and generation using only ground truth on the target sequence output.","North American Chapter of the Association for Computational Linguistics",2022,"Michael R. Glass,Gaetano Rossiello,Md. Faisal Mahbub Chowdhury,Ankita Rajaram Naik,Pengshan Cai,A. Gliozzo",7,52,1
"0d975a8bbc1e0495cb95df8666d42111b546ab34","https://www.semanticscholar.org/paper/0d975a8bbc1e0495cb95df8666d42111b546ab34",5,"Retrieval-Augmented Transformer for Image Captioning","This paper investigates the development of an image captioning approach with a kNN memory, with which knowledge can be retrieved from an external corpus to aid the generation process and increase caption quality.","International Conference on Content-Based Multimedia Indexing",2022,"Sara Sarto,Marcella Cornia,L. Baraldi,R. Cucchiara",4,66,0
"565712c543e2443ff05edd87f3c1d20c07617a3a","https://www.semanticscholar.org/paper/565712c543e2443ff05edd87f3c1d20c07617a3a",5,"Low-Resource Dense Retrieval for Open-Domain Question Answering: A Comprehensive Survey","A thorough structured overview of mainstream techniques for low-resource DR, dividing the techniques into three main categories based on their required resources, and highlighting the open issues and pros and cons.","ArXiv",2022,"Xiaoyu Shen,Svitlana Vakulenko,Marco Del Tredici,Gianni Barlacchi,B. Byrne,A. Gispert",3,204,0
"6032212d5790b6a580d68d469a9895aad6238c89","https://www.semanticscholar.org/paper/6032212d5790b6a580d68d469a9895aad6238c89",5,"Diverse Title Generation for Stack Overflow Posts with Multiple Sampling Enhanced Transformer","A novel approach to automatically generate multiple post titles from the given code snippets, using the maximal marginal multiple nucleus sampling strategy to generate multiple high-quality and diverse title candidates at a time for the developers to choose from.","ArXiv",2022,"Fengji Zhang,Jin Liu,Yao Wan,Xiao Yu,Xiao Liu,J. Keung",0,56,0
"befde3e07ce97f02f12fe92ab27e99f23ccd17aa","https://www.semanticscholar.org/paper/befde3e07ce97f02f12fe92ab27e99f23ccd17aa",5,"Evaluating Progress in Automatic Chest X-Ray Radiology Report Generation","This study quantitatively examines the correlation between automated metrics and the scoring of reports by radiologists, and proposes a composite metric, called RadCliQ, that is able to rank the quality of reports similarly to radiologists and better than existing metrics.","medRxiv",2022,"F. Yu,M. Endo,R. Krishnan,I. Pan,A. Tsai,E. P. Reis,E. Fonseca,H. M. H. Lee,Z. H. Abad,A. Y. Ng,C. Langlotz,V. Venugopal,P. Rajpurkar",1,33,0
"a2b8faa634d6768bd5d043963071fa5583805914","https://www.semanticscholar.org/paper/a2b8faa634d6768bd5d043963071fa5583805914",5,"Evaluation of Question Answering Systems: Complexity of judging a natural language","This survey attempts to provide a systematic overview of the general framework of QA, QA paradigms, benchmark datasets, and assessment techniques for a quantitative evaluation of Q a system, and hypothesize that the quantitative formalization of human judgment is an open problem.","ArXiv",2022,"A. Farea,Z. Yang,Kien Duong,Nadeesha Perera,F. Emmert-Streib",0,205,0
"d8f23086687fc4b4984921026a55d6e06a415e15","https://www.semanticscholar.org/paper/d8f23086687fc4b4984921026a55d6e06a415e15",5,"Chain of Explanation: New Prompting Method to Generate Higher Quality Natural Language Explanation for Implicit Hate Speech","The Chain of Explanation Prompting method, inspired by the chain of thoughts study, is proposed, to generate high-quality NLE for implicit hate speech and a benchmark is built based on the selected mainstream Pre-trained Language Models, including GPT-2,GPT-Neo, OPT, T5, and BART.","ArXiv",2022,"Fan Huang,Haewoon Kwak,Jisun An",2,65,0
"6da5686a64a3daaf677e8d320a1253a3890fb3e7","https://www.semanticscholar.org/paper/6da5686a64a3daaf677e8d320a1253a3890fb3e7",5,"A Unified Encoder-Decoder Framework with Entity Memory","EDMem is a unified framework that can be used on various entity-intensive question answering and generation tasks and outperforms both memory-based auto-encoder models and non-memory encoder-decoder models.","Conference on Empirical Methods in Natural Language Processing",2022,"Zhihan Zhang,W. Yu,Chenguang Zhu,Meng Jiang",3,53,1
"ab5b8f0becb66054b55347829602f730d1a99446","https://www.semanticscholar.org/paper/ab5b8f0becb66054b55347829602f730d1a99446",5,"Multimodal Event Transformer for Image-guided Story Ending Generation","A multimodal event transformer is proposed, an event-based reasoning framework for IgSEG to generate a story ending based on given story plots and ending image and utilizes cross-modal fusion to integrate different-modality features.","ArXiv",2023,"Yucheng Zhou,Guodong Long",0,35,0
"1c6015ffff034b9c304477bb31e55ca5a55f3a99","https://www.semanticscholar.org/paper/1c6015ffff034b9c304477bb31e55ca5a55f3a99",5,"Adversarial Transformer Language Models for Contextual Commonsense Inference","The result is an integrated system for contextual commonsense inference in stories, that can controllably generate plausible commonsense assertions, and takes advantage of joint inference between multiple commonsense knowledge bases.","ArXiv",2023,"Pedro Colon-Hernandez,H. Lieberman,Yida Xin,Claire Yin,C. Breazeal,Peter Chin",0,56,0
"ec0ef1cd3d177e3f13598a74753e62a64dfb7527","https://www.semanticscholar.org/paper/ec0ef1cd3d177e3f13598a74753e62a64dfb7527",5,"Generative Language Models for Paragraph-Level Question Generation","QG-Bench is introduced, a multilingual and multidomain benchmark for QG that unifies existing question answering datasets by converting them to a standard QG setting and proposes robust QG baselines based on fine-tuning generative language models.","Conference on Empirical Methods in Natural Language Processing",2022,"Asahi Ushio,Fernando Alva-Manchego,José Camacho-Collados",0,70,0
"041f5dbfcd07a3369ac44a6b902ee4b145eccf2b","https://www.semanticscholar.org/paper/041f5dbfcd07a3369ac44a6b902ee4b145eccf2b",5,"Towards a Unified Multi-Dimensional Evaluator for Text Generation","This paper re-frame NLG evaluation as a Boolean Question Answering (QA) task, and by guiding the model with different questions, they can use one evaluator to evaluate from multiple dimensions, and introduces an intermediate learning phase that enables UniEval to incorporate external knowledge from multiple related tasks and gain further improvement.","Conference on Empirical Methods in Natural Language Processing",2022,"Ming Zhong,Yang Liu,Da Yin,Yuning Mao,Yizhu Jiao,Peng Liu,Chenguang Zhu,Heng Ji,Jiawei Han",5,53,1
"d891de52e7c58e2443199a20bba7468bdc0736ae","https://www.semanticscholar.org/paper/d891de52e7c58e2443199a20bba7468bdc0736ae",5,"Q-TOD: A Query-driven Task-oriented Dialogue System","This paper introduces a novel query-driven task-oriented dialogue system, namely Q-TOD, which outperforms strong baselines and establishes a new state-of-the-art performance on these datasets.","Conference on Empirical Methods in Natural Language Processing",2022,"Xin Tian,Yingzhan Lin,Mengfei Song,Siqi Bao,Fan Wang,H. He,Shuqi Sun,Hua Wu",1,37,0
"1948447570f236338dd771a692a478b0fd091931","https://www.semanticscholar.org/paper/1948447570f236338dd771a692a478b0fd091931",5,"Controllable Fake Document Infilling for Cyber Deception","This work proposes a novel context-aware model, Fake Document Infilling (FDI), by converting the problem to a controllable mask-then-infill procedure, and shows that FDI outperforms the baselines in generating highly believable fakes with moderate modification to protect critical information and deceive adversaries.","Conference on Empirical Methods in Natural Language Processing",2022,"Yibo Hu,Yu Lin,Eric Parolin,Latif Khan,Kevin W. Hamlen",1,90,0
"7de0d0800fa2046ce74fff0bf60ff63a966e166d","https://www.semanticscholar.org/paper/7de0d0800fa2046ce74fff0bf60ff63a966e166d",5,"Metric-guided Distillation: Distilling Knowledge from the Metric to Ranker and Retriever for Generative Commonsense Reasoning","The metric distillation rule is proposed to distill knowledge from the metric (e.g., BLEU) to the ranker and transfer the critical knowledge summarized by the distilled ranker to the retriever, so that the relevance scores of candidate sentences predicted by theRanker and retriever will be more consistent with their quality measured by the metric.","Conference on Empirical Methods in Natural Language Processing",2022,"Xingwei He,Yeyun Gong,Alex Jin,Weizhen Qi,Hang Zhang,Jian Jiao,Bartuer Zhou,Biao Cheng,Sm Yiu,Nan Duan",1,50,0
"764a616937a5923aaf22288b35f6b991ae41521d","https://www.semanticscholar.org/paper/764a616937a5923aaf22288b35f6b991ae41521d",5,"ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation","ELMER is proposed: an efficient and effective PLM for NAR text generation to explicitly model the token dependency during NAR generation by leveraging the early exit technique and enabling the token generations at different layers, according to their prediction confidence.","Conference on Empirical Methods in Natural Language Processing",2022,"Junyi Li,Tianyi Tang,Wayne Xin Zhao,J. Nie,Ji-rong Wen",1,47,0
"75a843259ab9a1dd5c8fd0f25c7a74d5327e1bdd","https://www.semanticscholar.org/paper/75a843259ab9a1dd5c8fd0f25c7a74d5327e1bdd",5,"Universal Evasion Attacks on Summarization Scoring","The evasion attacks in this work indicate the low robustness of current scoring systems at the system level, and it is hoped that the highlighting of these proposed attack will facilitate the development of summary scores.","BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",2022,"Wenchuan Mu,Kwan Hui Lim",0,87,0
"b9f229a7491924404db36e91fcbd76449f3cec19","https://www.semanticscholar.org/paper/b9f229a7491924404db36e91fcbd76449f3cec19",5,"Fine-Grained Emotional Paraphrasing along Emotion Gradients","A new task of ﬁne-grained emotional paraphrasing along emotion gradients, that is, altering the emotional intensities of the paraphrases in grain following smooth variations in aﬀective dimensions while preserving the meanings of the orig-inals is introduced.","ArXiv",2022,"Justin J Xie",0,54,0
"587373fe118f4d6ae8a184d7ee622fb9f7c25dd8","https://www.semanticscholar.org/paper/587373fe118f4d6ae8a184d7ee622fb9f7c25dd8",5,"Leveraging Pre-trained Models for Failure Analysis Triplets Generation","It is observed that Generative Pre-trained Transformer 2 (GPT2) outperformed other transformer model for the failure analysis triplet generation (FATG) task and Levenshstein Sequential Evaluation metric (LESE) compares exactly with human judgement than existing metrics.","ArXiv",2022,"Kenneth Ezukwoke,Anis Hoayek,M. Batton-Hubert,Xavier Boucher,Pascal Gounet,Jerome Adrian",0,58,0
"99e16c2e93c69d240ea976acbab287a98c63d95f","https://www.semanticscholar.org/paper/99e16c2e93c69d240ea976acbab287a98c63d95f",5,"RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question","It is shown that RQUGE has a higher correlation with human judgment without re-lying on the reference question, and can improve the performance of QA models on out-of-domain datasets by tuning on the synthetic data generated by a question generation model and re-ranked by RQuge.","ArXiv",2022,"Ali Mohammadshahi,Thomas Scialom,Majid Yazdani,Pouya Yanki,Angela Fan,J. Henderson,Marzieh Saeidi",0,93,0
"c36ab572b5be7a470b725b87e369038295d5e7ab","https://www.semanticscholar.org/paper/c36ab572b5be7a470b725b87e369038295d5e7ab",5,"Time-aware Prompting for Text Generation","It is shown that linear prompts on encoder and textual prompts improve the generation quality on all datasets, and despite having less performance drop when testing on data drawn from a later time, linear prompts focus more on non-temporal information and are less sensitive to the given timestamps.","Conference on Empirical Methods in Natural Language Processing",2022,"Shuyang Cao,Lu Wang",0,43,0
"de4bce89f5297a00d41d10d4752fe28fbb0db9a4","https://www.semanticscholar.org/paper/de4bce89f5297a00d41d10d4752fe28fbb0db9a4",5,"Generative Transformers for Design Concept Generation","This study explores the recent advance of the natural language generation (NLG) technique in the artificial intelligence (AI) field to automate the early-stage design concept generation with a novel approach utilizing the generative pre-trained transformer (GPT).","Journal of Computing and Information Science in Engineering",2022,"Qihao Zhu,Jianxi Luo",2,118,0
"80bc1022ffd4cde85d9c24a50dcc37dbd0ea8f60","https://www.semanticscholar.org/paper/80bc1022ffd4cde85d9c24a50dcc37dbd0ea8f60",5,"Reranking Overgenerated Responses for End-to-End Task-Oriented Dialogue Systems","A simple yet effective reranking method which aims to select high-quality items from the lists of responses initially over-generated by the system, using any sequence-level (similarity) scoring function to divide the semantic space of responses into high-scoring versus low-scoring partitions.","ArXiv",2022,"Songbo Hu,Ivan Vulic,Fangyu Liu,A. Korhonen",0,117,0
"db3b99c407ff8a06bdc96151dfae1328fadfb858","https://www.semanticscholar.org/paper/db3b99c407ff8a06bdc96151dfae1328fadfb858",5,"Grafting Pre-trained Models for Multimodal Headline Generation","A novel approach to graft the video encoder from the pre- trained video-language model on the generative pre-trained language model, and presents a consensus fusion mechanism for the integration of different components, via in-ter/intra modality relation.","ArXiv",2022,"Lingfeng Qiao,Chen Wu,Ye Liu,Haoyuan Peng,Di Yin,Bo Ren",0,43,0
"ad6322a120cfe96d1b4dddbc383174f8c84967c9","https://www.semanticscholar.org/paper/ad6322a120cfe96d1b4dddbc383174f8c84967c9",5,"Contextual and selective attention networks for image captioning","A contextual and selective attention network that novelly memorizes contextual attention and brings out the principal components from each attention is presented, and extensive experiments on the COCO image captioning dataset demonstrate the superiority of CoSA-Net.","Science China Information Sciences",2022,"Jing Wang,Yehao Li,Yingwei Pan,Ting Yao,Jinhui Tang,Tao Mei",1,68,0
"9485adb961ba54e14f195c57f58f3f4e653bcb92","https://www.semanticscholar.org/paper/9485adb961ba54e14f195c57f58f3f4e653bcb92",5,"VER: Learning Natural Language Representations for Verbalizing Entities and Relations","This paper attempts to build a system that takes any entity or entity set as input and generates a sentence to represent entities and relations, named “natural language representation”, and demonstrates that the model can generate high-quality sentences describing entities and entity relationships and facilitate various tasks on entities and Relations, including definition modeling, relation modeling, and generative commonsense reasoning.","ArXiv",2022,"Jie Huang,K. Chang",1,48,0
"cb7d65ac2324afc92c48acb8efbd3d2f201f5840","https://www.semanticscholar.org/paper/cb7d65ac2324afc92c48acb8efbd3d2f201f5840",5,"In-sample Curriculum Learning by Sequence Completion for Natural Language Generation","This work proposes to do in-sample curriculum learning for natural language generation tasks, Inspired by the “easy-to-hard” intuition, and starts training the model to generate the last few words, and gradually extends to generated the whole output sequence.","ArXiv",2022,"Qi Jia,Yizhu Liu,Haifeng Tang,Kenny Q. Zhu",0,27,0
"15d6ef576fb07bb5fc07fef6f63708e440396dd9","https://www.semanticscholar.org/paper/15d6ef576fb07bb5fc07fef6f63708e440396dd9",5,"Aesthetically Relevant Image Captioning","","ArXiv",2022,"Zhipeng Zhong,Fei Zhou,G. Qiu",0,32,0
"1f84b6075ffa2d4ed685f31668ea1324bfba4fe5","https://www.semanticscholar.org/paper/1f84b6075ffa2d4ed685f31668ea1324bfba4fe5",5,"A Survey on Medical Document Summarization","This paper gives a comprehensive survey of the current techniques and trends in medical summarization.","ArXiv",2022,"Raghav Jain,Anubhav Jangra,S. Saha,A. Jatowt",0,132,0
"bd0c720e885dfd912f93d6b812497d2becbe4d82","https://www.semanticscholar.org/paper/bd0c720e885dfd912f93d6b812497d2becbe4d82",5,"Collaborating Heterogeneous Natural Language Processing Tasks via Federated Learning","This study further broaden the application scope of FL in NLP by proposing an A SSIGN -T HEN -C ONTRAST (denoted as ATC) framework, which enables clients with heterogeneous NLP tasks to construct an FL course and learn useful knowledge from each other.","ArXiv",2022,"Chenhe Dong,Yuexiang Xie,Bolin Ding,Ying Shen,Yaliang Li",0,47,0
"19e97c83e5637a751f6945344dc19ba658b67468","https://www.semanticscholar.org/paper/19e97c83e5637a751f6945344dc19ba658b67468",5,"Are Multimodal Models Robust to Image and Text Perturbations?","This paper investigates the robustness of 9 popular open-sourced image-text models under common perturbations on five tasks (image-text retrieval, visual reasoning, visual entailment, image captioning, and text-to-image generation), and proposes several new multimodal robustness benchmarks.","ArXiv",2022,"Jielin Qiu,Yi Zhu,Xingjian Shi,F. Wenzel,Zhiqiang Tang,D. Zhao,Bo Li,Mu Li",0,117,0
"e8059434aa997cf486e6ae83cfbf355d4829a95c","https://www.semanticscholar.org/paper/e8059434aa997cf486e6ae83cfbf355d4829a95c",5,"PoE: a Panel of Experts for Generalized Automatic Dialogue Assessment","A Panel of Experts (PoE) network is proposed, a multitask network that consists of a shared transformer encoder and a collection of lightweight adapters that exhibits better zero-shot generalization than existing state-of-the-art ADEMs and the ability to easily adapt to new domains with few-shot transfer learning.","ArXiv",2022,"Chen Zhang,L. F. D’Haro,Qiquan Zhang,Thomas Friedrichs,Haizhou Li",0,81,0
"9b93ebd7ff4d995ad92902096f6c55d9451c2239","https://www.semanticscholar.org/paper/9b93ebd7ff4d995ad92902096f6c55d9451c2239",5,"An AI Dungeon Master's Guide: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons","Human and automated evaluations show that a DM trained with RL to generate guidance by incorporating a theory-of-mind of the players signif-icantly improves the players’ ability to achieve goals grounded in their shared world.","ArXiv",2022,"Pei Zhou,Andrew Zhu,Jennifer Hu,J. Pujara,Xiang Ren,Chris Callison-Burch,Yejin Choi,Prithviraj Ammanabrolu",0,45,0
"447ddcb2b16c2cacabeec2933273918bd6fe1d79","https://www.semanticscholar.org/paper/447ddcb2b16c2cacabeec2933273918bd6fe1d79",5,"MAUVE Scores for Generative Models: Theory and Practice","MAUVE, a family of comparison measures between pairs of distributions such as those encountered in the generative modeling of text or images, is presented, finding that the proposed scores paired with a range of f -divergences and statistical estimation methods can quantify the gaps between the distributions of human-written text and those of modern neural language models.","ArXiv",2022,"Krishna Pillutla,Lang Liu,John Thickstun,S. Welleck,Swabha Swayamdipta,Rowan Zellers,Sewoong Oh,Yejin Choi,Z. Harchaoui",0,115,0
"1c83f3f9789df43bf937ae2618721e2da83dcc06","https://www.semanticscholar.org/paper/1c83f3f9789df43bf937ae2618721e2da83dcc06",5,"From Show to Tell: A Survey on Deep Learning-Based Image Captioning","This work aims at providing a comprehensive overview of image captioning approaches, from visual encoding and text generation to training strategies, datasets, and evaluation metrics, and quantitatively compare many relevant state-of-the-art approaches to identify the most impactful technical innovations in architectures and training strategies.","IEEE Transactions on Pattern Analysis and Machine Intelligence",2021,"Matteo Stefanini,Marcella Cornia,L. Baraldi,S. Cascianelli,G. Fiameni,R. Cucchiara",28,254,2
"93d829fd65d77d2ba5fa141fac85564f451707b2","https://www.semanticscholar.org/paper/93d829fd65d77d2ba5fa141fac85564f451707b2",5,"A dataset for plain language adaptation of biomedical abstracts","The Plain Language Adaptation of Biomedical Abstracts dataset is the first manually adapted dataset that is both document- and sentence-aligned, and contains 750 adapted abstracts, totaling 7643 sentence pairs.","Scientific Data",2022,"Kush Attal,Brian D. Ondov,Dina Demner-Fushman",0,49,0
"13579f2d5d522779caeb4aa916fb9ab283f13670","https://www.semanticscholar.org/paper/13579f2d5d522779caeb4aa916fb9ab283f13670",5,"SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph","A Situated Conversation Agent Petrained with Multimodal Questions from INcremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios and significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets.","ArXiv",2023,"Yuxing Long,Binyuan Hui,Fulong Ye,Yanyang Li,Zhuoxin Han,C. Yuan,Yongbin Li,Xiaojie Wang",0,48,0
"2d4cc999cf1a4202849ae09d0972660800c14eb4","https://www.semanticscholar.org/paper/2d4cc999cf1a4202849ae09d0972660800c14eb4",5,"Embodied Agents for Efficient Exploration and Smart Scene Description","This work proposes and evaluates an approach that combines recent advances in visual robotic exploration and image captioning on images generated through agent-environment interaction that can effectively describe the robot’s point of view during exploration, improving the human- friendly interpretability of its observations.","ArXiv",2023,"Roberto Bigazzi,Marcella Cornia,S. Cascianelli,L. Baraldi,R. Cucchiara",0,60,0
"cebbdc53a5fddbce44dd23d4ed1a45953a4c94a9","https://www.semanticscholar.org/paper/cebbdc53a5fddbce44dd23d4ed1a45953a4c94a9",5,"Visual Semantic Relatedness Dataset for Image Captioning","This paper proposes a textual visual context dataset for captioning, in which the publicly available dataset COCO Captions has been extended with information about the scene (such as objects in the image), which can be used to leverage any NLP task into captioning systems.","ArXiv",2023,"Ahmed Sabir,F. Moreno-Noguer,Llu'is Padr'o",0,48,0
"637384f1f6074ee6e8d2e2d058b5e0cf20edb5ed","https://www.semanticscholar.org/paper/637384f1f6074ee6e8d2e2d058b5e0cf20edb5ed",5,"Fashion-Oriented Image Captioning with External Knowledge Retrieval and Fully Attentive Gates","Experimental analyses were carried out on the fashion captioning dataset (FACAD) for fashion image captioning, validating the effectiveness of the proposed approach and the proposed architectural strategies in comparison with carefully designed baselines and state-of-the-art approaches.","Italian National Conference on Sensors",2023,"Nicholas Moratelli,Manuele Barraco,Davide Morelli,Marcella Cornia,L. Baraldi,R. Cucchiara",0,65,0
"ead6e2873c776448d38c7596220a5f74b718b60c","https://www.semanticscholar.org/paper/ead6e2873c776448d38c7596220a5f74b718b60c",5,"Counterfactual Editing for Search Result Explanation","A user study is conducted to investigate if counterfactual explanations indeed improve search sessions’ effectiveness and a method is proposed to provide pairwise explanations to search engine result page that outperforms baselines on both metrics and human evaluation.","ArXiv",2023,"Zhichao Xu,Hemank Lamba,Qingyao Ai,Joel Tetreault,A. Jaimes",0,69,0
"ce032d151caeffeafeab355e69454d89c3c0b6a9","https://www.semanticscholar.org/paper/ce032d151caeffeafeab355e69454d89c3c0b6a9",5,"Style-Aware Contrastive Learning for Multi-Style Image Captioning","This work presents a style-aware visual encoder with contrastive learning to mine potential visual content relevant to style, and proposes astyle-aware triplet contrast objective to distinguish whether the image, style and caption matched.","ArXiv",2023,"Yucheng Zhou,Guodong Long",0,41,0
"e4efdfe15d27c8a3240cafa4b6654e748b409ef1","https://www.semanticscholar.org/paper/e4efdfe15d27c8a3240cafa4b6654e748b409ef1",5,"On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex","This paper presents the first empirical study on the adversarial robustness of a large prompt-based language model of code, \codex, and proposes methods for improving robustness without the need for significant amounts of labeled data or heavy computational resources.","ArXiv",2023,"Terry Yue Zhuo,Zhuang Li,Yujin Huang,Yuan-Fang Li,Weiqing Wang,Gholamreza Haffari,Fatemeh Shiri",0,82,0
"a764d4f28612a7b5c4767ea6a2540b169fdb052c","https://www.semanticscholar.org/paper/a764d4f28612a7b5c4767ea6a2540b169fdb052c",5,"CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models","A benchmark named CoderEval of pragmatic code generation with generative pre-trained models is proposed, compared with the widely-used HumanEval benchmark from OpenAI, which can be used to assess the performance of models against pragmatic codegeneration beyond just generating standalone functions.","ArXiv",2023,"Hao Yu,Bo Shen,Dezhi Ran,Jiaxin Zhang,Qi Zhang,Yu Ma,Guangtai Liang,Ying Li,Tao Xie,Qianxiang Wang",0,21,0
"0445dec0464fcbd85c6cefa5da87e82d49460fb3","https://www.semanticscholar.org/paper/0445dec0464fcbd85c6cefa5da87e82d49460fb3",5,"Towards Local Visual Modeling for Image Captioning","Experimental results show that the proposed Locality-Sensitive Transformer Network (LSTNet) is not only capable of local visual modeling, but also outperforms a bunch of state-of-the-art captioning models on offline and online testings, i.e., 134.8 CIDEr and 136.3 C IDEr, respectively.","Pattern Recognition",2023,"Yiwei Ma,Jiayi Ji,Xiaoshuai Sun,Yiyi Zhou,R. Ji",0,53,0
"c4b957f7e5f8cdeb60575447396d3fed0091bfee","https://www.semanticscholar.org/paper/c4b957f7e5f8cdeb60575447396d3fed0091bfee",5,"Beyond Statistical Similarity: Rethinking Metrics for Deep Generative Models in Engineering Design","A set of design-specific metrics which have been proposed across different research communities and can be used for evaluating deep generative models focus on unique requirements in design and engineering, such as constraint satisfaction, functional performance, novelty, and conditioning.","ArXiv",2023,"Lyle Regenwetter,Akash Srivastava,Dan Gutfreund,Faez Ahmed",0,107,0
"dfe52273e90dcc2a4907079b34c4a2cbfc8593f8","https://www.semanticscholar.org/paper/dfe52273e90dcc2a4907079b34c4a2cbfc8593f8",5,"Protecting Language Generation Models via Invisible Watermarking","GINSEW, a novel method to protect text generation models from being stolen through distillation by injecting secret signals into the probability vector of the decoding steps for each target token, is proposed.","ArXiv",2023,"Xuandong Zhao,Yu-xiang Wang,Lei Li",0,33,0
"39de27b3ba14f358ff4c9adc0a79fd1206fc7292","https://www.semanticscholar.org/paper/39de27b3ba14f358ff4c9adc0a79fd1206fc7292",5,"CCRep: Learning Code Change Representations via Pre-Trained Code Model and Query Back","This work proposes a novel Code Change Representation learning approach named CCRep, which can learn to encode code changes as feature vectors for diverse downstream tasks and applies it to three tasks: commit message generation, patch correctness assessment, and just-in-time defect prediction.","ArXiv",2023,"Zhongxin Liu,Zhijie Tang,Xin Xia,Xiaohu Yang",0,67,0
"c39fc0b30d956088d6e4d0b82b38dc3a754cd862","https://www.semanticscholar.org/paper/c39fc0b30d956088d6e4d0b82b38dc3a754cd862",5,"NapSS: Paragraph-level Medical Text Simplification via Narrative Prompting and Sentence-matching Summarization","This work proposes a summarize-then-simplify two-stage strategy, which is called NapSS, identifying the relevant content to simplify while ensuring that the original narrative flow is preserved, and introduces new metrics that take into account both lexical and high-level semantic similarity.","ArXiv",2023,"Junru Lu,Jiazheng Li,Byron C. Wallace,Yulan He,Gabriele Pergola",0,53,0
"5c982f5dbb653d748e1ada858004e0847e09edff","https://www.semanticscholar.org/paper/5c982f5dbb653d748e1ada858004e0847e09edff",5,"Position Matters! Empirical Study of Order Effect in Knowledge-grounded Dialogue","This paper proposes a simple and novel technique to alleviate the order effect by modifying the position embeddings of knowledge input in transformer-based models, and shows that each knowledge statement is uniformly considered to generate responses.","ArXiv",2023,"Hsuan Su,Shachi H. Kumar,Sahisnu Mazumder,Wenda Chen,R. Manuvinakurike,Eda Okur,Saurav Sahay,L. Nachman,Shang-Tse Chen,Hung-yi Lee",0,42,0
"7a771d84301d12049cf72a017f9e62c3d1b6222d","https://www.semanticscholar.org/paper/7a771d84301d12049cf72a017f9e62c3d1b6222d",5,"Developer-Intent Driven Code Comment Generation","This work proposes DOME, an approach that utilizes Intent-guided Selective Attention to explicitly select intent-relevant information from the source code, and produces various comments reflecting different intents, which outperforms the state-of-the-art baselines.","",2023,"Fangwen Mu,Xiao Chen,Lin Shi,Song Wang,Qing Wang",0,58,0
"927a5203363fc9c8ba48599dc749cf0cc647444b","https://www.semanticscholar.org/paper/927a5203363fc9c8ba48599dc749cf0cc647444b",5,"Compute Trends Across Three Eras of Machine Learning","This paper curates a dataset with the training compute of 123 milestone ML systems, 3× larger than previous such datasets, and frames the trends in compute in in three eras - the Pre Deep Learning Era, the Deep learning Era, and the Large-Scale Era.","IEEE International Joint Conference on Neural Network",2022,"J. Sevilla,Lennart Heim,A. Ho,T. Besiroglu,Marius Hobbhahn,Pablo Villalobos",30,176,3
"9f96d8b71551e735171283976ce2160e0b88e824","https://www.semanticscholar.org/paper/9f96d8b71551e735171283976ce2160e0b88e824",5,"Can deep learning match the efficiency of human visual long-term memory in storing object details?","This paper asks whether deep learning via gradient descent can match the eﬃciency of human visual long-term memory to incorporate new information in a rigorous, head-to-head, quantitative comparison and answers in the negative.","ArXiv",2022,"A. Orhan",0,37,0
"999217305f51c69677ce4879495c60f499c08e99","https://www.semanticscholar.org/paper/999217305f51c69677ce4879495c60f499c08e99",5,"Cluster-based Evaluation of Automatically Generated Text","This work analyzes the general paradigm of language generator evaluation and proposes the use of distributions over clusters, where strings are cluster based on their text embeddings (obtained from a pretrained language model), finding these clusters may simply be better equipped to evaluate state-of-the-art language models.","ArXiv",2022,"Tiago Pimentel,Clara Meister,Ryan Cotterell",1,35,0
"8cf974fd3973900c0598730ee5d3617900ac8c3d","https://www.semanticscholar.org/paper/8cf974fd3973900c0598730ee5d3617900ac8c3d",5,"Transformers with Learnable Activation Functions","Analysis of the shapes of learned RAFs unveils that they substantially vary between different layers of the pre-trained model and mostly look very different from conventional activation functions, which opens a new research direction for analyzing and interpreting pre- trained models according to the learned activation functions.","ArXiv",2022,"Haishuo Fang,Ji-Ung Lee,N. Moosavi,Iryna Gurevych",0,69,0
"f1de30035ab2778aae09426ee7d068337fa661af","https://www.semanticscholar.org/paper/f1de30035ab2778aae09426ee7d068337fa661af",5,"Large-Scale Bidirectional Training for Zero-Shot Image Captioning","It is found that large-scale bidirectional training between image and text enables zero-shot image captioning and a new evaluation benchmark is proposed which comprises of high quality datasets and an extensive set of metrics to properly evaluate zero- shot captioning accuracy and societal bias.","ArXiv",2022,"Taehoon Kim,Mark A Marsden,Pyunghwan Ahn,Sangyun Kim,Sihaeng Lee,Alessandra Sala,Seung Hwan Kim",0,60,0
"7932b714e2ae1def5828df52b97f1decb9bebd32","https://www.semanticscholar.org/paper/7932b714e2ae1def5828df52b97f1decb9bebd32",5,"Considerations for Differentially Private Learning with Large-Scale Public Pretraining","Whether the use of large Web-scraped datasets should be viewed as diﬀerential-privacy-preserving and whether existing machine learning benchmarks are appropriate for measuring the ability of pretrained models to generalize to sensitive domains, which may be poorly represented in public Web data.","ArXiv",2022,"Florian Tramèr,Gautam Kamath,Nicholas Carlini",3,70,1
"f10d25c3a19d5bf3544dc56076d90a02ed99eae9","https://www.semanticscholar.org/paper/f10d25c3a19d5bf3544dc56076d90a02ed99eae9",5,"ClimaX: A foundation model for weather and climate","ClimaX is developed and demonstrated, a flexible and generalizable deep learning model for weather and climate science that can be trained using heterogeneous datasets spanning different variables, spatio-temporal coverage, and physical groundings and results in superior performance on benchmarks for weather forecasting and climate projections, even when pretrained at lower resolutions and compute budgets.","ArXiv",2023,"Tung Nguyen,Johannes Brandstetter,Ashish Kapoor,Jayesh K. Gupta,Aditya Grover",0,113,0
"a9e4d604d7a2bb4e0a3ddd5222d8f8bc7edda532","https://www.semanticscholar.org/paper/a9e4d604d7a2bb4e0a3ddd5222d8f8bc7edda532",5,"Analyzing Leakage of Personally Identifiable Information in Language Models","A taxonomy of PII leakage in LMs is proposed, novel attacks that can extract up to 10 times more PII sequences as existing attacks are proposed, and a subtle connection between record-level membership inference and PII reconstruction is made.","ArXiv",2023,"Nils Lukas,A. Salem,Robert Sim,Shruti Tople,L. Wutschitz,Santiago Zanella-B'eguelin",0,70,0
"101958920c32d67b6509cd849e6644b28d7e473f","https://www.semanticscholar.org/paper/101958920c32d67b6509cd849e6644b28d7e473f",5,"Binarized Neural Machine Translation","This work proposes a novel binarization technique for Transformers applied to machine translation (BMT), the first of its kind, and identifies and addresses the problem of inflated dot-product variance when using one-bit weights and activations.","ArXiv",2023,"Yichi Zhang,Ankush Garg,Yuan Cao,Lukasz Lew,B. Ghorbani,Zhiru Zhang,Orhan Firat",0,38,0
"5ecc8ca550baa8e4a08a942af06fbc2af2c74543","https://www.semanticscholar.org/paper/5ecc8ca550baa8e4a08a942af06fbc2af2c74543",5,"RL with KL penalties is better viewed as Bayesian inference","This paper analyzes challenges associated with treating a language model as an RL policy and shows how avoiding those challenges requires moving beyond the RL paradigm, and shows that KL-regularised RL is equivalent to variational inference: approximating a Bayesian posterior which specifies how to update a prior LM to conform with evidence provided by the reward function.","Conference on Empirical Methods in Natural Language Processing",2022,"Tomasz Korbak,Ethan Perez,C. Buckley",6,46,0
"e32185936ab3b23f39b1dd93e1507e6d80a71776","https://www.semanticscholar.org/paper/e32185936ab3b23f39b1dd93e1507e6d80a71776",5,"The Debate Over Understanding in AI's Large Language Models","","ArXiv",2022,"M. Mitchell,D. Krakauer",3,86,1
"cbf98ebe967e0f3f3236e7932f37013b98244e94","https://www.semanticscholar.org/paper/cbf98ebe967e0f3f3236e7932f37013b98244e94",5,"ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning","ExMIX (Extreme Mixture): a massive collection of 107 supervised NLP tasks across diverse domains and task-families is introduced, and a model pre-trained using a multi-task objective of self-supervised span denoising and supervised EXMIX is proposed.","International Conference on Learning Representations",2021,"V. Aribandi,Yi Tay,Tal Schuster,J. Rao,Huaixiu Zheng,Sanket Vaibhav Mehta,Honglei Zhuang,V. Tran,Dara Bahri,Jianmo Ni,Jai Gupta,Kai Hui,Sebastian Ruder,Donald Metzler",73,158,10
"82b3a2559b5cf1528348b9d35285868e1c154fce","https://www.semanticscholar.org/paper/82b3a2559b5cf1528348b9d35285868e1c154fce",5,"Overleaf Example","This paper proposes a new procedure to rank systems based on their performance across different tasks, motivated by the social choice theory, and shows that this method yields different conclusions on state-of-the-art systems than the mean-aggregation procedure while being both more reliable and robust.","",2022,"Pierre Colombo",0,109,0
"7db7fb25a8753c9efc6b3722d178f94fcc1f82d3","https://www.semanticscholar.org/paper/7db7fb25a8753c9efc6b3722d178f94fcc1f82d3",5,"KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Few-Shot NLP","It is demonstrated that the proposed Knowledge Mixture enables pre-trained language models the capability of generating proper synthetic instances from scratch for complicated tasks (i.e., the data sample has long sequences or multiple sentences).","ArXiv",2022,"Yufei Wang,Jiayi Zheng,Can Xu,Xiubo Geng,Tao Shen,Chongyang Tao,Daxin Jiang",0,118,0
"5ef91beb3037a35f296d8df8c556ac5353d1160a","https://www.semanticscholar.org/paper/5ef91beb3037a35f296d8df8c556ac5353d1160a",5,"Describing Differences between Text Distributions with Natural Language","This work fine-tune GPT-3 to automatically describe the differences between two distributions of text by “learning a natural language hypothesis”, and applies the system to describe distribution shifts, debug dataset shortcuts, summarize unknown tasks, and label text clusters, and present analyses based on automatically generated descriptions.","International Conference on Machine Learning",2022,"Ruiqi Zhong,Charles Burton Snell,D. Klein,J. Steinhardt",4,76,2
"c0a1811021d0f4e6864446c62658bd4375893b66","https://www.semanticscholar.org/paper/c0a1811021d0f4e6864446c62658bd4375893b66",5,"Summarizing Differences between Text Distributions with Natural Language","This work fine-tune GPT-3 to propose descriptions with the prompt “how do two distributions of text differ”, and applies this system to describe distribution shifts, debug dataset shortcuts, summarize unknown tasks, and label text clusters, and present analyses based on automatically generated descriptions.","ArXiv",2022,"Ruiqi Zhong,Charles Burton Snell,D. Klein,J. Steinhardt",3,60,0
"3e9b550e4a432886a627dde89e402a236975b844","https://www.semanticscholar.org/paper/3e9b550e4a432886a627dde89e402a236975b844",5,"What are the best systems? New perspectives on NLP Benchmarking","This paper proposes a new procedure to rank systems based on their performance across different tasks, motivated by the social choice theory, and shows that this method yields different conclusions on stateof-the-art systems than the mean-aggregation procedure while being both more reliable and robust.","ArXiv",2022,"Pierre Colombo,Nathan Noiry,Ekhine Irurozki,S. Clémençon",8,109,2
"bf81b2a50009fc7370d25f2ae6f8acc09c7da5d9","https://www.semanticscholar.org/paper/bf81b2a50009fc7370d25f2ae6f8acc09c7da5d9",5,"GrIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models","Gradientfree Instructional Prompt Search (GRIPS), a gradient-free, edit-based search approach for improving task instructions for large language models, which outperforms manual rewriting following the guidelines in Mishra et al. (2022b) and also outperforms purely examplebased prompts while controlling for the available compute and data budget.","ArXiv",2022,"Archiki Prasad,Peter Hase,Xiang Zhou,Mohit Bansal",21,42,3
"9060d9408fda662f717de99b004045ec1168e581","https://www.semanticscholar.org/paper/9060d9408fda662f717de99b004045ec1168e581",5,"Hyperdecoders: Instance-specific decoders for multi-task NLP","This work investigates input-conditioned hypernetworks for multi-tasking in NLP, generating parameter-efficient adaptations for a decoder using a hypernetwork conditioned on the output of an encoder, finding that it surpasses previous parameter efficient fine-tuning methods and often outperforms fully finetuning the underlying model.","Conference on Empirical Methods in Natural Language Processing",2022,"Hamish Ivison,Matthew E. Peters",5,75,0
"590f6817b42407f96b079e82c935fae298196359","https://www.semanticscholar.org/paper/590f6817b42407f96b079e82c935fae298196359",5,"Less is More: Summary of Long Instructions is Better for Program Synthesis","This work creates a meta-dataset from the frequently used APPS dataset and the newly created CodeContests dataset for the program synthesis task and shows that summaries significantly improve performance for introductory and interview related programming questions and shows improvement for competitive programming questions.","Conference on Empirical Methods in Natural Language Processing",2022,"Kirby Kuznia,Swaroop Mishra,Mihir Parmar,Chitta Baral",6,28,0
"237f5ca6fcccef2b77a2212b34fb06a1dbd09b72","https://www.semanticscholar.org/paper/237f5ca6fcccef2b77a2212b34fb06a1dbd09b72",5,"Evaluating Prompts Across Multiple Choice Tasks In a Zero-Shot Setting","Collect and standardize prompts from a diverse range of tasks for use with tasks they were not designed for and evaluate these prompts across multiple choice datasets for a quantitative analysis of how certain attributes of a prompt affect performance.","ArXiv",2022,"Gabriel Orlanski",0,47,0
"ec64e324ce1210fe5245dfd0fb5a92058732e5b9","https://www.semanticscholar.org/paper/ec64e324ce1210fe5245dfd0fb5a92058732e5b9",5,"Benchmarking Generalization via In-Context Instructions on 1, 600+ Language Tasks","This work introduces N ATURAL -I NSTRUCTIONS v 2, a collection of 1,600+ diverse language tasks and their expert written instructions that covers 70+ distinct task types, such as tagging, in-ﬁlling, and rewriting.","ArXiv",2022,"Yizhong Wang,Swaroop Mishra,Pegah Alipoormolabashi,Yeganeh Kordi,Amirreza Mirzaei,Anjana Arunkumar,Arjun Ashok,Arut Selvan Dhanasekaran,Atharva Naik,David Stap,Eshaan Pathak,Giannis Karamanolakis,Haizhi Gary Lai,I. Purohit,Ishani Mondal,Jacob Anderson,Kirby Kuznia,Krima Doshi,Maitreya Patel,Kuntal Kumar Pal,M. Moradshahi,Mihir Parmar,Mirali Purohit,Neeraj Varshney,Phani Rohitha Kaza,Pulkit Verma,Ravsehaj Singh Puri,Rushang Karia,Shailaja Keyur Sampat,Savan Doshi,S. Mishra,Sujan Reddy,Sumanta Patro,Tanay Dixit,Xudong Shen,Chitta Baral,Yejin Choi,Hannaneh Hajishirzi,Noah A. Smith,Daniel Khashabi",36,61,10
"eac7022fe02f867140514018806a3cae1da6864f","https://www.semanticscholar.org/paper/eac7022fe02f867140514018806a3cae1da6864f",5,"Unsupervised Cross-Task Generalization via Retrieval Augmentation","This paper proposes a retrieval-augmentation method named ReCross that takes a few unlabelled examples as queries to retrieve a small subset of upstream data and uses them to update the multi-task model for better generalization.","ArXiv",2022,"Bill Yuchen Lin,Kangmin Tan,Chris Miller,Beiwen Tian,Xiang Ren",13,25,5
"81986b8a3d3fe6c5be06fc4527953fb514ad12e8","https://www.semanticscholar.org/paper/81986b8a3d3fe6c5be06fc4527953fb514ad12e8",5,"Improving In-Context Few-Shot Learning via Self-Supervised Training","This paper proposes to use self-supervision in an intermediate training stage between pretraining and downstream few-shot usage with the goal to teach the model to perform in-context few shot learning.","North American Chapter of the Association for Computational Linguistics",2022,"Mingda Chen,Jingfei Du,Ramakanth Pasunuru,Todor Mihaylov,Srini Iyer,V. Stoyanov,Zornitsa Kozareva",5,89,1
"7cdaa08890895e1ad92afb5fad429690ad7b1dac","https://www.semanticscholar.org/paper/7cdaa08890895e1ad92afb5fad429690ad7b1dac",5,"Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning","A new parameter-efﬁcient ﬁne-tuning method called (IA) 3 that scales activations by learned vectors, attaining stronger performance while only introducing a relatively tiny amount of new parameters.","ArXiv",2022,"Haokun Liu,Derek Tam,Mohammed Muqeeth,Jay Mohta,Tenghao Huang,Mohit Bansal,Colin Raffel",52,81,13
"d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3","https://www.semanticscholar.org/paper/d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3",5,"Fine-tuned Language Models are Continual Learners","The resulting model Continual-T0 (CT0) is able to learn 8 new diverse language generation tasks, while still maintaining good performance on previous tasks, spanning in total of 70 datasets, demonstrating some level of instruction compositionality.","Conference on Empirical Methods in Natural Language Processing",2022,"Thomas Scialom,Tuhin Chakrabarty,S. Muresan",2,46,0
"07759a84f27e43cfa5bc8d579f8227c96e6ae1dc","https://www.semanticscholar.org/paper/07759a84f27e43cfa5bc8d579f8227c96e6ae1dc",5,"RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning","RLPrompt is proposed, an efficient discrete prompt optimization approach with reinforcement learning (RL) that formulates a parameter-efficient policy network that generates the optimized discrete prompt after training with reward.","Conference on Empirical Methods in Natural Language Processing",2022,"Mingkai Deng,Jianyu Wang,Cheng-Ping Hsieh,Yihan Wang,Han Guo,Tianmin Shu,Meng Song,E. Xing,Zhiting Hu",23,138,3
"686d9ee744fa013cc21cdd86acd864c936e9e456","https://www.semanticscholar.org/paper/686d9ee744fa013cc21cdd86acd864c936e9e456",5,"Large language models are few-shot clinical information extractors","This work shows that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain, and demonstrates how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs.","Conference on Empirical Methods in Natural Language Processing",2022,"Monica Agrawal,S. Hegselmann,Hunter Lang,Yoon Kim,D. Sontag",10,98,2
"6650e44f00f74c596b3981d01493b5f75cfa6f63","https://www.semanticscholar.org/paper/6650e44f00f74c596b3981d01493b5f75cfa6f63",5,"LEPUS: Prompt-based Unsupervised Multi-hop Reranking for Open-domain QA","Though unsupervised, LEPUS yields competitive reranking performance against state-of-the-art methods that are trained on thousands of examples, and when integrated with a reader module, it can obtain competitive multi-hop QA performance, e.g., out-performing fully-supervised QA systems.","ArXiv",2022,"Muhammad Khalifa,L. Logeswaran,Moontae Lee,Honglak Lee,Lu Wang",0,43,0
"e852c5ed7f4f1a4375f0f3bce1b4e445c7684e7e","https://www.semanticscholar.org/paper/e852c5ed7f4f1a4375f0f3bce1b4e445c7684e7e",5,"KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in Low-Resource NLP","The goal of KoMT is to condense diverse NLP task-speciﬁc knowledge into the single KnowDA model (i.e., all-in-one) such that KnowDA could utilize these knowledge to quickly grasp the inherent synthesis law of the target task through limited training instances.","",2022,"Yufei Wang,Jiayi Zheng,Can Xu,Xiubo Geng,Tao Shen,Chongyang Tao,Daxin Jiang",0,117,0
"6cf8a4d05e66266233380f989edaf647eba7e1a5","https://www.semanticscholar.org/paper/6cf8a4d05e66266233380f989edaf647eba7e1a5",5,"BioTABQA: Instruction Learning for Biomedical Table Question Answering","Experimental results show that the instruction-tuned model outperforms single and multi task baselines on an average by ∼ 23% and ∼ 6% across various evaluation settings, and more importantly, instruction- Tuned models outperforms baselines by ∼ 5% on cross-tasks.","Conference and Labs of the Evaluation Forum",2022,"Man Luo,S. Saxena,Swaroop Mishra,Mihir Parmar,Chitta Baral",7,40,0
"27fd24b7b9a7fd5777e9bda6e3b0d33c08472001","https://www.semanticscholar.org/paper/27fd24b7b9a7fd5777e9bda6e3b0d33c08472001",5,"Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization","Z-Code++ is a new pre-trained language model optimized for abstractive text summarization that outperforms the 600x larger PaLM 540B on XSum, and the 200x larger GPT3 175B on SAMSum in zero-shot and few-shot settings.","ArXiv",2022,"Pengcheng He,Baolin Peng,Liyang Lu,Songhe Wang,Jie Mei,Yang Liu,Ruochen Xu,Hany Hassan Awadalla,Yu Shi,Chenguang Zhu,Wayne Xiong,Michael Zeng,Jianfeng Gao,Xuedong Huang",6,52,1
"06272f6ab3c450e196b1f9879edb33b707d79da7","https://www.semanticscholar.org/paper/06272f6ab3c450e196b1f9879edb33b707d79da7",5,"Efficient Methods for Natural Language Processing: A Survey","This survey relates and synthesises methods andings in those efﬁciencies in NLP, aiming to guide new researchers in the field and inspire the development of new methods.","ArXiv",2022,"Marcos Vinícius Treviso,Tianchu Ji,Ji-Ung Lee,Betty van Aken,Qingqing Cao,Manuel R. Ciosici,Michael Hassid,Kenneth Heafield,Sara Hooker,Pedro Henrique Martins,André F. T. Martins,Peter Milder,Colin Raffel,Edwin Simpson,N. Slonim,Niranjan Balasubramanian,Leon Derczynski,Roy Schwartz",6,209,0
"4989c08930e42d322b3bfed167d7ea434a698f2c","https://www.semanticscholar.org/paper/4989c08930e42d322b3bfed167d7ea434a698f2c",5,"CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation","Experiments on natural language inference and sentiment analysis benchmarks show that CORE counterfactuals are more effective at improving generalization to OOD data compared to other DA approaches, and the CORE retrieval framework can be used to encourage diversity in manually authored perturbations.","Conference on Empirical Methods in Natural Language Processing",2022,"Tanay Dixit,Bhargavi Paranjape,Hannaneh Hajishirzi,Luke Zettlemoyer",0,71,0
"2922ebbfbf71885f1a7cce6f41c79e950f69ceac","https://www.semanticscholar.org/paper/2922ebbfbf71885f1a7cce6f41c79e950f69ceac",5,"Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey","This work provides a survey of practical methods for addressing potential threats and societal harms from language generation models and draws on several prior works’ taxonomies of language model risks to present a structured overview of strategies for detecting andiorating different kinds of risks/harms of language generators.","ArXiv",2022,"Sachin Kumar,Vidhisha Balachandran,Lucille Njoo,Antonios Anastasopoulos,Yulia Tsvetkov",2,100,0
"9c36c8f398a074801d6098287c4353bcf87a1d6c","https://www.semanticscholar.org/paper/9c36c8f398a074801d6098287c4353bcf87a1d6c",5,"Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values","A framework for value-aligned classiﬁcation that performs prediction based on explicitly written human values in the command that proves both inclusivity & explainability in AI is introduced.","ArXiv",2022,"Yejin Bang,Tiezheng Yu,Andrea Madotto,Zhaojiang Lin,Mona Diab,Pascale Fung",0,37,0
"8862ed012fe06a794fda3ceae3f471a0c2a40fbe","https://www.semanticscholar.org/paper/8862ed012fe06a794fda3ceae3f471a0c2a40fbe",5,"Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective","This work proposes a new paradigm for zero-shot learners that is format agnostic, i.e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis.","Conference on Empirical Methods in Natural Language Processing",2022,"Ping Yang,Junjie Wang,Ruyi Gan,Xinyu Zhu,Lin Zhang,Ziwei Wu,Xinyu Gao,Jiaxing Zhang,Tetsuya Sakai",0,64,0
"3c414e3125c12dbd23f62e6c1b85c1a4dc9a522e","https://www.semanticscholar.org/paper/3c414e3125c12dbd23f62e6c1b85c1a4dc9a522e",5,"Boosting Natural Language Generation from Instructions with Meta-Learning","This paper proposes to adapt meta-learning to MTIL in three directions: Model Agnostic Meta Learning (MAML), Hyper-Network (HNet) based adaptation to generate task specific parameters conditioned on instructions, and an approach combining HNet and MAML.","Conference on Empirical Methods in Natural Language Processing",2022,"Budhaditya Deb,Guoqing Zheng,A. Awadallah",3,30,0
"55adc6c9ad132d814e8c6e81b4e229fc9e6bcb82","https://www.semanticscholar.org/paper/55adc6c9ad132d814e8c6e81b4e229fc9e6bcb82",5,"Preserving In-Context Learning ability in Large Language Model Fine-tuning","ProMoT is proposed, a simple yet effective two-stage ﬁne-tuning framework that preserves in-context abilities of the pretrained model and shows remarkable generalization ability on tasks that have different formats, e.g. natural language inference and English-French translation.","ArXiv",2022,"Yihan Wang,Si Si,Daliang Li,M. Lukasik,Felix Yu,Cho-Jui Hsieh,I. Dhillon,Surinder Kumar",2,29,1
"78281482c1fdad8e167bab39cc9955c73d58ae8f","https://www.semanticscholar.org/paper/78281482c1fdad8e167bab39cc9955c73d58ae8f",5,"EVA: Exploring the Limits of Masked Visual Representation Learning at Scale","Evaluating the vision tower of a giant CLIP from EVA can greatly stabilize the training and outperform the training from scratch counterpart with much fewer samples and less compute, providing a new direction for scaling up and accelerating the costly training of multi-modal foundation models.","ArXiv",2022,"Yuxin Fang,Wen Wang,Binhui Xie,Quan-Sen Sun,Ledell Yu Wu,Xinggang Wang,Tiejun Huang,Xinlong Wang,Yue Cao",7,125,1
"f26d0419a3e8e0d3128279c0a1c962a67f30b729","https://www.semanticscholar.org/paper/f26d0419a3e8e0d3128279c0a1c962a67f30b729",5,"UnifiedABSA: A Unified ABSA Framework Based on Multi-task Instruction Tuning","U NIFIED ABSA is presented, a general-purpose ABSA framework based on multi- task instruction tuning, which can uniformly model various tasks and capture the inter-task dependency with multi-task learning.","ArXiv",2022,"Zengzhi Wang,Rui Xia,Jianfei Yu",0,59,0
"0ba0091c60c0346493b9ffb46ac682eee5453a53","https://www.semanticscholar.org/paper/0ba0091c60c0346493b9ffb46ac682eee5453a53",5,"Exploring the Limits of Differentially Private Deep Learning with Group-wise Clipping","Better performance than previously reported on the CIFAR-10 task with WRN16-4 and the SST-2 task with RoBERTa-base model is found.","ArXiv",2022,"Jiyan He,Xuechen Li,Da Yu,Huishuai Zhang,Janardhan Kulkarni,Y. Lee,A. Backurs,Nenghai Yu,J. Bian",0,70,0
"b4c80344081d8c548fc4d68868b8262182a146fa","https://www.semanticscholar.org/paper/b4c80344081d8c548fc4d68868b8262182a146fa",5,"Structured information extraction from complex scientific text with fine-tuned large language models","This work presents a simple sequence-to-sequence approach to joint named entity recognition and relation extraction for complex hierarchical information in scientiﬁc text that leverages a pre-trained large language model (LLM), GPT-3, that is capable of accurately extracting useful records of complex knowledge for three representative tasks in materials chemistry.","ArXiv",2022,"Alex Dunn,John Dagdelen,N. Walker,Sanghoon Lee,Andrew S. Rosen,G. Ceder,Kristin Persson,Anubhav Jain",3,46,1
"5d96a7b57f4959ebcf65eaa21b9f6004b7cdeae9","https://www.semanticscholar.org/paper/5d96a7b57f4959ebcf65eaa21b9f6004b7cdeae9",5,"A fine-grained comparison of pragmatic language understanding in humans and language models","","ArXiv",2022,"Jennifer Hu,Sammy Floyd,O. Jouravlev,Evelina Fedorenko,E. Gibson",3,74,0
"3585e08f2491859679b761eae8444afe7ec62f74","https://www.semanticscholar.org/paper/3585e08f2491859679b761eae8444afe7ec62f74",5,"FewFedWeight: Few-shot Federated Learning Framework across Multiple NLP Tasks","Experiments show that F EW F ED W EIGHT can signiﬁcantly improve the performance of client models on 61% tasks with an average performance improvement rate of 30.5% over the baseline and substantially outperform FedAvg and other decentralized learning methods.","ArXiv",2022,"Weilong Dong,Xinwei Wu,Junzhuo Li,Shuangzhi Wu,Chao Bian,Deyi Xiong",0,42,0
"96bdc84fba47a71f2a4dbdeb58439fa16693873f","https://www.semanticscholar.org/paper/96bdc84fba47a71f2a4dbdeb58439fa16693873f",5,"Go-tuning: Improving Zero-shot Learning Abilities of Smaller Language Models","This work revisits masked language modeling and presents a geometry-guided self-supervised learning method (Go-tuning for short) by taking a small number of task-aware self- supervised data to update language models further, which can enable T5-small (80M) competitive zero-shot results compared with large language models.","ArXiv",2022,"Jingjing Xu,Qingxiu Dong,Hongyi Liu,Lei Li",0,25,0
"df15f1efd70e7fa4d088c24931afef4d7539da4f","https://www.semanticscholar.org/paper/df15f1efd70e7fa4d088c24931afef4d7539da4f",5,"Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization","The results show that S OCRATIC pretraining cuts task-speciﬁc labeled data requirements in half, is more faithful to user-provided queries, and achieves state-of-the-art performance on QMSum and SQuALITY.","ArXiv",2022,"Artidoro Pagnoni,Alexander R. Fabbri,Wojciech Kryscinski,Chien-Sheng Wu",1,43,0
"ed5ebed7ff668fd7362d531a40b49b3aea33b3a9","https://www.semanticscholar.org/paper/ed5ebed7ff668fd7362d531a40b49b3aea33b3a9",5,"Understanding Stereotypes in Language Models: Towards Robust Measurement and Zero-Shot Debiasing","This paper proposes a new framework for robustly measuring and quantifying biases exhibited by generative language models and uses this framework to investigate GPT-3’s occupational gender bias and propose prompting techniques for mitigating these biases without the need for tuning.","ArXiv",2022,"Justus Mattern,Zhijing Jin,Mrinmaya Sachan,Rada Mihalcea,B. Schölkopf",0,54,0
"70d89d380ca5d20564e1dd8ed2f4c59f5c7b3656","https://www.semanticscholar.org/paper/70d89d380ca5d20564e1dd8ed2f4c59f5c7b3656",5,"HINT: Hypernetwork Instruction Tuning for Efficient Zero-Shot Generalisation","Hypernetworks for INstruction Tuning (HINT) is introduced, which convert task instructions and examples using a pretrained text encoder into parameter-efﬁcient modules inserted into an underlying model, eliminating the need to include instructions in the model input.","ArXiv",2022,"Hamish Ivison,Akshita Bhagia,Yizhong Wang,Hannaneh Hajishirzi,Matthew E. Peters",0,29,0
"d2aa89bbfa5eb972626f189cd7454f7d6d0af7c3","https://www.semanticscholar.org/paper/d2aa89bbfa5eb972626f189cd7454f7d6d0af7c3",5,"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning","This work introduces M ULTI I N - STRUCT, the first multimodal instruction tuning benchmark dataset, and designs a new evaluation metric – Sensitivity – to evaluate how sensitive the model is to the variety of instructions.","ArXiv",2022,"Zhiyang Xu,Ying Shen,Lifu Huang",1,48,0
"658a8195ca7dc839bf254d4b2eb67c50384c5c6e","https://www.semanticscholar.org/paper/658a8195ca7dc839bf254d4b2eb67c50384c5c6e",5,"Language models generalize beyond natural proteins","The results show that language models, though only trained on sequences, learn a deep grammar that enables the design of protein structure, extending beyond natural proteins.","bioRxiv",2022,"Robert Verkuil,Ori Kabeli,Yilun Du,B. Wicky,L. Milles,J. Dauparas,D. Baker,S. Ovchinnikov,Tom Sercu,Alexander Rives",5,75,0
"b13668fe9c944b8ad441edb473c218d4cf303de8","https://www.semanticscholar.org/paper/b13668fe9c944b8ad441edb473c218d4cf303de8",5,"Towards Few-Shot Identification of Morality Frames using In-Context Learning","This paper proposes prompting based approaches using pretrained Large Language Models for identification of morality frames, relying only on few-shot exemplars, and compares the models’ performance with few- shot RoBERTa and found promising results.","NLPCSS",2023,"Shamik Roy,Nishanth Nakshatri,Dan Goldwasser",0,32,0
"0392d58335ce674a70f5e58ac8c438de296a0e6a","https://www.semanticscholar.org/paper/0392d58335ce674a70f5e58ac8c438de296a0e6a",5,"Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models","A workflow that allows users to first focus on model feedback using small data before moving on to a large data regime that allows empirical grounding of promising prompts using quantitative measures of the task, and then allows easy deployment of the newly created ad-hoc models.","IEEE Transactions on Visualization and Computer Graphics",2022,"Hendrik Strobelt,Albert Webson,Victor Sanh,Benjamin Hoover,J. Beyer,H. Pfister,Alexander M. Rush",8,46,0
"80c3bc88913815bfe9f2c96c6008231433264dfd","https://www.semanticscholar.org/paper/80c3bc88913815bfe9f2c96c6008231433264dfd",5,"Learning to Exploit Temporal Structure for Biomedical Vision-Language Processing","The results show the advantages of incorporating prior images and reports to make most use of the data, and release a novel multi-modal temporal benchmark dataset, MS-CXR-T, to quantify the quality of vision–language representations in terms of temporal semantics.","ArXiv",2023,"Shruthi Bannur,Stephanie L. Hyland,Qianchu Liu,Fernando Pérez-García,Maximilian Ilse,Daniel Coelho de Castro,Benedikt Boecking,H. Sharma,Kenza Bouzid,Anja Thieme,Anton Schwaighofer,M. Wetscherek,M. Lungren,Aditya Nori,J. Alvarez-Valle,O. Oktay",1,77,0
"feee27c7a717fcb329b4e863b2c720a9defad504","https://www.semanticscholar.org/paper/feee27c7a717fcb329b4e863b2c720a9defad504",5,"Prompt-Based Editing for Text Style Transfer","A prompt-based editing approach for text style transfer that is a training-free process and more controllable than the autoregressive generation of sentences, and largely outperforms the state-of-the-art systems that have 20 times more parameters.","ArXiv",2023,"Guoqing Luo,Yu Tong Han,Lili Mou,Mauajama Firdaus",0,55,0
"f9338e1b32cb450d95094ce71957375754823e4b","https://www.semanticscholar.org/paper/f9338e1b32cb450d95094ce71957375754823e4b",5,"Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models","The results indicate that the best performing strategy (INST) substantially reduces the toxicity probability up to 61% while preserving the accuracy on five benchmark NLP tasks as well as improving AUC scores on four bias detection tasks by 1.3%.","",2023,"Shrimai Prabhumoye,M. Patwary,M. Shoeybi,Bryan Catanzaro",0,41,0
"0ef848249ff85ec6083865d56c7fe3ad517d0820","https://www.semanticscholar.org/paper/0ef848249ff85ec6083865d56c7fe3ad517d0820",5,"Natural Response Generation for Chinese Reading Comprehension","Penguin is the first benchmark towards natural response generation in Chinese MRC on a relatively large scale and develops two strong baselines: end-to-end and two-stage frameworks.","",2023,"Nuo Chen,Hongguang Li,Yinan Bao,Baoyuan Wang,Jia Li",0,34,0
"cdf54c147434c83a4a380916b6c1279b0ca19fc2","https://www.semanticscholar.org/paper/cdf54c147434c83a4a380916b6c1279b0ca19fc2",5,"LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action","Each model is pre-trained on its own dataset, and it is shown that the complete system can execute a variety of user-speciﬁed instructions in real-world outdoor environments — choosing the correct sequence of landmarks through a combination of language and spatial context — and handle mistakes.","ArXiv",2022,"Dhruv Shah,B. Osinski,Brian Ichter,S. Levine",17,75,1
"30d0a5a5f8e776c844a37afe3b1ace0b21b24859","https://www.semanticscholar.org/paper/30d0a5a5f8e776c844a37afe3b1ace0b21b24859",5,"Retrospectives on the Embodied AI Workshop","A retrospective on the state of Embodied AI research is presented and 13 challenges presented at the EmbodiedAI Workshop at CVPR are grouped into three themes: visual navigation, rearrangement and integration.","ArXiv",2022,"Matt Deitke,Dhruv Batra,Yonatan Bisk,Tommaso Campari,Angel X. Chang,Devendra Singh Chaplot,Changan Chen,Claudia P'erez D'Arpino,Kiana Ehsani,Ali Farhadi,Li Fei-Fei,Anthony Francis,Chuang Gan,K. Grauman,David Hall,Winson Han,Unnat Jain,Aniruddha Kembhavi,Jacob Krantz,Stefan Lee,Chengshu Li,Sagnik Majumder,Oleksandr Maksymets,Roberto Mart'in-Mart'in,Roozbeh Mottaghi,Sonia Raychaudhuri,Mike Roberts,S. Savarese,M. Savva,Mohit Shridhar,N. Sunderhauf,Andrew Szot,Ben Talbot,J. Tenenbaum,Jesse Thomason,Alexander Toshev,Joanne Truong,Luca Weihs,Jiajun Wu",4,220,0
"30477855d76058a9b542cabea3058aad1a837d51","https://www.semanticscholar.org/paper/30477855d76058a9b542cabea3058aad1a837d51",5,"A Case for Business Process-Specific Foundation Models","It is argued that business process data representations have unique characteristics that warrant the development of a new class of foundation models to handle tasks like process mining, optimization, and decision making.","ArXiv",2022,"Yara Rizk,P. Venkateswaran,Vatche Isahagian,Vinod Muthusamy",0,50,0
"a2d2bbe4c542173662a444b33b76c66992697830","https://www.semanticscholar.org/paper/a2d2bbe4c542173662a444b33b76c66992697830",5,"InstructPix2Pix: Learning to Follow Image Editing Instructions","The conditional diffusion model, InstructPix2Pix, is trained on generated data, and generalizes to real images and user-written instructions at inference time, and shows compelling editing results for a diverse collection of input images and written instructions.","ArXiv",2022,"Tim Brooks,Aleksander Holynski,Alexei A. Efros",10,72,1
"fe3ead702e8e8948d00caef9bc9dd075dc560236","https://www.semanticscholar.org/paper/fe3ead702e8e8948d00caef9bc9dd075dc560236",5,"I2MVFormer: Large Language Model Generated Multi-View Document Supervision for Zero-Shot Image Classification","This work establishes a new state-of-the-art on three public benchmark datasets for zero-shot image classiﬁcation with unsupervised semantic embeddings and shows that each text view of a class provides complementary information allowing a model to learn a highly discriminative class embedding.","ArXiv",2022,"Muhammad Ferjad Naeem,Muhammad Gul Zain Ali Khan,Yongqin Xian,Muhammad Zeshan Afzal,D. Stricker,L. Gool,F. Tombari",0,65,0
"933b37b21e9d61139660088adb032ff3fdf56d86","https://www.semanticscholar.org/paper/933b37b21e9d61139660088adb032ff3fdf56d86",5,"Learning Video Representations from Large Language Models","This work repurposes pre-trained LLMs to be conditioned on visual input, and finetune them to create automatic video narrators, which offer a number of advantages, including dense cover-age of long videos, better temporal synchronization of the visual information and text, and much higher diversity of text.","ArXiv",2022,"Yue Zhao,Ishan Misra,Philipp Krahenbuhl,Rohit Girdhar",0,86,0
"35bf7a8d6b74c0d8dc3d6d876c560532e230cb97","https://www.semanticscholar.org/paper/35bf7a8d6b74c0d8dc3d6d876c560532e230cb97",5,"Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners","This work presents VideoCoCa, an efficient approach to establish a foundational video-text model for tasks including open-vocabulary video classification, text-to-video retrieval, video captioning and video question-answering, and explores lightweight finetuning on top of this model.","ArXiv",2022,"Shen Yan,Tao Zhu,Zirui Wang,Yuan Cao,Mi Zhang,Soham Ghosh,Yonghui Wu,Jiahui Yu",1,66,1
"c39ced3609bc8cf854786b29d1c5b85b17c061a3","https://www.semanticscholar.org/paper/c39ced3609bc8cf854786b29d1c5b85b17c061a3",5,"LaMPP: Language Models as Probabilistic Priors for Perception and Action","This work describes how to leverage language models for *non-linguistic* perception and control tasks by casting labeling and decision-making as inference in probabilistic graphical models in which language models parameterize prior distributions over labels, decisions and parameters.","ArXiv",2023,"Belinda Z. Li,William Chen,Pratyusha Sharma,Jacob Andreas",0,25,0
"cd6652fe413d57d05b44e0f3aa036c54f0eef464","https://www.semanticscholar.org/paper/cd6652fe413d57d05b44e0f3aa036c54f0eef464",5,"Towards Boosting the Open-Domain Chatbot with Human Feedback","A novel andcient approach Diamante to boost the open-domain chatbot, where two kinds of human feedback are collected and leveraged and the implicit preference in the data collection process and the generation-evaluation joint training is introduced.","ArXiv",2022,"Hua Lu,Siqi Bao,H. He,Fan Wang,Hua Wu,Haifeng Wang",1,31,0
"2fa11f97ae084591d79013c0cbc65d9931d976df","https://www.semanticscholar.org/paper/2fa11f97ae084591d79013c0cbc65d9931d976df",5,"When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels","J UICER, a framework to make use of both binary and free-form textual human feedback, works by extending sparse binary feedback by training a satisfaction class to label the unlabeled data and training a reply corrector to map the bad replies to good ones.","ArXiv",2022,"Weiyan Shi,Emily Dinan,Kurt Shuster,J. Weston,Jing Xu",1,26,0
"5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691","https://www.semanticscholar.org/paper/5ff9cd8fcb959ca6b458c11e780d61c3f2bf7691",5,"PLACES: Prompting Language Models for Social Conversation Synthesis","This work uses a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting, and demonstrates that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi- party tasks.","ArXiv",2023,"Maximillian Chen,A. Papangelis,Chenyang Tao,Seokhwan Kim,Andrew Rosenbaum,Yang Liu,Zhou Yu,Dilek Z. Hakkani-Tür",0,62,0
"7b82fb74a28783aff4ff77340ef6f06dd9ed6f5e","https://www.semanticscholar.org/paper/7b82fb74a28783aff4ff77340ef6f06dd9ed6f5e",4,"Causal Inference Multi-Agent Reinforcement Learning for Traffic Signal Control","","Information Fusion",2023,"Shantian Yang,Bo Yang,Zheng Zeng,Zhongfeng Kang",0,46,0
"9651c3f83b9310829622305f5316443253861fba","https://www.semanticscholar.org/paper/9651c3f83b9310829622305f5316443253861fba",4,"Weakly Supervised Pre-Training for Multi-Hop Retriever","A new method for weakly supervised multi-hop retriever pretraining without human efforts is proposed, which includes a pre-training task for generating vector representations of complex questions, and a scalable data generation method that produces the nested structure of question and subquestion as weak supervision for pre- training.","Findings",2021,"Yeon Seonwoo,Sang-Woo Lee,Ji-Hoon Kim,Jung-Woo Ha,Alice H. Oh",6,24,1
"a19920428f9ad1e0e760d46695e6bb09adde5fcd","https://www.semanticscholar.org/paper/a19920428f9ad1e0e760d46695e6bb09adde5fcd",4,"Talk2Data: High-Level Question Decomposition for Data-Oriented Question and Answering","Talk2Data is introduced, a data-oriented online question and answering system that supports answering both low-level and high- level questions and leverages a novel deep-learning model to resolve high-level questions into a series of low-levels questions that can be answered by data facts.","ArXiv",2021,"Danqing Shi,Yi Guo,Mingjuan Guo,Yanqiu Wu,Qing Chen,Nan Cao",1,65,0
"3bdb464777dad270ad1c80426614af16c08dd361","https://www.semanticscholar.org/paper/3bdb464777dad270ad1c80426614af16c08dd361",4,"Battlesnake Challenge: A Multi-agent Reinforcement Learning Playground with Human-in-the-loop","The results show that agents with the proposed HILL methods consistently outperform agents without HILL, and heuristics of reward manipulation had the best performance in the online competition.","ArXiv",2020,"Jonathan Chung,Anna Luo,Xavier Raffin,Scott Perry",0,46,0
"243da4a2378386a7238398eace6f4da76e7fa397","https://www.semanticscholar.org/paper/243da4a2378386a7238398eace6f4da76e7fa397",4,"Modifying Simulated Perfect Oracles for Interactive Reinforcement Learning: a Participatory Design Methodology","This paper presents a participatory design approach that can modify perfect oracles to human-like oracles for I-RL algorithm testing and runs a user study and experiments with modified oracles generated from participants.","",2021,"",0,37,0
"a9fef6c25124db63818ce49367eb8f06b0ba5f98","https://www.semanticscholar.org/paper/a9fef6c25124db63818ce49367eb8f06b0ba5f98",4,"Correct Me If I am Wrong: Interactive Learning for Robotic Manipulation","The proposed CEILing (Corrective and Evaluative Interactive Learning) framework combines both corrective and evaluative feedback from the teacher to train a stochastic policy in an asynchronous manner, and employs a dedicated mechanism to trade off human corrections with the robot’s own experience.","IEEE Robotics and Automation Letters",2021,"Eugenio Chisari,T. Welschehold,J. Boedecker,W. Burgard,A. Valada",7,40,0
"dff829abffea125d72b9a2f2e0c1a0119b72438f","https://www.semanticscholar.org/paper/dff829abffea125d72b9a2f2e0c1a0119b72438f",4,"Reinforcement learning in medical image analysis: Concepts, applications, challenges, and future directions","The aim of this review is to help the readers formulate and solve their medical image analysis research through the lens of reinforcement learning, and to discuss the reviewed reinforcement learning approaches’ limitations and possible future improvements.","Journal of Applied Clinical Medical Physics",2022,"MingZhe Hu,Jiahan Zhang,L. Matkovic,Tian Liu,Xiaofeng Yang",1,89,0
"25d1df96dc08071719bd891c227fb2cf873c26cf","https://www.semanticscholar.org/paper/25d1df96dc08071719bd891c227fb2cf873c26cf",4,"BERT-kNN: Adding a kNN Search Component to Pretrained Language Models for Better QA","BERT-kNN outperforms BERT on cloze-style QA by large margins without any further training and excels for rare facts.","Findings",2020,"Nora Kassner,Hinrich Schütze",33,25,1
"5cc8ea815bd05be3b28519b489afe6de278a4209","https://www.semanticscholar.org/paper/5cc8ea815bd05be3b28519b489afe6de278a4209",4,"Learning to Recombine and Resample Data for Compositional Generalization","This work presents a family of learned data augmentation schemes that support a large category of compositional generalizations without appeal to latent symbolic structure in settings requiring Compositional generalization beyond the training data.","International Conference on Learning Representations",2020,"Ekin Akyürek,Afra Feyza Akyurek,Jacob Andreas",49,68,7
"183350b0c092c448198bb994d4ed1010f57e6b0d","https://www.semanticscholar.org/paper/183350b0c092c448198bb994d4ed1010f57e6b0d",4,"\infty-former: Infinite Memory Transformer","The \infty-former is proposed, which extends the vanilla transformer with an unbounded long-term memory, and maintains “sticky memories,” being able to model arbitrarily long contexts while keeping the computation budget fixed.","Annual Meeting of the Association for Computational Linguistics",2021,"Pedro Henrique Martins,Zita Marinho,André F. T. Martins",3,50,0
"2a672342035defd8d75b54e08597ef124c6a0172","https://www.semanticscholar.org/paper/2a672342035defd8d75b54e08597ef124c6a0172",4,"Fusing Sentence Embeddings Into LSTM-based Autoregressive Language Models","An LSTM-based autoregressive language model which uses pre-trained on text embeddings from a pretrained masked language model via fusion (e.g. concatenation) to obtain a richer context representation for language modelling to improve the perplexity.","ArXiv",2022,"Vilém Zouhar,Marius Mosbach,D. Klakow",1,54,0
"f7b755474da275c021f6950590c89f7461b5c274","https://www.semanticscholar.org/paper/f7b755474da275c021f6950590c89f7461b5c274",4,"Joint Retrieval and Generation Training for Grounded Text Generation","This work proposes a framework that alleviates data constraint by jointly training a grounded generator and document retriever on the language model signal, and demonstrates that both generator and retriever can take advantage of this joint training and work synergistically to produce more informative and relevant text in both prose and dialogue generation.","ArXiv",2021,"Yizhe Zhang,Siqi Sun,Xiang Gao,Yuwei Fang,Chris Brockett,Michel Galley,Jianfeng Gao,Bill Dolan",14,48,0
"9491da2a7097ac44d7509cbd26d1d09dbcf3a17e","https://www.semanticscholar.org/paper/9491da2a7097ac44d7509cbd26d1d09dbcf3a17e",4,"Information Retrieval & Question Answering in Aviation Safety Domain","This paper presents a Question Answering System using Deep Learning for the aviation domain, and presents two approaches: Deep Learning based QA (DLQA) and KG guided DL basedQA, which discusses techniques falling into two categories: open-book and closed-book approaches.","",2022,"Raju Gite,P. Bhattacharyya",0,43,0
"39a9f750c9b79fba4a0404179fdac6a7cb922838","https://www.semanticscholar.org/paper/39a9f750c9b79fba4a0404179fdac6a7cb922838",4,"RetGen: A Joint Framework for Retrieval and Grounded Text Generation Modeling","This work proposes a framework that alleviates this data constraint by jointly training a grounded generator and document retriever on the language model signal, and demonstrates that both generator and retriever can take advantage of this joint training and work synergistically to produce more informative and relevant text in both prose and dialogue generation.","AAAI Conference on Artificial Intelligence",2021,"Yizhe Zhang,Siqi Sun,Xiang Gao,Yuwei Fang,Chris Brockett,Michel Galley,Jianfeng Gao,Bill Dolan",5,54,1
"2555cfe0f77d55cc0d887da00fd58857d0c6edd5","https://www.semanticscholar.org/paper/2555cfe0f77d55cc0d887da00fd58857d0c6edd5",4,"Conformer-Kernel with Query Term Independence for Document Retrieval","It is demonstrated that incorporating explicit term matching signal into the model can be particularly useful in the full retrieval setting, and to reduce the memory complexity of the Transformer layers with respect to the input sequence length, a new Conformer layer is proposed.","ArXiv",2020,"Bhaskar Mitra,Sebastian Hofstätter,Hamed Zamani,Nick Craswell",19,65,2
"590bcbe623f212c1e27ab2edb0e400888f3f2601","https://www.semanticscholar.org/paper/590bcbe623f212c1e27ab2edb0e400888f3f2601",4,"Improving Transformer-Kernel Ranking Model Using Conformer and Query Term Independence","This work proposes a novel Conformer layer as an alternative approach to scale TK to longer input sequences and incorporates query term independence and explicit term matching to extend the model to the full retrieval setting.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2021,"Bhaskar Mitra,Sebastian Hofstätter,Hamed Zamani,Nick Craswell",4,108,0
"ba9865c11e6b5b18d8323e4fa2eed89309e66e6f","https://www.semanticscholar.org/paper/ba9865c11e6b5b18d8323e4fa2eed89309e66e6f",4,"SEINE: SEgment-based Indexing for NEural information retrieval","A novel SEgment-based Neural Indexing method, SEINE, is proposed, which provides a general indexing framework that can flexibly support a variety of interaction-based neural retrieval methods and proposes to use segment-level inverted index to store the atomic query-document interaction values.","",2022,"Sibo Dong,Justin Goldstein,G. Yang",2,62,0
"bbf0390847159f3d56089807a0ad8348986db5fd","https://www.semanticscholar.org/paper/bbf0390847159f3d56089807a0ad8348986db5fd",4,"CREPE: Can Vision-Language Foundation Models Reason Compositionally?","A new compositionality evaluation benchmark, CREPE, is introduced, which measures two important aspects of compositionality identified by cognitive science literature: systematicity and productivity.","ArXiv",2022,"Zixian Ma,Jerry Hong,Mustafa Omer Gul,Mona Gandhi,Irena Gao,Ranjay Krishna",1,92,0
"db20bd3bb82d1011ce704d440d8c2578f665e6e1","https://www.semanticscholar.org/paper/db20bd3bb82d1011ce704d440d8c2578f665e6e1",4,"Aligning Robot and Human Representations","It is suggested that because humans will be the ultimate evaluator of robot performance in the world, it is critical that the authors explicitly focus their efforts on aligning learned task representations with humans, in addition to learning the downstream task.","ArXiv",2023,"Andreea Bobu,Andi Peng,Pulkit Agrawal,J. Shah,A. Dragan",0,177,0
"0e34addae55a571d7efd3a5e2543e86dd7d41a83","https://www.semanticscholar.org/paper/0e34addae55a571d7efd3a5e2543e86dd7d41a83",4,"Interactive Language: Talking to Robots in Real Time","A framework for building interactive, real- time, natural language-instructable robots in the real world is presented, and the same policy is capable of being guided by a human via real-time language to address a wide range of precise long-horizon rearrange- ment goals.","ArXiv",2022,"Corey Lynch,Ayzaan Wahid,Jonathan Tompson,Tianli Ding,James Betker,Robert K. Baruch,Travis Armstrong,Peter R. Florence",6,61,1
"91cac43160ca45e5a1a41e0c5b7e6ec5a74033b3","https://www.semanticscholar.org/paper/91cac43160ca45e5a1a41e0c5b7e6ec5a74033b3",4,"Robotic Skill Acquisition via Instruction Augmentation with Vision-Language Models","DIAL is introduced, which utilizes semi-supervised language labels leveraging the semantic understanding of CLIP to propagate knowledge onto large datasets of unlabelled demonstration data and then train language-conditioned policies on the augmented datasets, enabling cheaper acquisition of useful language descriptions compared to expensive human labels.","ArXiv",2022,"Ted Xiao,Harris Chan,P. Sermanet,Ayzaan Wahid,Anthony Brohan,Karol Hausman,S. Levine,Jonathan Tompson",2,47,0
"832fff14d2ed50eb7969c4c4b976c35776548f56","https://www.semanticscholar.org/paper/832fff14d2ed50eb7969c4c4b976c35776548f56",4,"REALM: Retrieval-Augmented Language Model Pre-Training","The effectiveness of Retrieval-Augmented Language Model pre-training (REALM) is demonstrated by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA) and is found to outperform all previous methods by a significant margin, while also providing qualitative benefits such as interpretability and modularity.","ArXiv",2020,"Kelvin Guu,Kenton Lee,Z. Tung,Panupong Pasupat,Ming-Wei Chang",533,42,91
"a20712b1b9779ee43ce143a19b3f67f0cacbbf57","https://www.semanticscholar.org/paper/a20712b1b9779ee43ce143a19b3f67f0cacbbf57",4,"Neural Databases","This paper describes NeuralDB, a database system with no pre-defined schema, in which updates and queries are given in natural language, and describes an algorithm that learns how to create the appropriate sets of facts to be fed into each of the Neural SPJ operators.","ArXiv",2020,"James Thorne,Majid Yazdani,Marzieh Saeidi,F. Silvestri,Sebastian Riedel,A. Halevy",4,58,0
"64435711f6542aa6b53e95c6e084a0ccd2ec1c16","https://www.semanticscholar.org/paper/64435711f6542aa6b53e95c6e084a0ccd2ec1c16",4,"HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions","This paper proposes a new retrieval target, hop, to collect the hidden reasoning evidence from Wikipedia for complex question answering and builds HopRetriever which retrieves hops over Wikipedia to answer complex questions.","AAAI Conference on Artificial Intelligence",2020,"Shaobo Li,Xiaoguang Li,Lifeng Shang,Xin Jiang,Qun Liu,Chengjie Sun,Zhenzhou Ji,Bingquan Liu",18,28,2
"17b4a75b432b9f58de143918608de9234a4da988","https://www.semanticscholar.org/paper/17b4a75b432b9f58de143918608de9234a4da988",4,"Towards Continual Entity Learning in Language Models for Conversational Agents","EALM is introduced, where entity models trained on catalogues of entities into the pre-trained LMs are integrated and a combined language model adaptively adds information from 7 the entity models into thePre-trained LM depending on the sentence context.","ArXiv",2021,"R. Gadde,I. Bulyko",0,46,0
"c95d1a92163ebacac5b3a58b31c8d37447beafc0","https://www.semanticscholar.org/paper/c95d1a92163ebacac5b3a58b31c8d37447beafc0",4,"Vision-based navigation and obstacle avoidance via deep reinforcement learning","A deep Dyna-Q learning algorithm for room evacuation and obstacle avoidance in partially observable environments based on low-resolution raw image data from an onboard camera is employed and it is evident that the agent can navigate to a goal location while avoiding multiple static and dynamic obstacles, and can escape from a concave obstacle while searching for and navigating to the exit.","ArXiv",2022,"P. Blum,Peter Crowley,G. Lykotrafitis",0,30,0
"2b93e59f2ab24bdfd2f9160eb47b6d1936cbe1ae","https://www.semanticscholar.org/paper/2b93e59f2ab24bdfd2f9160eb47b6d1936cbe1ae",4,"Receding-Horizon Control of Constrained Switched Systems with Neural Networks as Parametric Function Approximators","","SN Computer Science",2022,"Lukas Markolf,O. Stursberg",0,38,0
"aa76febe2e6f6a96f1daa83828f2340bf871042e","https://www.semanticscholar.org/paper/aa76febe2e6f6a96f1daa83828f2340bf871042e",4,"Global Convergence of Localized Policy Iteration in Networked Multi-Agent Reinforcement Learning","A Localized Policy Iteration (LPI) algorithm that provably learns a near-globally-optimal policy using only local information is proposed, which explicitly captures the trade-off between optimality and computational complexity in choosing κ.","ArXiv",2022,"Yizhou Zhang,Guannan Qu,Pan Xu,Yiheng Lin,Zaiwei Chen,A. Wierman",1,45,0
"17e99278239bae41a2d2546a0af4aea88a6247ba","https://www.semanticscholar.org/paper/17e99278239bae41a2d2546a0af4aea88a6247ba",4,"Recent Advances in Artificial Intelligence and Tactical Autonomy: Current Status, Challenges, and Perspectives","This paper provides the state-of-the-art advanced AI methods available for tactical autonomy and is the first work that addresses the important current trends, strategies, critical challenges, tactical complexities, and future research directions of tactical autonomy.","Italian National Conference on Sensors",2022,"D. Hagos,D. Rawat",0,163,0
"f5bc137361ab303aa0c53c71418430c68ce52dc4","https://www.semanticscholar.org/paper/f5bc137361ab303aa0c53c71418430c68ce52dc4",4,"NARS vs. Reinforcement learning: ONA vs. Q-Learning","This project is looking to investigate the capability of NARS and answer the question of whether NARS has the potential to be a substitute for RL or not, and making a comparison between Q -Learning and ONA on some environments developed by an Open AI gym.","ArXiv",2022,"Ali Beikmohammadi",0,35,0
"1abed54dc77454fcb33f4da04b5bede4ccff8235","https://www.semanticscholar.org/paper/1abed54dc77454fcb33f4da04b5bede4ccff8235",4,"CoBeL-RL: A neuroscience-oriented simulation framework for complex behavior and learning","CoBeL-RL is a closed-loop simulator of complex behavior and learning based on RL and deep neural networks that provides a neuroscience-oriented framework for efficiently setting up and running simulations and fills an important gap in the software toolbox of computational neuroscience.","bioRxiv",2022,"Nicolas Diekmann,Sandhiya Vijayabaskaran,Xiangshuai Zeng,D. Kappel,Matheus Chaves Menezes,Sen Cheng",1,60,0
"8cc1912faa44981ff2dacfd749da6471344b9125","https://www.semanticscholar.org/paper/8cc1912faa44981ff2dacfd749da6471344b9125",4,"A deep reinforcement learning method for structural dominant failure modes searching based on self-play strategy","","Reliability Engineering &amp; System Safety",2023,"Xiaoshu Guan,Huabin Sun,Rongrong Hou,Yang Xu,Y. Bao,Hui Li",0,36,0
"41125af933ca21d5318b9fa2eb44e045a28bf216","https://www.semanticscholar.org/paper/41125af933ca21d5318b9fa2eb44e045a28bf216",4,"The Wisdom of the Crowd: Reliable Deep Reinforcement Learning Through Ensembles of Q-Functions","This work investigates a novel technique which harnesses the wisdom of crowds by combining Q-function approximator estimates utilizing a simple combination scheme similar to the supervised learning approach known as bagging, and demonstrates that the stability in learning allows an actor-critic method to find more efficient solutions.","IEEE Transactions on Neural Networks and Learning Systems",2018,"D. Elliott,C. Anderson",1,34,0
"009f39969ec181ac8b8548193a37d29cbafb1079","https://www.semanticscholar.org/paper/009f39969ec181ac8b8548193a37d29cbafb1079",4,"Variational Information Bottleneck Regularized Deep Reinforcement Learning for Efficient Robotic Skill Adaptation","Empirical results show that the proposed variational information bottleneck regularized deep reinforcement learning algorithm can improve sample efficiency by 200–5000 times on new tasks and achieves substantial asymptotic performance improvement.","Italian National Conference on Sensors",2023,"Guofei Xiang,S. Dian,Shaofeng Du,Zhonghui Lv",0,59,0
"fa13325dcc7af7f9bd9486acb8a974e9a8cf2d9c","https://www.semanticscholar.org/paper/fa13325dcc7af7f9bd9486acb8a974e9a8cf2d9c",4,"On The Convergence Of Policy Iteration-Based Reinforcement Learning With Monte Carlo Policy Evaluation","","ArXiv",2023,"Anna Winnicki,R. Srikant",0,30,0
"bdb971079c7cbbffd752197ae246146939bfc18c","https://www.semanticscholar.org/paper/bdb971079c7cbbffd752197ae246146939bfc18c",4,"Obstacle avoidance for environmentally-driven USVs based on deep reinforcement learning in large-scale uncertain environments","","Ocean Engineering",2023,"Peng Wang,Ranran Liu,Xinliang Tian,Xiantao Zhang,Lei Qiao,Yuntao Wang",0,43,0
"45f573f302dc7e77cbc5d1a74ccbac3564bbebc8","https://www.semanticscholar.org/paper/45f573f302dc7e77cbc5d1a74ccbac3564bbebc8",4,"PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training","This work presents an off-policy, interactive RL algorithm that capitalizes on the strengths of both feedback and off- policy learning, and is able to utilize real-time human feedback to effectively prevent reward exploitation and learn new behaviors that are difficult to specify with standard reward functions.","International Conference on Machine Learning",2021,"Kimin Lee,Laura Smith,P. Abbeel",47,79,14
"f70e82b8b7c792a3cdbf2c9bf2e7af06fd6a7269","https://www.semanticscholar.org/paper/f70e82b8b7c792a3cdbf2c9bf2e7af06fd6a7269",4,"Skill Preferences: Learning to Extract and Execute Robotic Skills from Human Feedback","Skill Preferences is presented, an algorithm that learns a model over human preferences and uses it to extract human-aligned skills from of-ine data and substantially outperforms prior leading RL algorithms with human preferences as well as leading skill extraction algorithms without human preferences.","Conference on Robot Learning",2021,"Xiaofei Wang,Kimin Lee,Kourosh Hakhamaneshi,P. Abbeel,M. Laskin",13,39,0
"239534e1d046c93bc4e98ace47f4657de67d96ec","https://www.semanticscholar.org/paper/239534e1d046c93bc4e98ace47f4657de67d96ec",4,"On-policy learning-based deep reinforcement learning assessment for building control efficiency and stability","","Science and Technology for the Built Environment",2022,"Joon-Yong Lee,Aowabin Rahman,Sen Huang,Amanda D. Smith,S. Katipamula",1,42,0
"a0202138a0e3291a853e1b9beaeafcfb9369340a","https://www.semanticscholar.org/paper/a0202138a0e3291a853e1b9beaeafcfb9369340a",4,"Researches advanced in credit assignment in reinforcement learning","The existing solutions to the credit assignment issue are reviewed, the impact of different credit assignment strategies on algorithms’ final performance is compared, and some suggestions for the future research directions are given.","Other Conferences",2022,"Juerui Li",0,23,0
"c5f96f151f23e75e5e99dd97d4a4ab4ca52a8f8e","https://www.semanticscholar.org/paper/c5f96f151f23e75e5e99dd97d4a4ab4ca52a8f8e",4,"Multi-Timeframe Algorithmic Trading Bots Using Thick Data Heuristics with Deep Reinforcement Learning","An augmented Artificial Intelligence algorithmic trading approach that combines Thick Data Heuristic (TDH), with Deep Reinforcement Learning (DRL), to successfully learn trading execution timing policies is presented.","Artificial Intelligence Evolution",2022,"Gregory Roy,J. Fiaidhi,Sabah Mohammed",0,81,0
"0fd6c747b48526ba4abc05b4ae9260f93718ce8f","https://www.semanticscholar.org/paper/0fd6c747b48526ba4abc05b4ae9260f93718ce8f",4,"Efficient Meta Reinforcement Learning for Preference-based Fast Adaptation","A meta-RL algorithm that enables fast policy adaptation with preference-based feedback and can adapt to new tasks by querying human’s preference between behavior trajectories instead of using per-step numeric rewards is developed.","ArXiv",2022,"Zhizhou Ren,Anji Liu,Yitao Liang,Jian Peng,Jianzhu Ma",1,65,0
"34861a134bc2f515bf937e488b5b0b46f94fe64c","https://www.semanticscholar.org/paper/34861a134bc2f515bf937e488b5b0b46f94fe64c",4,"State-Aware Proximal Pessimistic Algorithms for Offline Reinforcement Learning","The key idea of SA-PP is leveraging discounted stationary state distribution ratios between the learning policy and the ofﬂine dataset to modulate the degree of behavior regularization in a state-wise manner, so that pessimism can be implemented in a more appropriate way.","ArXiv",2022,"Chen Chen,Hongyao Tang,Yi Ma,Chao Wang,Qianli Shen,Dong Li,Jianye Hao",0,37,0
"b6a71f4ab3a6fa53bde2c606abd195c033e9eb31","https://www.semanticscholar.org/paper/b6a71f4ab3a6fa53bde2c606abd195c033e9eb31",4,"CrowdHMT: Crowd Intelligence With the Deep Fusion of Human, Machine, and IoT","The vision of the next generation of MCSC, crowd intelligence with the deep fusion of human, machine, and Internet of Things (IoT) is presented, namely, CrowdHMT, which aims to build a self-organizing, self-learning,self-adaptive, and continuous-evolving smart space with theDeep fusion of Crowdsourced human,Machine, and IoT intelligence.","IEEE Internet of Things Journal",2022,"Bin Guo,Yan Liu,Sicong Liu,Zhiwen Yu,Xingshe Zhou",0,190,0
"203ce4bd674b127df54824047e94051fccb239be","https://www.semanticscholar.org/paper/203ce4bd674b127df54824047e94051fccb239be",4,"Offline Robot Reinforcement Learning with Uncertainty-Guided Human Expert Sampling","This work proposes a novel approach that uses uncertainty estimation to trigger the injection of human demonstration data and guide policy training towards optimal behavior while reducing overall sample complexity of existing ofﬂine reinforcement learning algorithms.","ArXiv",2022,"Ashish Kumar,Ilya Kuzovkin",0,37,0
"bb7ae5aa82d3241743436a1699752814f46a2f22","https://www.semanticscholar.org/paper/bb7ae5aa82d3241743436a1699752814f46a2f22",4,"Joint Optimization of Jamming Link and Power Control in Communication Countermeasures: A Multiagent Deep Reinforcement Learning Approach","A novel decentralized jamming resource allocation algorithm based on multiagent deep reinforcement learning (MADRL) to improve the efficiency of jamming resources allocation in battlefield communication countermeasures and develops the multiagent soft actor-critic (MASAC) algorithm to enhance the exploration capability of agents and accelerate the learning of cooperative policies among agents by leveraging the maximum policy entropy criterion.","Wireless Communications and Mobile Computing",2022,"Ning Rao,Hua Xu,Yue Zhang,Dan Wang,Lei Jiang,Xiang Peng",0,40,0
"7edae4a0acd6ff65a561a5c040a97107a8cd24a9","https://www.semanticscholar.org/paper/7edae4a0acd6ff65a561a5c040a97107a8cd24a9",4,"Review of Machine Learning and Artificial Intelligence (ML/AI) for the Pediatric Neurologist.","An overview of AI and ML (AI/ML), including definitions of common terms, is provided and instances of how AI/ML can be applied to pediatric neurology are provided.","Pediatric Neurology",2023,"Grace Y. Gombolay,N. Gopalan,A. Bernasconi,R. Nabbout,J. T. Megerian,Benjamin I. Siegel,Jamika Hallman-cooper,S. Bhalla,M. Gombolay",0,85,0
"235ec101999a9c26ef24a59367dcd7738a40c2ec","https://www.semanticscholar.org/paper/235ec101999a9c26ef24a59367dcd7738a40c2ec",4,"Reinforcement Learning informs optimal treatment strategies to limit antibiotic resistance","This work shows that it is possible for RL agents to learn effective drug cycling protocols using current population fitness as the only training input, and represents a proof-of-concept for using AI to control complex evolutionary processes.","bioRxiv",2023,"Davis T. Weaver,Jeff Maltas,Jacob G. Scott",0,50,0
"fcf0cbae0d4986fb33b201f99426723a437d16e7","https://www.semanticscholar.org/paper/fcf0cbae0d4986fb33b201f99426723a437d16e7",4,"SaFormer: A Conditional Sequence Modeling Approach to Offline Safe Reinforcement Learning","A novel ofﬂine safe RL approach referred to as SaFormer, which tackles the above issues via conditional sequence modeling, and proposes cost-related tokens to restrict the action space and a posterior safety veriﬁcation to enforce the constraint explicitly.","ArXiv",2023,"Q. Zhang,Linrui Zhang,Haoran Xu,Li Shen,Bowen Wang,Yongzhe Chang,Xueqian Wang,Bo Yuan,Dacheng Tao",0,28,0
"215e07a9d3796b10294a840c9e369e4c70743d17","https://www.semanticscholar.org/paper/215e07a9d3796b10294a840c9e369e4c70743d17",4,"Continuous Control for High-Dimensional State Spaces: An Interactive Learning Approach","Experimental results validate the efficiency of the D-COACH framework in three different problems, and show that its enhanced version reduces the human training effort considerably, and makes it feasible to learn policies within periods of time in which a DRL agent do not reach any improvement.","IEEE International Conference on Robotics and Automation",2019,"Rodrigo Pérez-Dattari,C. Celemin,Javier Ruiz-del-Solar,J. Kober",9,24,0
"2ae3b5fc450bd22bec0b86f7b2f12b35617c65e3","https://www.semanticscholar.org/paper/2ae3b5fc450bd22bec0b86f7b2f12b35617c65e3",4,"Reinforcement Learning for Machine Translation: from Simulations to Real-World Applications","This thesis investigates solutions for machine learning updates, the suitability of feedback interfaces, and the dependency on reliability and expertise for different types of feedback, and proposes a self-regulation approach, where the learner decides which type of feedback to choose for each input.","",2020,"Julia Kreutzer",0,259,0
"357b2db482e3f59f22493de3d8a2f6cf9ca9d634","https://www.semanticscholar.org/paper/357b2db482e3f59f22493de3d8a2f6cf9ca9d634",4,"Real-Time Holding Control for Transfer Synchronization via Robust Multiagent Reinforcement Learning","The promising results in terms of both online computational efficiency and solution effectiveness suggest that the proposed RL method is a valid candidate for real-time transit control when the dynamics cannot be modeled perfectly with system uncertainties, as is the case for the network-wide transfer synchronization problem.","IEEE transactions on intelligent transportation systems (Print)",2022,"Xinlian Yu,A. Khani,Jingxu Chen,Hongli Xu,Haijun Mao",0,50,0
"c8a2d383a42ffe4ee819844c846c6cc35c72b8e4","https://www.semanticscholar.org/paper/c8a2d383a42ffe4ee819844c846c6cc35c72b8e4",4,"CRC-RL: A Novel Visual Feature Representation Architecture for Unsupervised Reinforcement Learning","The proposed architecture, called CRC-RL, is shown to outperform the existing state-of-the-art methods on the challenging Deep mind control suite environments by a signiﬁcant margin thereby creating a new benchmark in thisRL field.","ArXiv",2023,"Darshita Jain,A. Majumder,S. Dutta,Swagat Kumar",0,48,0
"9c6ee29930206b508d69799cea3bf7091912fc11","https://www.semanticscholar.org/paper/9c6ee29930206b508d69799cea3bf7091912fc11",4,"Non-blocking Asynchronous Training for Reinforcement Learning in Real-World Environments","This paper proposes a non-blocking and asynchronous DRL training architecture for non-linear, real-time dynamical systems tailored to handling variable delays and demonstrates the efficacy of this architecture with a physical implementations of a commodity-grade swing-up pendulum and a quadrupedal robot.","IEEE/RJS International Conference on Intelligent RObots and Systems",2022,"P. Bohm,P. Pounds,Archie C. Chapman",0,25,0
"e0eb9870a6c105cadd92cae8f5218b2a84955849","https://www.semanticscholar.org/paper/e0eb9870a6c105cadd92cae8f5218b2a84955849",4,"Active Task Randomization: Learning Visuomotor Skills for Sequential Manipulation by Proposing Feasible and Novel Tasks","This work introduces Active Task Randomization (ATR), an approach that learns visuomotor skills for sequential manipulation by automatically creating feasible and novel tasks in simulation by developing a relational neural network that maps each task parameter into a compact embedding.","ArXiv",2022,"Kuan Fang,Toki Migimatsu,Ajay Mandlekar,Li Fei-Fei,J. Bohg",0,98,0
"382504c7013f4578d0f1829fdcd413fed529cde1","https://www.semanticscholar.org/paper/382504c7013f4578d0f1829fdcd413fed529cde1",4,"Learning to Solve Complex Tasks by Talking to Agents","This work proposes a new benchmark called COMMAQA that contains three kinds of complex reasoning tasks that are designed to be solved by “talking” to four agents with different capabilities and hopes it serves as a novel benchmark to enable the development of “green” AI systems that build upon existing agents.","ArXiv",2021,"Tushar Khot,Kyle Richardson,Daniel Khashabi,Ashish Sabharwal",5,61,1
"5564fcc4a0da606029867678317c42fc0f20fb13","https://www.semanticscholar.org/paper/5564fcc4a0da606029867678317c42fc0f20fb13",4,"Retrieval Data Augmentation Informed by Downstream Question Answering Performance","This work identifies relevant passages based on whether they are useful for a trained QA model to arrive at the correct answers, and develops a search process guided by the QAmodel’s loss that generalizes better to the end QA task.","FEVER",2022,"James Ferguson,Hannaneh Hajishirzi,Pradeep Dasigi,Tushar Khot",2,16,0
"dbeff5429ff0caa85f9e02621928e787e789ca2b","https://www.semanticscholar.org/paper/dbeff5429ff0caa85f9e02621928e787e789ca2b",4,"Hey AI, Can You Solve Complex Tasks by Talking to Agents?","A synthetic benchmark, CommaQA, with three complex reasoning tasks designed to be solved by communicating with existing QA agents, showing that black-box models struggle to learn this task from scratch even with access to each agent’s knowledge and gold facts supervision.","Findings",2021,"Tushar Khot,Kyle Richardson,Daniel Khashabi,Ashish Sabharwal",6,61,0
"5c80c7c898bd880d65ee1565f627acd454bd7413","https://www.semanticscholar.org/paper/5c80c7c898bd880d65ee1565f627acd454bd7413",4,"Adaptive Discount Factor for Deep Reinforcement Learning in Continuing Tasks with Uncertainty","The proposed adaptive discount factor automatically finds a discount factor that leads to comparable training performance, and that can be applied to representative deep reinforcement learning problems.","Italian National Conference on Sensors",2022,"Myeongseop Kim,Jung-Su Kim,Myoung-Su Choi,Jae-Han Park",1,36,0
"522ac9eb08bb0c5a422700bb254ea1c44e9157de","https://www.semanticscholar.org/paper/522ac9eb08bb0c5a422700bb254ea1c44e9157de",4,"Discovered Policy Optimisation","By analysing LPO, this paper gains original insights into policy optimisation which are used to formulate a novel, closed-form RL algorithm, Discovered Policy Optimisation (DPO), and explores the Mirror Learning space by meta-learning a “drift” function.","ArXiv",2022,"Chris Xiaoxuan Lu,J. Kuba,Alistair Letcher,Luke Metz,C. S. D. Witt,J. Foerster",3,44,0
"3e5b3258df48dd41f53ffbd76ea391775b1d9dd3","https://www.semanticscholar.org/paper/3e5b3258df48dd41f53ffbd76ea391775b1d9dd3",4,"Policy Gradient With Serial Markov Chain Reasoning","A new framework that performs decision-making in reinforcement learning (RL) as an iterative reasoning process, optimized with a new tractable estimate of the policy gradient that allows agent behavior to approximate any continuous distribution over actions by parameterizing the RMC with a simple Gaussian transition function.","ArXiv",2022,"Edoardo Cetin,O. Çeliktutan",0,96,0
"8a79ac36b26348c1293433b68bc5e538706f321b","https://www.semanticscholar.org/paper/8a79ac36b26348c1293433b68bc5e538706f321b",4,"Deep Whole-Body Control: Learning a Unified Policy for Manipulation and Locomotion","This work proposes to learn a uniﬁed policy for whole-body control of a legged manipulator using reinforcement learning, Regularized Online Adaptation to bridge the Sim2Real gap for high-DoF control, and Advantage Mixing exploiting the causal dependency in the action space to overcome local minima during training the whole- body system.","ArXiv",2022,"Zipeng Fu,Xuxin Cheng,Deepak Pathak",3,63,0
"d32855c1af70db05db88615508fb063055e1b9ad","https://www.semanticscholar.org/paper/d32855c1af70db05db88615508fb063055e1b9ad",4,"DIAMBRA Arena: a New Reinforcement Learning Platform for Research and Experimentation","DIAMBRA Arena is presented, a new platform for reinforcement learning research and experimentation, featuring a collection of high-quality environments exposing a Python API fully compliant with OpenAI Gym standard, and software capabilities are demonstrated by successfully training multiple deep reinforcement learning agents with proximal policy optimization obtaining human-like behavior.","ArXiv",2022,"A. Palmas",0,29,0
"ddbc085f17efb92a90b1e1038ff9fe15e464262d","https://www.semanticscholar.org/paper/ddbc085f17efb92a90b1e1038ff9fe15e464262d",4,"Keeping Humans in the Loop: Teaching via Feedback in Continuous Action Space Environments","Continuous Action-space Interactive Reinforcement learning (CAIR) is presented: the first continuous action-space IntRL algorithm that is capable of using teacher feedback to out-perform state-of-the-art RL algorithms in those tasks.","IEEE/RJS International Conference on Intelligent RObots and Systems",2022,"Isaac S. Sheidlower,Allison Moore,Elaine Schaertl Short",0,37,0
"ca365e7a6bb383287bfcbc39720bd572e25e6eca","https://www.semanticscholar.org/paper/ca365e7a6bb383287bfcbc39720bd572e25e6eca",4,"Global and Local Analysis of Interestingness for Competency-Aware Deep Reinforcement Learning","A recently-proposed framework for explainable RL that is based on anal- yses of “interestingness” is extended, providing various measures of RL agent competence stemming from inter- estingness analysis and is applicable to a wide range of RL algorithms.","ArXiv",2022,"Pedro Sequeira,Jesse Hostetler,M. Gervasio",0,41,0
"9a9779825a6706d985232d5ae2946bab3214ebde","https://www.semanticscholar.org/paper/9a9779825a6706d985232d5ae2946bab3214ebde",4,"From deterministic to stochastic: an interpretable stochastic model-free reinforcement learning framework for portfolio optimization","This work proposes a novel interpretable stochastic reinforcement learning framework which tailors a Stochastic policy parameterized by Gaussian Mixtures and a distributional critic realized by quantiles for the problem of portfolio optimization.","Applied intelligence (Boston)",2022,"Zitao Song,Yining Wang,Pin Qian,Sifan Song,Frans Coenen,Zhengyong Jiang,Jionglong Su",0,43,0
"158b8bdfbb8542ba949a513ab02efa229fe71e43","https://www.semanticscholar.org/paper/158b8bdfbb8542ba949a513ab02efa229fe71e43",4,"Shortest-Path-Based Deep Reinforcement Learning for EV Charging Routing Under Stochastic Traffic Condition and Electricity Prices","","IEEE Internet of Things Journal",2022,"Jiangliang Jin,Yunjian Xu",1,50,0
"1711bda8fbf86301c9297b2925419fd8680cd43f","https://www.semanticscholar.org/paper/1711bda8fbf86301c9297b2925419fd8680cd43f",4,"Simultaneously Updating All Persistence Values in Reinforcement Learning","This work derives a novel All-Persistence Bellman Operator, which allows an effective use of both the low-persistence experience, by decomposition into sub-transition, and the high-persistent experience, thanks to the introduction of a suitable bootstrap procedure.","ArXiv",2022,"Luca Sabbioni,Luca Al Daire,L. Bisi,A. Metelli,Marcello Restelli",0,47,0
"b8ba8aebb5f222d7ec93cc3c737a4e88dcf3fd8e","https://www.semanticscholar.org/paper/b8ba8aebb5f222d7ec93cc3c737a4e88dcf3fd8e",4,"Learning to Box: Reinforcement Learning using Heuristic Three-step Curriculum Learning","","International Conference on Control, Automation and Systems",2022,"Heeseon Rho,Yeonguk Yu,Kyoobin Lee",0,19,0
"dc40ab903403d46fea6d0bef0dcee92498facbb0","https://www.semanticscholar.org/paper/dc40ab903403d46fea6d0bef0dcee92498facbb0",4,"Domain Knowledge-Assisted Deep Reinforcement Learning Power Allocation for MIMO Radar Detection","A domain-knowledge-assisted DRL (DKADRL) framework in which a domain- knowledge-based timely reward generator is utilized to generate timely rewards that assist the agent’s policy learning is proposed.","IEEE Sensors Journal",2022,"Yuedong Wang,Yan Liang,Huixia Zhang,Yijing Gu",0,30,0
"e449f48a676af35e0a22c6251fd3bbfd3960454a","https://www.semanticscholar.org/paper/e449f48a676af35e0a22c6251fd3bbfd3960454a",4,"Adaptive Cooperative Exploration for Reinforcement Learning from Imperfect Demonstrations","","Pattern Recognition Letters",2022,"Fuxian Huang,Naye Ji,Huajian Ni,Shijian Li,Xi Li",0,37,0
"e5f567508a6b1a135f4258411f9b4ea48a49b379","https://www.semanticscholar.org/paper/e5f567508a6b1a135f4258411f9b4ea48a49b379",4,"A Deep Reinforcement Learning Approach for Airport Departure Metering Under Spatial–Temporal Airside Interactions","Results, on a typical day of simulated operations at Singapore Changi Airport, demonstrate that DRL can learn an effective DM policy to contain congestion on the taxiways, reduce total fuel consumption and better manage the airside traffic.","IEEE transactions on intelligent transportation systems (Print)",2022,"Hasnain Ali,D. Pham,S. Alam,M. Schultz",0,50,0
"a49d00573720f58e775aefa8b9056900cd9ba77e","https://www.semanticscholar.org/paper/a49d00573720f58e775aefa8b9056900cd9ba77e",4,"Multi-Robot Real-time Game Strategy Learning based on Deep Reinforcement Learning","A reinforcement-learning-based multi-robot control method that enhanced the reinforcement learning algorithm PPO with the self-play method by easy-to-implement tricks for multi-agent training and improve training efficiency is proposed to improve the strategy performance.","IEEE International Conference on Robotics and Biomimetics",2022,"Ki Deng,Yanjie Li,Songshuo Lu,Yongjin Mu,Xizheng Pang,Qi Liu",0,28,0
"5cef819106a386fe876a868b52d933e98e5c32e4","https://www.semanticscholar.org/paper/5cef819106a386fe876a868b52d933e98e5c32e4",4,"Leveraging Efficiency through Hybrid Prioritized Experience Replay in Door Environment","A method called Proximal Policy Optimization with Hybrid Prioritized Experience Replay (HPER-PPO) to adjust the sample priority and guide the selection, through which the policy can be better optimized and the cumulative reward can be maximized.","IEEE International Conference on Robotics and Biomimetics",2022,"Haofu Qian,Shiqiang Zhu,Hongjiang Ge,Haolei Shi,Jianfeng Liao,Wei Song,Jianjun Gu",0,40,0
"13b120fad7ebe58f4d2257a1ee7901c30219feaf","https://www.semanticscholar.org/paper/13b120fad7ebe58f4d2257a1ee7901c30219feaf",4,"Policy Transfer via Enhanced Action Space","A novel algorithm named EASpace (Enhanced Action Space) is proposed in this paper to transfer the knowledge of multiple sub-optimal expert policies to improve the data efﬁciency and alleviate the non-stationarity issue in multi-agent settings.","ArXiv",2022,"Zheng Zhang,Qingrui Zhang,Bo Zhu,Xiaohan Wang,Tianjiang Hu",0,44,0
"8b211a7e6ccff5cc8cd482da51761ecc9d21662c","https://www.semanticscholar.org/paper/8b211a7e6ccff5cc8cd482da51761ecc9d21662c",4,"An immediate-return reinforcement learning for the atypical Markov decision processes","This paper proposes an immediate-return algorithm for the atypical MDPs with continuous action space by designing an unbiased and low variance target Q-value and a simplified network framework and shows significant advantages in learning efficiency, the effective rate of control, and computing resource usage.","Frontiers in Neurorobotics",2022,"Zebang Pan,G. Wen,Zhao Tan,Shan Yin,Xiaoyan Hu",0,38,0
"3d3b0704c61d47c7bafb70ae2670b2786b8e4d81","https://www.semanticscholar.org/paper/3d3b0704c61d47c7bafb70ae2670b2786b8e4d81",4,"Efficient Exploration in Resource-Restricted Reinforcement Learning","Experiments demonstrate that the proposed RAEB outperforms state-of-the-art exploration strategies in resource-restricted reinforce- ment learning environments, improving the sample efﬁciency by up to an order of magnitude.","ArXiv",2022,"Zhihai Wang,Taoxing Pan,Qi Zhou,Jie Wang",0,35,0
"991d16740d6aabcaa11de3241037ad6c3fced3f2","https://www.semanticscholar.org/paper/991d16740d6aabcaa11de3241037ad6c3fced3f2",4,"Design and control of soft biomimetic pangasius fish robot using fin ray effect and reinforcement learning","","Scientific Reports",2022,"Samuel M Youssef,Mennaallah Soliman,M. A. Saleh,Ahmed H. Elsayed,A. Radwan",0,63,0
"bd6be9e58ed58aad21b2f334c3a8c18fd3072786","https://www.semanticscholar.org/paper/bd6be9e58ed58aad21b2f334c3a8c18fd3072786",4,"On Deep Recurrent Reinforcement Learning for Active Visual Tracking of Space Noncooperative Objects","A novel tracker based on deep recur- rent reinforcement learning, named as RAMAVT which drives the chasing spacecraft to follow arbitrary space noncooperative object with high-frequency and near-optimal velocity control commands is proposed.","ArXiv",2022,"D. Zhou,Guanghui Sun,Zhao-jie Zhang,Ligang Wu",0,38,0
"b3758ef7307842ea5df27c9cdca58cff03d471a1","https://www.semanticscholar.org/paper/b3758ef7307842ea5df27c9cdca58cff03d471a1",4,"Sim-to-real via latent prediction: Transferring visual non-prehensile manipulation policies","This work proposes a sim-to-real technique that trains a Soft-Actor Critic agent together with a decoupled feature extractor and a latent-space dynamics model, and shows how this architecture can allow the transfer of a trained agent from simulation to reality without retraining or finetuning the control policy, but using real-world data only for adapting the feature Extractor.","Frontiers in Robotics and AI",2023,"Carlo Rizzardo,Fei Chen,Darwin Caldwell",0,49,0
"e408af9c5f68beb9838532405cd0abba86681cb9","https://www.semanticscholar.org/paper/e408af9c5f68beb9838532405cd0abba86681cb9",4,"Offloading Mechanisms Based on Reinforcement Learning and Deep Learning Algorithms in the Fog Computing Environment","A systematic analysis of using RL or DRL algorithms to address offloading-related issues in fog computing is presented and the future research directions and open issues are discussed thoroughly.","IEEE Access",2023,"Dezheen Abdulazeez,Shavan K. Askar",0,141,0
"dd5c088f13c44a45a386a072b3e2ebb65d43e304","https://www.semanticscholar.org/paper/dd5c088f13c44a45a386a072b3e2ebb65d43e304",4,"SMIX(λ): Enhancing Centralized Value Functions for Cooperative Multiagent Reinforcement Learning","This article proposes an approach, named SMIX, that uses an OFF-policy training to achieve this by avoiding the greedy assumption commonly made in CVF learning and can be used as a general tool to improve the overall performance of other centralized training with decentralized execution (CTDE)-type algorithms by enhancing their CVFs.","IEEE Transactions on Neural Networks and Learning Systems",2020,"Xinghu Yao,Chao Wen,Yuhui Wang,Xiaoyang Tan",18,47,2
"24a4f8bf9725477097453d895ca3390fa011d3b3","https://www.semanticscholar.org/paper/24a4f8bf9725477097453d895ca3390fa011d3b3",4,"Phy-Q as a measure for physical reasoning intelligence","A new testbed that requires an agent to reason about physical scenarios and take an action appropriately is proposed that is based on a two-dimensional physics environment and encourages the development of intelligent agents that can reach the human-level Phy-Q score.","Nature Machine Intelligence",2021,"Cheng Xue,Vimukthini Pinto,C. Gamage,Ekaterina Nikonova,Peng Zhang,Jochen Renz",0,73,0
"1395a90c8affba1b29e5dc12d12f1950b4c112fa","https://www.semanticscholar.org/paper/1395a90c8affba1b29e5dc12d12f1950b4c112fa",4,"Reinforcement learning for automatic quadrilateral mesh generation: a soft actor-critic approach","A reinforcement learning (RL) algorithm called ""soft actor-critic"" to automatically learn from trials the policy of actions for mesh generation allows to build a fully automatic mesh generation system without human intervention and any extra clean-up operations, which fills the gap in the existing mesh generation tools.","Neural Networks",2022,"J. Pan,Jingwei Huang,G. Cheng,Yong Zeng",4,79,1
"472babf52b449c510e5b3777c3ee45abb5135e43","https://www.semanticscholar.org/paper/472babf52b449c510e5b3777c3ee45abb5135e43",4,"A Comparison of Deep Reinforcement Learning Models for Isolated Traffic Signal Control","Testing results indicate that the soft actor–critic (SAC) outperforms other DRL algorithms and the maximum pressure method in most cases and has enlightening effects on other traffic decision management problems, such as ramp and multi-intersection control.","IEEE Intelligent Transportation Systems Magazine",2023,"Feng Mao,Zhiheng Li,Li Li",3,55,1
"5aebd1906852fc6c4ced4a336bf131b985c99287","https://www.semanticscholar.org/paper/5aebd1906852fc6c4ced4a336bf131b985c99287",4,"Fully Automated Design Method Based on Reinforcement Learning and Surrogate Modeling for Antenna Array Decoupling","The decoupling metasurfaces designed by the proposed fully automated method based on RL showed satisfactory results comparable to the results achievable by human designers, indicating that the proposed method can be used to build powerful tools to boost the design efficiency of EM devices.","IEEE Transactions on Antennas and Propagation",2023,"Zhaohui Wei,Zhao Zhou,Peng Wang,Jian-lin Ren,Ying-Zheng Yin,G. Pedersen,Ming Shen",0,55,0
"397156af1b4fc1f1c3bbbe5c2dbc698ef0b9b6ec","https://www.semanticscholar.org/paper/397156af1b4fc1f1c3bbbe5c2dbc698ef0b9b6ec",4,"Policy Pre-training for End-to-end Autonomous Driving via Self-supervised Geometric Modeling","PPGeo (Policy Pre-training via Geometric modeling), an intuitive and straightforward fully self-supervised framework curated for the policy pre-training in visuomotor driving, aimed at learning policy representations as a powerful abstraction by modeling 3D geometric scenes on large-scale unlabeled and uncalibrated YouTube driving videos.","ArXiv",2023,"Peng Wu,Li Chen,Hongyang Li,Xiaosong Jia,Junchi Yan,Y. Qiao",0,59,0
"6eba2f014a17b26e15d251463b8e9dd1dbda2d3d","https://www.semanticscholar.org/paper/6eba2f014a17b26e15d251463b8e9dd1dbda2d3d",4,"Centralized Cooperative Exploration Policy for Continuous Control Tasks","This work proposes CCEP, which utilizes underestimation and overestimation of value functions to maintain the capacity of exploration and ensures it outperforms the current state-of-the-art methods across multiple continuous control tasks shown in experiments.","ArXiv",2023,"C. Li,Chen Gong,Qiang He,Xinwen Hou,Yu Liu",0,54,0
"6074a6b7262be53f3501b461ff2a6bfd8082d02d","https://www.semanticscholar.org/paper/6074a6b7262be53f3501b461ff2a6bfd8082d02d",4,"PRUDEX-Compass: Towards Systematic Evaluation of Reinforcement Learning in Financial Markets","","ArXiv",2023,"Shuo Sun,Molei Qin,Xinrun Wang,Bo An",1,80,0
"1860740f211064e430dae614a771df256f1e3685","https://www.semanticscholar.org/paper/1860740f211064e430dae614a771df256f1e3685",4,"Neuro-Symbolic World Models for Adapting to Open World Novelty","WorldCloner is intro-duce, an end-to-end trainable neuro-symbolic world model for rapid novelty adaptation that helps its policy adapt more efficiently than neural-only reinforcement learning methods.","ArXiv",2023,"Jonathan C. Balloch,Zhiyu Lin,R. Wright,Xiangyu Peng,Mustafa Hussain,Aarun Srinivas,Julia Kim,Mark O. Riedl",0,35,0
"2ba32d52efa4e08567b5a44f9c9e42fa1a854dec","https://www.semanticscholar.org/paper/2ba32d52efa4e08567b5a44f9c9e42fa1a854dec",4,"Improving Monte Carlo Evaluation with Offline Data","This work designs a tailored behavior policy such that the variance of the oﬀ-policy MC estimator is provably smaller than the ordinaryMC estimator, and can be eﬃciently learned from existing data, i,e.","ArXiv",2023,"Shuze Liu,Shangtong Zhang",0,76,0
"54e3065e2cfdc9d30d1a190dafb1c80335e88662","https://www.semanticscholar.org/paper/54e3065e2cfdc9d30d1a190dafb1c80335e88662",4,"Learning Cut Selection for Mixed-Integer Linear Programming via Hierarchical Sequence Model","A novel hierarchical sequence model (HEM) is proposed to learn cut selection policies via reinforcement learning that significantly improves the efficiency of solving MILPs compared to human-designed and learning-based baselines on both synthetic and large-scale real-world MILPs, including MIPLIB 2017.","ArXiv",2023,"Zhihai Wang,Xijun Li,Jie Wang,Yufei Kuang,M. Yuan,Jianguo Zeng,Yongdong Zhang,Feng Wu",0,69,0
"c199d061ac01d731b216a6dbb9bd51457b42fc5d","https://www.semanticscholar.org/paper/c199d061ac01d731b216a6dbb9bd51457b42fc5d",4,"Diversity Induced Environment Design via Self-Play","This paper proposes a task-agnostic method to identify observed/hidden states that are representative of a given level and incorporates the self-play technique that allows the environment generator to automatically generate environments that are of great benefit to the training agent.","ArXiv",2023,"Dexun Li,WenJu Sun,Pradeep Varakantham",0,33,0
"21d97df47384fb355cd23fedbb89c502a1e0a884","https://www.semanticscholar.org/paper/21d97df47384fb355cd23fedbb89c502a1e0a884",4,"Sample Dropout: A Simple yet Effective Variance Reduction Technique in Deep Policy Optimization","This paper shows in a principled way that the variance of importance sampling estimate grows quadratically with importance ratios and the large ratios could consequently jeopardize the effectiveness of surrogate objective optimization, and proposes a technique called sample dropout to bound the estimation variance by dropping out samples when their ratio deviation is too high.","ArXiv",2023,"Zichuan Lin,Xiapeng Wu,Mingfei Sun,Deheng Ye,Qiang Fu,Wei Yang,Wei Liu",0,48,0
"fbf48e013c963aa90fa3bfd04604935d952d674a","https://www.semanticscholar.org/paper/fbf48e013c963aa90fa3bfd04604935d952d674a",4,"Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning","A positive-unlabeled adversarial imitation learning algorithm is developed to dynamically sample expert demonstrations that can well match the trajectories from the constantly optimized agent policy.","",2023,"Yunke Wang,Bo Du,Changming Xu",0,55,0
"32b3f9220a72fc7eecbd78dc1fabe7f8823091e1","https://www.semanticscholar.org/paper/32b3f9220a72fc7eecbd78dc1fabe7f8823091e1",4,"EdgeMatrix: A Resource-Redefined Scheduling Framework for SLA-Guaranteed Multi-Tier Edge-Cloud Computing Systems","A multi-tier edge-cloud computing framework, EdgeMatrix, is proposed to maximize the throughput of the system while guaranteeing different SLA priorities, and a multi-task mechanism is designed in EdgeMatrix to solve the problem of Joint Service Orchestration and Request Dispatch.","IEEE Journal on Selected Areas in Communications",2023,"Shihao Shen,Yuanming Ren,Yanli Ju,Xiaofei Wang,Wenyu Wang,Victor C. M. Leung",0,39,0
"1ec9c5004e62f709abff4185c5c77747054a2ab4","https://www.semanticscholar.org/paper/1ec9c5004e62f709abff4185c5c77747054a2ab4",4,"A Deep Reinforcement Learning Approach to Supply Chain Inventory Management","Numerical experiments show that DRL performs consistently better than standard reorder policies, such as the static ( s , Q )-policy, and can be considered a practical and effective option for solving real-world instances of the stochastic two-echelon SCIM problem.","",2022,"Francesco Stranieri,Fabio Stella",1,38,0
"525934efb9ea7ac84de9d504f6a16ee54f936815","https://www.semanticscholar.org/paper/525934efb9ea7ac84de9d504f6a16ee54f936815",4,"Deep reinforcement learning applied to an assembly sequence planning problem with user preferences","An approach to the implementation of DRL methods in assembly sequence planning problem, which introduces in the RL environment parametric actions to improve training time and sample efficiency and uses two different reward signals: user’s preferences and total assembly time duration.","The International Journal of Advanced Manufacturing Technology",2022,"M. Neves,P. Neto",2,32,0
"052e9eae2c404ed85639265dcb9688c24ac13683","https://www.semanticscholar.org/paper/052e9eae2c404ed85639265dcb9688c24ac13683",4,"Dependent Task Offloading for Edge Computing based on Deep Reinforcement Learning","This work proposes an intelligent task offloading scheme leveraging off-policy reinforcement learning empowered by a Sequence-to-Sequence (S2S) neural network, where the dependent tasks are represented by a Directed Acyclic Graph (DAG) to improve the training efficiency.","IEEE transactions on computers",2022,"Jin Wang,Jia Hu,G. Min,Wenhan Zhan,Albert Y. Zomaya,N. Georgalas",15,39,1
"a826d00e7f1035d67b915941b409b5b26673b9fd","https://www.semanticscholar.org/paper/a826d00e7f1035d67b915941b409b5b26673b9fd",4,"Spatial-Temporal Aligned Multi-Agent Learning for Visual Dialog Systems","A novel spatial-temporal aligned sta multi-agent reinforcement learning framework is proposed to better align the multimodal data within and between agents over time and develops sample-efficient visual dialog systems.","ACM Multimedia",2022,"Yong Zhuang,Tong Yu,Junda Wu,Shiqu Wu,Shuai Li",0,40,0
"fe929e3210fec3d4fcaa35eb93792d6e6de69e9c","https://www.semanticscholar.org/paper/fe929e3210fec3d4fcaa35eb93792d6e6de69e9c",4,"Climate Change Policy Exploration using Reinforcement Learning","It is found that in this simplistic model, the growth of the economy is a significant feature for the agents when deciding which policies to enact, and there is much more to be done for this framework to be applicable to climate related policy.","ArXiv",2022,"Theodore Wolf",0,58,0
"2a3b65244350fdd9051d14f499a6773a5b0f2cb0","https://www.semanticscholar.org/paper/2a3b65244350fdd9051d14f499a6773a5b0f2cb0",4,"Geometry and convergence of natural policy gradient methods","This work shows linear convergence for unregularized and regularized NPGs and reward functions with the metrics proposed by Kakade and Morimura and co-authors by observing that these arise from the Hessian geometries of conditional entropy and entropy respectively.","ArXiv",2022,"Johannes Muller,Guido Montúfar",0,75,0
"cfd232ade1fdee8f00d90a0c1e6148b8ee530e29","https://www.semanticscholar.org/paper/cfd232ade1fdee8f00d90a0c1e6148b8ee530e29",4,"Choreographer: Learning and Adapting Skills in Imagination","This work presents Choreographer, a model-based agent that exploits its world model to learn and adapt skills in imagination, and decouples the exploration and skill learning processes, being able to discover skills in the latent state space of the model.","ArXiv",2022,"Pietro Mazzaglia,T. Verbelen,B. Dhoedt,Alexandre Lacoste,Sai Rajeswar",1,66,0
"a2fcc41996acbd70cd87cc7d27d8cb1f6ebfc6ee","https://www.semanticscholar.org/paper/a2fcc41996acbd70cd87cc7d27d8cb1f6ebfc6ee",4,"Analysis of Measure-Valued Derivatives in a Reinforcement Learning Actor-Critic Framework","The empirical results of this study suggest that measure-valued derivatives can serve as low-variance alternative to score functions in on-policy actor-critic and indeed reduce the need for variance reduction techniques.","Online World Conference on Soft Computing in Industrial Applications",2022,"Kim van den Houten,Emile van Krieken,B. Heidergott",0,28,0
"1558a92344ab38b5b650d703166c0c92bc565f55","https://www.semanticscholar.org/paper/1558a92344ab38b5b650d703166c0c92bc565f55",4,"Understanding the Complexity Gains of Single-Task RL with a Curriculum","Under mild regularity conditions on the curriculum, it is shown that sequentially solving each task in the multi-task RL problem is more computationally efficient than solving the original single-task problem, without any explicit exploration bonuses or other exploration strategies.","ArXiv",2022,"Qiyang Li,Yuexiang Zhai,Yi Ma,S. Levine",0,106,0
"9b448ed51816d6226fc616d6c76ae43bb5649db8","https://www.semanticscholar.org/paper/9b448ed51816d6226fc616d6c76ae43bb5649db8",4,"Robustness Analysis and Enhancement of Deep Reinforcement Learning-Based Schedulers","The black-box perturbation system is devised, in which, a proxy model is trained to mimic the DRL-based scheduling policy and it is shown that the high-faith proxy model can help to craft effective perturbations.","IEEE Transactions on Parallel and Distributed Systems",2023,"Shaojun Zhang,Chen Wang,Albert Y. Zomaya",0,42,0
"50cfa8f4f98be6435fee58df1f876c1b95db083c","https://www.semanticscholar.org/paper/50cfa8f4f98be6435fee58df1f876c1b95db083c",4,"Quasi-optimal Learning with Continuous Treatments","A novel quasi-optimal learning algorithm is developed which can be easily optimized in off-policy settings with guaranteed convergence under general function approximations and is evaluated with comprehensive simulated experiments and a dose suggestion real application to Ohio Type 1 diabetes dataset.","ArXiv",2023,"Yuhan Li,Wenzhuo Zhou,R. Zhu",0,99,0
"15474fb68ce1451e9099fcba6631d7b8de3a5452","https://www.semanticscholar.org/paper/15474fb68ce1451e9099fcba6631d7b8de3a5452",4,"Beyond Exponentially Fast Mixing in Average-Reward Reinforcement Learning via Multi-Level Monte Carlo Actor-Critic","This work proposes an RL methodology attuned to the mixing time by employing a multi-level Monte Carlo estimator for the critic, the actor, and the average reward embedded within an actor-critic (AC) algorithm and achieves a convergence rate comparable to the state-of-the-art AC algorithms.","ArXiv",2023,"Wesley A. Suttle,A. S. Bedi,Bhrij Patel,Brian M. Sadler,Alec Koppel,Dinesh Manocha",0,47,0
"da6fd7839d15e956f095441cb52e01c2446c0ace","https://www.semanticscholar.org/paper/da6fd7839d15e956f095441cb52e01c2446c0ace",4,"OSTTD: Offloading of Splittable Tasks With Topological Dependence in Multi-Tier Computing Networks","OSTTD is the first method in which the topological dependence among sub-tasks of the splittable task is fully considered and can significantly reduce the task processing time, thus, improving the overall task processing efficiency in multi-tier computing networks.","IEEE Journal on Selected Areas in Communications",2023,"Rui Zhang,Xuesen Chu,Ruhui Ma,Meng Zhang,Liwei Lin,Honghao Gao,Haibing Guan",0,47,0
"71b2cf7e5516ca8a3a245cd61be2032ca259380a","https://www.semanticscholar.org/paper/71b2cf7e5516ca8a3a245cd61be2032ca259380a",4,"On the Robustness of Question Rewriting Systems to Questions of Varying Hardness","To enhance the robustness of QR systems to questions of varying hardness, a novel learning framework for QR is proposed that first trains a QR model independently on each subset of questions of a certain level of hardness, then combines these QR models as one joint model for inference.","Annual Meeting of the Association for Computational Linguistics",2022,"Hai Ye,H. Ng,Wenjuan Han",1,39,0
"4e76896393ef578807d3428f7a7d820cf30b58ca","https://www.semanticscholar.org/paper/4e76896393ef578807d3428f7a7d820cf30b58ca",4,"Adaptable Claim Rewriting with Offline Reinforcement Learning for Effective Misinformation Discovery","A novel system to help fact-checkers formulate search queries for known misinformation claims and effectively search across multiple social media platforms using an adaptable rewriting strategy that uses a decision transformer to learn a sequence of editing actions that maximize query retrieval metrics such as mean average precision.","ArXiv",2022,"Ashkan Kazemi,Artem Abzaliev,Naihao Deng,Rui Hou,Davis Liang,Scott A. Hale,Verónica Pérez-Rosas,Rada Mihalcea",0,29,0
"89e2154d608cc8eced17bd7b276e278c89f8f0c1","https://www.semanticscholar.org/paper/89e2154d608cc8eced17bd7b276e278c89f8f0c1",4,"Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding","Cluster-Former is proposed, a novel clustering-based sparse Transformer to perform attention across chunked sequences that allows information integration beyond local windows, which is especially beneficial for question answering (QA) and language modeling tasks that rely on long-range dependencies.","ArXiv",2020,"Shuohang Wang,Luowei Zhou,Zhe Gan,Yen-Chun Chen,Yuwei Fang,S. Sun,Yu Cheng,Jingjing Liu",19,44,6
"42aa8ae1eb726b0bcc6aca785eab6132a447c8f4","https://www.semanticscholar.org/paper/42aa8ae1eb726b0bcc6aca785eab6132a447c8f4",4,"Is Retriever Merely an Approximator of Reader?","This work makes a careful conjecture that the architectural constraint of the retriever, which has been originally intended for enabling approximate search, seems to also make the model more robust in large-scale search, and proposes to distill the reader into the retriver so that the retrivers absorbs the strength of the reader while keeping its own benefit.","ArXiv",2020,"Sohee Yang,Minjoon Seo",31,34,4
"4a9a2b64ced3cee261bece01c429083708d77ecb","https://www.semanticscholar.org/paper/4a9a2b64ced3cee261bece01c429083708d77ecb",4,"Retrieve, Rerank, Read, then Iterate: Answering Open-Domain Questions of Arbitrary Complexity from Text","This work proposes a unified system to answer open-domain questions of arbitrary complexity directly from text that works with off-the-shelf retrieval systems on arbitrary text collections and achieves strong performance on a new unified benchmark.","ArXiv",2020,"Peng Qi,Haejun Lee,OghenetegiriTGSido,Christopher D. Manning",14,45,1
"c6ba01a86927c3abb891ed268353c14f9faa8097","https://www.semanticscholar.org/paper/c6ba01a86927c3abb891ed268353c14f9faa8097",4,"End-to-End QA on COVID-19: Domain Adaptation with Synthetic Training","This work combines neural IR and MRC systems and shows significant improvements in end-to-end QA on the CORD-19 collection over a state-of-the-art open-domain QA baseline.","ArXiv",2020,"R. Reddy,Bhavani Iyer,Md Arafat Sultan,Rong Zhang,Avirup Sil,Vittorio Castelli,Radu Florian,S. Roukos",15,46,2
"b59d64ba042afbc198a806954517007074213b86","https://www.semanticscholar.org/paper/b59d64ba042afbc198a806954517007074213b86",4,"Big Bird: Transformers for Longer Sequences – Appendix","","",2021,"",0,113,0
"e47d338ca879a184c1977ffa8623d2a225b0a319","https://www.semanticscholar.org/paper/e47d338ca879a184c1977ffa8623d2a225b0a319",4,"Multi-Task Dense Retrieval via Model Uncertainty Fusion for Open-Domain Question Answering","This work proposes to train individual dense passage retrievers (DPR) for different tasks and aggregate their predictions during test time, where they use uncertainty estimation as weights to in-dicate how probable a speciﬁc query belongs to each expert’s expertise.","Conference on Empirical Methods in Natural Language Processing",2021,"Minghan Li,Ming Li,Kun Xiong,Jimmy J. Lin",5,45,0
"77db3d91786935f91656d4193a742220651f869f","https://www.semanticscholar.org/paper/77db3d91786935f91656d4193a742220651f869f",4,"Multi-stage Training with Improved Negative Contrast for Neural Passage Retrieval","This work proposes a multi-stage framework comprising of pre-training with synthetic data, fine-tuning with labeled data, and negative sampling at both stages, and explores fusion methods that combine negatives from different strategies.","Conference on Empirical Methods in Natural Language Processing",2021,"Jing-Bin Lu,Gustavo Hernández Ábrego,Ji Ma,Jianmo Ni,Yinfei Yang",12,32,2
"a1890836dbd0fc7b4e2a50f267e7347491468ae5","https://www.semanticscholar.org/paper/a1890836dbd0fc7b4e2a50f267e7347491468ae5",4,"D ISTILLING K NOWLEDGE FROM R EADER TO R ETRIEVER FOR Q UESTION A NSWERING","This paper describes a method to train the retriever to reproduce the ranking of documents corresponding to a metric using a database of documents.documents.","",2021,"Gautier Izacard,Edouard Grave",0,39,0
"43003de1bdf12e14e917c98807ad0ab244caa923","https://www.semanticscholar.org/paper/43003de1bdf12e14e917c98807ad0ab244caa923",4,"Distantly-Supervised Dense Retrieval Enables Open-Domain Question Answering without Evidence Annotation","This paper introduces a novel approach that iteratively improves over a weak retriever by alternately finding evidence from the up-to-date model and encouraging the model to learn the most likely evidence, and confirms that DistDR finds more accurate evidence over iterations, which leads to model improvements.","Conference on Empirical Methods in Natural Language Processing",2021,"Chen Zhao,Chenyan Xiong,Jordan L. Boyd-Graber,Hal Daumé",3,34,1
"fe7ea2dea7d24b5c661ea901c14e82c92c5fbe20","https://www.semanticscholar.org/paper/fe7ea2dea7d24b5c661ea901c14e82c92c5fbe20",4,"MultiReQA: A Cross-Domain Evaluation forRetrieval Question Answering Models","This dataset paper presents MultiReQA, a new multi-domain ReQA evaluation suite composed of eight retrieval QA tasks drawn from publicly available QA datasets, which explores systematic retrieval based evaluation and transfer learning across domains over these datasets using a number of strong base-lines.","ADAPTNLP",2020,"Mandy Guo,Yinfei Yang,Daniel Matthew Cer,Qinlan Shen,Noah Constant",28,39,3
"c9b8593db099869fe7254aa1fa53f3c9073b0176","https://www.semanticscholar.org/paper/c9b8593db099869fe7254aa1fa53f3c9073b0176",4,"Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval","Approximate nearest neighbor Negative Contrastive Estimation (ANCE) is presented, a training mechanism that constructs negatives from an Approximate Nearest Neighbor (ANN) index of the corpus, which is parallelly updated with the learning process to select more realistic negative training instances.","International Conference on Learning Representations",2020,"Lee Xiong,Chenyan Xiong,Ye Li,Kwok-Fung Tang,Jialin Liu,Paul Bennett,Junaid Ahmed,Arnold Overwijk",475,64,141
"aea909a04e4d848855afcf8ce8ae55a81a2623e4","https://www.semanticscholar.org/paper/aea909a04e4d848855afcf8ce8ae55a81a2623e4",4,"SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval","SPARTA achieves new state-of-the-art results across a variety of open-domain question answering tasks in both English and Chinese datasets, including open SQuAD, CMRC and etc.","North American Chapter of the Association for Computational Linguistics",2020,"Tiancheng Zhao,XiaoPeng Lu,Kyusong Lee",35,59,7
"2b4bc49a3b23229a060609380752666b24b435fb","https://www.semanticscholar.org/paper/2b4bc49a3b23229a060609380752666b24b435fb",4,"Distilling Knowledge from Reader to Retriever for Question Answering","This paper proposes a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents.","International Conference on Learning Representations",2020,"Gautier Izacard,Edouard Grave",99,47,20
"89181e26874c4ea418937d7a6980d1476d4c0b0b","https://www.semanticscholar.org/paper/89181e26874c4ea418937d7a6980d1476d4c0b0b",4,"Multi-Task Retrieval for Knowledge-Intensive Tasks","This work proposes a multi-task trained model for neural retrieval that not only outperforms previous methods in the few-shot setting, but also rivals specialised neural retrievers, even when in-domain training data is abundant.","Annual Meeting of the Association for Computational Linguistics",2021,"Jean Maillard,Vladimir Karpukhin,Fabio Petroni,Wen-tau Yih,Barlas Oğuz,Veselin Stoyanov,Gargi Ghosh",38,41,4
"17d680f0dc9211492107eac5ff62b08b627f107a","https://www.semanticscholar.org/paper/17d680f0dc9211492107eac5ff62b08b627f107a",4,"UnitedQA: A Hybrid Approach for Open Domain Question Answering","It is demonstrated that a simple hybrid approach by combining answers from both readers can efficiently take advantages of extractive and generative answer inference strategies and outperforms single models as well as homogeneous ensembles.","Annual Meeting of the Association for Computational Linguistics",2021,"Hao Cheng,Yelong Shen,Xiaodong Liu,Pengcheng He,Weizhu Chen,Jianfeng Gao",23,35,5
"3661a8d4f2f40efc4d60daf16b0465e9cd55cb4b","https://www.semanticscholar.org/paper/3661a8d4f2f40efc4d60daf16b0465e9cd55cb4b",4,"SF-QA: Simple and Fair Evaluation Library for Open-domain Question Answering","SF-QA framework modularizes the pipeline open-domain QA system, which makes the task itself easily accessible and reproducible to research groups without enough computing resources.","Conference of the European Chapter of the Association for Computational Linguistics",2021,"XiaoPeng Lu,Kyusong Lee,Tiancheng Zhao",0,24,0
"5505d608a1d482fdc083796db812379ec1cb8723","https://www.semanticscholar.org/paper/5505d608a1d482fdc083796db812379ec1cb8723",4,"Can Small and Synthetic Benchmarks Drive Modeling Innovation? A Retrospective Study of Question Answering Modeling Approaches","Small, targeted synthetic benchmarks are constructed that do not resemble natural language, yet have high concurrence with SQuAD, demonstrating that naturalness and size are not necessary for reflecting historical modeling improvements on SQuad.","ArXiv",2021,"Nelson F. Liu,Tony Lee,Robin Jia,Percy Liang",18,107,1
"870711939dc3b666d0551102e175212ab31be202","https://www.semanticscholar.org/paper/870711939dc3b666d0551102e175212ab31be202",4,"Pruning the Index Contents for Memory Efficient Open-Domain QA","This work presents a simple approach for pruning the contents of a massive index such that the open-domain QA system altogether with index, OS, and library components fits into 6GiB docker image while retaining only 8% of original index contents and losing only 3% EM accuracy1.","ArXiv",2021,"Martin Fajcik,Martin Docekal,Karel Ondrej,P. Smrz",5,43,0
"0994da8e3d70ce64e4ebcade3a592caa513161af","https://www.semanticscholar.org/paper/0994da8e3d70ce64e4ebcade3a592caa513161af",4,"Towards Robust Neural Retrieval Models with Synthetic Pre-Training","In-domain and out-of-domain evaluations of neural IR are conducted, and synthetic training examples generated using a sequence-tosequence generator can be effective towards its robustness across different scenarios, including zeroshot settings.","ArXiv",2021,"Revanth Reddy Gangi Reddy,Vikas Yadav,Md Arafat Sultan,M. Franz,Vittorio Castelli,Heng Ji,Avirup Sil",8,24,2
"807600ef43073cd9c59d4208ee710e90cf14efa8","https://www.semanticscholar.org/paper/807600ef43073cd9c59d4208ee710e90cf14efa8",4,"BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models","This work extensively analyzes different retrieval models and provides several suggestions that it believes may be useful for future work, finding that performing well consistently across all datasets is challenging.","NeurIPS Datasets and Benchmarks",2021,"Nandan Thakur,Nils Reimers,Andreas Ruckl'e,Abhishek Srivastava,Iryna Gurevych",191,95,63
"6c8fa47803b9958f66b144d5f0bcca78f6d99e50","https://www.semanticscholar.org/paper/6c8fa47803b9958f66b144d5f0bcca78f6d99e50",4,"Weakly-Supervised Question Answering with Effective Rank and Weighted Loss over Candidates","This paper designs several simple yet effective scoring functions to rank the candidate solutions in order to reduce the spuriousness of candidate solutions used for training, and presents an effective method to learn a question answering model in a weak supervision way.","The Web Conference",2021,"Haozhe Qin,Jiangang Zhu,Beijun Shen",0,42,0
"fea3e850e3d18026e0f0d761f75016bf6ccdbf53","https://www.semanticscholar.org/paper/fea3e850e3d18026e0f0d761f75016bf6ccdbf53",4,"Few-Shot Conversational Dense Retrieval","The analyses reveal that the advantages of ConvDR come from its ability to capture informative context while ignoring the unrelated context in previous conversation rounds, which makes ConvDR more effective as conversations evolve while previous systems may get confused by the increased noise from previous turns.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2021,"S. Yu,Zhenghao Liu,Chenyan Xiong,Tao Feng,Zhiyuan Liu",33,49,8
"16529f7194bf7faee8a4e43fd54aefeb8730f236","https://www.semanticscholar.org/paper/16529f7194bf7faee8a4e43fd54aefeb8730f236",4,"Database reasoning over text","This work proposes a modular architecture to answer database-style queries over multiple spans from text and aggregating these at scale, which scales to databases containing thousands of facts whereas contemporary models are limited by how many facts can be encoded.","Annual Meeting of the Association for Computational Linguistics",2021,"James Thorne,Majid Yazdani,Marzieh Saeidi,F. Silvestri,Sebastian Riedel,A. Halevy",15,35,1
"4572ce690e5eff7d7d38c6f3f67561d0b263b34f","https://www.semanticscholar.org/paper/4572ce690e5eff7d7d38c6f3f67561d0b263b34f",4,"Training Adaptive Computation for Open-Domain Question Answering with Computational Constraints","The proposed Adaptive Passage Encoder keeps the parameters of the base ODQA model fixed, but it overrides the default layer-by-layer computation of the encoder with an AC policy that is trained to optimise the computational efficiency of the model.","Annual Meeting of the Association for Computational Linguistics",2021,"Yuxiang Wu,Pasquale Minervini,Pontus Stenetorp,S. Riedel",4,29,0
"824666e5e6721bc83a1768579062077d719f7089","https://www.semanticscholar.org/paper/824666e5e6721bc83a1768579062077d719f7089",4,"Synthetic Target Domain Supervision for Open Retrieval QA","This work stress-test the Dense Passage Retriever (DPR)---a state-of-the-art (SOTA) open domain neural retrieval model---on closed and specialized target domains such as COVID-19, and finds that it lags behind standard BM25 in this important real-world setting.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2021,"Revanth Reddy Gangi Reddy,Bhavani Iyer,Md Arafat Sultan,Rong Zhang,Avirup Sil,Vittorio Castelli,Radu Florian,S. Roukos",4,40,1
"285428daf56a1530b11b6deb515f10c8f1dc5739","https://www.semanticscholar.org/paper/285428daf56a1530b11b6deb515f10c8f1dc5739",4,"Dual Reader-Parser on Hybrid Textual and Tabular Evidence for Open Domain Question Answering","A hybrid framework that takes both textual and tabular evidences as input and generates either direct answers or SQL queries depending on which form could better answer the question is proposed, which achieves the state-of-the-art performance on OpenSQuAD dataset using a T5-base model.","Annual Meeting of the Association for Computational Linguistics",2021,"A. Li,Patrick Ng,Peng Xu,Henghui Zhu,Zhiguo Wang,Bing Xiang",12,45,1
"4097ae9aca6444fd7536bfbed1e62560521b70d3","https://www.semanticscholar.org/paper/4097ae9aca6444fd7536bfbed1e62560521b70d3",4,"PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval","This work proposes a novel approach that leverages both query-centric and PAssage-centric sImilarity Relations (called PAIR) for dense passage retrieval that significantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions datasets.","Findings",2021,"Ruiyang Ren,Shangwen Lv,Yingqi Qu,Jing Liu,Wayne Xin Zhao,Qiaoqiao She,Hua Wu,Haifeng Wang,Ji-rong Wen",39,35,9
"1c2edf38c684b1938304cf024f5993241642f3d4","https://www.semanticscholar.org/paper/1c2edf38c684b1938304cf024f5993241642f3d4",4,"Improving Query Representations for Dense Retrieval with Pseudo Relevance Feedback","ANCE-PRF, a new query encoder that uses pseudo relevance feedback (PRF) to improve query representations for dense retrieval, significantly outperforms ANCE and other recent dense retrieval systems on several datasets.","International Conference on Information and Knowledge Management",2021,"HongChien Yu,Chenyan Xiong,Jamie Callan",23,35,6
"248816ded4e927fff2c092721d85aeb8038b49a0","https://www.semanticscholar.org/paper/248816ded4e927fff2c092721d85aeb8038b49a0",4,"Unsupervised Open-Domain Question Answering","This paper pioneers the work of unsupervised ODQA by formally introducing the task and proposing a series of key data construction methods and inspiringly shows un supervised ODZA can reach up to 86% performance of supervised ones.","ArXiv",2021,"Pengfei Zhu,Xiaoguang Li,Jian Li,Hai Zhao",1,19,0
"f7a6b57adebb5f6a10d16e120f0b0ef55aab7b2b","https://www.semanticscholar.org/paper/f7a6b57adebb5f6a10d16e120f0b0ef55aab7b2b",4,"Simple Entity-Centric Questions Challenge Dense Retrievers","This paper investigates the issue and uncover that dense retrievers can only generalize to common entities unless the question pattern is explicitly observed during training, and demonstrates that data augmentation is unable to fix the generalization problem.","Conference on Empirical Methods in Natural Language Processing",2021,"Christopher Sciavolino,Zexuan Zhong,Jinhyuk Lee,Danqi Chen",53,32,12
"3cf7a6153518805a26787a514aa38594b83e68ef","https://www.semanticscholar.org/paper/3cf7a6153518805a26787a514aa38594b83e68ef",4,"Towards Universal Dense Retrieval for Open-domain Question Answering","This paper introduces an entity-rich question answering dataset constructed from Wikidata facts and demonstrates dense models are unable to generalize to unseen input question distributions, and encourages the field to further investigate the creation of a single, universal dense retrieval model that generalizes well across all input distributions.","ArXiv",2021,"Christopher Sciavolino",0,26,0
"50ec3d960ac458573a1e4a1556420c5e96d58609","https://www.semanticscholar.org/paper/50ec3d960ac458573a1e4a1556420c5e96d58609",4,"Distantly-Supervised Evidence Retrieval Enables Question Answering without Evidence Annotation","This paper introduces a novel approach (DistDR) that iteratively improves over a weak retriever by alternately finding evidence from the up-to-date model and encouraging the model to learn the most likely evidence, which leads to model improvements.","ArXiv",2021,"Chenyan Xiong,Hal Daumé",2,36,0
"6e0cfc8a2e743e3a90ad089f0fd4e4985f2f6834","https://www.semanticscholar.org/paper/6e0cfc8a2e743e3a90ad089f0fd4e4985f2f6834",4,"RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking","A novel joint training approach for dense passage retrieval and passage reranking is proposed, where the dynamic listwise distillation is introduced, where a unified listwise training approach is designed for both the retriever and the re-ranker.","Conference on Empirical Methods in Natural Language Processing",2021,"Ruiyang Ren,Yingqi Qu,Jing Liu,Wayne Xin Zhao,Qiaoqiao She,Hua Wu,Haifeng Wang,Ji-rong Wen",75,48,21
"2d48cfd946d727cacdb54a49724db67a4d22351e","https://www.semanticscholar.org/paper/2d48cfd946d727cacdb54a49724db67a4d22351e",4,"Cross-Lingual GenQA: A Language-Agnostic Generative Question Answering Approach for Open-Domain Question Answering","This paper presents the first generalization of the GENQA approach for the multilingual environment, and presents the GEN-TYDIQA dataset, which extends the TyDiQA evaluation data with natural-sounding, well-formed answers in Arabic, Bengali, English, Japanese, and Russian.","ArXiv",2021,"Benjamin Muller,Luca Soldaini,Rik Koncel-Kedziorski,Eric Lind,Alessandro Moschitti",4,46,0
"5a166cfd781ac871cd4fc26fd8b7fb0e0a1fa795","https://www.semanticscholar.org/paper/5a166cfd781ac871cd4fc26fd8b7fb0e0a1fa795",4,"Open Domain Question Answering over Virtual Documents: A Unified Approach for Data and Text","This work uses the data-to-text method as a means for coding structured knowledge for knowledge- intensive applications, i.e. open-domain answering (ODQA), and poses a verbalizer-retriever-reader framework for ODQA over data and text where verbalized tables from Wikipedia and graphs from Wikidata are used as augmented knowledge sources.","ArXiv",2021,"Kaixin Ma,Hao Cheng,Xiaodong Liu,Eric Nyberg,Jianfeng Gao",7,48,0
"a729503f528d5f0be0f897aa1841e1ff8ffcb313","https://www.semanticscholar.org/paper/a729503f528d5f0be0f897aa1841e1ff8ffcb313",4,"Dense Hierarchical Retrieval for Open-Domain Question Answering","Dense Hierarchical Retrieval (DHR) is proposed, a hierarchical framework which can generate accurate dense representations of passages by utilizing both macroscopic semantics in the document and microscopic semantics specific to each passage.","Conference on Empirical Methods in Natural Language Processing",2021,"Ye Liu,Kazuma Hashimoto,Yingbo Zhou,Semih Yavuz,Caiming Xiong,Philip S. Yu",4,32,0
"8cda255351168fab95c7b59d12d24590ad57a6ac","https://www.semanticscholar.org/paper/8cda255351168fab95c7b59d12d24590ad57a6ac",4,"Question Answering Survey: Directions, Challenges, Datasets, Evaluation Matrices","In this review work, the research directions of QA field are analyzed based on the type of question, answer type, source of evidence-answer, and modeling approach, followed by open challenges of the field like automatic question generation, similarity detection and, low resource availability for a language.","Journal of Xidian University",2021,"Hariom A. Pandya,Brijesh S. Bhatt",4,121,0
"05cb33c55c44ab26848a865eb6062b5b027caacc","https://www.semanticscholar.org/paper/05cb33c55c44ab26848a865eb6062b5b027caacc",4,"An Encoder Attribution Analysis for Dense Passage Retriever in Open-Domain Question Answering","It is found that the passage encoder contributes more than the question encoder to in-domain retrieval accuracy, and a probabilistic framework called encoder marginalization is formulated, where the contribution of a single encoder is quantified by marginalizing other variables.","TRUSTNLP",2022,"Minghan Li,Xueguang Ma,Jimmy Lin",0,63,0
"d14db1ed48129b55f88f6be56b47180a9ea7b059","https://www.semanticscholar.org/paper/d14db1ed48129b55f88f6be56b47180a9ea7b059",4,"Dynamically Generated Question Answering Evidence using Efficient Context-preserving Subdivision","It is proposed to dynamically draw content corresponding to an article-section url from the most updated online Wikipedia rather than from an archived snapshot, approaching space complexity of O(1), downward from O(n) for a dataset that is fully populated with static context.","International Conference on Agents and Artificial Intelligence",2022,"A. Bleiweiss",0,27,0
"7c85f8b5f78b0010328a9063f6460156b30dd4ed","https://www.semanticscholar.org/paper/7c85f8b5f78b0010328a9063f6460156b30dd4ed",4,"In defense of dual-encoders for neural ranking","This paper establishes theoretically that with a sufﬁciently large encoder size, dual-encoder models can capture a broad class of scores without cross-attention, and proposes a distillation strategy that focuses on preserving the ordering amongst documents, and its impact on neural re-ranking benchmarks.","International Conference on Machine Learning",2022,"A. Menon,Sadeep Jayasumana,A. Rawat,Seungyeon Kim,Sashank J. Reddi,Surinder Kumar",4,67,0
"1540045f8967a0c70384d9f095c64cfc88a2fc4a","https://www.semanticscholar.org/paper/1540045f8967a0c70384d9f095c64cfc88a2fc4a",4,"UniK-QA: Unified Representations of Structured and Unstructured Knowledge for Open-Domain Question Answering","It is demonstrated that the UniK-QA model is a simple and yet effective way to combine heterogeneous sources of knowledge, advancing the state-of-the-art results on two popular question answering benchmarks, NaturalQuestions and WebQuestions, by 3.5 and 2.6 points, respectively.","NAACL-HLT",2020,"Barlas Oğuz,Xilun Chen,Vladimir Karpukhin,Stanislav Peshterliev,Dmytro Okhonko,M. Schlichtkrull,Sonal Gupta,Yashar Mehdad,S. Yih",34,58,10
"9f808d689639f3eb577614d2236ad7feaa3b6ecb","https://www.semanticscholar.org/paper/9f808d689639f3eb577614d2236ad7feaa3b6ecb",4,"Semantic Models for the First-Stage Retrieval: A Comprehensive Review","The current landscape of the first-stage retrieval models under a unified framework is described to clarify the connection between classical term-based retrieval methods, early semantic retrieved methods, and neural semantic retrieval methods.","ACM Trans. Inf. Syst.",2021,"Yinqiong Cai,Yixing Fan,Jiafeng Guo,Fei Sun,Ruqing Zhang,Xueqi Cheng",29,254,3
"18eb32d43ed10cf57abd386287016f44182c7a55","https://www.semanticscholar.org/paper/18eb32d43ed10cf57abd386287016f44182c7a55",4,"FaVIQ: FAct Verification from Information-seeking Questions","This paper constructs a large-scale challenging fact verification dataset called FAVIQ, consisting of 188k claims derived from an existing corpus of ambiguous information-seeking questions, verified to be natural, contain little lexical bias, and require a complete understanding of the evidence for verification.","Annual Meeting of the Association for Computational Linguistics",2021,"Jungsoo Park,Sewon Min,Jaewoo Kang,Luke Zettlemoyer,Hannaneh Hajishirzi",7,47,3
"ec307b17f193b14292206b65a1bcc95bfd8f02ed","https://www.semanticscholar.org/paper/ec307b17f193b14292206b65a1bcc95bfd8f02ed",4,"♫ MuSiQue: Multihop Questions via Single-hop Question Composition","A bottom–up approach is introduced that systematically selects composable pairs of single-hop questions that are connected, that is, where one reasoning step critically relies on information from another, to create a new multihop QA dataset with 25K 2–4 hop questions.","International Conference on Topology, Algebra and Categories in Logic",2021,"H. Trivedi,Niranjan Balasubramanian,Tushar Khot,Ashish Sabharwal",15,56,4
"a69d0b93d2ffcf25c964d93cc9b1adb73085232d","https://www.semanticscholar.org/paper/a69d0b93d2ffcf25c964d93cc9b1adb73085232d",4,"Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations","Momentum adversarial Domain Invariant Representation learning (MoDIR) is proposed, which introduces a momentum method to train a domain classifier that distinguishes source versus target domains, and then adversarially updates the DR encoder to learn domain invariant representations.","Findings",2021,"Ji Xin,Chenyan Xiong,A. Srinivasan,Ankita Sharma,Damien Jose,Paul Bennett",20,54,6
"753fd6952c9f06f3bbd46e37129acc3f7a984896","https://www.semanticscholar.org/paper/753fd6952c9f06f3bbd46e37129acc3f7a984896",4,"Hindsight: Posterior-guided training of retrievers for improved open-ended generation","This work model the guide retriever after the posterior distribution Q of passages given the input and the target output and train it jointly with the standard retriever and the generator by maximizing the evidence lower bound (ELBo) in expectation over Q.","International Conference on Learning Representations",2021,"Ashwin Paranjape,O. Khattab,Christopher Potts,M. Zaharia,Christopher D. Manning",19,40,2
"aaea853381050b4456d0d8e2e4b0c282391e41dc","https://www.semanticscholar.org/paper/aaea853381050b4456d0d8e2e4b0c282391e41dc",4,"Learning to Retrieve Passages without Supervision","The resulting model, named Spider, performs surprisingly well without any labeled training examples on a wide range of ODQA datasets, and significantly outperforms all other pretrained baselines in a zero-shot setting, and is competitive with BM25, a strong sparse baseline.","North American Chapter of the Association for Computational Linguistics",2021,"Ori Ram,Gal Shachaf,Omer Levy,Jonathan Berant,A. Globerson",28,55,5
"2e2f4e4ec35a527211adcf7d89661fce5ed373a7","https://www.semanticscholar.org/paper/2e2f4e4ec35a527211adcf7d89661fce5ed373a7",4,"Boosted Dense Retriever","DrBoost is a dense retrieval ensemble inspired by boosting, which produces representations which are 4x more compact, while delivering comparable retrieval results, reducing latency and bandwidth needs by another 4x.","North American Chapter of the Association for Computational Linguistics",2021,"Patrick Lewis,Barlas Oğuz,Wenhan Xiong,Fabio Petroni,Wen-tau Yih,Sebastian Riedel",11,74,2
"97f456643712e9618edd7465676c62af3c8ae690","https://www.semanticscholar.org/paper/97f456643712e9618edd7465676c62af3c8ae690",4,"A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models","This paper aims to summarize the current progress of pre-trained language modelbased knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods.","ArXiv",2022,"Da Yin,Li Dong,Hao Cheng,Xiaodong Liu,Kai-Wei Chang,Furu Wei,Jianfeng Gao",7,75,0
"7a54248d35448e1c95743373ddbb9170ad7c039a","https://www.semanticscholar.org/paper/7a54248d35448e1c95743373ddbb9170ad7c039a",4,"DuReader-Retrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine","The experiments demonstrate that DuReader-retrieval is challenging and a number of problems remain unsolved, such as the salient phrase mismatch and the syntactic mismatch between queries and paragraphs.","Conference on Empirical Methods in Natural Language Processing",2022,"Yifu Qiu,Hongyu Li,Yingqi Qu,Ying Chen,Qiaoqiao She,Jing Liu,Hua Wu,Haifeng Wang",4,54,1
"9e522f6a2d6ee97c7414ebd2fdc8910ca791d198","https://www.semanticscholar.org/paper/9e522f6a2d6ee97c7414ebd2fdc8910ca791d198",4,"A Survey on Measuring and Mitigating Reasoning Shortcuts in Machine Reading Comprehension","This survey paper focuses on the task of machine reading comprehension (MRC), an important task for showcasing high-level language understanding that also suffers from a range of shortcuts, and summarizes the available techniques for measuring and mitigating shortcuts.","ArXiv",2022,"Xanh Ho,Johannes Mario Meissner,Saku Sugawara,Akiko Aizawa",0,87,0
"d72ae3c981a2ef6685049183452466a29b85f96c","https://www.semanticscholar.org/paper/d72ae3c981a2ef6685049183452466a29b85f96c",4,"A Study on the Efficiency and Generalization of Light Hybrid Retrievers","A lighter dense retriever (LITE) is introduced which is jointly trained on contrastive learning and knowledge distillation from DrBoost and achieves better robustness performance than both sparse and dense retrievers.","ArXiv",2022,"Man Luo,Shashank Jain,Anchit Gupta,Arash Einolghozati,Barlas Oğuz,Debojeet Chatterjee,Xilun Chen,Chitta Baral,P. Heidari",1,36,0
"0caf0fa48aced139c0d8214be4a795d9576b9990","https://www.semanticscholar.org/paper/0caf0fa48aced139c0d8214be4a795d9576b9990",4,"Natural Test Generation for Precise Testing of Question Answering Software","QA, a sentence-level mutation based metamorphic testing technique for QA software that leverages five Metamorphic Relations as well as semantics-guided search and enhanced test oracles, outperforms the state-of-the-art in both quantity and quality.","International Conference on Automated Software Engineering",2022,"Qingchao Shen,Junjie Chen,J Zhang,Haoyu Wang,Shuang Liu,Menghan Tian",1,42,0
"09ff29678778e3f887b9a358e6ab493ab379e1cd","https://www.semanticscholar.org/paper/09ff29678778e3f887b9a358e6ab493ab379e1cd",4,"Semantic matching in machine reading comprehension: An empirical study","This paper forms a twostage framework which consists of a semantic matching model and a reading model, based on pre-trained language models, and finds that semantic matching is helpful for answering who/where/when/what/how/which questions, whereas it decreases the MRC performance on why questions.","Information Processing &amp; Management",2022,"Qian Liu,Rui Mao,Xiubo Geng,E. Cambria",1,77,0
"412494a830fb7ee13db268879db1539612d6c6e6","https://www.semanticscholar.org/paper/412494a830fb7ee13db268879db1539612d6c6e6",4,"Diverse Multi-Answer Retrieval with Determinantal Point Processes","This paper addresses multi-answer retrieval which entails retrieving passages that can capture majority of the diverse answers to the question, and proposes a re-ranking based approach using Determinantal point processes utilizing BERT as kernels.","International Conference on Computational Linguistics",2022,"Poojitha Nandigam,Nikhil Rayaprolu,Manish Shrivastava",1,24,0
"7e44002c4f78458987a90dc7a0408d60dd5cdb7c","https://www.semanticscholar.org/paper/7e44002c4f78458987a90dc7a0408d60dd5cdb7c",4,"Defending Against Poisoning Attacks in Open-Domain Question Answering","A new method is introduced that uses query augmentation to search for a diverse set of retrieved passages that could answer the original question, comparing the predicted answer to its appearance in the retrieved contexts and providing gains of 5-20% exact match across varying levels of data poisoning.","ArXiv",2022,"Orion Weller,Aleem Khan,Nathaniel Weir,Dawn J Lawrie,Benjamin Van Durme",0,25,0
"c3d091c4ab12cc2d1503d40aeb25374e477f16ae","https://www.semanticscholar.org/paper/c3d091c4ab12cc2d1503d40aeb25374e477f16ae",4,"Modeling Sequential Sentence Relation to Improve Cross-lingual Dense Retrieval","Comprehensive experiments on four cross-lingual retrieval tasks show MSM significantly outperforms existing advanced pre-training models, demonstrating the effectiveness and stronger cross-lingsual retrieval capabilities of this approach.","ArXiv",2023,"Shunyu Zhang,Yaobo Liang,Ming Gong,Daxin Jiang,Nan Duan",0,75,0
"65fc1f1c567801fee3788974e753cdbf934f07e9","https://www.semanticscholar.org/paper/65fc1f1c567801fee3788974e753cdbf934f07e9",4,"Video PreTraining (VPT): Learning to Act by Watching Unlabeled Online Videos","This work extends the internet-scale pretraining paradigm to sequential decision domains through semi-supervised imitation learning wherein agents learn to act by watching online unlabeled videos, and is the first to report computer agents that can craft diamond tools.","ArXiv",2022,"Bowen Baker,Ilge Akkaya,P. Zhokhov,Joost Huizinga,Jie Tang,Adrien Ecoffet,Brandon Houghton,Raul Sampedro,J. Clune",40,85,8
"cb0396b055e03d68eaca98f53ce56f2de69aeab6","https://www.semanticscholar.org/paper/cb0396b055e03d68eaca98f53ce56f2de69aeab6",4,"How to Enable Uncertainty Estimation in Proximal Policy Optimization","This work proposesitions of uncertainty and OOD for Actor-Critic RL algorithms, namely, proximal policy optimization (PPO), and presents possible applicable measures, and discusses the concepts of value and policy uncertainty.","ArXiv",2022,"Eugene Bykovets,Yannick Metz,Mennatallah El-Assady,D. Keim,J. Buhmann",0,45,0
"4dcf08e1b4bf77fc27af4db2242efec929bcc2aa","https://www.semanticscholar.org/paper/4dcf08e1b4bf77fc27af4db2242efec929bcc2aa",4,"Answering Complex Open-domain Questions Through Iterative Query Generation","This work presents GoldEn (Gold Entity) Retriever, which iterates between reading context and retrieving more supporting documents to answer open-domain multi-hop questions, and demonstrates that it outperforms the best previously published model despite not using pretrained language models such as BERT.","Conference on Empirical Methods in Natural Language Processing",2019,"Peng Qi,Xiaowen Lin,L. Mehr,Zijian Wang,Christopher D. Manning",81,31,14
"569b731b2cf30c63d1919a38c875e95e79e278ab","https://www.semanticscholar.org/paper/569b731b2cf30c63d1919a38c875e95e79e278ab",4,"Learning with imperfect supervision for language understanding","It is argued that even noisy and limited signals can contain a great deal of valid information that can be incorporated along with prior knowledge and biases that are encoded into learning algorithms in order to solve complex problems.","",2020,"M. Dehghani",7,340,0
"3ca320cb73c962cd29b8211cb4fd8074c5e8c9b8","https://www.semanticscholar.org/paper/3ca320cb73c962cd29b8211cb4fd8074c5e8c9b8",4,"Contextualized Representations Using Textual Encyclopedic Knowledge","It is shown that integrating background knowledge from text is effective for tasks focusing on factual reasoning and allows direct reuse of powerful pretrained BERT-style encoders and knowledge integration can be further improved with suitable pretraining via a self-supervised masked language model objective over words in background-augmented input text.","ArXiv",2020,"Mandar Joshi,Kenton Lee,Yi Luan,Kristina Toutanova",18,64,2
"653927114923a82bbe92e4872e5dd555f078c056","https://www.semanticscholar.org/paper/653927114923a82bbe92e4872e5dd555f078c056",4,"Learn to Resolve Conversational Dependency: A Consistency Training Framework for Conversational Question Answering","A novel framework, ExCorD (Explicit guidance on how to resolve Conversational Dependency) is proposed to enhance the abilities of QA models in comprehending conversational context, while addressing the limitations of the existing approaches.","Annual Meeting of the Association for Computational Linguistics",2021,"Gangwoo Kim,Hyunjae Kim,Jungsoo Park,Jaewoo Kang",18,42,7
"238946a8dc0b88707cbff3512065ff1f37828bbf","https://www.semanticscholar.org/paper/238946a8dc0b88707cbff3512065ff1f37828bbf",4,"Can Open Domain Question Answering Systems Answer Visual Knowledge Questions?","This work proposes a potentially data-efficient approach that reuses existing systems for image analysis, question rewriting, and text-based question answering to answer many visual questions, and explores two rewriting strategies that combines adaptive rewriting and reinforcement learning techniques to use the implicit feedback from the QA system.","ArXiv",2022,"Jiawen Zhang,Abhijit Mishra,Avinesh P.V.S.,Siddharth Patwardhan,Sachin Agarwal",0,40,0
"42edbc3c29af476c27f102b3de9f04e56b5c642d","https://www.semanticscholar.org/paper/42edbc3c29af476c27f102b3de9f04e56b5c642d",4,"A Survey of Generalisation in Deep Reinforcement Learning","It is argued that taking a purely procedural content generation approach to benchmark design is not conducive to progress in generalisation, and fast online adaptation and tackling RL-specific problems as some areas for future work on methods for generalisation are suggested.","ArXiv",2021,"Robert Kirk,Amy Zhang,Edward Grefenstette,Tim Rocktaschel",103,203,11
"5f4f196fc6277185d85816501bb814dfaeed69e4","https://www.semanticscholar.org/paper/5f4f196fc6277185d85816501bb814dfaeed69e4",4,"The Free Energy Principle for Perception and Action: A Deep Learning Perspective","This work investigates the tool of deep learning to design and realize artificial agents based on active inference, presenting a deep-learning oriented presentation of the free energy principle, surveying works that are relevant in both machine learning and active inference areas, and discussing the design choices that are involved in the implementation process.","Entropy",2022,"Pietro Mazzaglia,T. Verbelen,Ozan Çatal,B. Dhoedt",4,193,0
"6d0adac188152fbaa45a88ba4da788926ed8144a","https://www.semanticscholar.org/paper/6d0adac188152fbaa45a88ba4da788926ed8144a",4,"Reinforcement Learning in Practice: Opportunities and Challenges","","",2022,"Yuxi Li",1,333,0
"af4b9a5bbcda271f2a08a4c3437a3fbe6125ed6e","https://www.semanticscholar.org/paper/af4b9a5bbcda271f2a08a4c3437a3fbe6125ed6e",4,"Train timetabling with the general learning environment and multi-agent deep reinforcement learning","","Transportation Research Part B: Methodological",2022,"Wenqing Li,S. Ni",2,31,0
"a62c2b9cce3bd3df9ba1eea42aceeb070bd089b2","https://www.semanticscholar.org/paper/a62c2b9cce3bd3df9ba1eea42aceeb070bd089b2",4,"A Novel Reinforcement Learning Collision Avoidance Algorithm for USVs Based on Maneuvering Characteristics and COLREGs","A reinforcement learning collision avoidance (RLCA) algorithm is proposed that complies with USV maneuverability that bridged the divide between USV navigation status information and collision avoidance behavior, resulting in successfully planning a safe and economical path to the terminal.","Italian National Conference on Sensors",2022,"Yunsheng Fan,Zhe Sun,Guofeng Wang",5,48,0
"0f4fff63f5f637e0f807532e37462e0619c86568","https://www.semanticscholar.org/paper/0f4fff63f5f637e0f807532e37462e0619c86568",4,"On the link between conscious function and general intelligence in humans and machines","This work examines the cognitive abilities associated with three contemporary theories of conscious function: Global Workspace Theory (GWT), Information Generation Theory (IGT), and Attention Schema Theory (AST) to propose ways in which insights from each of the three theories may be combined into a uniﬁed model.","ArXiv",2022,"A. Juliani,Kai Arulkumaran,Shuntaro Sasai,R. Kanai",1,253,0
"9064845595d2fe7dd860c612050e4818a191ff62","https://www.semanticscholar.org/paper/9064845595d2fe7dd860c612050e4818a191ff62",4,"Reinforcement learning on graphs: A survey","This survey provides a comprehensive overview of RL and graph mining methods and generalize these methods to Graph Reinforcement Learning (GRL) as a uniﬁed formulation and creates an online open- source for both interested scholars who want to enter this rapidly developing domain and experts who would like to compare GRL methods.","",2022,"Mingshuo Nie,Dongming Chen,Dongqi Wang",1,209,0
"5d15c5a5bde2ae457038a0432dd6aa1a61227977","https://www.semanticscholar.org/paper/5d15c5a5bde2ae457038a0432dd6aa1a61227977",4,"Scalable Multi-Agent Model-Based Reinforcement Learning","It is argued that communication between agents is enough to sustain a world model for each agent during execution phase while imaginary rollouts can be used for training, removing the necessity to interact with the environment.","Adaptive Agents and Multi-Agent Systems",2022,"Vladimir Egorov,A. Shpilman",0,77,0
"ad053a050d6095a2bdb2bd00bfec2a6253280fba","https://www.semanticscholar.org/paper/ad053a050d6095a2bdb2bd00bfec2a6253280fba",4,"Generalized Data Distribution Iteration","It is argued that there is still a long way to go before obtaining real superhuman agents in ALE, and theoretical guarantee of the superiority of GDI compared with GPI is concluded.","International Conference on Machine Learning",2022,"Jiajun Fan,Changnan Xiao",2,50,0
"955536024c5db4166e63d41406c290fcf7ade696","https://www.semanticscholar.org/paper/955536024c5db4166e63d41406c290fcf7ade696",4,"A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning","It is empirically show that ˆ Z estimated by this method can signiﬁcantly reduce dynamics prediction errors and improve the performance of model-based RL methods on zero-shot new environments with unseen dynamics.","International Conference on Learning Representations",2022,"Jixian Guo,Mingming Gong,Dacheng Tao",6,79,2
"25bc06b508b2c63b9faf77881e528530b147b988","https://www.semanticscholar.org/paper/25bc06b508b2c63b9faf77881e528530b147b988",4,"DayDreamer: World Models for Physical Robot Learning","This paper applies Dreamer to four robots and tasks to learn online and directly in the real world, without any simulators, suggesting that Dreamer is capable of online learning in thereal world, establishing a strong baseline.","ArXiv",2022,"Philipp Wu,Alejandro Escontrela,Danijar Hafner,Ken Goldberg,P. Abbeel",17,73,1
"9d516df01688e830b4b3acc3bc995746f6fecfb5","https://www.semanticscholar.org/paper/9d516df01688e830b4b3acc3bc995746f6fecfb5",4,"A Game-Theoretic Perspective of Generalization in Reinforcement Learning","GiRL is propound, a game-theoretic framework for generalization in reinforcement learning, where a RL agent is trained against an adversary over a set of tasks, over which the adversary can manipulate the distributions within a given threshold.","ArXiv",2022,"Chang Yang,Rui Wang,Xinrun Wang,Zhen Wang",0,39,0
"be33823886361b68d27a33f7dfb0986a8414ac33","https://www.semanticscholar.org/paper/be33823886361b68d27a33f7dfb0986a8414ac33",4,"Techniques and Paradigms in Modern Game AI Systems","It is claimed that deep reinforcement learning is the most general methodology to become a mainstream method for games with higher complexity and will bring inspiration to the game AI community for future directions.","Algorithms",2022,"Yunlong Lu,Wenxin Li",0,80,0
"ee6e701be37ab3f2257197a09a2724f8e9ac7681","https://www.semanticscholar.org/paper/ee6e701be37ab3f2257197a09a2724f8e9ac7681",4,"Speedup Training Artificial Intelligence for Mahjong via Reward Variance Reduction","Results show that RVR significantly reduces the variance in Mahjong AI training and improves the model performance, as well as improving the training stability using an expected reward network to adapt to the complex, dynamic, and highly stochastic reward environment.","2022 IEEE Conference on Games (CoG)",2022,"Jinqiu Li,Shuang Wu,Haobo Fu,Qiang Fu,Enmin Zhao,Junliang Xing",0,30,0
"d038814af60dd92d14325a986a9f06a37dbbd0a9","https://www.semanticscholar.org/paper/d038814af60dd92d14325a986a9f06a37dbbd0a9",4,"Reinforcement Learning using Reward Expectations in Scenarios with Aleatoric Uncertainties","In scenarios with aleatoric uncertainties, the reward got by an agent when executing the same action in the same state is random, which can reduce the stability and convergence speed of the reinforcement algorithms.","2022 IEEE Conference on Games (CoG)",2022,"Yubin Wang,Yifeng Sun,Jiang Wu,Hao Hu,Zhiqiang Wu,Weigui Huang",0,17,0
"46d16ec6cc28081742454f7967b9170afd3650b9","https://www.semanticscholar.org/paper/46d16ec6cc28081742454f7967b9170afd3650b9",4,"Transformers are Sample Efficient World Models","IRIS is a data-efﬁcient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer that sets a new state of the art for methods without lookahead search, and even surpasses MuZero.","ArXiv",2022,"Vincent Micheli,Eloi Alonso,Franccois Fleuret",11,57,2
"fccebab2f14ed96365684137002c80b849045a45","https://www.semanticscholar.org/paper/fccebab2f14ed96365684137002c80b849045a45",4,"Off-Policy Actor-critic for Recommender Systems","The key designs in setting up an off-policy actor-critic agent for production recommender systems are shared and it is demonstrated in offline and live experiments that the new framework out-performs baseline and improves long term user experience.","ACM Conference on Recommender Systems",2022,"Minmin Chen,Can Xu,Vince Gatto,Devanshu Jain,Aviral Kumar,Ed H. Chi",3,77,0
"2a2cbe0bd0889ff7b1653a4de977ab662b8154dd","https://www.semanticscholar.org/paper/2a2cbe0bd0889ff7b1653a4de977ab662b8154dd",4,"Integrating artificial and biological neural networks to improve animal task performance using deep reinforcement learning","This work interfaced the nervous system of the nematode Caenorhabditis elegans with a deep reinforcement learning agent, enabling the animal to navigate to targets and enhancing its natural ability to search for food.","bioRxiv",2022,"Chenguang Li,Gabriel Kreiman,S. Ramanathan",0,37,0
"6942045726eb5ff6b51bfe79519987ebd9c5785a","https://www.semanticscholar.org/paper/6942045726eb5ff6b51bfe79519987ebd9c5785a",4,"Unsupervised Model-based Pre-training for Data-efficient Control from Pixels","This work designs an effective unsupervised RL strategy for data-efﬁcient visual control and demonstrates robust performance on the Real-Word RL benchmark, hinting that the approach generalizes to noisy environments.","ArXiv",2022,"Sai Rajeswar,Pietro Mazzaglia,T. Verbelen,Alexandre Pich'e,B. Dhoedt,Aaron C. Courville,Alexandre Lacoste",3,58,1
"e48e12d51d6805d42f60a148133af6dab29b3a60","https://www.semanticscholar.org/paper/e48e12d51d6805d42f60a148133af6dab29b3a60",4,"Hierarchical Reinforcement Learning for Furniture Layout in Virtual Indoor Scenes","","ArXiv",2022,"Xinhan Di,Pengqian Yu",0,36,0
"b9263e73468186b64af6991c54eeb8a612d205e4","https://www.semanticscholar.org/paper/b9263e73468186b64af6991c54eeb8a612d205e4",4,"Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions","Experiments show that the Virtual MCTS (V-MCTS) can achieve comparable performances to the original search algorithm while requiring less than 50% search time on average, and it is believed that this approach is a viable alternative for tasks under limited time and resources.","ArXiv",2022,"Weirui Ye,P. Abbeel,Yang Gao",1,34,0
"1cc6f304f019ce1ae0ba57877c17019da2238616","https://www.semanticscholar.org/paper/1cc6f304f019ce1ae0ba57877c17019da2238616",4,"On All-Action Policy Gradients","The decompose the variance of SPG and derive an optimality condition, which shows when all-action SPG should be preferred over single-action counterpart and allows to determine a variance-minimizing sampling scheme in SPG estimation.","ArXiv",2022,"Michal Nauman,Marek Cygan",0,44,0
"7f1c79aba76005d09156b684ba2e133280c47277","https://www.semanticscholar.org/paper/7f1c79aba76005d09156b684ba2e133280c47277",4,"Autonomous maneuver decision-making method based on reinforcement learning and Monte Carlo tree search","","Frontiers in Neurorobotics",2022,"Hongpeng Zhang,Huan Zhou,Yujie Wei,Changqiang Huang",0,38,0
"ac1c0034d1ec0e685c30736deb50023d5c9b2d6e","https://www.semanticscholar.org/paper/ac1c0034d1ec0e685c30736deb50023d5c9b2d6e",4,"Mastering construction heuristics with self-play deep reinforcement learning","Inspired by AlphaGo Zero, this paper proposes a novel self-play reinforcement learning algorithm (CH-Zero) based on the Monte Carlo tree search (MCTS) for routing optimization problems in this paper and applies self- play reinforcement learning without MCTS to train offline policy and value networks.","Neural computing & applications (Print)",2022,"Qi Wang,Yuqing He,Chunlei Tang",0,61,0
"bc4c90256a13379ee9f2856c22e2e626fbe57d55","https://www.semanticscholar.org/paper/bc4c90256a13379ee9f2856c22e2e626fbe57d55",4,"Reservoir Computing via Quantum Recurrent Neural Networks","This work approaches sequential modeling by applying a reservoir computing (RC) framework to quantum recurrent neural networks (QRNN-RC) that are based on classical RNN, LSTM and GRU, and shows that the quantum version learns faster by requiring fewer training epochs in most cases.","ArXiv",2022,"Samuel Yen-Chi Chen,D. Fry,Amol Deshmukh,V. Rastunkov,Charlee Stefanski",2,119,0
"7ddff9d44d8b04060f1955b83a01836510eb0dc1","https://www.semanticscholar.org/paper/7ddff9d44d8b04060f1955b83a01836510eb0dc1",4,"Reward-Predictive Clustering","A clustering algorithm is provided that enables the application of such state abstractions to deep learning settings, providing compressed representations of an agent’s inputs that preserve the ability to predict sequences of reward.","ArXiv",2022,"Lucas Lehnert,Michael J. Frank,M. Littman",0,54,0
"fd15dce0aa20f0b0691a334995f46e792371d8ad","https://www.semanticscholar.org/paper/fd15dce0aa20f0b0691a334995f46e792371d8ad",4,"Coordinating CAV Swarms at Intersections with a Deep Learning Model","A novel cooperative driving algorithm (AlphaOrder) that combines of deep learning and online tree searching to generate a near-optimal passing order in real-time and provides a general approach to managing preemptive resource sharing between swarm robotics.","ArXiv",2022,"Jiawei Zhang,Sheng Li,Li Li",0,42,0
"ce4b01c6eca06ae3b24e5bc96c1a4b7405240569","https://www.semanticscholar.org/paper/ce4b01c6eca06ae3b24e5bc96c1a4b7405240569",4,"Multi-agent reinforcement learning for autonomous vehicles: a survey","This paper investigates recent advances of multi-agent reinforcement learning (MARL) algorithms in mixed traffic problems and analyzes how the authors formulated the MARL problem in terms of observation, action, and rewards to match the paradigm they apply.","Autonomous Intelligent Systems",2022,"Joris Dinneweth,Abderrahmane Boubezoul,R. Mandiau,S. Espié",0,69,0
"2e1ca97d8f7604e3b334ff4903bfa67267379317","https://www.semanticscholar.org/paper/2e1ca97d8f7604e3b334ff4903bfa67267379317",4,"The Surprising Effectiveness of Latent World Models for Continual Reinforcement Learning","This work studies the use of model-based reinforcement learning methods, in particular, world models for continual reinforcement learning, and shows that world models are a simple and effective continual reinforcementlearning baseline.","ArXiv",2022,"Samuel Kessler,Piotr Milo's,Jack Parker-Holder,Stephen J. Roberts",0,61,0
"9ec568cb93702a0efa75532e296af22740834843","https://www.semanticscholar.org/paper/9ec568cb93702a0efa75532e296af22740834843",4,"Deep Deterministic Policy Gradient-Based Autonomous Driving for Mobile Robots in Sparse Reward Environments","The proposed method demonstrated that the HER technique could help mitigate the sparse reward problem; this was further corroborated by the successful autonomous driving results obtained after applying the proposed method to two reward systems, as well as actual experimental results.","Italian National Conference on Sensors",2022,"Minjae Park,Seok Young Lee,Jin-Seok Hong,N. Kwon",0,34,0
"6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2","https://www.semanticscholar.org/paper/6143e809cd2e9c7a18c3bc8819419fd3b02fbcf2",4,"Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness","This work shows that high sensitivity directions do not lie only along particular worst-case directions, but rather are more abundant in the deep neural policy landscape and can be found via more natural means in a black-box set- ting.","ArXiv",2023,"Ezgi Korkmaz",3,34,0
"d0b93a2fcfe277edd1d9f59360df1deca5c98f56","https://www.semanticscholar.org/paper/d0b93a2fcfe277edd1d9f59360df1deca5c98f56",4,"SoftTreeMax: Exponential Variance Reduction in Policy Gradient via Tree Search","It is proved that the resulting variance decays exponentially with the planning horizon as a function of the expansion policy, and the closer the resulting state transitions are to uniform, the faster the decay.","ArXiv",2023,"Gal Dalal,Assaf Hallak,Gugan Thoppe,Shie Mannor,Gal Chechik",0,51,0
"924501c0205218280cb0251c89bda88c5a142b3e","https://www.semanticscholar.org/paper/924501c0205218280cb0251c89bda88c5a142b3e",4,"Investigating the role of model-based learning in exploration and transfer","It is found that a model-based approach outperforms controlled model-free baselines for transfer learning and intrinsic exploration combined with environment models present a viable direction towards agents that are self-supervised and able to generalize to novel reward functions.","ArXiv",2023,"Jacob Walker,Eszter V'ertes,Yazhe Li,Gabriel Dulac-Arnold,Ankesh Anand,T. Weber,Jessica B. Hamrick",0,60,0
"d15d96517370c9ed0658d176b979bcf92d1373ea","https://www.semanticscholar.org/paper/d15d96517370c9ed0658d176b979bcf92d1373ea",4,"Reason first, then respond: Modular Generation for Knowledge-infused Dialogue","This work proposes a modular model, Knowledge to Response (K2R), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps, and finds that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity.","Conference on Empirical Methods in Natural Language Processing",2021,"Leonard Adolphs,Kurt Shuster,Jack Urbanek,Arthur D. Szlam,J. Weston",17,46,1
"8e7760a3eb57a41124ac9e600df3882d9a7ea4d0","https://www.semanticscholar.org/paper/8e7760a3eb57a41124ac9e600df3882d9a7ea4d0",4,"XF2T: Cross-lingual Fact-to-Text Generation for Low-Resource Languages","An extensive study using popular Transformer-based text generation models on an extended multi-lingual dataset, which is called XA LIGN V2, and investigates the performance of different text generation strategies: multiple variations of pretraining, fact-aware embeddings and structure-aware input encoding.","ArXiv",2022,"Shivprasad Sagare,Tushar Abhishek,Bhavyajeet Singh,Anubhav Sharma,Manish Gupta,Vasudeva Varma",0,51,0
"bceebd434d7502dcd87004ec7313c2eea2c512fc","https://www.semanticscholar.org/paper/bceebd434d7502dcd87004ec7313c2eea2c512fc",4,"A Survey for Efficient Open Domain Question Answering","This paper walks through the ODQA models and concludes the core techniques on efﬁciency, and Quantitative analysis on memory cost, processing speed, accuracy and overall comparison are given.","ArXiv",2022,"Qin Zhang,Shan Chen,Dongkuan Xu,Qingqing Cao,Xiaojun Chen,Trevor Cohn,Meng Fang",4,86,1
"c055a4d03e7ee6647873e8d25ebb7998512507a8","https://www.semanticscholar.org/paper/c055a4d03e7ee6647873e8d25ebb7998512507a8",4,"Search-engine-augmented dialogue response generation with cheaply supervised query production","","Artificial Intelligence",2023,"Ante Wang,Linfeng Song,Qi Liu,Haitao Mi,Longyue Wang,Zhaopeng Tu,Jinsong Su,Dong Yu",0,47,0
"d5fe97309afdf0da633e04b5da4212a054661ecf","https://www.semanticscholar.org/paper/d5fe97309afdf0da633e04b5da4212a054661ecf",4,"Lucid: A Non-intrusive, Scalable and Interpretable Scheduler for Deep Learning Training Jobs","Lucid is designed and implemented, a non-intrusive deep learning workload scheduler based on interpretable models that reduces the average job completion time and provides explicit system interpretations and excellent scalability for practical deployment.","International Conference on Architectural Support for Programming Languages and Operating Systems",2023,"Qi Hu,Mengdie Zhang,Peng Sun,Yonggang Wen,Tianwei Zhang",0,105,0
"615c923b75f2934853889e19d11a2a2514e9f44e","https://www.semanticscholar.org/paper/615c923b75f2934853889e19d11a2a2514e9f44e",4,"Grounding human-object interaction to affordance behavior in multimodal datasets","The model, AffordanceUPT, is based on a two-stage adaptation of the Unary-Pairwise Transformer, which is modularize to make affordance detection independent of object detection and can effectively make the Gibsonian/telic distinction.","Frontiers in Artificial Intelligence",2023,"Alexander Henlein,Anju Gopinath,Nikhil Krishnaswamy,Alexander Mehler,J. Pustejovsky",0,73,0
"f3e80e71aa45d0ecfedf8e18030e353353d6b6f1","https://www.semanticscholar.org/paper/f3e80e71aa45d0ecfedf8e18030e353353d6b6f1",4,"MAKE: Product Retrieval with Vision-Language Pre-training in Taobao Search","This paper presents a novel vision-language (V+L) pre-training methods to exploit the multimodal information of (user query, product title, product image), and demonstrates that the retrieval-specific pre- training model (referred to as MAKE) outperforms existing V+L pre- Training methods on the text-to-multimodal retrieval task.","ArXiv",2023,"Xiaoyang Zheng,Zilong Wang,Sen-Yuan Li,Ke Xu,Tao Zhuang,Qingwen Liu,Xiaoyi Zeng",0,20,0
"adfe0e8eea02b4fff42ab02ecd778ce02c73bf7d","https://www.semanticscholar.org/paper/adfe0e8eea02b4fff42ab02ecd778ce02c73bf7d",4,"TAP: Accelerating Large-Scale DNN Training Through Tensor Automatic Parallelisation","A model parallelism framework TAP is presented that automatically searches for the best data and tensor parallel schedules, and the performance of its discovered schedules is competitive with the expert-engineered ones.","ArXiv",2023,"Ziji Shi,Le Jiang,Ang Wang,J. Zhang,Xianyan Jia,Yong Li,Chencan Wu,Jialin Li,Wei Lin",0,33,0
"74d0b14ce45c0af16a3bec9406f157009b415414","https://www.semanticscholar.org/paper/74d0b14ce45c0af16a3bec9406f157009b415414",4,"Deep Class-Incremental Learning: A Survey","A rigorous and unified evaluation of 16 methods in benchmark image classification tasks to find out the characteristics of different algorithms empirically and advocate fair comparison by aligning the memory budget in evaluation, as well as several memory-agnostic performance measures.","ArXiv",2023,"Da-Wei Zhou,Qiwen Wang,Zhiyuan Qi,Han-Jia Ye,De-chuan Zhan,Ziwei Liu",3,240,0
"45793225c6593db60e9efd95bce1d70bf4844198","https://www.semanticscholar.org/paper/45793225c6593db60e9efd95bce1d70bf4844198",4,"Evaluation Paradigms in Question Answering","By better understanding the epistemic heritage of QA, researchers, academia, and industry can more effectively accelerate QA research.","Conference on Empirical Methods in Natural Language Processing",2021,"Pedro Rodriguez,Jordan L. Boyd-Graber",5,135,0
"0b09448f7543453cc066416f547292dc1e4471f6","https://www.semanticscholar.org/paper/0b09448f7543453cc066416f547292dc1e4471f6",4,"KILT: a Benchmark for Knowledge Intensive Language Tasks","It is found that a shared dense vector index coupled with a seq2seq model is a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue, and yielding competitive results on entity linking and slot filling, by generating disambiguated text.","North American Chapter of the Association for Computational Linguistics",2020,"Fabio Petroni,Aleksandra Piktus,Angela Fan,Patrick Lewis,Majid Yazdani,Nicola De Cao,James Thorne,Yacine Jernite,Vassilis Plachouras,Tim Rocktaschel,Sebastian Riedel",189,65,26
"3122a2d7799ba585b993e432b3deb47659b3f3c1","https://www.semanticscholar.org/paper/3122a2d7799ba585b993e432b3deb47659b3f3c1",4,"Hurdles to Progress in Long-form Question Answering","The task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress, and a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset is designed.","North American Chapter of the Association for Computational Linguistics",2021,"Kalpesh Krishna,Aurko Roy,Mohit Iyyer",63,52,8
"b8c864635656a7ec09c8dcdfc85f600cfba12ccf","https://www.semanticscholar.org/paper/b8c864635656a7ec09c8dcdfc85f600cfba12ccf",4,"Attention-guided Generative Models for Extractive Question Answering","A simple strategy to obtain an extractive answer span from the generative model by leveraging the decoder cross-attention patterns, which allows for hallucination-free inference while conferring significant improvements to the model’s ability to rerank relevant passages.","ArXiv",2021,"Peng Xu,Davis Liang,Zhiheng Huang,Bing Xiang",5,30,1
"4919cd4ad287a3f0679846bd95c6805cb8dda4bd","https://www.semanticscholar.org/paper/4919cd4ad287a3f0679846bd95c6805cb8dda4bd",4,"Generating Biographies on Wikipedia: The Impact of Gender Bias on the Retrieval-Based Generation of Women Biographies","A model for English text is developed that uses a retrieval mechanism to identify relevant supporting information on the web and a cache-based pre-trained encoder-decoder to generate long-form biographies section by section, including citation information.","Annual Meeting of the Association for Computational Linguistics",2022,"Angela Fan,Claire Gardent",1,88,0
"388513e8e09ad60f619054361f4d2cdf5a146bc8","https://www.semanticscholar.org/paper/388513e8e09ad60f619054361f4d2cdf5a146bc8",4,"FeTaQA: Free-form Table Question Answering","This work introduces FeTaQA, a new dataset with 10K Wikipedia-based table, question, free-form answer, supporting table cells pairs, and provides two benchmark methods for the proposed task: a pipeline method based on semantic parsing-based QA systems and an end-to-end methodBased on large pretrained text generation models, and shows that FeTaZA poses a challenge for both methods.","International Conference on Topology, Algebra and Categories in Logic",2021,"Linyong Nan,Chia-Hsuan Hsieh,Ziming Mao,Xi Victoria Lin,Neha Verma,Rui Zhang,Wojciech Kryscinski,Nick Schoelkopf,Riley Kong,Xiangru Tang,Murori Mutuma,B. Rosand,Isabel Trindade,Renusree Bandaru,Jacob Cunningham,Caiming Xiong,Dragomir R. Radev",24,49,6
"a295abfbbbcd92489d5a828d1c25e91e6d4393d4","https://www.semanticscholar.org/paper/a295abfbbbcd92489d5a828d1c25e91e6d4393d4",4,"MixQG: Neural Question Generation with Mixed Answer Types","This paper introduces a neural question generator, MixQG, that outperforms existing work in both seen and unseen domains, and can generate questions with different cognitive levels when conditioned on different answer types.","NAACL-HLT",2021,"Lidiya Murakhovs'ka,C. Wu,Philippe Laban,Tong Niu,Wenhao Liu,Caiming Xiong",19,51,1
"37297ac9b85129f8483078bcef6bcb519fb71b1b","https://www.semanticscholar.org/paper/37297ac9b85129f8483078bcef6bcb519fb71b1b",4,"Read before Generate! Faithful Long Form Question Answering with Machine Reading","A new end-to-end framework is proposed that jointly models answer generation and machine reading with an emphasis on faithful facts and state-of-the-art results on two LFQA datasets demonstrate the effectiveness of the method, in comparison with strong baselines on automatic and human evaluation metrics.","Findings",2022,"Dan Su,Xiaoguang Li,Jindi Zhang,Lifeng Shang,Xin Jiang,Qun Liu,Pascale Fung",8,60,1
"f7fd184eaa573205dff97d86c836f3038143e87a","https://www.semanticscholar.org/paper/f7fd184eaa573205dff97d86c836f3038143e87a",4,"An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks","The Efficient Memory-Augmented Transformer (EMAT) is proposed – it encodes external knowledge into a key-value memory and exploits the fast maximum inner product search for memory querying and produces more accurate results on WoW and ELI5.","Conference on Empirical Methods in Natural Language Processing",2022,"Yuxiang Wu,Yu Zhao,Baotian Hu,Pasquale Minervini,Pontus Stenetorp,Sebastian Riedel",0,39,0
"a63f3785611125257a7feefbb9533ca41af59c13","https://www.semanticscholar.org/paper/a63f3785611125257a7feefbb9533ca41af59c13",4,"CREPE: Open-Domain Question Answering with False Presuppositions","C REPE, a QA dataset containing a natural distribution of presupposition failures from online information-seeking forums, is introduced, showing that 25% of questions contain false presuppositions, and that adaptations of existing open-domain QA models can be adapted moderately well, but struggle when pre-dicting whether a presupposition is factually correct.","ArXiv",2022,"Xinyan Velocity Yu,Sewon Min,Luke Zettlemoyer,Hannaneh Hajishirzi",1,40,0
"2a9b5aadf2d79a56edcd60e332dc7b5973cd047d","https://www.semanticscholar.org/paper/2a9b5aadf2d79a56edcd60e332dc7b5973cd047d",4,"Continual Learning for Grounded Instruction Generation by Observing Human Following Behavior","This work compares user execution of generated instructions to the original system intent as an indication to the system's success communicating its intent, and shows how to use this signal to improve the system’s ability to generate instructions via contextual bandit learning.","Transactions of the Association for Computational Linguistics",2021,"Noriyuki Kojima,Alane Suhr,Yoav Artzi",9,56,1
"56152658a3bb42e0afd0231e6fd942ea3dc3604f","https://www.semanticscholar.org/paper/56152658a3bb42e0afd0231e6fd942ea3dc3604f",4,"Simulating Bandit Learning from User Feedback for Extractive Question Answering","This work shows that systems initially trained on few examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation effort, but instead improving the system on-the-fly via user feedback.","Annual Meeting of the Association for Computational Linguistics",2022,"Ge Gao,Eunsol Choi,Yoav Artzi",3,53,0
"6ba3e4172e5c22c8c3ace05a31e9b119a2e3c33c","https://www.semanticscholar.org/paper/6ba3e4172e5c22c8c3ace05a31e9b119a2e3c33c",4,"Continual Learning for Instruction Following from Realtime Feedback","This work studies the problem of continually training an instruction-following agent from feedback provided by users during collaborative interactions, and shows that the feedback signal is roughly equivalent to the learning signal of supervised demonstration data.","ArXiv",2022,"Alane Suhr,Yoav Artzi",0,47,0
"15ddeb9b812e4063a8b907d50c720e01c753b2b4","https://www.semanticscholar.org/paper/15ddeb9b812e4063a8b907d50c720e01c753b2b4",4,"Reincarnating Reinforcement Learning: Reusing Prior Computation to Accelerate Progress","This work argues for an alternative approach to RL research that could improve real-world RL adoption and help democratize it further, and presents reincarnating RL as an alternative workﬂow or class of problem settings.","",2022,"Rishabh Agarwal,Max Schwarzer,P. S. Castro,Aaron C. Courville,Marc G. Bellemare",4,88,1
"a66e581eca1e6531298563f39d8b4ccdcf9489e2","https://www.semanticscholar.org/paper/a66e581eca1e6531298563f39d8b4ccdcf9489e2",4,"Fast Inference and Transfer of Compositional Task Structures for Few-shot Task Generalization","The proposed multi-task subtask graph inferencer (MTSGI) infers the common high-level task structure in terms of the subtaskgraph graph from the training tasks, and uses it as a prior to improve the task inference in testing.","Conference on Uncertainty in Artificial Intelligence",2022,"Sungryull Sohn,Hyunjae Woo,Jongwook Choi,lyubing qiang,Izzeddin Gur,Aleksandra Faust,Honglak Lee",2,43,0
"20e5561e3e576fbc10b0e97f8f64d8c875e17ad7","https://www.semanticscholar.org/paper/20e5561e3e576fbc10b0e97f8f64d8c875e17ad7",4,"A Few More Examples May Be Worth Billions of Parameters","This work hypothesizes that unlike open question answering, which involves recalling specific information, solving strategies for tasks with a more restricted output space transfer across examples, and can therefore be learned with small amounts of labeled data, the contribution of additional examples highly depends on the task's format.","Conference on Empirical Methods in Natural Language Processing",2021,"Yuval Kirstain,Patrick Lewis,S. Riedel,Omer Levy",5,65,0
"f9ad1fffa1cc76fd5db3ff758c0839492c5147c4","https://www.semanticscholar.org/paper/f9ad1fffa1cc76fd5db3ff758c0839492c5147c4",4,"In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models","This work proposes to combine in- context learning objectives with language modeling objectives to distill both the ability to read in-context examples and task knowledge to the smaller models and shows consistent improvements for both Meta-ICT and Multitask-ICT on two benchmarks.","ArXiv",2022,"Yukun Huang,Yanda Chen,Zhou Yu,K. McKeown",0,40,0
"c44120f765fc43994c5cfb4e12e4f62999efeae6","https://www.semanticscholar.org/paper/c44120f765fc43994c5cfb4e12e4f62999efeae6",4,"How Context Affects Language Models' Factual Predictions","This paper reports that augmenting pre-trained language models in this way dramatically improves performance and that the resulting system, despite being unsupervised, is competitive with a supervised machine reading baseline.","Conference on Automated Knowledge Base Construction",2020,"Fabio Petroni,Patrick Lewis,Aleksandra Piktus,Tim Rocktäschel,Yuxiang Wu,Alexander H. Miller,Sebastian Riedel",96,56,18
"02d8cfa5bc5f086acc57bb4ac8e4e94515fed7f9","https://www.semanticscholar.org/paper/02d8cfa5bc5f086acc57bb4ac8e4e94515fed7f9",4,"PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them","It is found that PAQ preempts and caches test questions, enabling RePAQ to match the accuracy of recent retrieve-and-read models, whilst being significantly faster, and a new QA-pair retriever, RePAZ, is introduced to complement PAQ.","Transactions of the Association for Computational Linguistics",2021,"Patrick Lewis,Yuxiang Wu,Linqing Liu,Pasquale Minervini,Heinrich Kuttler,Aleksandra Piktus,Pontus Stenetorp,Sebastian Riedel",102,73,27
"b58d8579ece27a60432e667bfbdb750590fa65d9","https://www.semanticscholar.org/paper/b58d8579ece27a60432e667bfbdb750590fa65d9",4,"True Few-Shot Learning with Language Models","This work evaluates the few-shot ability of LMs when such held-out examples are unavailable, a setting the authors call true few- shot learning, and suggests that prior work significantly overestimated thetrue few-shots ability ofLMs given the difficulty of few-Shot model selection.","Neural Information Processing Systems",2021,"Ethan Perez,Douwe Kiela,Kyunghyun Cho",145,101,24
"537d98e241975dc5c32d9372ae85134dffe45532","https://www.semanticscholar.org/paper/537d98e241975dc5c32d9372ae85134dffe45532",4,"DP-KB: Data Programming with Knowledge Bases Improves Transformer Fine Tuning for Answer Sentence Selection","This paper implements an efficient, data-programming technique that enriches training data with KB-derived context and improves transformer utilization of encoded knowledge when fine-tuning for a particular QA task, namely answer sentence selection (AS2).","ArXiv",2022,"Nic Jedema,Thuy Vu,Manish Gupta,Alessandro Moschitti",0,36,0
"8ec9d3e29e1db209925f08f505bd5da9777d1dee","https://www.semanticscholar.org/paper/8ec9d3e29e1db209925f08f505bd5da9777d1dee",4,"Elaboration-Generating Commonsense Question Answering at Scale","This work uses smaller language models to generate useful intermediate context, referred to here as elaborations, and alternates between updating two language models—an elaboration generator and an answer predictor—allowing each to inﬂuence the other.","ArXiv",2022,"Wenya Wang,Vivek Srikumar,Hannaneh Hajishirzi,Noah A. Smith",2,49,0
"3917602c6139811fe3c20bc32070d6cee474fe49","https://www.semanticscholar.org/paper/3917602c6139811fe3c20bc32070d6cee474fe49",4,"Knowledge Graph Generation From Text","A novel end-to-end multi-stage Knowledge Graph (KG) generation system from textual inputs, separating the overall process into two stages, showing strong overall performance, outperforming the existing baselines.","Conference on Empirical Methods in Natural Language Processing",2022,"Igor Melnyk,Pierre L. Dognin,Payel Das",1,32,0
"b2d783c0ed3bd2c631b99b1487399016a5f00d5f","https://www.semanticscholar.org/paper/b2d783c0ed3bd2c631b99b1487399016a5f00d5f",4,"LabelPrompt: Effective Prompt-based Learning for Relation Classification","This paper presents a novel prompt-based learning method, namely LabelPrompt, for the relation classification task, and applies an attention query strategy to self-attention layers to resolve two types of tokens, prompt tokens and sequence tokens.","",2023,"W. Zhang,Xiaoning Song,Zhenhua Feng,Tianyang Xu,Xiaojun Wu",0,57,0
"91eb2e73f8f3574c00dc6787a3e277eedaf33531","https://www.semanticscholar.org/paper/91eb2e73f8f3574c00dc6787a3e277eedaf33531",4,"CONSISTENT: Open-Ended Question Generation From News Articles","This work proposes CONSISTENT, a new end-to-end system for generating open-ended questions that are answerable from and faithful to the input text, and demonstrates its strength over several baselines using both automatic and human=based evaluations.","Conference on Empirical Methods in Natural Language Processing",2022,"Tuhin Chakrabarty,Justin Lewis,S. Muresan",0,43,0
"2843661ee0d5fa159165beba50c345566cc44c57","https://www.semanticscholar.org/paper/2843661ee0d5fa159165beba50c345566cc44c57",4,"Do Text-to-Text Multi-Task Learners Suffer from Task Conflict?","This work studies how certain factors in the shift towards text-to-text models affects multi-task conflict and negative transfer, finding that both directional conflict and transfer are surprisingly constant across architectures.","Conference on Empirical Methods in Natural Language Processing",2022,"David Mueller,Nicholas Andrews,Mark Dredze",0,37,0
"f9711475b3b20e349bdb1ee5f474d9aaabd784f1","https://www.semanticscholar.org/paper/f9711475b3b20e349bdb1ee5f474d9aaabd784f1",4,"Zero-shot Triplet Extraction by Template Infilling","It is argued that reducing triplet extraction to a template ﬁlling task over a pre-trained language model can equip the model with zero-shot learning capabilities and enable it to leverage the implicit knowledge in the language model.","ArXiv",2022,"Bosung Kim,Hayate Iso,Nikita Bhutani,Estevam Hruschka,Ndapa Nakashole",0,34,0
"9e42cb2b133bc41600824a1002cb05844c6a46a9","https://www.semanticscholar.org/paper/9e42cb2b133bc41600824a1002cb05844c6a46a9",4,"Learning to Generate Task-Specific Adapters from Task Description","Hypter is introduced, a framework that improves text-to-text transformer’s generalization ability to unseen tasks by training a hypernetwork to generate task-specific, light-weight adapters from task descriptions.","Annual Meeting of the Association for Computational Linguistics",2021,"Qinyuan Ye,Xiang Ren",12,28,0
"6f9fc51102cf49bff4f4e2b336739a45f8389c80","https://www.semanticscholar.org/paper/6f9fc51102cf49bff4f4e2b336739a45f8389c80",4,"Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?","This work proposes a new language understanding task, Linguistic Ethical Interventions (LEI), where the goal is to amend a questionanswering (QA) model’s unethical behavior by communicating context-specific principles of ethics and equity to it.","Findings",2021,"Jieyu Zhao,Daniel Khashabi,Tushar Khot,Ashish Sabharwal,Kai-Wei Chang",15,40,1
"771923db144e8b6f908eb93693edef71a8b682ea","https://www.semanticscholar.org/paper/771923db144e8b6f908eb93693edef71a8b682ea",4,"What is Not in the Context? Evaluation of Few-shot Learners with Informative Demonstrations","This work argues that the commonly-used evaluation settings of few-shot models utilizing a random selection of in-context demonstrations is not able to disentangle models’ ability of learning new skills from demonstrations, as most of such-selected demonstrations are commonly not informative for prediction beyond exposing the new task’s input and output distribution.","",2022,"Michal vStef'anik,Marek Kadlvc'ik",0,19,0
"8ae9a17c87a4518b513e860683a0ef7824be994d","https://www.semanticscholar.org/paper/8ae9a17c87a4518b513e860683a0ef7824be994d",4,"Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference","This work introduces Pattern-Exploiting Training (PET), a semi-supervised training procedure that reformulates input examples as cloze-style phrases to help language models understand a given task.","Conference of the European Chapter of the Association for Computational Linguistics",2020,"Timo Schick,Hinrich Schütze",566,64,78
"a6a83754a0d1e9a8e41c1e9bbdbca32d3b9d1fd3","https://www.semanticscholar.org/paper/a6a83754a0d1e9a8e41c1e9bbdbca32d3b9d1fd3",4,"It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners","This work shows that performance similar to GPT-3 can be obtained with language models that are much “greener” in that their parameter count is several orders of magnitude smaller, and identifies key factors required for successful natural language understanding with small language models.","North American Chapter of the Association for Computational Linguistics",2020,"Timo Schick,Hinrich Schütze",415,65,55
"ace5e1d171f80181cd3fdecccd88d6a0ab89e0e0","https://www.semanticscholar.org/paper/ace5e1d171f80181cd3fdecccd88d6a0ab89e0e0",4,"Towards Teachable Autonomous Agents","The purpose of this paper is to elucidate the key obstacles standing in the way towards the design of teachable and autonomous agents and focus on autotelic agents, i.e. agents equipped with forms of intrinsic motivations that enable them to represent, self-generate and pursue their own goals.","ArXiv",2021,"Olivier Sigaud,Hugo Caselles-Dupr'e,Cédric Colas,Ahmed Akakzia,P. Oudeyer,M. Chetouani",14,184,0
"7cbe7c4bad376c9097a17ca4015c309bf1b17993","https://www.semanticscholar.org/paper/7cbe7c4bad376c9097a17ca4015c309bf1b17993",4,"Co-training Improves Prompt-based Learning for Large Language Models","Co-training makes it possible to improve the original prompt model and at the same time learn a smaller, downstream task-specific model, and models trained in this manner can significantly improve performance on challenging datasets where there is currently a large gap between prompt-based learning and fully-supervised models.","International Conference on Machine Learning",2022,"Hunter Lang,Monica Agrawal,Yoon Kim,D. Sontag",8,48,1
"c513df38b37b9bae49641a8ad73b01e40fb14f7e","https://www.semanticscholar.org/paper/c513df38b37b9bae49641a8ad73b01e40fb14f7e",4,"Online learning with binary feedback for multi-class problems","This work investigates methods for using and labeling training data in the absence of complete information by attempting to usefully utilize a binary feedback method where the human indicates whether the prediction is correct or incorrect.","IEEE Symposium Series on Computational Intelligence",2022,"Evan Lucas,Steven Whitaker,T. Havens",0,17,0
"1439777b9e22dca3a10a6c4b9faa712bc74510cc","https://www.semanticscholar.org/paper/1439777b9e22dca3a10a6c4b9faa712bc74510cc",4,"Query Enhanced Knowledge-Intensive Conversation via Unsupervised Joint Modeling","This paper proposes an unsupervised query enhanced approach for knowledge-intensive conversations, namely QKConv, and con-ducted comprehensive experiments on conversational question-answering, task-oriented dialogue, and knowledge-grounded conversation to demonstrate the effectiveness of the proposed method.","ArXiv",2022,"Mingzhu Cai,Siqi Bao,Xin Tian,H. He,Fan Wang,Hua Wu",0,38,0
"f1e7332a76be8f38091193e6e929d0d653f4867c","https://www.semanticscholar.org/paper/f1e7332a76be8f38091193e6e929d0d653f4867c",4,"On The Fragility of Learned Reward Functions","This work demonstrates with experiments in tabular and continuous control environments that the severity of relearning failures can be sensitive to changes in reward model design and the trajectory dataset composition.","ArXiv",2023,"Lev McKinney,Yawen Duan,David Krueger,A. Gleave",0,42,0
"8505170798a21bd7764955f9952cbe346a5d0a50","https://www.semanticscholar.org/paper/8505170798a21bd7764955f9952cbe346a5d0a50",4,"Molecular Language Model as Multi-task Generator","This work proposes M OL G EN, a pre-trained molecular language model that effectively learns and shares knowledge across multiple generation tasks and domains, and proposes multi-task molecular preﬁx tuning across several moleculargeneration tasks and different molecular domains with a self-feedback mechanism.","ArXiv",2023,"Yin Fang,Ningyu Zhang,Zhuo Chen,Xiaohui Fan,Huajun Chen",0,59,0
"f4db4a18080e9e4ebba9ba68bb7d34230c84d0c3","https://www.semanticscholar.org/paper/f4db4a18080e9e4ebba9ba68bb7d34230c84d0c3",4,"Truth Machines: Synthesizing Veracity in AI Language Models","","ArXiv",2023,"Luke Munn,L. Magee,Vanicka Arora",0,79,0
"2e96513b803d8d3b0e06373edd33cda4aa72df27","https://www.semanticscholar.org/paper/2e96513b803d8d3b0e06373edd33cda4aa72df27",4,"On the portability of extractive Question-Answering systems on scientific papers to real-life application scenarios","This work addresses the portability of extractive Question Answering systems from academic spheres to industries basing their decisions on thorough scientific papers analysis by adopting the pipeline-based retriever-ranker-reader architecture for answering a question on a scientific paper.","WIESP",2022,"Chyrine Tahri,Xavier Tannier,Patrick Haouat",0,36,0
"96df989cba0e6cd88b994c4459349fd80b7cf213","https://www.semanticscholar.org/paper/96df989cba0e6cd88b994c4459349fd80b7cf213",4,"Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient Multi-task Knowledge Sharing","Experimental results across 17 diverse datasets show that ATTEMPT improves prompt tuning by up to a 22% absolute performance gain and outperforms or matches fully fine-tuned or other parameter-efficient tuning approaches that use over ten times more parameters.","ArXiv",2022,"Akari Asai,Mohammadreza Salehi,Matthew E. Peters,Hannaneh Hajishirzi",10,67,3
"775c439186b037c09cd9f95b9daf81d23ca21b54","https://www.semanticscholar.org/paper/775c439186b037c09cd9f95b9daf81d23ca21b54",4,"WinoDict: Probing language models for in-context word acquisition","A new in-context learning paradigm is introduced to measure Large Language Models’ (LLMs) ability to learn novel words during in-ference, rewriting Winograd-style co-reference resolution problems by replacing the key concept word with a synthetic but plausible word that the model must understand to complete the task.","ArXiv",2022,"Julian Martin Eisenschlos,Jeremy R. Cole,Fangyu Liu,William W. Cohen",0,29,0
"b4c16b0f26f9f5ad5e12f9bec3f1ad72eaa5491b","https://www.semanticscholar.org/paper/b4c16b0f26f9f5ad5e12f9bec3f1ad72eaa5491b",4,"Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs","","Conference on Empirical Methods in Natural Language Processing",2022,"Maarten Sap,Ronan Le Bras,Daniel Fried,Yejin Choi",8,130,2
"cc7462b76d5e8acb28e61ea1f57e17905540a415","https://www.semanticscholar.org/paper/cc7462b76d5e8acb28e61ea1f57e17905540a415",4,"TEMPERA: Test-Time Prompting via Reinforcement Learning","Theency of the method compared to netuning is compared to TEMPERA, showing that TEMperA can achieve same performance with 5.33x less data.","ArXiv",2022,"Tianjun Zhang,Xuezhi Wang,Denny Zhou,D. Schuurmans,Joseph Gonzalez",0,32,0
"7e5709d81558d3ef4265de29ea75931afeb1f2dd","https://www.semanticscholar.org/paper/7e5709d81558d3ef4265de29ea75931afeb1f2dd",4,"Efficient Transformers: A Survey","This article characterizes a large and thoughtful selection of recent efficiency-flavored “X-former” models, providing an organized and comprehensive overview of existing work and models across multiple domains.","ACM Computing Surveys",2020,"Yi Tay,M. Dehghani,Dara Bahri,Donald Metzler",478,104,49
"ec31364e266ac691da29be7d2309fc2a4f8e0ee6","https://www.semanticscholar.org/paper/ec31364e266ac691da29be7d2309fc2a4f8e0ee6",4,"Creative Writing with an AI-Powered Writing Assistant: Perspectives from Professional Writers","","ArXiv",2022,"Daphne Ippolito,Ann Yuan,Andy Coenen,Sehmon Burnam",1,42,0
"428854d9e75f94f0e61f37c6887c77800437d516","https://www.semanticscholar.org/paper/428854d9e75f94f0e61f37c6887c77800437d516",4,"MusicLM: Generating Music From Text","This work introduces MusicLM, a model for generating high-ﬁdelity music from text descriptions such as “a calming violin melody backed by a distorted guitar riff” and demonstrates that it can transform whistled and hummed melodies according to the style described in a text caption.","ArXiv",2023,"A. Agostinelli,Timo I. Denk,Zalán Borsos,Jesse Engel,M. Verzetti,Antoine Caillon,Qingqing Huang,A. Jansen,Adam Roberts,M. Tagliasacchi,Matthew Sharifi,Neil Zeghidour,C. Frank",2,49,0
"17a8b5e6fef1f69979d57021a8f30a5159e152c7","https://www.semanticscholar.org/paper/17a8b5e6fef1f69979d57021a8f30a5159e152c7",4,"Commonsense Reasoning for Conversational AI: A Survey of the State of the Art","A survey of recent conversational AI research focused on commonsense reasoning, including preliminary observations of the limited commonsense capabilities of two state-of-the-art open dialogue models, BlenderBot3 and LaMDA, and its negative effect on natural interactions.","",2023,"Christopher Richardson,Larry Heck",0,90,0
"46f0064af5557e4a2c9c65d245815bc29050ea62","https://www.semanticscholar.org/paper/46f0064af5557e4a2c9c65d245815bc29050ea62",4,"LegalBench: Prototyping a Collaborative Benchmark for Legal Reasoning","How IRAC—a framework legal scholars use to distinguish types of legal reasoning—can guide the construction of a Foundation Model oriented benchmark is described and a seed set of 44 tasks built according to this framework is presented.","ArXiv",2022,"Neel Guha,Daniel E. Ho,Julian Nyarko,Christopher R'e",1,29,0
"ad62d710f1854daf372680263f50a4e135e309f2","https://www.semanticscholar.org/paper/ad62d710f1854daf372680263f50a4e135e309f2",4,"CHARD: Clinical Health-Aware Reasoning Across Dimensions for Text Generation Models","It is shown that while the models can perform decently, CHARD is very challenging with strong potential for further exploration.","ArXiv",2022,"Steven Y. Feng,Vivek Khetan,Bogdan Sacaleanu,A. Gershman,E. Hovy",1,38,0
"c094cfee1e93cb76f5fc867ae6d89c83ed0d55ef","https://www.semanticscholar.org/paper/c094cfee1e93cb76f5fc867ae6d89c83ed0d55ef",4,"PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance","A novel method is proposed, namely UniPCQA, to adapt a hybrid format of input and output content in PCQA into the Seq2Seq problem, including the reformulation of the numerical reasoning process as code generation.","Conference on Empirical Methods in Natural Language Processing",2022,"Yang Deng,Wenqiang Lei,Wenxuan Zhang,W. Lam,Tat-Seng Chua",1,59,0
"1d417bdd331912a458de920459f23fcc7f6e8699","https://www.semanticscholar.org/paper/1d417bdd331912a458de920459f23fcc7f6e8699",4,"Learning to Decompose: Hypothetical Question Decomposition Based on Comparable Texts","It is shown that with such intermediate pre-training, developing robust decomposition-based models for a diverse range of tasks becomes more feasible, and the model, DecompT5, improves 20% to 30% on two datasets, Overnight and TORQUE, over the baseline language model.","Conference on Empirical Methods in Natural Language Processing",2022,"Ben Zhou,Kyle Richardson,Xiaodong Yu,D. Roth",3,38,0
"18b3ab9763ed3c4633ee68aa6dd75f6377837553","https://www.semanticscholar.org/paper/18b3ab9763ed3c4633ee68aa6dd75f6377837553",4,"Natural Language Deduction with Incomplete Information","This work proposes a new system that can handle the underspecified setting where not all premises are stated at the outset; that is, additional assumptions need to be materialized to prove a claim.","Conference on Empirical Methods in Natural Language Processing",2022,"Zayne Sprague,Kaj Bostrom,Swarat Chaudhuri,Greg Durrett",1,40,0
"1b4c0a28b0c2a30cc3b84a3222e795c90357bc8a","https://www.semanticscholar.org/paper/1b4c0a28b0c2a30cc3b84a3222e795c90357bc8a",4,"SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images","A new multi- image document VQA dataset, SlideVQA, containing 2.6k-+ slide decks composed of 52k+ slide images and 14.5k ques- tions about a slide deck is proposed, and a new end-to-end document VZA model is developed that treats evidence selection and question answering in a sequence- to-sequence format.","ArXiv",2023,"Ryota Tanaka,Kyosuke Nishida,Kosuke Nishida,Taku Hasegawa,Itsumi Saito,Kuniko Saito",0,46,0
"4e2e59546a4d67dd25f30ca744feb5717e03d9fc","https://www.semanticscholar.org/paper/4e2e59546a4d67dd25f30ca744feb5717e03d9fc",4,"SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning","SURF is presented, a semi-supervised reward learning framework that utilizes a large amount of unlabeled samples with data augmentation and improves the feedback-efficiency of the state-ofthe-art preference-based method on a variety of locomotion and robotic manipulation tasks.","",2022,"Jongjin Park,Younggyo Seo,Jinwoo Shin,Honglak Lee,P. Abbeel,Kimin Lee",0,56,0
"b0726dd009bae5f602a4e71ac5f9e8f53b6e385c","https://www.semanticscholar.org/paper/b0726dd009bae5f602a4e71ac5f9e8f53b6e385c",4,"Advances in Preference-based Reinforcement Learning: A Review","A unified PbRL framework is presented to include the newly emerging approaches that improve the scalability and efficiency of Pb RL.","IEEE International Conference on Systems, Man and Cybernetics",2022,"Youssef Abdelkareem,Shady Shehata,F. Karray",1,56,0
"24615e613d4551f7aaa0557befa0a8bc403f39cd","https://www.semanticscholar.org/paper/24615e613d4551f7aaa0557befa0a8bc403f39cd",4,"Stateful Memory-Augmented Transformers for Dialogue Modeling","A new memory-augmented Transformer is proposed that is compatible with existing pre-trained encoder-decoder models and enables efﬁcient preservation of history information and incorporates a separate memory module alongside the pre- trained Transformer to effectively interchange information between the memory states and the current input context.","ArXiv",2022,"Qing-yang Wu,Zhou Yu",0,36,0
"8283064365ae7594d891e8b7daf36fd37ca809b0","https://www.semanticscholar.org/paper/8283064365ae7594d891e8b7daf36fd37ca809b0",4,"Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers","It is shown that OODG can occur on a complex problem if the training set includes examples sampled from the whole distribution of simpler component tasks, and that suppressing sensitivity to absolute positions overcomes this limitation.","",2022,"A. Nam,Mustafa Abdool,Trevor Maxfield,James L. McClelland",0,17,0
"b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce","https://www.semanticscholar.org/paper/b1eebb2df3b9ff7ff2b00fb1a786f6ada2caebce",4,"Towards a Mathematics Formalisation Assistant using Large Language Models","The abilities of a large language model (Codex) to help with formalisation in the Lean theorem prover are explored, finding that with careful inputdependent prompt selection and postprocessing, Codex is able to formalise short mathematical statements at undergrad level with nearly 75% accuracy for 120 theorem statements.","ArXiv",2022,"Ayush Agrawal,Siddhartha Gadgil,Navin Goyal,Ashvni Narayanan,Anand Tadipatri",0,26,0
"5c8cb5d39aa8531fcb5962821ac404e4a0e109d1","https://www.semanticscholar.org/paper/5c8cb5d39aa8531fcb5962821ac404e4a0e109d1",4,"Is It Smaller Than a Tennis Ball? Language Models Play the Game of Twenty Questions","It is found that only the largest model has enough world knowledge to play the game of Twenty Questions well, although it still has difficulties with the shape and size of objects.","BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",2022,"Maxime De Bruyn,Ehsan Lotfi,Jeska Buhmann,Walter Daelemans",0,33,0
"f557f3a32d309373e7d31bb93ca1b80b4a6e39e7","https://www.semanticscholar.org/paper/f557f3a32d309373e7d31bb93ca1b80b4a6e39e7",4,"Symbolic Math Reasoning with Language Models","GPT-3’s davinci-002 model, in addition to having good performance on numerical math word problems, also performs well on the potentially harder symbolic version of the same problems, and adopting a two-step approach leads to better accuracy on the numerical test set in the zero-shot regime.","2022 IEEE MIT Undergraduate Research Technology Conference (URTC)",2022,"Vedant Gaur,Nikunj Saunshi",0,10,0
"66f333c51e2bfa25380069f66500b491218da9c3","https://www.semanticscholar.org/paper/66f333c51e2bfa25380069f66500b491218da9c3",4,"Can Pretrained Language Models (Yet) Reason Deductively?","It is suggested that PLMs cannot yet perform reliable deductive reasoning, demonstrating the importance of controlled examinations and probing of PLMs' reasoning abilities; the results reach beyond (misleading) task performance, revealing thatPLMs are still far from human-level reasoning capabilities, even for simple deductive tasks.","ArXiv",2022,"Zhangdie Yuan,Songbo Hu,Ivan Vulic,A. Korhonen,Zaiqiao Meng",0,72,0
"32635a3daba6cbd7f0dd930aa325254b191c1343","https://www.semanticscholar.org/paper/32635a3daba6cbd7f0dd930aa325254b191c1343",4,"Multilingual Relation Classification via Efficient and Effective Prompting","This paper presents the first work on prompt-based multilingual relation classification (RC), by introducing an efficient and effective method that constructs prompts from relation triples and involves only minimal translation for the class labels.","Conference on Empirical Methods in Natural Language Processing",2022,"Yuxuan Chen,David Harbecke,Leonhard Hennig",0,64,0
"3f4f11b530bd6c3faa1f7fcf6bde9dae95a19673","https://www.semanticscholar.org/paper/3f4f11b530bd6c3faa1f7fcf6bde9dae95a19673",4,"Zero-Shot Classification by Logical Reasoning on Natural Language Explanations","This work proposes the framework CLORE (Classification by LOgical Reasoning on Explanations).","ArXiv",2022,"Chi Han,Hengzhi Pei,X. Du,Heng Ji",0,52,0
"acc61b1a55ace8bba5595d8aee3dc9a14370a4d8","https://www.semanticscholar.org/paper/acc61b1a55ace8bba5595d8aee3dc9a14370a4d8",4,"Learning UI Navigation through Demonstrations composed of Macro Actions","This work has developed a framework to reliably build agents capable of UI navigation and made a customization of DQfD to allow demos collected on screenshots to facilitate the demo coverage of rare cases.","ArXiv",2021,"Wei Li",1,11,0
"300529850ca8e8ad6633a2b566206bf7f2a38fd9","https://www.semanticscholar.org/paper/300529850ca8e8ad6633a2b566206bf7f2a38fd9",4,"Evolving Curricula with Regret-Based Environment Design","This work proposes harnessing the power of evolution in a principled, regret-based curriculum that seeks to constantly produce levels at the frontier of an agent’s capabilities, resulting in curricula that start simple but become increasingly complex.","International Conference on Machine Learning",2022,"Jack Parker-Holder,Minqi Jiang,Michael Dennis,Mikayel Samvelyan,J. Foerster,Edward Grefenstette,Tim Rocktaschel",24,99,4
"549bfdfd9fa718331076810f0d5817adcd79fe69","https://www.semanticscholar.org/paper/549bfdfd9fa718331076810f0d5817adcd79fe69",4,"AutoDIME: Automatic Design of Interesting Multi-Agent Environments","The results suggest that intrinsic teacher rewards, and in particular value disagreement, are a promising approach for automating both single and multi-agent environment design.","ArXiv",2022,"I. Kanitscheider,Harrison Edwards",0,59,0
"590432f953b6ce1b4b36bf66a2ac65eeee567515","https://www.semanticscholar.org/paper/590432f953b6ce1b4b36bf66a2ac65eeee567515",4,"ColBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction","Maize is introduced, a retriever that couples an aggressive residual compression mechanism with a denoised supervision strategy to simultaneously improve the quality and space footprint of late interaction and establishes state-of-the-art quality within and outside the training domain.","North American Chapter of the Association for Computational Linguistics",2021,"Keshav Santhanam,O. Khattab,Jon Saad-Falcon,Christopher Potts,M. Zaharia",75,77,24
"9d40837175577bb0009b138269b422f6d5820d00","https://www.semanticscholar.org/paper/9d40837175577bb0009b138269b422f6d5820d00",4,"Transformer Memory as a Differentiable Search Index","The Differentiable Search Index is introduced, a new paradigm that learns a text-to-text model that maps string queries directly to relevant docids; in other words, a DSI model answers queries directly using only its parameters, dramatically simplifying the whole retrieval process.","ArXiv",2022,"Yi Tay,V. Tran,M. Dehghani,Jianmo Ni,Dara Bahri,Harsh Mehta,Zhen Qin,Kai Hui,Zhe Zhao,Jai Gupta,Tal Schuster,William W. Cohen,Donald Metzler",39,36,9
"82938e991a4094022bc190714c5033df4c35aaf2","https://www.semanticscholar.org/paper/82938e991a4094022bc190714c5033df4c35aaf2",4,"Retrieval-Augmented Reinforcement Learning","This paper augments an RL agent with a retrieval process (parameterized as a neural network) that has direct access to a dataset of experiences that may be useful in the current context, to help the agent achieve its goal faster and more efﬁciently.","International Conference on Machine Learning",2022,"Anirudh Goyal,A. Friesen,Andrea Banino,T. Weber,Nan Rosemary Ke,Adrià Puigdomènech Badia,A. Guez,Mehdi Mirza,Ksenia Konyushkova,Michal Valko,Simon Osindero,T. Lillicrap,N. Heess,C. Blundell",12,93,0
"76453afd79968f2de8356beaca5e0468715feab8","https://www.semanticscholar.org/paper/76453afd79968f2de8356beaca5e0468715feab8",4,"Non-Parametric Temporal Adaptation for Social Media Topic Classification","This paper studies temporal adaptation through the task of longitudinal hash- tag prediction and proposes a non-parametric technique as a simple but effective solution: non- Parametric classiﬁers use datastores which can be updated, either to adapt to test distribution shift or training data deletion, without re-training.","ArXiv",2022,"Fatemehsadat Mireshghallah,Nikolai Vogler,Junxian He,Omar U. Florez,Ahmed El-Kishky,Taylor Berg-Kirkpatrick",2,48,0
"38b0803b59e4973f09018ce942164b02be4b8bc9","https://www.semanticscholar.org/paper/38b0803b59e4973f09018ce942164b02be4b8bc9",4,"MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text","The first Multimodal Retrieval-Augmented Transformer (MuRAG) is proposed, which accesses an external non-parametric multimodal memory to augment language generation and achieves state-of-the-art accuracy.","Conference on Empirical Methods in Natural Language Processing",2022,"Wenhu Chen,Hexiang Hu,Xi Chen,Pat Verga,William W. Cohen",6,43,3
"135b66a1a3fd887f89c32524139dba915a27f61b","https://www.semanticscholar.org/paper/135b66a1a3fd887f89c32524139dba915a27f61b",4,"Revision Transformers: Getting RiT of No-Nos","This work proposes the Revision Transformer (RiT), a combination of a large-scale pre-trained LM that inherently but also diffusely encodes world knowledge with a clear-structured revision engine that makes it possible to update the model's knowledge with little effort and the help of user interaction.","ArXiv",2022,"Felix Friedrich,Wolfgang Stammer,P. Schramowski,K. Kersting",1,36,0
"d95b441c2838888d7ac1af73b5f9c800f22fad3a","https://www.semanticscholar.org/paper/d95b441c2838888d7ac1af73b5f9c800f22fad3a",4,"An Invariant Learning Characterization of Controlled Text Generation","This paper shows that the performance of controlled generation may be poor if the target distribution of text differs from the distribution the predictor was trained on, and takes inspiration from causal representation learning and cast controlled generation under distribution shift as an invariant learning problem.","",2022,"Claudia Shi,Carolina Zheng,Amir Feder,Keyon Vafa,D. Blei",0,36,0
"e5aa2a1e36a2c68fa4aa59afdb8b6e1c419f547c","https://www.semanticscholar.org/paper/e5aa2a1e36a2c68fa4aa59afdb8b6e1c419f547c",4,"Natural Language Deduction through Search over Statement Compositions","This work proposes a system for doing deductive reasoning in natural language by decomposing the task into separate steps coordinated by a search procedure, producing a tree of intermediate conclusions that faithfully reflects the system's reasoning process.","Conference on Empirical Methods in Natural Language Processing",2022,"Kaj Bostrom,Zayne Sprague,Swarat Chaudhuri,Greg Durrett",16,36,3
"de04aa282f8055cebe86966c592bf37af6aecc99","https://www.semanticscholar.org/paper/de04aa282f8055cebe86966c592bf37af6aecc99",4,"The Unreliability of Explanations in Few-Shot In-Context Learning","A framework for calibrating model predictions based on the reliability of explanations is presented and it is shown that explanations judged as good by humans—those that are logically consistent with the input and the prediction—usually indicate more accurate predictions.","ArXiv",2022,"Xi Ye,Greg Durrett",18,57,2
"a3780e8f45b6c1ab3e27c0ad87c3ea23176dc8a7","https://www.semanticscholar.org/paper/a3780e8f45b6c1ab3e27c0ad87c3ea23176dc8a7",4,"The Curious Case of Control","","Conference on Empirical Methods in Natural Language Processing",2022,"Elias Stengel-Eskin,Benjamin Van Durme",0,42,0
"cdc0c46d510fb70367a084e1bf2ee63155b47569","https://www.semanticscholar.org/paper/cdc0c46d510fb70367a084e1bf2ee63155b47569",4,"What does a platypus look like? Generating customized prompts for zero-shot image classification","This work introduces a simple method to generate higher accuracy prompts, without relying on any explicit knowledge of the task domain and with far fewer hand-constructed sentences, and improves accuracy on a range of zero-shot image classiﬁcation benchmarks, including over one percentage point gain on ImageNet.","ArXiv",2022,"Sarah Pratt,Rosanne Liu,Ali Farhadi",7,43,2
"b4fcd453c04dc5312ebb5a33f248c9fbd112cf87","https://www.semanticscholar.org/paper/b4fcd453c04dc5312ebb5a33f248c9fbd112cf87",4,"Selecting Better Samples from Pre-trained LLMs: A Case Study on Question Generation","This case study framed in the context of question generation proposes two prompt-based approaches to selecting high-quality questions from a set of LLM-generated candidates and empirically demon-strate that the proposed approach can effectively select questions of higher qualities than greedy generation.","ArXiv",2022,"Xingdi Yuan,Tong Wang,Yen-Hsiang Wang,Emery Fine,Rania Abdelghani,Pauline Lucas,H'elene Sauz'eon,P. Oudeyer",1,46,0
"ad3dfb2514cb0c899fcb9a14d229ff2a6018892f","https://www.semanticscholar.org/paper/ad3dfb2514cb0c899fcb9a14d229ff2a6018892f",4,"Deep Bidirectional Language-Knowledge Graph Pretraining","D RAGON is proposed, a self-supervised method to pretrain a deeply joint language-knowledge foundation model from text and KG at scale and achieves strong performance on complex reasoning about language and knowledge and low-resource QA and new state-of-the-art results on various BioNLP tasks.","ArXiv",2022,"Michihiro Yasunaga,Antoine Bosselut,Hongyu Ren,Xikun Zhang,Christopher D. Manning,Percy Liang,J. Leskovec",6,87,0
"7a21e72f1f7b3824bf8f33676a99a305ed1558a2","https://www.semanticscholar.org/paper/7a21e72f1f7b3824bf8f33676a99a305ed1558a2",4,"Prompting Language Models for Linguistic Structure","This work presents a structured prompting approach that can be used to prompt for linguistic structure prediction tasks, allowing it to perform zero-and few-shot sequence tagging with autoregressive PLMs and shows that structured prompting can retrieve linguistic structure even with arbitrary labels.","ArXiv",2022,"Terra Blevins,Hila Gonen,Luke Zettlemoyer",0,44,0
"b562be15b076b494023b8ac24fc8c459f4fdf80a","https://www.semanticscholar.org/paper/b562be15b076b494023b8ac24fc8c459f4fdf80a",4,"Craft an Iron Sword: Dynamically Generating Interactive Game Characters by Prompting Large Language Models Tuned on Code","It is demonstrated that use of a few example conversational prompts can power a conversational agent to generate both natural language and novel code, which can permit development of NPCs with which players can have grounded conversations that are free-form and less repetitive.","WORDPLAY",2022,"Ryan Volum,Sudha Rao,Michael Xu,Gabriel DesGarennes,Chris Brockett,Benjamin Van Durme,Olivia Deng,Akanksha Malhotra,Bill Dolan",3,21,1
"f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c","https://www.semanticscholar.org/paper/f9d38e03c97562b5f5942f3a0c43bdb751b9dc1c",4,"Wordplay 2022 The 3rd Wordplay: When Language Meets Games Workshop Proceedings of the Workshop","Novel techniques to generate text in a particular style are described, providing an approach of generating engaging naturalistic conversation responses using knowledge generated by pre-trained language models, considering their recent success in a multitude of NLP tasks.","",2022,"Shrimai Prabhumoye",0,67,0
"c6bb04f3d8000b7e800f6359082de39548c7da79","https://www.semanticscholar.org/paper/c6bb04f3d8000b7e800f6359082de39548c7da79",4,"Capturing Structural Locality in Non-parametric Language Models","This paper proposes a simple yet effective approach for adding locality information into non-parametric language models by adding learned parameters that improve the likelihood of retrieving examples from local neighborhoods.","International Conference on Learning Representations",2021,"Frank F. Xu,Junxian He,Graham Neubig,V. Hellendoorn",5,47,0
"4a4581003f56e8cb581ad6f383c037964765d3d5","https://www.semanticscholar.org/paper/4a4581003f56e8cb581ad6f383c037964765d3d5",4,"Active Programming by Example with a Natural Language Prior","APEL, a new framework that enables non-programmers to indirectly annotate natural language utterances with executable meaning representations, such as SQL programs, is introduced, to reduce effort required from annotators and synthesize simple input databases that nonetheless have high information gain.","ArXiv",2022,"Ruiqi Zhong,Charles Burton Snell,D. Klein,Jason Eisner",2,60,0
"7107d06366b48b3593c8128ed2ca67e0b413628c","https://www.semanticscholar.org/paper/7107d06366b48b3593c8128ed2ca67e0b413628c",4,"Learning Math Reasoning from Self-Sampled Correct and Partially-Correct Solutions","It is shown that the use of self-sampled correct and partially-correct solutions can benefit learning and help guide the sampling process, leading to more efficient exploration of the solution space and the effectiveness of the method is shown.","",2022,"Ansong Ni,J. Inala,Chenglong Wang,Oleksandr Polozov,Christopher Meek,Dragomir R. Radev,Jianfeng Gao",0,28,0
"35afb74de9660962ebac2843d26de22a6fac2ef6","https://www.semanticscholar.org/paper/35afb74de9660962ebac2843d26de22a6fac2ef6",4,"Learning from Self-Sampled Correct and Partially-Correct Programs","This work proposes to let the model perform sampling during training and learn from both self-sampled fully-Correct programs, which yield the gold execution results, as well as partially-correct programs, whose intermediate execution state matches another correct program.","ArXiv",2022,"Ansong Ni,J. Inala,Chenglong Wang,Oleksandr Polozov,Christopher Meek,Dragomir R. Radev,Jianfeng Gao",5,28,3
"40edfa97cd02268fccff75eb9c693b11c1a968b2","https://www.semanticscholar.org/paper/40edfa97cd02268fccff75eb9c693b11c1a968b2",4,"Formal Specifications from Natural Language","These experiments show that language models maintain their generalization capabilities from pre-trained knowledge of natural language to generalize, e.g., to new variable names or operator descriptions, and achieve competitive performance, and even outperform the state-of-the-art for translating into regular expressions.","ArXiv",2022,"Christopher Hahn,Frederik Schmitt,Julia J. Tillman,Niklas Metzger,Julian Siber,B. Finkbeiner",1,97,0
"075b6fb7d3787953164eecc1bd2e13f97c9f3c44","https://www.semanticscholar.org/paper/075b6fb7d3787953164eecc1bd2e13f97c9f3c44",4,"Fault-Aware Neural Code Rankers","C ODE R ANKER is a neural ranker that can predict the correctness of a sampled program without executing it and can signiﬁcantly increase the pass@1 accuracy of various code generation models on APPS, HumanEval, and MBPP datasets.","ArXiv",2022,"J. Inala,Chenglong Wang,Mei Yang,Andrés Codas,Mark Encarnaci'on,Shuvendu K. Lahiri,M. Musuvathi,Jianfeng Gao",7,41,2
"3ba793e937cb90ea3e82b4a6903ee4a95f307ddf","https://www.semanticscholar.org/paper/3ba793e937cb90ea3e82b4a6903ee4a95f307ddf",4,"X-Risk Analysis for AI Research","A collection of time-tested concepts from hazard analysis and systems safety, which have been designed to steer large processes in safer directions are reviewed, to discuss how AI researchers can realistically have long-term impacts on the safety of AI systems.","ArXiv",2022,"Dan Hendrycks,Mantas Mazeika",12,77,1
"780f7eebde16b1ae5843df3a79a7772899ef6a71","https://www.semanticscholar.org/paper/780f7eebde16b1ae5843df3a79a7772899ef6a71",4,"MultiPL-E: A Scalable and Extensible Approach to Benchmarking Neural Code Generation","This work creates the first massively multilingual code generation benchmark by using MultiPL-E to translate two popular Python code generation benchmarks to 18 additional programming languages and evaluates the multi-language performance of three state-of-the-art code generation models.","",2022,"Federico Cassano,John Gouwar,Daniel Nguyen,S. Nguyen,Luna Phipps-Costin,Donald Pinckney,Ming-Ho Yee,Yangtian Zi,Carolyn Jane Anderson,Molly Q. Feldman,Arjun Guha,M. Greenberg,Abhinav Jangda",0,42,0
"6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a","https://www.semanticscholar.org/paper/6b5d1e50894b1f28e4798cf20e9ffa88b9ec011a",4,"How to Prompt? Opportunities and Challenges of Zero- and Few-Shot Learning for Human-AI Interaction in Creative Applications of Generative Models","This work discusses the key opportunities and challenges for interactive creative applications that use prompting as a new paradigm for Human-AI interaction and proposes four design goals for user interfaces that support prompting.","ArXiv",2022,"Hai Dang,Lukas Mecke,Florian Lehmann,Sven Goller,D. Buschek",2,22,0
"0b8772b7790c69f40897b5eb7f8fd57f24138f3d","https://www.semanticscholar.org/paper/0b8772b7790c69f40897b5eb7f8fd57f24138f3d",4,"ContraGen: Effective Contrastive Learning For Causal Language Model","It is shown that C ONTRA G EN can effectively enhance both uniformity and discrimination of the representations and lead to the desired improvement on various language understanding tasks where discriminative representations are crucial for attaining good performance.","ArXiv",2022,"Nihal Jain,Dejiao Zhang,Wasi Uddin Ahmad,Zijian Wang,Feng Nan,Xiaopeng Li,M. Tan,Ramesh Nallapati,Baishakhi Ray,Parminder Bhatia,Xiaofei Ma,Bing Xiang",0,66,0
"c140fe515de2f20d0c85c813c7b3ec1defc41f9d","https://www.semanticscholar.org/paper/c140fe515de2f20d0c85c813c7b3ec1defc41f9d",4,"Binding Language Models in Symbolic Languages","","ArXiv",2022,"Zhoujun Cheng,Tianbao Xie,Peng Shi,Chengzu Li,R.K. Nadkarni,Yushi Hu,Caiming Xiong,Dragomir R. Radev,M. Ostendorf,Luke Zettlemoyer,N. A. Smith,Tao Yu",17,58,1
"39e40821b7207125e54e6ed7112e55cd38c6f0c3","https://www.semanticscholar.org/paper/39e40821b7207125e54e6ed7112e55cd38c6f0c3",4,"Language Models of Code are Few-Shot Commonsense Learners","This paper shows that when this task is frame as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than L Ms of natural language, even when the downstream task does not involve source code at all.","Conference on Empirical Methods in Natural Language Processing",2022,"Aman Madaan,Shuyan Zhou,Uri Alon,Yiming Yang,Graham Neubig",13,38,1
"6d4a12ea469ff08634eeb24c47b265a7dca2fce2","https://www.semanticscholar.org/paper/6d4a12ea469ff08634eeb24c47b265a7dca2fce2",4,"PADL: Language-Directed Physics-Based Character Control","PADL, which leverages recent innovations in NLP in order to take steps towards developing language-directed controllers for physics-based character animation, is presented and it is shown that the framework can be applied to effectively direct a simulated humanoid character to perform a diverse array of complex motor skills.","ACM SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia",2022,"Jordan Juravsky,Yunrong Guo,S. Fidler,X. B. Peng",0,71,0
"d6d90a28b2b4ceb9b81150b5bd498541d5d9aa89","https://www.semanticscholar.org/paper/d6d90a28b2b4ceb9b81150b5bd498541d5d9aa89",4,"Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments","This paper formalizes prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and ﬁne-Grained classiﬁcation, and employs three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection.","ArXiv",2022,"Zhivar Sourati,Vishnu Priya Prasanna Venkatesh,D. Deshpande,Himanshu Rawlani,Filip Ilievski,Hong-An Sandlin,Alain Mermoud",0,132,0
"b8d06dd769f89d08bdd9997d7bd363c89ede845b","https://www.semanticscholar.org/paper/b8d06dd769f89d08bdd9997d7bd363c89ede845b",4,"ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models","This work proposes Z ERO TOP, a zero-shot task-oriented parsing method that decomposes a semantic parsing problem into a set of abstractive and extractive question-answering (QA) problems, enabling us to leverage the ability of LLMs to zero- shot answer reading comprehension questions.","ArXiv",2022,"Dheeraj Mekala,J. Wolfe,Subhro Roy",0,29,0
"5435ed7c26f0c250493f244acffb69dd929d116b","https://www.semanticscholar.org/paper/5435ed7c26f0c250493f244acffb69dd929d116b",4,"Structured Case-based Reasoning for Inference-time Adaptation of Text-to-SQL parsers","StructCBR is posed, a structured case-based reasoning approach, which leverages subtree-level similarity between logical forms of cases and candidate outputs, resulting in better decoder deci-sions and consistent performance improvements over prior inference-time adaptation methods.","ArXiv",2023,"Abhijeet Awasthi,Soumen Chakrabarti,Sunita Sarawagi",0,42,0
"1f22de83d912176cb8857efa1c6d65b14d6a2f5c","https://www.semanticscholar.org/paper/1f22de83d912176cb8857efa1c6d65b14d6a2f5c",4,"ChatGPT is not all you need. A State of the Art Review of large Generative AI models","This work consists on an attempt to describe in a concise way the main models are sectors that aresector that are aﬀected by generative AI and to provide a taxonomy of the main generative models published recently.","ArXiv",2023,"Roberto Gozalo-Brizuela,E.C. Garrido-Merchán",7,34,0
"8927db4ee890bf42608752bb840bc9d7db556da1","https://www.semanticscholar.org/paper/8927db4ee890bf42608752bb840bc9d7db556da1",4,"ChatGPT and Software Testing Education: Promises & Perils","How well ChatGPT performs when tasked with solving common questions in a popular software testing curriculum is examined, and the potential promise, and dangers related to the use ofChatGPT by students and instructors are discussed.","ArXiv",2023,"Sajed Jalil,Suzzana Rafi,Thomas D. LaToza,Kevin Moran,Wing Lam",0,25,0
"98207fea68db75d3941577ef87d685944519e09c","https://www.semanticscholar.org/paper/98207fea68db75d3941577ef87d685944519e09c",4,"Reliable Natural Language Understanding with Large Language Models and Answer Set Programming","This work shows how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language, and proposes STAR, a framework that combines LLMs with Answer Set Programming (ASP) to bridge the gap of reasoning in NLU tasks.","ArXiv",2023,"Abhiramon Rajasekharan,Yankai Zeng,Parth Padalkar,Gopal Gupta",0,27,0
"7677e9ead35f8f2578acbf5ad15fb330c83762c4","https://www.semanticscholar.org/paper/7677e9ead35f8f2578acbf5ad15fb330c83762c4",4,"Systematically Finding Security Vulnerabilities in Black-Box Code Generation Models","This work proposes a novel black-box inversion approach based on few-shot prompting that automatically and systematically finds 1000s of security vulnerabilities in various code generation models, including the commercial black- box model GitHub Copilot.","ArXiv",2023,"Hossein Hajipour,Thorsten Holz,Lea Schonherr,Mario Fritz",0,45,0
"5e2bceb56f116e98baf7e418208057bc0e1c1861","https://www.semanticscholar.org/paper/5e2bceb56f116e98baf7e418208057bc0e1c1861",4,"ConceptFusion: Open-set Multimodal 3D Mapping","ConceptFusion enables effective zero-shot spatial reasoning, not needing any additional training or finetuning, and retains long-tailed concepts better than supervised approaches, outperforming them by more than 40% margin on 3D IoU.","",2023,"Krishna Murthy Jatavallabhula,Ali Kuwajerwala,Qiao Gu,Mohd Omama,Tao Chen,Shuang Li,Ganesh Iyer,Soroush Saryazdi,Nikhil Varma Keetha,Ayush Tewari,J. Tenenbaum,Celso M. de Melo,M. Krishna,L. Paull,F. Shkurti,A. Torralba",0,79,0
"6487a26c6a1afbf3880d87010684094aa856c71c","https://www.semanticscholar.org/paper/6487a26c6a1afbf3880d87010684094aa856c71c",4,"Train Hard, Fight Easy: Robust Meta Reinforcement Learning","Robust Meta RL algorithm ( RoML) is a meta-algorithm that generates a robust version of any given MRL algorithm, by identifying and over-sampling harder tasks throughout training, and achieves robust returns on several navigation and continuous control benchmarks.","ArXiv",2023,"Ido Greenberg,Shie Mannor,Gal Chechik,E. Meirom",0,44,0
"c715b3b607445998acc869633a4fde32e1933fa2","https://www.semanticscholar.org/paper/c715b3b607445998acc869633a4fde32e1933fa2",4,"On the principles of Parsimony and Self-consistency for the emergence of intelligence","A theoretical framework is proposed that sheds light on understanding deep networks within a bigger picture of intelligence in general and introduces two fundamental principles, Parsimony and Self-consistency, which address two fundamental questions regarding intelligence: what to learn and how to learn, respectively.","Frontiers of Information Technology & Electronic Engineering",2022,"Y. Ma,Doris Y. Tsao,H. Shum",17,150,1
"2f440b3771db1adb578044f9cee914aaff328239","https://www.semanticscholar.org/paper/2f440b3771db1adb578044f9cee914aaff328239",4,"A rubric for human-like agents and NeuroAI","This paper proposes that a closer look at research in recent decades reveals three main dimensions of goals and contributions across these fields: a commitment to achieving agents with human-like (or animal-like) behaviour, neural plausibility, or to solving specific computer science or engineering problems.","Philosophical Transactions of the Royal Society of London. Biological Sciences",2022,"I. Momennejad",0,185,0
"65bad077608a3c2ed8eac242e993aa40aa8c13e9","https://www.semanticscholar.org/paper/65bad077608a3c2ed8eac242e993aa40aa8c13e9",4,"QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation","It is demonstrated that Retrieval Augmentation of queries provides LLMs with valuable additional context enabling improved understanding, and the proposed approach (QUILL) on a billion-scale, real-world query understanding system resulting in huge gains is demonstrated.","ArXiv",2022,"Krishna Srinivasan,K. Raman,Anupam Samanta,Ling-Yen Liao,L. Bertelli,Michael Bendersky",0,32,0
"c7fc4c09a18bf0c26d04fc69f5567bfd3ac0c8f6","https://www.semanticscholar.org/paper/c7fc4c09a18bf0c26d04fc69f5567bfd3ac0c8f6",4,"Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language Understanding","This work provides a more general and complete formulation of the comparison principle and comparative loss, and directly uses a unified comparative loss as the final loss being optimized, eliminating the need to set a weighting coefficient between the comparative regularization term and the task-specific losses.","ArXiv",2023,"Yunchang Zhu,Liang Pang,Kangxi Wu,Yanyan Lan,Huawei Shen,Xueqi Cheng",0,72,0
"931e2f94e44f3799612118ac0de54073783d9130","https://www.semanticscholar.org/paper/931e2f94e44f3799612118ac0de54073783d9130",4,"Link the World: Improving Open-domain Conversation with Dynamic Spatiotemporal-aware Knowledge","Through automatic and human evaluations, it is found that service information improves the consistency, informativeness, factuality, and engagingness of the dialogue system, making it behave more like a human.","",2022,"Han Zhou,Xinchao Xu,Wenquan Wu,Zheng-Yu Niu,Hua Wu,Siqi Bao,Fan Wang,Haifeng Wang",1,30,0
"c1614ab718dad97018ee34fd57864bb58b6ecaba","https://www.semanticscholar.org/paper/c1614ab718dad97018ee34fd57864bb58b6ecaba",4,"Knowledge-grounded Dialog State Tracking","This work queries relevant knowledge of various forms based on the dialog context where such information can ground the prediction of dialog states, and demonstrates superior performance of the proposed method over strong baselines, especially in the few-shot learning setting.","Conference on Empirical Methods in Natural Language Processing",2022,"Dian Yu,Mingqiu Wang,Yuan Cao,I. Shafran,Laurent El Shafey,H. Soltau",0,45,0
"b8b813111c411ae61881ab9cd25707d9de6444ec","https://www.semanticscholar.org/paper/b8b813111c411ae61881ab9cd25707d9de6444ec",4,"Compositional Attention: Disentangling Search and Retrieval","This work proposes a novel attention mechanism, called Compositional Attention, that replaces the standard head structure, and demonstrates that it outperforms standard multi-head attention on a variety of tasks, including some out-of-distribution settings.","International Conference on Learning Representations",2021,"Sarthak Mittal,Sharath Chandra Raparthy,I. Rish,Yoshua Bengio,Guillaume Lajoie",8,45,1
"4f451ba06c4c9effd6c4ac0bae222495501a6200","https://www.semanticscholar.org/paper/4f451ba06c4c9effd6c4ac0bae222495501a6200",4,"Innovations in Neural Data-to-text Generation","This survey draws boundaries separating DTG from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella.","ArXiv",2022,"Mandar Sharma,Ajay K. Gogineni,Naren Ramakrishnan",1,347,0
"72e6b14c081ad3e6a1c295b60e5c834837e6b304","https://www.semanticscholar.org/paper/72e6b14c081ad3e6a1c295b60e5c834837e6b304",4,"Towards Question Format Independent Numerical Reasoning: A Set of Prerequisite Tasks","This work introduces NUMBERGAME, a multifaceted benchmark to evaluate model performance across numerical reasoning tasks of eight diverse formats, and takes forward the recent progress in generic system development, demonstrating the scope of under-explored tasks.","ArXiv",2020,"Swaroop Mishra,Arindam Mitra,Neeraj Varshney,Bhavdeep Singh Sachdeva,Chitta Baral",10,45,1
"d9e0b07313a04b033a9f2dcc74c41b2bed8c3614","https://www.semanticscholar.org/paper/d9e0b07313a04b033a9f2dcc74c41b2bed8c3614",4,"Explanations for CommonsenseQA: New Dataset and Models","This work human-annotates a first-of-its-kind dataset of positive and negative properties, as well as free-flow explanations, for 11K QA pairs taken from the CQA dataset, and proposes a latent representation based property retrieval model aswell as a GPT-2 based property generation model with a novel two step fine-tuning procedure.","Annual Meeting of the Association for Computational Linguistics",2021,"Shourya Aggarwal,Divyanshu Mandowara,Vishwajeet Agrawal,Dinesh Khandelwal,Parag Singla,Dinesh Garg",31,47,8
"57d1e7ac339e783898f2c3b1af55737cbeee9fc5","https://www.semanticscholar.org/paper/57d1e7ac339e783898f2c3b1af55737cbeee9fc5",4,"Measuring Mathematical Problem Solving With the MATH Dataset","This work introduces MATH, a new dataset of 12, 500 challenging competition mathematics problems which can be used to teach models to generate answer derivations and explanations, and shows that accuracy remains relatively low, even with enormous Transformer models.","NeurIPS Datasets and Benchmarks",2021,"Dan Hendrycks,Collin Burns,Saurav Kadavath,Akul Arora,Steven Basart,Eric Tang,D. Song,J. Steinhardt",91,65,20
"c09ebcb1ca6ad1eced57340f3e81e456416ed185","https://www.semanticscholar.org/paper/c09ebcb1ca6ad1eced57340f3e81e456416ed185",4,"A Systematic Investigation of Commonsense Knowledge in Large Language Models","This work conducts a systematic and rigorous zero-shot and few-shot commonsense evaluation of large pre-trained LMs, where it carefully controls for the LMs’ ability to exploit potential surface cues and annotation artefacts and accounts for variations in performance that arise from factors that are not related to commonsense knowledge.","Conference on Empirical Methods in Natural Language Processing",2021,"Xiang Lorraine Li,A. Kuncoro,Jordan Hoffmann,Cyprien de Masson d'Autume,P. Blunsom,Aida Nematzadeh",1,64,0
"2b5d234efd26e7377698cf16c901601a3d3c4e56","https://www.semanticscholar.org/paper/2b5d234efd26e7377698cf16c901601a3d3c4e56",4,"CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities","It is argued that by curating and analyzing large interaction datasets, the HCI community can foster more incisive examinations of LMs’ generative capabilities, and presents CoAuthor, a dataset designed for revealing GPT-3’s capabilities in assisting creative and argumentative writing.","International Conference on Human Factors in Computing Systems",2022,"Mina Lee,Percy Liang,Qian Yang",38,73,2
"acbe813244e07f32eb034d6c27547d772a995d1d","https://www.semanticscholar.org/paper/acbe813244e07f32eb034d6c27547d772a995d1d",4,"Uncertainty Estimation for Language Reward Models","It is found that in this setting ensemble active learning does not outperform random sampling, and current pre-training methods will need to be modified to support uncertainty estimation, e.g. by training multiple language models.","ArXiv",2022,"A. Gleave,Geoffrey Irving",7,55,4
"2aba5bba16dac5cd62683bab9de5d6faaaed0de1","https://www.semanticscholar.org/paper/2aba5bba16dac5cd62683bab9de5d6faaaed0de1",4,"Shepherd Pre-trained Language Models to Develop a Train of Thought: An Iterative Prompting Approach","An iterative prompting framework, a new prompting paradigm which progressively elicits relevant knowledge from PLMs for multi-step inference tasks, and proposes an iterative context-aware prompter, which addresses limitations by learning to dynamically synthesize prompts conditioned on the current step’s contexts.","ArXiv",2022,"Boshi Wang,Xiang Deng,Huan Sun",4,44,2
"7ef9aafc68511afab5b287e62b754576ea37b4ce","https://www.semanticscholar.org/paper/7ef9aafc68511afab5b287e62b754576ea37b4ce",4,"Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks","A hybrid Parse-and-Solve model is proposed, which augments distributional LLMs with a symbolic reasoning module, and shows more robust adaptation to out-of-distribution plan- ning problems, demonstrating the promise of hybrid AI models for more human-like reasoning.","ArXiv",2022,"K. M. Collins,Catherine Wong,Jiahai Feng,Megan Wei,J. Tenenbaum",3,19,1
"750448e5d852ec0a2e4f7f809f16a1470b2b479b","https://www.semanticscholar.org/paper/750448e5d852ec0a2e4f7f809f16a1470b2b479b",4,"StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models","It is shown that parametric models can be updated without full retraining, while avoiding catastrophic forgetting, and for semi-parametric models, adding new articles into the search space allows for rapid adaptation, however, models with an outdated underlying LM under-perform those with a retrained LM.","International Conference on Machine Learning",2022,"Adam Livska,Tom'avs Kovcisk'y,E. Gribovskaya,Tayfun Terzi,Eren Sezener,Devang Agrawal,Cyprien de Masson d'Autume,Tim Scholtes,M. Zaheer,Susannah Young,Ellen Gilsenan-McMahon,Sophia Austin,P. Blunsom,Angeliki Lazaridou",6,38,0
"1a7a24c73521eecf0a2d555e921b27e2c4d8e3c3","https://www.semanticscholar.org/paper/1a7a24c73521eecf0a2d555e921b27e2c4d8e3c3",4,"What Artificial Neural Networks Can Tell Us About Human Language Acquisition","Before language learning requires more prior domain-speciﬁc knowledge than current models possess, non-linguistic inputs in the form of multimodal stimuli and multi-agent interaction are explored as ways to make learners morecient at learning from limited linguistic input.","ArXiv",2022,"Alex Warstadt,Samuel R. Bowman",8,174,0
"ace4d199aa72ab0808af0f30a61fc16727c95dec","https://www.semanticscholar.org/paper/ace4d199aa72ab0808af0f30a61fc16727c95dec",4,"AudioLM: a Language Modeling Approach to Audio Generation","The proposed hybrid tokenization scheme leverages the discretized activations of a masked language model pre-trained on audio to capture long-term structure and the discrete codes produced by a neural audio codec to achieve high-quality synthesis.","ArXiv",2022,"Zalán Borsos,Raphaël Marinier,Damien Vincent,E. Kharitonov,O. Pietquin,Matthew Sharifi,O. Teboul,David Grangier,M. Tagliasacchi,Neil Zeghidour",34,64,4
"4403bb8e839e175142b877222ff736cf949f232e","https://www.semanticscholar.org/paper/4403bb8e839e175142b877222ff736cf949f232e",4,"A Code Centric Evaluation of C/C++ Vulnerability Datasets for Deep Learning Based Vulnerability Detection Techniques","This work aims to propose code-centric features that are relevant to security program analysis tasks like vulnerability detection and a thorough examination of the existing code datasets that demonstrate the main characteristics of the individual datasets to have a clear comparison.","",2023,"Ridhi Jain,Nicole Gervasoni,Mthandazo Ndhlovu,Sanjay Rawat",0,40,0
"07d7965b04d8e4bfb21faeb3ffe2524753c7ab7a","https://www.semanticscholar.org/paper/07d7965b04d8e4bfb21faeb3ffe2524753c7ab7a",4,"Exploring Fluent Query Reformulations with Text-to-Text Transformers and Reinforcement Learning","This work explores methods to generate query reformulations by training reformulators using text-to-text transformers and applies policy-based reinforcement learning algorithms to further encourage reward learning.","ArXiv",2020,"Jerry Zikun Chen,S. Yu,Haoran Wang",3,68,0
"553b3d53dff9a36f1266c5c97ad09e0c0e8b51d7","https://www.semanticscholar.org/paper/553b3d53dff9a36f1266c5c97ad09e0c0e8b51d7",4,"Generative Context Pair Selection for Multi-hop Question Answering","This work proposes a generative context selection model for multi-hop QA that reasons about how the given question could have been generated given a context pair and not just independent contexts and shows that on HotpotQA, the proposed generative passage selection model has a better performance than state-of-the-art answering performance.","Conference on Empirical Methods in Natural Language Processing",2021,"Dheeru Dua,C. D. Santos,Patrick Ng,Ben Athiwaratkun,Bing Xiang,Matt Gardner,Sameer Singh",2,34,0
"723fcade538f71df5fe5d1cde279686240f97b9f","https://www.semanticscholar.org/paper/723fcade538f71df5fe5d1cde279686240f97b9f",4,"A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models","This is the first survey paper to summarize CTG techniques from the perspective of PLMs, and it is hoped it can help researchers in related fields to quickly track the academic frontier, providing them with a landscape of the area and a roadmap for future research.","ArXiv",2022,"Han Zhang,Haolin Song,Shaoyu Li,Ming Zhou,Dawei Song",27,203,2
"492a655a67e6ec7423a968cedb70eec0cdbc8e98","https://www.semanticscholar.org/paper/492a655a67e6ec7423a968cedb70eec0cdbc8e98",4,"A Contrastive Framework for Neural Text Generation","This work shows that an underlying reason for model degeneration is the anisotropic distribution of token representations, and presents a contrastive solution that outperforms state-of-the-art text generation methods as evaluated by both human and automatic metrics.","ArXiv",2022,"Yixuan Su,Tian Lan,Yan Wang,Dani Yogatama,Lingpeng Kong,N. Collier",31,79,8
"75a5a50865b32d600ac18267746d376de7738ce8","https://www.semanticscholar.org/paper/75a5a50865b32d600ac18267746d376de7738ce8",4,"Recent Advances in Neural Text Generation: A Task-Agnostic Survey","A task-agnostic survey of recent advances in neural text generation is presented, which group under the following four headings: data construction, neural frameworks, training and inference strategies, and evaluation metrics.","ArXiv",2022,"Cheng Tang,Frank Guerin,Yucheng Li,Chenghua Lin",6,262,0
"c9f48406851954cb098911eccb4124ea5f966675","https://www.semanticscholar.org/paper/c9f48406851954cb098911eccb4124ea5f966675",4,"A Survey on Multi-hop Question Answering and Generation","A general and formal definition of MHQA task is provided, the existing attempts to this highly interesting, yet quite challenging task are summarized, and the best methods to createMHQA datasets are outlined.","ArXiv",2022,"Vaibhav Mavi,Anubhav Jangra,A. Jatowt",5,183,0
"47e15941c8b157873c8264e4bf50318d1ba5cd18","https://www.semanticscholar.org/paper/47e15941c8b157873c8264e4bf50318d1ba5cd18",4,"Natural Language to Code Translation with Execution","This work introduces execution result–based minimum Bayes risk decoding (MBR-EXEC) for program selection and finds that it consistently improves over all execution-unaware selection methods, suggesting it as an effective approach for natural language to code translation.","Conference on Empirical Methods in Natural Language Processing",2022,"Freda Shi,Daniel Fried,Marjan Ghazvininejad,Luke Zettlemoyer,Sida I. Wang",15,47,5
"23447f473cd240494b0a20ea008038aaef7e3391","https://www.semanticscholar.org/paper/23447f473cd240494b0a20ea008038aaef7e3391",4,"RankGen: Improving Text Generation with Large Ranking Models","RankGen, a 1.2B parameter encoder model for English that scores model generations given a prefix that significantly outperforms decoding algorithms like nucleus, top-k, and typical sampling on both automatic metrics and human evaluations with English writers.","Conference on Empirical Methods in Natural Language Processing",2022,"Kalpesh Krishna,Yapei Chang,J. Wieting,Mohit Iyyer",11,126,2
"32e3ef76772229106747613606021afc5937968a","https://www.semanticscholar.org/paper/32e3ef76772229106747613606021afc5937968a",4,"Multimodal Knowledge Alignment with Reinforcement Learning","This work proposes ESPER, a novel approach to reinforcement learning which extends language-only zero-shot models to unseen multimodal tasks, like image and audio captioning, and demonstrates that it outperforms baselines and prior work on a variety of zero- shot tasks.","ArXiv",2022,"Youngjae Yu,Jiwan Chung,Heeseung Yun,Jack Hessel,J. Park,Ximing Lu,Prithviraj Ammanabrolu,Rowan Zellers,Ronan Le Bras,Gunhee Kim,Yejin Choi",4,81,1
"2098244c530933e92cbb72217e43b918dce25e23","https://www.semanticscholar.org/paper/2098244c530933e92cbb72217e43b918dce25e23",4,"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples","A major security vulnerability is highlighted in the public release of GPT-3 and this work underscores token distance-minimized perturbations as an effective adversarial approach, bypassing both supervised and unsupervised quality measures.","ArXiv",2022,"Hezekiah J. Branch,Jonathan Rodriguez Cefalu,Jeremy McHugh,Leyla Hujer,Aditya Bahl,Daniel del Castillo Iglesias,Ron Heichman,Ramesh Darwishi",2,43,0
"891db4adb6d10a51882430ab1266f51e6e3408c5","https://www.semanticscholar.org/paper/891db4adb6d10a51882430ab1266f51e6e3408c5",4,"Augmenting Multi-Turn Text-to-SQL Datasets with Self-Play","Self-play improves the accuracy of a strong baseline on SParC and CoSQL, two widely used cross-domain text-to-SQL datasets, and enhances cross- domain generalization and improves beam-search.","Conference on Empirical Methods in Natural Language Processing",2022,"Qi Liu,Zihuiwen Ye,Tao Yu,P. Blunsom,Linfeng Song",0,56,0
"9e8b29d025cd2718ff61b363ce1c1f422d612303","https://www.semanticscholar.org/paper/9e8b29d025cd2718ff61b363ce1c1f422d612303",4,"Learning General World Models in a Handful of Reward-Free Deployments","This work introduces the reward-free deployment efﬁciency setting, a new paradigm for RL research, and presents CASCADE, a novel approach for self-supervised exploration in this new setting, using an information theoretic objective inspired by Bayesian Active Learning.","ArXiv",2022,"Yingchen Xu,Jack Parker-Holder,Aldo Pacchiano,Philip J. Ball,Oleh Rybkin,Stephen J. Roberts,Tim Rocktaschel,Edward Grefenstette",0,121,0
"27202f962798d08b39601a36127360c5ccd9c625","https://www.semanticscholar.org/paper/27202f962798d08b39601a36127360c5ccd9c625",4,"Knowledge Transfer from Answer Ranking to Answer Generation","This paper proposes to train a GenQA model by transferring knowledge from a trained AS2 model, and proposes to use the As2 model prediction scores for loss weighting and score-conditioned input/output shaping, to aid the knowledge transfer.","Conference on Empirical Methods in Natural Language Processing",2022,"Matteo Gabburo,Rik Koncel-Kedziorski,Siddhant Garg,Luca Soldaini,Alessandro Moschitti",0,51,0
"97833e2aa0da5240e62436373b58af988a4ab6ab","https://www.semanticscholar.org/paper/97833e2aa0da5240e62436373b58af988a4ab6ab",4,"The Curious Case of Absolute Position Embeddings","It is observed that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information, which raises questions about the efficacy of APEs to model the relativity of position information.","Conference on Empirical Methods in Natural Language Processing",2022,"Koustuv Sinha,Amirhossein Kazemnejad,Siva Reddy,J. Pineau,D. Hupkes,Adina Williams",2,56,0
"36543b4441c9d88b57b06a7ba887f409afd8141d","https://www.semanticscholar.org/paper/36543b4441c9d88b57b06a7ba887f409afd8141d",4,"Does Self-Rationalization Improve Robustness to Spurious Correlations?","It is found that while self-rationalization can improve robustness to spurious correlations in low-resource settings, it tends to hurt robustness in higher- resource settings, and appropriate care should be taken when training self- rationalizing models with the goal of creating more trustworthy models.","Conference on Empirical Methods in Natural Language Processing",2022,"Alexis Ross,Matthew E. Peters,Ana Marasović",0,44,0
"6f39c929df030c85f1d5aa029f21a6fedd9f92c8","https://www.semanticscholar.org/paper/6f39c929df030c85f1d5aa029f21a6fedd9f92c8",4,"SSD-LM: Semi-autoregressive Simplex-based Diffusion Language Model for Text Generation and Modular Control","S SD -LM is semi-autoregressive, iteratively generating blocks of text, allowing for ﬂexible output length at decoding time while enabling local bidirectional context updates, and is simplex-based, performing diffusion on the natural vocabulary space rather than a learned latent space, allowing to incorporate classiﬁer guidance and modular control without any adaptation of off-the-shelf classi ﬁers.","ArXiv",2022,"Xiaochuang Han,Sachin Kumar,Yulia Tsvetkov",4,82,1
"0f7a6c557e376d8c77d684bcda0daee74fc29acf","https://www.semanticscholar.org/paper/0f7a6c557e376d8c77d684bcda0daee74fc29acf",4,"Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation","This work treats the generated knowledge as a noisy knowledge source and proposes the posterior-based reweighing as well as the noisy training strategy to better exploit such generated knowledge in dialogue generation.","Conference on Empirical Methods in Natural Language Processing",2022,"Yanyang Li,Jianqiao Zhao,M. Lyu,Liwei Wang",0,45,0
"bcec7d17e68aceb91d020dd796ece075694f77c6","https://www.semanticscholar.org/paper/bcec7d17e68aceb91d020dd796ece075694f77c6",4,"COPEN: Probing Conceptual Knowledge in Pre-trained Language Models","Inspired by knowledge representation schemata, this work comprehensively evaluates conceptual knowledge of PLMs by designing three tasks to probe whether PLMs organize entities by conceptual similarities, learn conceptual properties, and conceptualize entities in contexts, respectively.","Conference on Empirical Methods in Natural Language Processing",2022,"Hao Peng,Xiaozhi Wang,Shengding Hu,Hailong Jin,Lei Hou,Juanzi Li,Zhiyuan Liu,Qun Liu",0,64,0
"0bacfdef9db436b2fdf686dfc90d780df5a51a15","https://www.semanticscholar.org/paper/0bacfdef9db436b2fdf686dfc90d780df5a51a15",4,"Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control","This work tackles the problem of generating text following arbitrary distributions by proposing N ANO, a few-shot human-in-the-loop training algorithm that continuously learns from human feedback that achieves state-of- the-art results on single topic/attribute as well as quantiﬁed distribution control compared to previous works.","ArXiv",2022,"Xiang Fan,Yiwei Lyu,Paul Pu Liang,R. Salakhutdinov,Louis-Philippe Morency",1,60,0
"0b871a9f12e5c2da1b291a8b166c671256ebe1cd","https://www.semanticscholar.org/paper/0b871a9f12e5c2da1b291a8b166c671256ebe1cd",4,"A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural Machine Translation","This work proposes to integrate a copy mechanism for neural SPARQL query generation by adding a copy layer and a dynamic knowledge base vocabulary to two Seq2Seq architectures (CNNs and Transform-ers) that makes the models copy KB elements directly from the questions, instead of generating them.","AACL/IJCNLP",2022,"Rose Hirigoyen,A. Zouaq,Samuel Reyd",0,26,0
"0e1f80a3f52c9051026656f00e31c0b9c1428d7a","https://www.semanticscholar.org/paper/0e1f80a3f52c9051026656f00e31c0b9c1428d7a",4,"Can language models automate data wrangling?","A major finding is that language models appear as a powerful tool for a wide range of data wrangling tasks, and some guidelines about how they can be integrated into data processing pipelines are provided, provided the users can take advantage of their flexibility and the diversity of tasks to be addressed.","Machine-mediated learning",2022,"Gonzalo Jaimovitch-López,C. Ferri,J. Hernández-Orallo,Fernando Martínez-Plumed,M. J. Ramírez-Quintana",1,46,0
"91b07210ec07a229e5caf2d5f009a523b39e40ae","https://www.semanticscholar.org/paper/91b07210ec07a229e5caf2d5f009a523b39e40ae",4,"Momentum Decoding: Open-ended Text Generation As Graph Exploration","This study formulate open-ended text generation from a new perspective, i.e., it is viewed as an exploration process within a directed graph, and proposes a novel decoding method— momentum decoding—which encourages the LM to greedily explore new nodes outside the current graph.","ArXiv",2022,"Tian Lan,Yixuan Su,Shuhang Liu,Heyan Huang,Xian-Ling Mao",1,23,0
"fee5a9bddaa4d60a3a5bdbe8c2ed0503173a5ab6","https://www.semanticscholar.org/paper/fee5a9bddaa4d60a3a5bdbe8c2ed0503173a5ab6",4,"Pre-trained Language Models can be Fully Zero-Shot Learners","This paper proposes nonparametric prompting PLM (NPPrompt) for fully zero-shot language understanding, which uses only pre-trained language models and does not require any labeled data or additional raw corpus for further fine-tuning, nor does it rely on humans to construct a comprehensive set of prompt label words.","ArXiv",2022,"Xuandong Zhao,Siqi Ouyang,Zhiguo Yu,Ming-li Wu,Lei Li",1,46,0
"f9020636530faaf1801f00089ea250b16d2eacd7","https://www.semanticscholar.org/paper/f9020636530faaf1801f00089ea250b16d2eacd7",4,"Visually-augmented pretrained language models for NLP tasks without images","A novel visually-augmented fine-tuning approach that can be generally applied to various PLMs or NLP tasks, without using any retrieved or generated images, namely VAWI is proposed.","ArXiv",2022,"Hangyu Guo,Kun Zhou,Wayne Xin Zhao,Qinyu Zhang,Ji-rong Wen",0,32,0
"f1b475c6bde80880dd8edfc223c1f20c087201b7","https://www.semanticscholar.org/paper/f1b475c6bde80880dd8edfc223c1f20c087201b7",4,"Ethical Issues in Automatic Dialogue Generation for Non-Player Characters in Digital Games","It is argued that hierarchical ethical considerations for the automatic generation of character utterances in digital games are essential for designing the digital games in the incoming era.","2022 IEEE International Conference on Big Data (Big Data)",2022,"Yusuke Mori,Youichiro Miyake",0,35,0
"60e2daaf76a4259e2db955963a544e3a4328856f","https://www.semanticscholar.org/paper/60e2daaf76a4259e2db955963a544e3a4328856f",4,"Low-Resource Authorship Style Transfer with In-Context Learning","This paper proposes a method for automatic evaluation on the low-resource authorship style transfer task utilizing authorship and style representation embeddings and demonstrates that this method, S TYLL, is able to outperform S TRAP and a comprehensive set of baselines.","ArXiv",2022,"Ajay Patel,Nicholas Andrews,Chris Callison-Burch",0,45,0
"23b7cde603b5ec8d5d13d46e1c453dc52d7c3f6c","https://www.semanticscholar.org/paper/23b7cde603b5ec8d5d13d46e1c453dc52d7c3f6c",4,"Latent Diffusion for Language Generation","It is demonstrated that continuous diffusion models can be learned in the latent space of a pre-trained encoder-decoder model, enabling them to sample continuous latent representations that can be decoded into natural language with the pre- trained decoder.","ArXiv",2022,"Justin Lovelace,Varsha Kishore,Chao-gang Wan,Eliot Shekhtman,Kilian Q. Weinberger",1,38,0
"c59129f2cd52aaa02de295baf110cdbb6588f331","https://www.semanticscholar.org/paper/c59129f2cd52aaa02de295baf110cdbb6588f331",4,"TeSS: Zero-Shot Classification via Textual Similarity Comparison with Prompting using Sentence Encoder","TeSS is introduced, a framework for zero-shot classiﬁcation where the assigned label is determined by the embedding similarity between the input text and each candidate label prompt, and a simple interface to assess the quality of sentence encoders.","ArXiv",2022,"Jimin Hong,Jungsoo Park,Daeyoung Kim,Seongjae Choi,Bokyung Son,Jaewook Kang",0,57,0
"ec671e72494c3b1ba9556094ec83706da17a738d","https://www.semanticscholar.org/paper/ec671e72494c3b1ba9556094ec83706da17a738d",4,"A Brief History of Deep Learning-Based Text Generation","The paper describes deep learning models for a broad audience, focusing on traditional, convolutional, recurrent and generative adversarial networks, as well as transformer architecture.","International Conferences on Computing Advancements",2022,"Anil Bas,M. O. Topal,Ç. Duman,Imke Van Heerden",0,41,0
"0817de9f2bbc4f6db8cd5289d367a8c64aebbebb","https://www.semanticscholar.org/paper/0817de9f2bbc4f6db8cd5289d367a8c64aebbebb",4,"Contrastive Language-Vision AI Models Pretrained on Web-Scraped Multimodal Data Exhibit Sexual Objectification Bias","","ArXiv",2022,"R. Wolfe,Yiwei Yang,Billy Howe,Aylin Caliskan",0,79,0
"cb648d482dbd1e6ad0b0f4da43aca71c06538d4f","https://www.semanticscholar.org/paper/cb648d482dbd1e6ad0b0f4da43aca71c06538d4f",4,"Text Generation with Diffusion Language Models: A Pre-training Approach with Continuous Paragraph Denoise","To pre-train GENIE on a large-scale language corpus, a new continuous paragraph denoise objective is designed, which encourages the diffusion-decoder to reconstruct a clean text paragraph from a corrupted version, while preserving the semantic and syntactic coherence.","",2022,"Zhenghao Lin,Yeyun Gong,Yelong Shen,Tong Wu,Zhihao Fan,Chen Lin,Nan Duan,Weizhu Chen",0,44,0
"40c7b3e24bc6d6fe518a8ff60e58bd4877813b1a","https://www.semanticscholar.org/paper/40c7b3e24bc6d6fe518a8ff60e58bd4877813b1a",4,"Membership Inference Attacks With Token-Level Deduplication on Korean Language Models","It is shown that considering both language- and model-specific characteristics is essential to improve the effectiveness of attack strategies, and a deduplication strategy to replace the traditional word-level similarity metric with the BPE token level is proposed.","IEEE Access",2023,"Myung Gyo Oh,L. Park,Jaeuk Kim,Jaewoo Park,T.-H. Kwon",0,71,0
"165224b81f46fbda2140a4b656991287e96d3548","https://www.semanticscholar.org/paper/165224b81f46fbda2140a4b656991287e96d3548",4,"Is This Abstract Generated by AI? A Research for the Gap between AI-generated Scientific Text and Human-written Scientific Text","There exists a “writing style” gap between AI-generated scientific text and human-written scientific text, which suggests that while AI has the potential to generate scientific content that is as accurate as human- written content, there is still a gap in terms of depth and overall quality.","ArXiv",2023,"Yongqiang Ma,Jiawei Liu,Fan Yi",1,59,0
"34eb9de4a36dbeb47266c53b6e26003acb3523cc","https://www.semanticscholar.org/paper/34eb9de4a36dbeb47266c53b6e26003acb3523cc",4,"Machine learning and deep learning—A review for ecologists","It is concluded that ML and DL are powerful new tools for predictive modeling and data analysis, comparable to other traditional statistical tools.","Methods in Ecology and Evolution",2022,"Maximilian Pichler,F. Hartig",1,232,0
"0cffb48b8036d62ccc0ebd3bbbfb433860747c83","https://www.semanticscholar.org/paper/0cffb48b8036d62ccc0ebd3bbbfb433860747c83",4,"Learning from flowsheets: A generative transformer model for autocompletion of flowsheets","A novel method enabling autocompletion of chemical flowsheets that can provide chemical engineers with recommendations during interactive flowsheet synthesis and demonstrates a high potential for future AI-assisted process synthesis.","Computers &amp; Chemical Engineering",2022,"Gabriel Vogel,Lukas Schulze Balhorn,Artur M. Schweidtmann",1,49,1
"b3ca64d5c579b5209bfe629a698468beebfa6dee","https://www.semanticscholar.org/paper/b3ca64d5c579b5209bfe629a698468beebfa6dee",4,"Self Supervision Does Not Help Natural Language Supervision at Scale","This work finds that a combination of two state of the art approaches: masked auto-encoders, MAE and contrastive language image pre-training, CLIP provides a beneﬁt over CLIP when trained on a corpus of 11.3M image-text pairs, but lit-tle to no beneﷁt (as evaluated on a suite of common vision tasks) over ClIP when training on a large corpus of 1.4B images.","ArXiv",2023,"F.R.T. Weers,Vaishaal Shankar,Angelos Katharopoulos,Yinfei Yang,Tom Gunter",0,92,0
"121c3831752cb92e1222d8d1d8cc529016845247","https://www.semanticscholar.org/paper/121c3831752cb92e1222d8d1d8cc529016845247",4,"Information Retrieval: Recent Advances and Beyond","A detailed overview of the models used for information retrieval in the first and second stages of the typical processing chain is provided, including methods based on terms, semantic retrieval, and neural.","ArXiv",2023,"Kailas Hambarde,H. Proença",0,229,0
"de352871a2fb75fc49e4c469d21e92c33701b28d","https://www.semanticscholar.org/paper/de352871a2fb75fc49e4c469d21e92c33701b28d",4,"A Watermark for Large Language Models","A statistical test for detecting the watermark with interpretable p-values is proposed, and an information-theoretic framework for analyzing the sensitivity of the watermarks is derived.","ArXiv",2023,"John Kirchenbauer,Jonas Geiping,Yuxin Wen,Jonathan Katz,Ian Miers,T. Goldstein",6,53,0
"125a4f12bb93a8db8bbc45d77bc001a6a628a47e","https://www.semanticscholar.org/paper/125a4f12bb93a8db8bbc45d77bc001a6a628a47e",4,"AI vs. Human -- Differentiation Analysis of Scientific Content Generation","It is found that there exists a ""writing style""gap between AI-generated scientific text and human-written scientific text that contributes to guiding the optimization of AI models to produce high-quality content and addressing related ethical and security concerns.","",2023,"Yongqiang Ma,Jiawei Liu,Fan Yi,Qikai Cheng,Yong Huang,Wei Lu,Xiaozhong Liu",0,59,0
"76beae98abf567b31219d5fdf2ed4593189b98b0","https://www.semanticscholar.org/paper/76beae98abf567b31219d5fdf2ed4593189b98b0",4,"Protein Representation Learning via Knowledge Enhanced Primary Structure Modeling","The proposed Knowledge-exploited Auto-encoder for Protein (KeAP), which performs tokenlevel knowledge graph exploration for protein representation learning, and can consistently outperform the previous counterpart on 9 representative downstream applications, sometimes surpassing it by large margins.","bioRxiv",2023,"Hong-Yu Zhou,Yunxiang Fu,Zhicheng Zhang,Cheng Bian,Yizhou Yu",1,56,0
"2f43383da215ef757703ee570af296fbe9268246","https://www.semanticscholar.org/paper/2f43383da215ef757703ee570af296fbe9268246",4,"Dialogue Management and Language Generation for a Robust Conversational Virtual Coach: Validation and User Study","A Dialogue Manager and a Language Generator that are the core modules of a Voice-based Spoken Dialogue System capable of carrying out challenging, long and complex coaching conversations and an efficient integration procedure that will act as an intelligent and robust Virtual Coach are presented.","Italian National Conference on Sensors",2023,"A. Vázquez,Asier López Zorrilla,J. M. Olaso,M. Inés Torres",0,87,0
"8264257f573696fc0a1ef7531c825041832197f8","https://www.semanticscholar.org/paper/8264257f573696fc0a1ef7531c825041832197f8",4,"Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases","This work fully investigate the feasibility of usingINT4 quantization for language models, and shows that using INT4 introduces no or negligible accuracy degradation for encoder-only and encoder -decoder models, but causes a signiﬁcant accuracy drop for decoder- only models.","ArXiv",2023,"Xiaoxia Wu,Cheng Li,Reza Yazdani Aminabadi,Z. Yao,Yuxiong He",0,67,0
"2ca1985816f6670cba0a34ab53bdc73cf82d99af","https://www.semanticscholar.org/paper/2ca1985816f6670cba0a34ab53bdc73cf82d99af",4,"ST$^{2}$: Spatial-Temporal State Transformer for Crowd-Aware Autonomous Navigation","This letter proposes a Spatial-Temporal State Transformer to encode the states while leveraging the deep reinforcement learning method to find the optimal navigation policy accordingly, and extensive experiments demonstrate the superiority of the proposed ST<inline-formula><tex-math notation=""LaTeX"">$^{2}$</tex- math></inline- formula> over representative state-of-the-art methods.","IEEE Robotics and Automation Letters",2023,"Yuxiang Yang,Jiahao Jiang,Jing Zhang,Jiye Huang,Mingyu Gao",0,38,0
"11ffe64c7c0c6ae58016afdf84c3eacfb4e227b8","https://www.semanticscholar.org/paper/11ffe64c7c0c6ae58016afdf84c3eacfb4e227b8",4,"Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data","This work focuses on automated sampling strategies for FLAD and relates them to the explore-exploit dilemma that is central in multi-armed bandit settings, and proposes two algorithms to train T5 that yield a 9% absolute improvement over the explicitly multi-task pre-trained T0 model.","ArXiv",2023,"Alon Albalak,Colin Raffel,William Yang Wang",0,61,0
"512ff5037b28be7415d318ae6e8eeb0abb8c7013","https://www.semanticscholar.org/paper/512ff5037b28be7415d318ae6e8eeb0abb8c7013",4,"DTATrans: Leveraging Dynamic Token-Based Quantization With Accuracy Compensation Mechanism for Efficient Transformer Architecture","The transformer accelerator with the variable-speed systolic array (VSSA) is designed and an effective optimization strategy to alleviate the pipeline-stall problem in VSSA without hardware overhead is proposed.","IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",2023,"Tao Yang,Fei Ma,Xiaoling Li,Fangxin Liu,Yilong Zhao,Zhezhi He,Li Jiang",0,36,0
"2a261c6eb6886ba3a0f93319bf7b71939b0176ec","https://www.semanticscholar.org/paper/2a261c6eb6886ba3a0f93319bf7b71939b0176ec",4,"SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling","SimMTM proposes to recover masked time points by the weighted aggregation of multiple neighbors outside the manifold, which eases the reconstruction task by assembling ruined but complementary temporal variations from multiple masked series.","ArXiv",2023,"Jiaxiang Dong,Haixu Wu,Haoran Zhang,Li Zhang,Jianmin Wang,Mingsheng Long",0,44,0
"2a17c170afd50830276455b297f58b0b413e68dc","https://www.semanticscholar.org/paper/2a17c170afd50830276455b297f58b0b413e68dc",4,"Unleashing the True Potential of Sequence-to-Sequence Models for Sequence Tagging and Structure Parsing","A systematic study of S2S modeling using contained decoding on four core tasks: part-of-speech tagging, named entity recognition, constituency and dependency parsing, to develop efficient exploitation methods costing zero extra parameters.","ArXiv",2023,"Han He,Jinho D. Choi",0,65,0
"9c987cba9512a5dfbf141d2981108b9c2b0203c0","https://www.semanticscholar.org/paper/9c987cba9512a5dfbf141d2981108b9c2b0203c0",4,"Computation vs. Communication Scaling for Future Transformers on Future Hardware","This work provides a comprehensive multi-axial (algorithmic, empirical, hardware evolution) analysis of compute vs. communication (Comp-vs-Comm) scaling for future Transformer models on future hardware and underscores the increasingly large role communication will play as models scale.","ArXiv",2023,"Suchita Pati,Shaizeen Aga,Mahzabeen Islam,N. Jayasena,Matthew D. Sinclair",0,43,0
"bf6b8d2ed08b1538616caac9da6f0fb463f2077d","https://www.semanticscholar.org/paper/bf6b8d2ed08b1538616caac9da6f0fb463f2077d",4,"Boosting Zero-shot Classification with Synthetic Data Diversity via Stable Diffusion","This work proposes a $\textit{bag of tricks}$ to improve diversity and is able to achieve performance on par with one of the vision-language models, CLIP, and allows for endow zero-shot classification capabilities on any classification model.","ArXiv",2023,"Jordan Shipard,A. Wiliem,Kien Nguyen Thanh,Wei Xiang,C. Fookes",0,29,0
"31eb3316e4c79f3b2eee3c672c83feceb0893b6b","https://www.semanticscholar.org/paper/31eb3316e4c79f3b2eee3c672c83feceb0893b6b",4,"Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery","This work describes an approach to robustly optimize hard text prompts through efficient gradient-based optimization and shows that hard prompts can be automatically discovered that are effective in tuning LMs for classification.","ArXiv",2023,"Yuxin Wen,Neel Jain,John Kirchenbauer,Micah Goldblum,Jonas Geiping,T. Goldstein",0,37,0
"09053afc612c6d78aa47971b60bfe6fb152739cf","https://www.semanticscholar.org/paper/09053afc612c6d78aa47971b60bfe6fb152739cf",4,"Zero-shot Generation of Coherent Storybook from Plain Text Story using Diffusion Models","A novel neural pipeline for generating a coherent storybook from the plain text of a story using a combination of a pre-trained Large Language Model and a text-guided Latent Diffusion Model to generate coherent images.","ArXiv",2023,"Hyeonho Jeong,Gihyun Kwon,Jong-Chul Ye",0,56,0
"1467ced85b3ae2d695079a1557063a445c43988a","https://www.semanticscholar.org/paper/1467ced85b3ae2d695079a1557063a445c43988a",4,"Global Constraints with Prompting for Zero-Shot Event Argument Classification","This work proposes to use global constraints with prompting to effectively tackles event argument classification without any annotation and task-specific training, exploiting cross-task, cross-argument, and cross-event relations.","ArXiv",2023,"Zizheng Lin,Hongming Zhang,Yangqiu Song",0,51,0
"39266f38bdddd04ec89749db1776bfbf63e7f600","https://www.semanticscholar.org/paper/39266f38bdddd04ec89749db1776bfbf63e7f600",4,"Impact of Code Language Models on Automated Program Repair","This work is the first to evaluate ten CLMs on four APR benchmarks, which shows that surprisingly, the best CLM, as is, fixes 72% more bugs than the state-of-the-art deep-learning (DL)-based APR techniques.","ArXiv",2023,"Nan Jiang,Kevin Liu,Thibaud Lutellier,Lin Tan",0,60,0
"f2909fcd0a1c265097490ce43f5065ef6486310d","https://www.semanticscholar.org/paper/f2909fcd0a1c265097490ce43f5065ef6486310d",4,"Investigating the Effect of Relative Positional Embeddings on AMR-to-Text Generation with Structural Adapters","Through ablation studies, graph attack and link prediction, it is revealed that RPE might be partially encoding input graphs, and further research regarding the role of RPE will provide valuable insights for Graph-to-Text generation.","ArXiv",2023,"Sébastien Montella,Alexis Nasr,Johannes Heinecke,Frédéric Béchet,L. Rojas-Barahona",0,38,0
"f640a2635f38cbb3dbb83775088c2e27b790ad77","https://www.semanticscholar.org/paper/f640a2635f38cbb3dbb83775088c2e27b790ad77",4,"A Unified View of Long-Sequence Models towards Modeling Million-Scale Dependencies","This work takes a step back, studies and compares existing solutions to long-sequence modeling in terms of their pure mathematical formulation, and summarizes them using a unified template, given their shared nature of token mixing, to propose a machine learning system for handling million-scale dependencies.","",2023,"Hongyu He,Marko Kabic",0,48,0
"30c07037fe40754690af3f873f12f1724b092635","https://www.semanticscholar.org/paper/30c07037fe40754690af3f873f12f1724b092635",4,"A Uniﬁed View of Long-Sequence Models towards Million-Scale Dependencies","This work study and compare existing solutions to long-sequence modeling in terms of their pure mathematical formulation, and proposes a machine learning system for handling million-scale dependencies, inspired by emerging sparse models of huge capacity.","",2023,"Hongyu He",0,47,0
"a3ff4df653b6970898c04e6b768e58b99786d073","https://www.semanticscholar.org/paper/a3ff4df653b6970898c04e6b768e58b99786d073",4,"Learning gain differences between ChatGPT and human tutor generated algebra hints","This paper conducts the first learning gain evaluation of ChatGPT by comparing the efficacy of its hints with hints authored by human tutors with 77 participants across two algebra topic areas, Elementary Algebra and Intermediate Algebra.","",2023,"Z. Pardos,Shreya Bhandari",0,30,0
"7c817fa57edd087820d3b4d16e4d1f40d4cb5200","https://www.semanticscholar.org/paper/7c817fa57edd087820d3b4d16e4d1f40d4cb5200",4,"Generation Probabilities Are Not Enough: Exploring the Effectiveness of Uncertainty Highlighting in AI-Powered Code Completions","The question of whether conveying information about uncertainty enables programmers to more quickly and accurately produce code when collaborating with an AI-powered code completion tool, and if so, what measure of uncertainty best fits programmers' needs is explored.","",2023,"Helena Vasconcelos,Gagan Bansal,Adam Fourney,Q. Liao,Jennifer Wortman Vaughan",0,55,0
"6ffd19930ab0170f8cfdbf926e8f3c11f85e289a","https://www.semanticscholar.org/paper/6ffd19930ab0170f8cfdbf926e8f3c11f85e289a",4,"Decoupled Model Schedule for Deep Learning Training","A schedule language to decouple model execution from definition is proposed and uses a set of schedule primitives to convert the model for common model training optimizations such as high-performance kernels, effective 3D parallelism, and efficient activation checkpointing, preserving programmability and debuggability for users to a large extent.","",2023,"Hongzheng Chen,Cody Hao Yu,Shuai Zheng,Zhen Zhang,Zhiru Zhang,Yida Wang",0,53,0
"51879aeb001a8397253755247ccd6507d64d2403","https://www.semanticscholar.org/paper/51879aeb001a8397253755247ccd6507d64d2403",4,"Role of Bias Terms in Dot-Product Attention","This work mathematically shows that the bias term of the key linear transformation is redundant and could be omitted without any impact on the attention module, and argues that the biases of the value linear transformation has a more prominent role than that of the bias terms of the query linear transformation.","",2023,"Mahdi Namazifar,Devamanyu Hazarika,Dilek Z. Hakkani-Tür",0,19,0
"b70ae44769fac99295832f5f89f25e9a7b8a5a2c","https://www.semanticscholar.org/paper/b70ae44769fac99295832f5f89f25e9a7b8a5a2c",4,"Multimodal Subtask Graph Generation from Instructional Videos","This work presents Multimodal Sub task Graph Generation (MSG2), an approach that constructs a Subtask Graph defining the dependency between a task's subtasks relevant to a task from noisy web videos, closer to human-annotated graphs compared to prior approaches.","",2023,"Y. Jang,Sungryull Sohn,L. Logeswaran,Tiange Luo,Moontae Lee,Ho Hin Lee",0,58,0
"9d877509f3fb8fbbf3e3d54eeef3c84bc0e1e3b2","https://www.semanticscholar.org/paper/9d877509f3fb8fbbf3e3d54eeef3c84bc0e1e3b2",4,"A Simplistic Model of Neural Scaling Laws: Multiperiodic Santa Fe Processes","A model of narration is proposed that has the vanishing entropy rate and applies a randomly chosen deterministic sequence called a multiperiodic sequence that exhibits asymptotic relative frequencies given by Zipf's law.","",2023,"Lukasz Dkebowski",0,57,0
"194ae9479003351c27192df619c3c789c655e0e7","https://www.semanticscholar.org/paper/194ae9479003351c27192df619c3c789c655e0e7",4,"Black-box Prompt Learning for Pre-trained Language Models","A Black-box Discrete Prompt Learning (BDPL) is established to resonate with pragmatic interactions between the cloud infrastructure and edge devices and achieves significant improvement on eight benchmarks in a cloud-device collaboration manner.","ArXiv",2022,"Shizhe Diao,Xuechun Li,Yong Lin,Zhichao Huang,Tong Zhang",14,66,1
"6edccbd83a9aae204785d4821f97855677c33866","https://www.semanticscholar.org/paper/6edccbd83a9aae204785d4821f97855677c33866",4,"Scaling Laws vs Model Architectures: How does Inductive Bias Influence Scaling?","","ArXiv",2022,"Yi Tay,M. Dehghani,Samira Abnar,Hyung Won Chung,W. Fedus,J. Rao,Sharan Narang,V. Tran,Dani Yogatama,Donald Metzler",19,38,0
"4f4a80148cb8f328aeaee68b34f9797cfb5ea150","https://www.semanticscholar.org/paper/4f4a80148cb8f328aeaee68b34f9797cfb5ea150",4,"Unpacking Large Language Models with Conceptual Consistency","This novel metric measures how well a model can be characterized by finding out how consistent its responses to queries about conceptually relevant background knowledge are, and shows significant variation in conceptual consistency across different kinds of relations, concepts, and prompts.","ArXiv",2022,"Pritish Sahu,Michael Cogswell,Yunye Gong,Ajay Divakaran",1,38,0
"17a496e051dd4b8da26a29baeee01f7d072005ce","https://www.semanticscholar.org/paper/17a496e051dd4b8da26a29baeee01f7d072005ce",4,"SQA3D: Situated Question Answering in 3D Scenes","","ArXiv",2022,"Xiaojian Ma,Silong Yong,Zilong Zheng,Qing Li,Yitao Liang,Song-Chun Zhu,Siyuan Huang",0,72,0
"fa9312468957ad7d2d39de00cd85c9856ce0d0b0","https://www.semanticscholar.org/paper/fa9312468957ad7d2d39de00cd85c9856ce0d0b0",4,"Towards Better Out-of-Distribution Generalization of Neural Algorithmic Reasoning Tasks","An attention-based 2WL-graph neural network (GNN) processor which complements message passing GNNs so their combination outperforms the state-of-the-art model by a 3% margin averaged over all algorithms.","ArXiv",2022,"Sadegh Mahdavi,Kevin Swersky,Thomas Kipf,Milad Hashemi,Christos Thrampoulidis,Renjie Liao",1,55,0
"2c43ef2d8e44d055b61eecddf323a3412007cef8","https://www.semanticscholar.org/paper/2c43ef2d8e44d055b61eecddf323a3412007cef8",4,"Deanthropomorphising NLP: Can a Language Model Be Conscious?","It is taken that such a language model cannot be sentient, or conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it, and the necessary background in language modelling is presented.","ArXiv",2022,"M. Shardlow,Piotr Przybyła",0,65,0
"c9ef79d6d47c90722a10c32c64c752eb0343fd61","https://www.semanticscholar.org/paper/c9ef79d6d47c90722a10c32c64c752eb0343fd61",4,"Progress measures for grokking via mechanistic interpretability","This work argues that progress measures can be found via mechanistic interpretability: reverseengineering learned behaviors into their individual components, and defines progress measures that allow to study the dynamics of training and split training into three continuous phases: memorization, circuit formation, and cleanup.","ArXiv",2023,"Neel Nanda,Lawrence Chan,Tom Lieberum,Jess Smith,J. Steinhardt",1,23,1
"e962f95e03a50ff2f3a0fe7840daebac04578c46","https://www.semanticscholar.org/paper/e962f95e03a50ff2f3a0fe7840daebac04578c46",4,"Structure-informed Language Models Are Protein Designers","LM-Design, a generic approach to reprogramming sequence-based protein language models (pLMs), that have learned massive sequential evolutionary knowledge from the universe of natural protein sequences, to acquire an immediate capability to design preferable protein sequences for given folds is presented.","bioRxiv",2023,"Zaixiang Zheng,Yifan Deng,Dongyu Xue,Yi Zhou,YE Fei,Quanquan Gu",1,83,0
"61e721334296ebfbbf6443b5ed9eb8c83b708c95","https://www.semanticscholar.org/paper/61e721334296ebfbbf6443b5ed9eb8c83b708c95",4,"Scaling Vision Transformers to 22 Billion Parameters","A recipe for highly efficient and stable training of a 22B-parameter ViT (ViT-22B) and a wide variety of experiments on the resulting model, which demonstrates the potential for ""LLM-like""scaling in vision, and provides key steps towards getting there.","ArXiv",2023,"M. Dehghani,Josip Djolonga,Basil Mustafa,Piotr Padlewski,J. Heek,J. Gilmer,A. Steiner,Mathilde Caron,Robert Geirhos,Ibrahim M. Alabdulmohsin,Rodolphe Jenatton,L. Beyer,M. Tschannen,Anurag Arnab,Xiao Wang,C. Riquelme,Matthias Minderer,J. Puigcerver,Utku Evci,Manoj Kumar,Sjoerd van Steenkiste,Gamaleldin F. Elsayed,Aravindh Mahendran,F. Yu,Avital Oliver,Fantine Huot,Jasmijn Bastings,Mark Collier,A. Gritsenko,Vighnesh Birodkar,C. Vasconcelos,Yi Tay,Thomas Mensink,Alexander Kolesnikov,Filip Paveti'c,Dustin Tran,Thomas Kipf,Mario Luvci'c,Xiaohua Zhai,Daniel Keysers,Jeremiah Harmsen,N. Houlsby",0,121,0
"cbcd19395e4b5ad5e047e0476cb906ca6461df72","https://www.semanticscholar.org/paper/cbcd19395e4b5ad5e047e0476cb906ca6461df72",4,"Few-Shot Natural Language Inference Generation with PDD: Prompt and Dynamic Demonstration","This paper proposes language models with prompt and dynamic demonstration (LM-PDD) to tackle the problem of natural language generation in few-shot settings, and shows that the dynamic demonstration method has good generalizability.","ArXiv",2022,"Kaijian Li,Shansan Gong,Kenny Q. Zhu",0,50,0
"f0575b2b10e2178f9675a6d92ab7cb80015948d0","https://www.semanticscholar.org/paper/f0575b2b10e2178f9675a6d92ab7cb80015948d0",4,"DEER: Descriptive Knowledge Graph for Explaining Entity Relationships","Experiments demonstrate that the system can extract and generate high-quality relation descriptions for explaining entity relationships and suggest that it can build an open and informative knowledge graph without human annotation.","Conference on Empirical Methods in Natural Language Processing",2022,"Jie Huang,Kerui Zhu,K. Chang,Jinjun Xiong,W. Hwu",3,34,0
"dbeef935bedf509967bf472b183c12bce12f5aea","https://www.semanticscholar.org/paper/dbeef935bedf509967bf472b183c12bce12f5aea",4,"DKG: A Descriptive Knowledge Graph for Explaining Relationships between Entities","To construct DKGs, a self-supervised learning method to extract relation descriptions with the analysis of dependency patterns and a transformer-based relation description synthesizing model to generate relation descriptions are proposed.","ArXiv",2022,"Jie Huang,Kerui Zhu,K. Chang,Jinjun Xiong,W. Hwu",0,29,0
"422d8c989adeb904563d0c96d5038f6c8596fa99","https://www.semanticscholar.org/paper/422d8c989adeb904563d0c96d5038f6c8596fa99",4,"Neural Knowledge Bank for Pretrained Transformers","A Neural Knowledge Bank (NKB) and a knowledge in- jection strategy to introduce extra factual knowledge for pretrained Transformers and the interpretability of the NKB is thoroughly analyzed and reveal the meaning of its keys and values in a human-readable way.","ArXiv",2022,"Damai Dai,Wen-Jie Jiang,Qingxiu Dong,Yajuan Lyu,Qiaoqiao She,Zhifang Sui",0,46,0
"732e3faec4e5be4d144256f2c379b9dc49f0b227","https://www.semanticscholar.org/paper/732e3faec4e5be4d144256f2c379b9dc49f0b227",4,"Efficient Long-Text Understanding with Short-Text Models","This work proposes SLED, a simple approach for processing long sequences that re-uses and leverages battle-tested short-text pretrained LMs and shows that SLED is competitive with specialized models that are up to 50x larger and require a dedicated and expensive pretraining step.","ArXiv",2022,"Maor Ivgi,Uri Shaham,Jonathan Berant",3,53,1
"67f32dec9973d81b9bd3fa9f59dd40263decde91","https://www.semanticscholar.org/paper/67f32dec9973d81b9bd3fa9f59dd40263decde91",4,"On Grounded Planning for Embodied Tasks with Language Models","This paper addresses the question of whether language models have the capacity to generate grounded, executable plans for embodied tasks and demonstrates that the use of tables for encoding the environment and an iterative decoding strategy can significantly enhance the LMs' ability in grounded planning.","ArXiv",2022,"Bill Yuchen Lin,Chengsong Huang,Qianchu Liu,Wenda Gu,Sam Sommerer,Xiang Ren",0,33,0
"e88180a9256b3a97849f92d1ca252f8c803681ab","https://www.semanticscholar.org/paper/e88180a9256b3a97849f92d1ca252f8c803681ab",4,"Continuous QA Learning with Structured Prompts","Diana is proposed : a dynamic architecture-based lifelong QA model that tries to learn a sequence of QA tasks with a prompt enhanced lan- guage model and outperforms state-of-the-art lifelongQA models, especially in handling unseen tasks.","",2022,"Yinhe Zheng",0,77,0
"b04a2d101532fc7f8cdb1db0e94f408afec990ae","https://www.semanticscholar.org/paper/b04a2d101532fc7f8cdb1db0e94f408afec990ae",4,"Lifelong Learning for Question Answering with Hierarchical Prompts","Diana is proposed : a dynamic architecture-based lifelong QA model that tries to learn a sequence of QA tasks with a prompt enhanced lan- guage model and outperforms state-of-the-art lifelongQA models, especially in handling unseen tasks.","ArXiv",2022,"Yinpei Dai,Hao Lang,Yinhe Zheng,Fei Huang,Luo Si,Yongbin Li",4,77,0
"d6f86c2dc340621f0ae2a246cb1d76e7b86969c6","https://www.semanticscholar.org/paper/d6f86c2dc340621f0ae2a246cb1d76e7b86969c6",4,"Incorporating Task-specific Concept Knowledge into Script Learning","This paper presents T ETRIS, a new task of Goal-Oriented Script Completion, a more realistic and more general setting, where the input includes not only the goal but also additional user context, including preferences and history, to address the problem using a knowledge-based approach.","ArXiv",2022,"Chenkai Sun,Tie Xu,ChengXiang Zhai,Heng Ji",0,58,0
"891edceb78a274b0c2494d8176bc4d6f6e3f9cbc","https://www.semanticscholar.org/paper/891edceb78a274b0c2494d8176bc4d6f6e3f9cbc",4,"Calibrating Sequence likelihood Improves Conditional Language Generation","This work introduces sequence likelihood calibration (SLiC) where the likelihood of model generated sequences are calibrated to better align with reference sequences in the model’s latent space, and presents alternative ways to improve quality with limited training and inference budgets.","ArXiv",2022,"Yao Zhao,Misha Khalman,Rishabh Joshi,Shashi Narayan,Mohammad Saleh,Peter J. Liu",3,50,0
"3b622664d44a57280d3a189fa6475e56b96f1add","https://www.semanticscholar.org/paper/3b622664d44a57280d3a189fa6475e56b96f1add",4,"CIKQA: Learning Commonsense Inference with a Unified Knowledge-in-the-loop QA Paradigm","This work focuses on investigating models’ commonsense inference capabilities from two per-spectives: (1) Whether models can know if the knowledge they have is enough to solve the task; (2) whether models can learn commonsens inference capabilities, that generalize across commonsense tasks.","ArXiv",2022,"Hongming Zhang,Yintong Huo,Yanai Elazar,Yangqiu Song,Yoav Goldberg,D. Roth",0,41,0
"2b5e3fbca8b70395eafc1c28bfbe999c8ae7c69a","https://www.semanticscholar.org/paper/2b5e3fbca8b70395eafc1c28bfbe999c8ae7c69a",4,"Converge to the Truth: Factual Error Correction via Iterative Constrained Editing","V EN CE proposes V EN CE, a novel method for factual error correction (FEC) with minimal edits, which formulates the FEC problem as iterative sampling editing actions with respect to a target density function.","ArXiv",2022,"Jiangjie Chen,Rui Xu,Wenyuan Zeng,Changzhi Sun,Lei Li,Yanghua Xiao",0,56,0
"c4995582ef008116b878eaf23c4bc15271680086","https://www.semanticscholar.org/paper/c4995582ef008116b878eaf23c4bc15271680086",4,"Best-k Search Algorithm for Neural Text Generation","Experiments on four NLG tasks show that best- k search yields more diverse and natural outputs compared to strong baselines, while the proposed algorithm maintains high text quality.","ArXiv",2022,"Jiacheng Xu,Caiming Xiong,S. Savarese,Yingbo Zhou",0,60,0
"e25febbcdc351826a174f181ecd83b65084b0146","https://www.semanticscholar.org/paper/e25febbcdc351826a174f181ecd83b65084b0146",4,"Neural text summarization for Hungarian","The first Hungarian abstractive summarization tool based on mBART and mT5 models, which gained state-of-the-art results is presented.","Acta Linguistica Academica",2022,"Zijian Győző Yang",0,71,0
"5122b1239af8c259190ff2725a7289ed52c5e879","https://www.semanticscholar.org/paper/5122b1239af8c259190ff2725a7289ed52c5e879",4,"Implementing Deep Learning-Based Approaches for Article Summarization in Indian Languages","This work explores different pre-trained seq2seq models and fine-tune those with the ILSUM 2022 datasets and found the fine-tuned SoTA PEGASUS model worked the best for English, thefine-tuning IndicBART model with augmented data for Hindi, and again fine- Tuned PEGasUS model along with a translation mapping-based approach for Gujarati.","ArXiv",2022,"Rahul Tangsali,Aabha Pingle,Aditya Vyawahare,I. Joshi,Raviraj Joshi",1,40,0
"e29f6d3f72dc57ee08feb04865a490a117a6e270","https://www.semanticscholar.org/paper/e29f6d3f72dc57ee08feb04865a490a117a6e270",4,"Meeting Summarization: A Survey of the State of the Art","This survey offers a general overview of text summarization along with datasets and evaluation metrics for meeting summarization, and provides the performance of each summarizer on a leaderboard.","ArXiv",2022,"L. P. Kumar,Arman Kabiri",0,100,0
"f8528fd83bcf4edf7e839a7123c3725177faea1c","https://www.semanticscholar.org/paper/f8528fd83bcf4edf7e839a7123c3725177faea1c",4,"SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding Tasks","This work introduces several new annotated SLU benchmark tasks based on freely available speech data, which complement existing benchmarks and address gaps in the SLU evaluation landscape.","ArXiv",2022,"Suwon Shon,Siddhant Arora,Chyi-Jiunn Lin,Ankita Pasad,Felix Wu,Roshan Sharma,Wei Yu Wu,Hung-yi Lee,Karen Livescu,Shinji Watanabe",0,75,0
"c372842e46f42d722be433c042bbe21ead604230","https://www.semanticscholar.org/paper/c372842e46f42d722be433c042bbe21ead604230",4,"SPEC: Summary Preference Decomposition for Low-Resource Abstractive Summarization","This paper proposes a novel decoding method to automatically estimate suitable preferences and generate corresponding summary candidates from the few training examples and proposes a meta learning framework to transfer few-shot learning processes from source corpora to the target corpus.","IEEE/ACM Transactions on Audio Speech and Language Processing",2023,"Yi-Syuan Chen,Yun-Zhu Song,Hong-Han Shuai",0,65,0
"0126c13e2674f057b7109baddbafe0bb080d194b","https://www.semanticscholar.org/paper/0126c13e2674f057b7109baddbafe0bb080d194b",4,"Incorporating Knowledge into Document Summarization: an Application of Prefix-Tuning on GPT-2","The improvements on fact preservation in the generated summaries indicates the effectiveness of adopting this preﬁx-tuning-based method in knowledge-enhanced document summarization, and also shows a great potential on other natural language processing tasks.","ArXiv",2023,"Chen Chen,Wei Emma Zhang,A. Shakeri",0,19,0
"064a89270249fb3fa3f95efed1b6f768dc8fa7c3","https://www.semanticscholar.org/paper/064a89270249fb3fa3f95efed1b6f768dc8fa7c3",4,"Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings","This work aims to automatically construct research highlights given certain segments of the research paper, using a pointer-generator network with coverage mechanism and a contextual embedding layer at the input that encodes the input tokens into SciBERT embeddings.","",2023,"Tohida Rehman,Debarshi Kumar Sanyal,S. Chattopadhyay,Plaban Kumar Bhowmick,Partha Pratim Das",0,47,0
"04a55a02059d949a7667c4028ad1cd1ee3e5444d","https://www.semanticscholar.org/paper/04a55a02059d949a7667c4028ad1cd1ee3e5444d",4,"Distribution Aware Metrics for Conditional Natural Language Generation","This work proposes a novel paradigm for multi-candidate evaluation of conditional language generation models, and a new family of metrics that compare the distributions of reference and model-generated caption sets using small sample sets of each.","ArXiv",2022,"David Chan,Yiming Ni,Austin Myers,Sudheendra Vijayanarasimhan,David A. Ross,J. Canny",3,49,0
"a7435722d8ab595da5a9c70ac9160f57d0dcd75a","https://www.semanticscholar.org/paper/a7435722d8ab595da5a9c70ac9160f57d0dcd75a",4,"Enabling Transformers to Understand Low-Level Programs","This work applies transfer learning to low-level (LLVM) programs and study how low- level programs can be made more amenable to Transformer models through various techniques, including preprocessing, infix/prefix operators, and information deduplication.","IEEE Conference on High Performance Extreme Computing",2022,"Zifan Carl Guo,William S. Moses",0,53,0
"5b9aee8d1689ce0452d81ab032d2c5fae0302d70","https://www.semanticscholar.org/paper/5b9aee8d1689ce0452d81ab032d2c5fae0302d70",4,"Multiple-Choice Question Generation: Towards an Automated Assessment Framework","This work proposes a set of performance criteria that assess different aspects of the generated multiple-choice questions of interest, including: grammatical correctness, answerability, diversity and complexity.","ArXiv",2022,"Vatsal Raina,M. Gales",0,48,0
"8c15556f2292b7db8d87050cb1286db699c0a22c","https://www.semanticscholar.org/paper/8c15556f2292b7db8d87050cb1286db699c0a22c",4,"Paraphrasing Is All You Need for Novel Object Captioning","Paraphrasing-to-Captioning (P2C) is presented, a two-stage learning framework for NOC which would heuristically optimize the output captions via paraphrasing and leverages cross-modality (image-text) association modules to ensure the above caption characteristics can be properly preserved.","ArXiv",2022,"Cheng Yang,Yao-Hung Hubert Tsai,Wanshu Fan,R. Salakhutdinov,Louis-Philippe Morency,Yu-Chiang Frank Wang",0,46,0
"50b8ba87a90d9e5a76adf082883e9e694d7807ff","https://www.semanticscholar.org/paper/50b8ba87a90d9e5a76adf082883e9e694d7807ff",4,"UCEpic: Unifying Aspect Planning and Lexical Constraints for Explainable Recommendation","Compared to previous work controlled by soft constraints, UCE PIC incorporates speciﬁc information from keyphrases and then largely improves the diversity and informativeness of generated explanations.","ArXiv",2022,"Jiacheng Li,Zhankui He,Jingbo Shang,Julian McAuley",0,40,0
"752ba6b4da4048b0ce0a34cd03ff84a2861aa2fb","https://www.semanticscholar.org/paper/752ba6b4da4048b0ce0a34cd03ff84a2861aa2fb",4,"Differentially Private Bias-Term only Fine-tuning of Foundation Models","This work proposes diﬀerentially private bias-term ﬁne-tuning (DP-BiTFiT), which matches the state-of-the-art accuracy for DP algorithms and the eﬃciency of the standard Bi TFiT, and is even faster than the standard full full DP-ne- Tuning.","ArXiv",2022,"Zhiqi Bu,Yu-Xiang Wang,Sheng Zha,G. Karypis",1,70,1
"adb93f1571748f01a32f76faf395291f820e410e","https://www.semanticscholar.org/paper/adb93f1571748f01a32f76faf395291f820e410e",4,"Multi-Modal Code Summarization with Retrieved Summary","A novel approach based on contrastive learning to build a retrieval model to retrieve semantically similar summaries that incorporates lexical, syntactic and semantic modalities of codes.","IEEE Working Conference on Source Code Analysis and Manipulation",2022,"Lile Lin,Zhiqiu Huang,Yaoshen Yu,Ya-Ping Liu",0,52,0
"38288e285748b3bace77b1422531da76fdab7b3a","https://www.semanticscholar.org/paper/38288e285748b3bace77b1422531da76fdab7b3a",4,"Video Captioning Using Global-Local Representation","This work proposes a GLR framework, namely a global-local representation granularity, which exploits extensive vision representations from different video ranges to improve linguistic expression and introduces the progressive training strategy which can effectively organize feature learning to incur optimal captioning behavior.","IEEE transactions on circuits and systems for video technology (Print)",2022,"Liqi Yan,Siqi Ma,Qifan Wang,Yingjie Chen,X. Zhang,A. Savakis,Dongfang Liu",5,88,1
"ef6002ccc9e72ba483390ee130f17e8f81a2cb11","https://www.semanticscholar.org/paper/ef6002ccc9e72ba483390ee130f17e8f81a2cb11",4,"Just ClozE! A Fast and Simple Method for Evaluating the Factual Consistency in Abstractive Summarization","This paper demonstrates that ClozE can reduce the evaluation time by nearly 96 % relative to QA-based metrics while retaining their interpretability and performance through experiments on six human-annotated datasets and a meta-evaluation benchmark GO FIGURE (Gabriel et al., 2020).","ArXiv",2022,"Yiyang Li,Lei Li,Qing Yang,Marina Litvak,N. Vanetik,Dingxing Hu,Yuze Li,Yanquan Zhou,Dongliang Xu,Xuanyu Zhang",0,46,0
"591627746d0f8c3b642b7c9415bbc8af66e24a0e","https://www.semanticscholar.org/paper/591627746d0f8c3b642b7c9415bbc8af66e24a0e",4,"Visualize Before You Write: Imagination-Guided Open-Ended Text Generation","This work proposes iNLG that uses machine-generated images to guide language models in open-ended text generation in both few-shot and full-data scenarios and demonstrates the effectiveness ofiNLG on open-ending text generation tasks, including text completion, story generation, and concept-to-text generation.","ArXiv",2022,"Wanrong Zhu,An Yan,Yujie Lu,Wenda Xu,X. Wang,Miguel Eckstein,William Yang Wang",1,81,0
"56f0b389ea785efdc8fcad28b76417e134f2a580","https://www.semanticscholar.org/paper/56f0b389ea785efdc8fcad28b76417e134f2a580",4,"QAScore—An Unsupervised Unreferenced Metric for the Question Generation Evaluation","A new reference-free evaluation metric called QAScore is proposed, which is capable of providing a better mechanism for evaluating QG systems and can obtain a stronger correlation with human judgement according to the human evaluation experiment.","Entropy",2022,"Tianbo Ji,Chenyang Lyu,Gareth J. F. Jones,Liting Zhou,Yvette Graham",3,55,0
"0e6b7111c1b08b1467e26780613ac0f8053e9ec1","https://www.semanticscholar.org/paper/0e6b7111c1b08b1467e26780613ac0f8053e9ec1",4,"Talk2Face: A Unified Sequence-based Framework for Diverse Face Generation and Analysis Tasks","This work proposed a single model, Talk2Face, to simultaneously tackle a large number of face generation and analysis tasks, e.g. text guided face synthesis, face captioning and age estimation, by cast different tasks into a sequence-to-sequence format with the same architecture, parameters and objectives.","ACM Multimedia",2022,"Yudong Li,Xianxu Hou,Zhe Zhao,Linlin Shen,Xuefeng Yang,Kimmo Yan",1,62,0
"9e06248853f41ab547814fed70e640eba44764cf","https://www.semanticscholar.org/paper/9e06248853f41ab547814fed70e640eba44764cf",4,"DATScore: Evaluating Translation with Data Augmented Translations","This work introduces DATScore, a metric leveraging the BART language model to evaluate the quality of generated text from various aspects and uses data augmentation techniques to improve the evaluation of machine translation.","ArXiv",2022,"Moussa Kamal Eddine,Guokan Shang,M. Vazirgiannis",0,48,0
"6d72e1c59f21ba1c7722cf708c7ada70ad712161","https://www.semanticscholar.org/paper/6d72e1c59f21ba1c7722cf708c7ada70ad712161",4,"EduQG: A Multi-format Multiple Choice Dataset for the Educational Domain","A high-quality dataset that contains 3,397 samples comprising multiple choice questions, answers (including distractors), and their source documents, from the educational domain, that can be used for both question and distractor generation, as well as to explore new challenges such as question format conversion.","ArXiv",2022,"Amir Hadifar,Semere Kiros Bitew,Johannes Deleu,Chris Develder,Thomas Demeester",0,65,0
"969f45a3adf5e0bcf741447b1c67a0f3a386801a","https://www.semanticscholar.org/paper/969f45a3adf5e0bcf741447b1c67a0f3a386801a",4,"BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation","In-depth analysis suggests that choosing paradigms (matching, regression, or generation) of the metric has a greater impact on fairness than choosing PLMs, and develops debiasing adapters that are injected into PLM layers, mitigating bias in PLM-based metrics while retaining high performance for evaluating text generation.","Conference on Empirical Methods in Natural Language Processing",2022,"Tianxiang Sun,Junliang He,Xipeng Qiu,Xuanjing Huang",0,47,0
"361d25efdb55681b3925b38b7e298b54acbc3259","https://www.semanticscholar.org/paper/361d25efdb55681b3925b38b7e298b54acbc3259",4,"Summary Workbench: Unifying Application and Evaluation of Text Summarization Models","A new tool for developing and evaluating text summarization models that can be easily integrated as Docker-based plugins, allowing to examine the quality of their summaries against any input and to evaluate them using various evaluation measures.","ArXiv",2022,"S. Syed,Dominik Schwabe,Martin Potthast",0,47,0
"0b574244f2ecea75a536106789f08d3c3c2590e0","https://www.semanticscholar.org/paper/0b574244f2ecea75a536106789f08d3c3c2590e0",4,"Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text Generation","This work presents Visual Spatial Description (VSD), a new perspective for image-to-text toward spatial semantics, which aims to produce one description focusing on the spatial perspective between the two objects in an image.","Conference on Empirical Methods in Natural Language Processing",2022,"Yu Zhao,Jianguo Wei,Zhichao Lin,Yueheng Sun,Meishan Zhang,M. Zhang",0,71,0
"c6e4518dfd687a2a5bed4e78d5d9f999292a1746","https://www.semanticscholar.org/paper/c6e4518dfd687a2a5bed4e78d5d9f999292a1746",4,"Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario","This paper designs the counterfactual recipe generation task, which asks models to modify a base recipe according to the change of an ingredient, and finetune pretrained language models on the recipe corpus, and uses unsupervised counterfactUAL generation methods to generate modified recipes.","Conference on Empirical Methods in Natural Language Processing",2022,"Xiao Liu,Yansong Feng,Jizhi Tang,ChenGang Hu,Dongyan Zhao",0,36,0
"58b8da3821affc426895a85dbac5556322e6e2a9","https://www.semanticscholar.org/paper/58b8da3821affc426895a85dbac5556322e6e2a9",4,"EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention","EtriCA is presented, a novel neural generation model, which improves the relevance and coherence of the generated stories through residually mapping context features to event sequences with a cross-attention mechanism.","Conference on Empirical Methods in Natural Language Processing",2022,"Cheng Tang,Chenghua Lin,Hen-Hsen Huang,Frank Guerin,Zhihao Zhang",1,47,0
"b305c995821c6e9510b9c20e966bb9a6f4658bfe","https://www.semanticscholar.org/paper/b305c995821c6e9510b9c20e966bb9a6f4658bfe",4,"There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning","To extend the hypothesis space of knowledge selection to enhance the mapping relationship between multiple knowledge and multiple responses, a span-based variational model is devised and optimize the model in a wake-sleep style with an ameliorated evidence lower bound objective to learn the one-to-many generalization.","Conference on Empirical Methods in Natural Language Processing",2022,"Xueliang Zhao,Tingchen Fu,Chongyang Tao,Rui Yan",0,38,0
"2ae0c69cac7bb2ba386faf6e9702db54b2ca594d","https://www.semanticscholar.org/paper/2ae0c69cac7bb2ba386faf6e9702db54b2ca594d",4,"P3LM: Probabilistically Permuted Prophet Language Modeling for Generative Pre-Training","P$^3$LM, a probabilistically permuted prophet language model, which strengthens the modeling of bidirectional information and long token dependencies for sequence generation, achieves state-of-the-art results compared with strong publicly available generative pre-training methods.","Conference on Empirical Methods in Natural Language Processing",2022,"Junwei Bao,Yifan Wang,Jiangyong Ying,Yeyun Gong,Jing Zhao,Youzheng Wu,Xiaodong He",0,40,0
"40b0d9e116c46bd8d6813712f013c54c2790c17c","https://www.semanticscholar.org/paper/40b0d9e116c46bd8d6813712f013c54c2790c17c",4,"Adaptive Label Smoothing with Self-Knowledge in Natural Language Generation","This work proposes a regularization scheme that brings dynamic nature into the smoothing parameter by taking model probability distribution into account, thereby varying the parameter per instance.","Conference on Empirical Methods in Natural Language Processing",2022,"Dongkyu Lee,K. Cheung,N. Zhang",0,34,0
"be050e69aadd6461ff3bc35dcfa7a551742ef840","https://www.semanticscholar.org/paper/be050e69aadd6461ff3bc35dcfa7a551742ef840",4,"Varifocal Question Generation for Fact-checking","Varifocal is presented, a method that generates questions based on different focal points within a given claim, i.e. different spans of the claim and its metadata, such as its source and date, on a wide range of automatic evaluation metrics.","Conference on Empirical Methods in Natural Language Processing",2022,"N. Ousidhoum,Zhangdie Yuan,Andreas Vlachos",0,52,0
"0514444cd3564a7d7a561c4e5851c854000adb9f","https://www.semanticscholar.org/paper/0514444cd3564a7d7a561c4e5851c854000adb9f",4,"Hard Gate Knowledge Distillation - Leverage Calibration for Robust and Reliable Language Model","Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error.","Conference on Empirical Methods in Natural Language Processing",2022,"Dongkyu Lee,Zhiliang Tian,Ying Zhao,K. Cheung,N. Zhang",0,31,0
"9443a623d6e0d423adb9c61b5d225f0077f38767","https://www.semanticscholar.org/paper/9443a623d6e0d423adb9c61b5d225f0077f38767",4,"DEMETR: Diagnosing Evaluation Metrics for Translation","DEMETR is a diagnostic dataset with 31K English examples for evaluating the sensitivity of MT evaluation metrics to 35 different linguistic perturbations spanning semantic, syntactic, and morphological error categories and it is found that learned metrics perform substantially better than string-based metrics on DEMETR.","Conference on Empirical Methods in Natural Language Processing",2022,"Marzena Karpinska,N. Raj,Katherine Thai,Yixiao Song,Ankita Gupta,Mohit Iyyer",1,47,0
"87fed8c2eb9f2b8d3b50e7d4a279fd59ae52ea1e","https://www.semanticscholar.org/paper/87fed8c2eb9f2b8d3b50e7d4a279fd59ae52ea1e",4,"End-to-End Multimodal Representation Learning for Video Dialog","This study proposes a new framework that combines 3D-CNN network and transformer-based networks into a single visual encoder to extract more robust semantic representations from videos.","ArXiv",2022,"Huda AlAmri,Anthony Bilic,Michael Hu,Apoorva Beedu,Irfan Essa",0,49,0
"ffa0032150e2edf21633b6a6867b54ea121cb9d9","https://www.semanticscholar.org/paper/ffa0032150e2edf21633b6a6867b54ea121cb9d9",4,"MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective","A novel multi-task training strategy for long text generation grounded on the cognitive theory of writing is proposed, which empowers the model to learn essential subskills needed for writing including planning and reviewing besides end-to-end generation.","Conference on Empirical Methods in Natural Language Processing",2022,"Zhe Hu,Hou Pong Chan,Lifu Huang",0,43,0
"1cc512fc89651dc4e9a1998447a6693d90b73ee0","https://www.semanticscholar.org/paper/1cc512fc89651dc4e9a1998447a6693d90b73ee0",4,"FaD-VLP: Fashion Vision-and-Language Pre-training towards Unified Retrieval and Captioning","This work proposes a novel fashion-specific pre-training framework based on weakly-supervised triplets constructed from fashion image-text pairs and proposes a flexible decoder-based model architecture capable of both fashion retrieval and captioning tasks.","Conference on Empirical Methods in Natural Language Processing",2022,"Suvir Mirchandani,Licheng Yu,Mengjiao MJ Wang,Animesh Sinha,Wen-Jun Jiang,Tao Xiang,Ning Zhang",1,61,0
"dbeb1284c623f09b43ec60655b7ebd7028b5922f","https://www.semanticscholar.org/paper/dbeb1284c623f09b43ec60655b7ebd7028b5922f",4,"Terminology-aware Medical Dialogue Generation","A novel framework to improve medical dialogue generation by considering features centered on domain-speciﬁc terminology is proposed, which outperforms SOTA language models and leverages an attention mechanism to incorporate terminologically centred features.","ArXiv",2022,"Cheng Tang,Hongbo Zhang,Tyler Loakman,Chenghua Lin,Frank Guerin",1,15,0
"cba98048f3e85a974c287b271692bf6c197db940","https://www.semanticscholar.org/paper/cba98048f3e85a974c287b271692bf6c197db940",4,"Aligning Offline Metrics and Human Judgments of Value of AI-Pair Programmers","A simple hybrid metric is proposed, which combines functional correctness and similarity- based metrics to capture different dimensions of what programmers might value and shows that this hybrid metric more accurately captures effort.","ArXiv",2022,"Victor C. Dibia,Adam Fourney,Gagan Bansal,Forough Poursabzi-Sangdeh,Han Liu,Saleema Amershi",1,32,0
"3c5f7e7ee0ab7413ba3bf8ad3400810da542d617","https://www.semanticscholar.org/paper/3c5f7e7ee0ab7413ba3bf8ad3400810da542d617",4,"How Far are We from Robust Long Abstractive Summarization?","This work performs fine-grained human annotations to evaluate long document abstractive summarization systems (i.e., models and metrics) with the aim of implementing them to generate reliable summaries and suggests promising directions in the endeavor of developing factual consistency metrics.","Conference on Empirical Methods in Natural Language Processing",2022,"Huan Yee Koh,Jiaxin Ju,He Zhang,Ming Liu,Shirui Pan",0,81,0
"684e0925aa11628a165a6faf2095e45447258769","https://www.semanticscholar.org/paper/684e0925aa11628a165a6faf2095e45447258769",4,"Towards Inter-character Relationship-driven Story Generation","This paper proposes Relationships as Latent Variables for Story Generation, (ReLiSt), a model for modeling interpersonal relationships for story generation that is able to generate stories with relationships that are more faithful to desired relationships while maintaining the content quality.","Conference on Empirical Methods in Natural Language Processing",2022,"Anvesh Rao Vijjini,Faeze Brahman,Snigdha Chaturvedi",1,45,0
"cfc53d08b5e25a2ecfd94de71e7d23aa3175862f","https://www.semanticscholar.org/paper/cfc53d08b5e25a2ecfd94de71e7d23aa3175862f",4,"Medical Text Simplification Using Reinforcement Learning (TESLEA): Deep Learning–Based Text Simplification Approach","The proposed TS approach can be applied to automatically generate simplified text for complex medical text data, which would enhance the accessibility of biomedical research to a wider audience.","JMIR Medical Informatics",2022,"Atharva Phatak,D. Savage,R. Ohle,Jonathan Smith,Vijay K. Mago",0,49,0
"4b353d924f656824f9833dfc53a3f41dc1021edd","https://www.semanticscholar.org/paper/4b353d924f656824f9833dfc53a3f41dc1021edd",4,"Semantic space captioner: generating image captions step by step","The semantic space captioner model is proposed to introduce the concept of dense captioning into image captioning using contrastive language-image pretraining as an encoder for text and images.","Journal of Electronic Imaging (JEI)",2022,"Chenhao Zhu,Xia Ye,Qiduo Lu",0,50,0
"a054e491539f76cc2da4bb7a823c4195b7d90535","https://www.semanticscholar.org/paper/a054e491539f76cc2da4bb7a823c4195b7d90535",4,"Persona-Based Conversational AI: State of the Art and Challenges","This study evaluates two strong baseline methods, the Ranking Profile Memory Network and the Poly-Encoder, on the NeurIPS ConvAI2 benchmark dataset and elucidates the importance of incorporating persona information into conversational systems.","2022 IEEE International Conference on Data Mining Workshops (ICDMW)",2022,"Junfeng Liu,Christopher Symons,R. Vatsavai",0,38,0
"3a3bcbdcfbf63ccc38c4c7e30a5111885dffd240","https://www.semanticscholar.org/paper/3a3bcbdcfbf63ccc38c4c7e30a5111885dffd240",4,"OSIC: A New One-Stage Image Captioner Coined","This paper proposes a novel One-Stage Image Captioner (OSIC) with dynamic multi-sight learning, which directly transforms input images into descriptive sentences in one stage and can obtain rich and useful information to improve the image caption task.","ArXiv",2022,"Bo Wang,Zhao Zhang,Ming Zhao,Xiaojie Jin,Mingliang Xu,Meng Wang",1,47,0
"2e5a5769bdc81e1329961e44efad31c67ab4d281","https://www.semanticscholar.org/paper/2e5a5769bdc81e1329961e44efad31c67ab4d281",4,"Investigations in Audio Captioning: Addressing Vocabulary Imbalance and Evaluating Suitability of Language-Centric Performance Metrics","This work identifies and improves on three main challenges in automated audio captioning: i) data scarcity, ii) imbalance or limitations in the audio captions vocabulary, and iii) the proper performance evaluation metric that can best capture both auditory and semantic characteristics.","ArXiv",2022,"Sandeep Reddy Kothinti,Dimitra Emmanouilidou",0,26,0
"019145218663108e451fc5f3492af960f96df872","https://www.semanticscholar.org/paper/019145218663108e451fc5f3492af960f96df872",4,"AutoTemplate: A Simple Recipe for Lexically Constrained Text Generation","The AutoTemplate is introduced, a simple yet effective lexically constrained text generation framework divided into template generation and lexicalization tasks that outperforms the competitive baselines on both tasks while satisfying the hard lexical constraints.","ArXiv",2022,"Hayate Iso",0,54,0
"7ae089060ecb7ac2788e94ee7e04a3eb7009f6b4","https://www.semanticscholar.org/paper/7ae089060ecb7ac2788e94ee7e04a3eb7009f6b4",4,"CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware Dialog Generation","This work makes the very first attempt to release a high-quality multi-turn Medical Dialog dataset relating to Covid-19 disease named CDialog, with over 1K conversations collected from the online medical counselling websites.","Conference on Empirical Methods in Natural Language Processing",2022,"Deeksha Varshney,Aizan Zafar,Niranshu Kumar Behra,Asif Ekbal",0,44,0
"e402dd77eba504ea93bc38e2a052398bb95db351","https://www.semanticscholar.org/paper/e402dd77eba504ea93bc38e2a052398bb95db351",4,"Execution-based Evaluation for Data Science Code Generation Models","ExeDS is introduced, an evaluation dataset for execution evaluation for data science code generation tasks that contains a set of 534 problems from Jupyter Notebooks, each consisting of code context, task description, reference program, and the desired execution output.","DASH",2022,"Junjie Huang,Chenglong Wang,Jipeng Zhang,Cong Yan,Haotian Cui,J. Inala,Colin B. Clement,Nan Duan,Jianfeng Gao",2,36,2
"484b4e96428a7d3ab46330a15b14278ca7bd68ca","https://www.semanticscholar.org/paper/484b4e96428a7d3ab46330a15b14278ca7bd68ca",4,"GENIUS: Sketch-based Language Model Pre-training via Extreme and Selective Masking for Text Generation and Augmentation","This work introduces GENIUS, a conditional text model, which can be used as a strong and ready-to-use data augmentation tool for various natural language processing (NLP) tasks and proposes GeniusAug, which extracts the target-aware sketches from the original training set and then generates new samples based on the sketches.","ArXiv",2022,"Biyang Guo,Yeyun Gong,Yelong Shen,Songqiao Han,Hailiang Huang,Nan Duan,Weizhu Chen",1,64,0
"ad2149957cd288a5626adcce48f9981a2ab59184","https://www.semanticscholar.org/paper/ad2149957cd288a5626adcce48f9981a2ab59184",4,"Operationalizing Specifications, In Addition to Test Sets for Evaluating Constrained Generative Models","It is argued that the scale of generative models could be exploited to raise the abstraction level at which evaluation itself is conducted and provided recommendations, based on leveraging specifications as a powerful instrument to evaluate generation quality.","ArXiv",2022,"Vikas Raunak,Matt Post,Arul Menezes",0,28,0
"f991d1622949a2dea285d2ad0cfb2e8157cb84b4","https://www.semanticscholar.org/paper/f991d1622949a2dea285d2ad0cfb2e8157cb84b4",4,"Exploring Discrete Diffusion Models for Image Captioning","A diffusion-based captioning model, dubbed the name DDCap, is presented to allow more decoding of texts in image captions, and is competitive to the best well-developed auto-regressive frameworks.","ArXiv",2022,"Zixin Zhu,Yixuan Wei,Jianfeng Wang,Zhe Gan,Zheng Zhang,Le Wang,G. Hua,Lijuan Wang,Zicheng Liu,Han Hu",1,82,0
"6787e08233ef6716f2a23ed52e28ea8593676810","https://www.semanticscholar.org/paper/6787e08233ef6716f2a23ed52e28ea8593676810",4,"Expectation-Maximization Contrastive Learning for Compact Video-and-Language Representations","Extensive experiments on three benchmark text-video retrieval datasets prove that the proposed EMCL can learn more discriminative video-and-language representations than previous methods, and signiﬁcantly outperform previous state-of-the-art methods across all metrics.","ArXiv",2022,"Peng Jin,Jinfa Huang,Fenglin Liu,Xian Wu,Shen Ge,Guoli Song,D. Clifton,Jing Chen",0,80,0
"120f4e798d78c3f6dceed218bee1ca83a5855f55","https://www.semanticscholar.org/paper/120f4e798d78c3f6dceed218bee1ca83a5855f55",4,"Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music Generation Task","This paper carries out the first study of generating complete and semantically consistent symbolic music scores from text descriptions, and explores theacy of using publicly available checkpoints for natural language processing in the task of text-to-music generation.","ArXiv",2022,"Shangda Wu,Maosong Sun",0,24,0
"e83241e1c6e7f47fadc39d3506baebf157ad8cae","https://www.semanticscholar.org/paper/e83241e1c6e7f47fadc39d3506baebf157ad8cae",4,"IvCDS: An End-to-End Driver Simulator for Personal In-Vehicle Conversational Assistant","This proposed driver simulator enables one to interact with an in-vehicle assistant like a real person, and the diversity of conversations can be simply controlled by changing the assigned driver profile.","International Journal of Environmental Research and Public Health",2022,"Tianbo Ji,Xuanhua Yin,Peng Cheng,Liting Zhou,Siyou Liu,Wei Bao,Chenyang Lyu",0,81,0
"90c5d0a3566e0616956ff68955b58712c1b2b74a","https://www.semanticscholar.org/paper/90c5d0a3566e0616956ff68955b58712c1b2b74a",4,"HaRiM^+: Evaluating Summary Quality with Hallucination Risk","This study reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries, and proposes a reference-free metric, HaRiM+, which only requires an off-the-shelf summarization model to compute the hallucinationrisk based on token likelihoods.","AACL",2022,"Seonil Son,Junsoo Park,J. Hwang,Junghwa Lee,Hyungjong Noh,Yeonsoo Lee",0,50,0
"1382cd1a16b001cbb5a298d4458b788c2f0a6ffa","https://www.semanticscholar.org/paper/1382cd1a16b001cbb5a298d4458b788c2f0a6ffa",4,"Human or Machine? Turing Tests for Vision and Language","Surprisingly, the results reveal that current AIs are not far from being able to impersonate human judges across different ages, genders, and educational levels.","ArXiv",2022,"Mengmi Zhang,Giorgia Dellaferrera,Ankur Sikarwar,M. Armendáriz,Noga Mudrik,Prachi Agrawal,Spandan Madan,Andrei Barbu,Haochen Yang,T. Kumar,Meghna Sadwani,Stella Dellaferrera,Michele Pizzochero,H. Pfister,Gabriel Kreiman",0,78,0
"8aa23a86603f7dd4eceda3d2e0337ba90dff7f4f","https://www.semanticscholar.org/paper/8aa23a86603f7dd4eceda3d2e0337ba90dff7f4f",4,"CodeExp: Explanatory Code Document Generation","This work first conducted a human study to identify the criteria for high-quality explanatory docstring for code, collected and refined a large-scale code docstring corpus, and formulated automatic evaluation metrics that best match human assessments that can boost future code explanation research.","Conference on Empirical Methods in Natural Language Processing",2022,"Haotian Cui,Chenglong Wang,Junjie Huang,J. Inala,Todd Mytkowicz,Bolong Wang,Jian Gao,Nan Duan",0,36,0
"d9b26d458f43d204bc0fb2781ab6bea21ce98a22","https://www.semanticscholar.org/paper/d9b26d458f43d204bc0fb2781ab6bea21ce98a22",4,"Controlled Language Generation for Language Learning Items","This work aims to employ natural language generation to rapidly generate items for English language learning applications, and to control the output of the generation to match the requirements of the relevant items.","ArXiv",2022,"Kevin Stowe,Debanjan Ghosh,Mengxuan Zhao",0,40,0
"5cadbebda3bd266560a7d24e52d5d207049c663a","https://www.semanticscholar.org/paper/5cadbebda3bd266560a7d24e52d5d207049c663a",4,"Automated Generating Natural Language Requirements based on Domain Ontology","Experiments show that ReqGen outperforms six popular natural language generation approaches with respect to the hard constraint of keywords(phrases) inclusion, BLEU, ROUGE and syntax compliance.","ArXiv",2022,"Z. Zhao,Li Zhang,Xiao-qian Gao,Xiaoli Lian,Heyang Lv,Lina Shi",0,73,0
"6d889cea94c76a37a80b4ab6cc77838ce751be4e","https://www.semanticscholar.org/paper/6d889cea94c76a37a80b4ab6cc77838ce751be4e",4,"Long-Document Cross-Lingual Summarization","Per Perseus, the first long-document CLS dataset, is constructed, which collects about 94K Chinese scientific documents paired with English summaries and shows the superiority of the end-to-end baseline, outperforming the strong pipeline models equipped with sophisticated machine translation systems.","ArXiv",2022,"Shaohui Zheng,Zhixu Li,Jiaan Wang,Jianfeng Qu,An Liu,Lei Zhao,Zhigang Chen",0,42,0
"6e0087571449c002d412e283e2db6dbef7fc3b3f","https://www.semanticscholar.org/paper/6e0087571449c002d412e283e2db6dbef7fc3b3f",4,"Code Question Answering via Task-Adaptive Sequence-to-Sequence Pre-training","The proposed CodeMaster is a novel pre-training based approach for automatically answering code questions via task adaptation, and achieves state-of-the-art performance, and highlights the effectiveness of the approach.","Asia-Pacific Software Engineering Conference",2022,"Tingrui Yu,Xiaodong Gu,Beijun Shen",0,32,0
"32b3b990b00e890c44d769ac297889a7c75a394f","https://www.semanticscholar.org/paper/32b3b990b00e890c44d769ac297889a7c75a394f",4,"Grounded Keys-to-Text Generation: Towards Factual Open-Ended Generation","A new grounded keys-to-text generation task is proposed, to generate a factual description about an entity given a set of guiding keys, and grounding passages, and an automatic metric, MAFE, is proposed for factual correctness of generated descriptions.","Conference on Empirical Methods in Natural Language Processing",2022,"Faeze Brahman,Baolin Peng,Michel Galley,Sudha Rao,Bill Dolan,Snigdha Chaturvedi,Jianfeng Gao",1,56,0
"72d7f6e605879976d7fbda1b656ffead7befe56a","https://www.semanticscholar.org/paper/72d7f6e605879976d7fbda1b656ffead7befe56a",4,"Harnessing the Power of Multi-Task Pretraining for Ground-Truth Level Natural Language Explanations","This work proposes to evade limitations by applying recent advances in large-scale multi-task pretraining of generative Transformer models to the problem of VL-NLE tasks and shows that jointly training on multiple tasks can increase the explanation quality.","ArXiv",2022,"Björn Plüster,Jakob Ambsdorf,Lukas Braach,Jae Hee Lee,S. Wermter",0,49,0
"7cd7ed841ef4d82604ad2a65411299e7edd109e1","https://www.semanticscholar.org/paper/7cd7ed841ef4d82604ad2a65411299e7edd109e1",4,"Momentum Calibration for Text Generation","MoCa is an online method that dynamically generates slowly evolving samples using a momentum moving average generator with beam search and MoCa learns to align its model scores of these samples with their actual qualities.","ArXiv",2022,"Xingxing Zhang,Yiran Liu,Xun Wang,Pengcheng He,Yang Yu,Si-Qing Chen,Wayne Xiong,Furu Wei",0,44,0
"4a43a773f0725c998c65f2d51ddd49d5919183f7","https://www.semanticscholar.org/paper/4a43a773f0725c998c65f2d51ddd49d5919183f7",4,"Real-World Compositional Generalization with Disentangled Sequence-to-Sequence Learning","A new architecture is introduced to Dangle which leads to better generalization performance across existing tasks and datasets, and a new machine translation benchmark which is created by detecting naturally occurring compositional patterns in relation to a training set.","ArXiv",2022,"Hao Zheng,Mirella Lapata",0,39,0
"c6784d18a77176f58b75e639d0b99d797a0b4f84","https://www.semanticscholar.org/paper/c6784d18a77176f58b75e639d0b99d797a0b4f84",4,"Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue","Text Hallucination Mitigating (THAM) framework is designed, which incorporates Text Hallucinations Regularization (THR) loss derived from the proposed information-theoretic text hallucination measurement approach, which validates the effectiveness on VGD benchmarks and shows enhanced interpretability.","Conference on Empirical Methods in Natural Language Processing",2022,"Sunjae Yoon,Eunseop Yoon,Hee Suk Yoon,Junyeong Kim,Changdong Yoo",0,37,0
"2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd","https://www.semanticscholar.org/paper/2dd4bdb71e8d1a1bb6f7f2cb500972f082aa91fd",4,"NLIP: Noise-robust Language-Image Pre-training","By collaboratively optimiz- ing noise-harmonization and noise-completion schemes, the NLIP can alleviate the common noise effects during image- text pre-training in a more efﬁcient way.","ArXiv",2022,"Runhu Huang,Yanxin Long,Jianhua Han,Hang Xu,Xiwen Liang,Chunjing Xu,Xiaodan Liang",1,64,0
"c1bc6168ee5e8b943d3b904266fc445b08f3aa3d","https://www.semanticscholar.org/paper/c1bc6168ee5e8b943d3b904266fc445b08f3aa3d",4,"Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems","This paper utilizes light-weight adapters that can be easily integrated with PLMs and serve as a repository for facts learned from different KBs and introduces Knowledge Probing using Response Selection (KPRS) – a probe designed specifically for TOD models.","Conference on Empirical Methods in Natural Language Processing",2022,"Denis Emelin,Daniele Bonadiman,Sawsan Alqahtani,Yi Zhang,Saab Mansour",2,25,1
"8b6e5c63078e53800807d27a0b3e0686633c67cb","https://www.semanticscholar.org/paper/8b6e5c63078e53800807d27a0b3e0686633c67cb",4,"Swing Distillation: A Privacy-Preserving Knowledge Distillation Framework","Experiments demonstrate that the proposed swing distillation can signiﬁcantly reduce (by over 80% in terms of canary exposure) the risk of privacy leakage in comparison to KD with competitive or better performance.","ArXiv",2022,"Junzhuo Li,Xinwei Wu,Weilong Dong,Shuangzhi Wu,Chao Bian,Deyi Xiong",0,67,0
"8210cef990b8e5cddbc95000e46309bdd25337f7","https://www.semanticscholar.org/paper/8210cef990b8e5cddbc95000e46309bdd25337f7",4,"Asking Clarification Questions for Code Generation in General-Purpose Programming Language","The empirical results support the hypothesis that clariﬁcations result in more precise generated code, as shown by an improve-ment of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7% in the exact match.","ArXiv",2022,"Haau-Sing Li,Mohsen Mesgar,André F. T. Martins,Iryna Gurevych",0,43,0
"71fe1a42838bedb0ce774d7df46ecb4413650688","https://www.semanticscholar.org/paper/71fe1a42838bedb0ce774d7df46ecb4413650688",4,"LENS: A Learnable Evaluation Metric for Text Simplification","This work introduces R ANK & R ATE , a human evaluation framework that rates simpliﬁcations from several models in a list-wise manner by leveraging an interactive interface, which ensures both consistency and accuracy in the evaluation process.","ArXiv",2022,"Mounica Maddela,Yao Dou,David Heineman,Wei Xu",0,79,0
"fa427cf7371bd0ef9801004b1f062cffc41f0283","https://www.semanticscholar.org/paper/fa427cf7371bd0ef9801004b1f062cffc41f0283",4,"GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator","A GAN-style model for encoder-decoder pre-training by introducing an auxiliary discriminator, unifying the ability of language understanding and generation in a single model and achieves state-of-the-art performance.","ArXiv",2022,"Jian Yang,Shuming Ma,Li Dong,Shaohan Huang,Haoyang Huang,Yuwei Yin,Dongdong Zhang,Liqun Yang,Zhoujun Li,Furu Wei",2,48,0
"bae76e1d13abe54f66dc140be53538b864578ba8","https://www.semanticscholar.org/paper/bae76e1d13abe54f66dc140be53538b864578ba8",4,"A Survey on Pretrained Language Models for Neural Code Intelligence","This paper presents a comprehensive survey of the NCI domain, including a thorough review of pretraining techniques, tasks, datasets, and model architectures, and hopes it will serve as a bridge between the natural language and programming language communities.","ArXiv",2022,"Yichen Xu,Yanqiao Zhu",0,77,0
"bc9d103493d93a9ad8e6b60af4d9a900e4470146","https://www.semanticscholar.org/paper/bc9d103493d93a9ad8e6b60af4d9a900e4470146",4,"CausalDialogue: Modeling Utterance-level Causality in Conversations","This research examines user utterances as causes and generated responses as effects and proposes a causality-enhanced method called Exponential Maximum Average Treatment Effect (ExMATE) to enhance the impact of causality at the utterance level in training neural conversation models.","ArXiv",2022,"Yi-Lin Tuan,Alon Albalak,Wenda Xu,Michael Stephen Saxon,Connor Pryor,L. Getoor,William Yang Wang",0,50,0
"8e79d63d9747d05bed2c1e851f6f7d14c0fbbdd2","https://www.semanticscholar.org/paper/8e79d63d9747d05bed2c1e851f6f7d14c0fbbdd2",4,"SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers","This work proposes SeqDiffuSeq, a text diffusion model for sequence-to-sequence generation that uses an encoder-decoder Transformers architecture to model denoising function and combines the self-conditioning technique and a newly proposed adaptive noise schedule technique.","ArXiv",2022,"Hongyi Yuan,Zheng Yuan,Chuanqi Tan,Fei Huang,Songfang Huang",2,36,0
"d184b066aca3e5a5a0bab8da6edd1c6f58bce9a8","https://www.semanticscholar.org/paper/d184b066aca3e5a5a0bab8da6edd1c6f58bce9a8",4,"TegFormer: Topic-to-Essay Generation with Good Topic Coverage and High Text Coherence","A novel approach called TegFormer is proposed which utilizes the Transformer architecture where the encoder is enriched with domain-speciﬁc contexts while the decoder is enhanced by a large-scale pre-trained language model.","ArXiv",2022,"Wang Qi,R. Liu,Y. Zuo,Yong Chen,Dell Zhang",0,41,0
"808245dbe81f988fbcf5143d0762462500e705c0","https://www.semanticscholar.org/paper/808245dbe81f988fbcf5143d0762462500e705c0",4,"Graph-based Keyword Planning for Legal Clause Generation from Topics","This paper proposes a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses, and illustrates the effectiveness of this two-stage approach on a broad set of clause topics in contracts.","NLLP",2023,"Sagar Joshi,Sumanth Balaji,Aparna Garimella,Vasudeva Varma",0,17,0
"0bc2753f59e653de718b5c7a2a0a7e00d13778c7","https://www.semanticscholar.org/paper/0bc2753f59e653de718b5c7a2a0a7e00d13778c7",4,"NL2CMD: An Updated Workflow for Natural Language to Bash Commands Translation","A state-of-the-art translation model used to generate Bash Commands from the corresponding English text is described and a new NL2CMD dataset is introduced that is automatically generated, involves minimal human intervention, and is over six times larger than prior datasets.","",2023,"Quchen Fu,Zhongwei Teng,Marco Georgaklis,Jules White,Douglas,C. Schmidt",0,70,0
"294c1bd38f4d18e5ace4c8d1a57739902cf3a6e8","https://www.semanticscholar.org/paper/294c1bd38f4d18e5ace4c8d1a57739902cf3a6e8",4,"Automated Audio Captioning With Topic Modeling","This study proposes a framework that integrates audio embeddings with audio topics in a transformer-based encoder-decoder architecture and believes that the topic modeling can be used to extract semantic content in the AAC task.","IEEE Access",2023,"Aysegül Özkaya Eren,M. Sert",0,44,0
"658a912984d6a4899d1369ca674b06c7aafd45d0","https://www.semanticscholar.org/paper/658a912984d6a4899d1369ca674b06c7aafd45d0",4,"DIRECT: Toward Dialogue-Based Reading Comprehension Tutoring","A dialogue-based intelligent tutoring system (ITS) that imitates human expert tutors that asks questions, assesses student answers, provides hints, and even chats to encourage student engagement is developed.","IEEE Access",2023,"Jin-Xia Huang,Yohan Lee,Oh-Woog Kwon",0,44,0
"906dba49de4b320eefeea04d206ef4d8f4e5d583","https://www.semanticscholar.org/paper/906dba49de4b320eefeea04d206ef4d8f4e5d583",4,"Multi-Hop Reasoning Question Generation and Its Application","This article proposes a new adaptive meta-learner to optimize the basic QG model according to the specific characteristic of the evaluated case and proposes a data-driven multi-level recognizer to measure the similarity of such structured inputs.","IEEE Transactions on Knowledge and Data Engineering",2021,"Jianxing Yu,Qinliang Su,Xiaojun Quan,Jian Yin",0,59,0
"69e330037afd18e5546fdcacbc9a9f7deb69bba9","https://www.semanticscholar.org/paper/69e330037afd18e5546fdcacbc9a9f7deb69bba9",4,"Memorization and Generalization in Neural Code Intelligence Models","This work evaluates the memorization and generalization tendencies in neural code intelligence models through a case study across several benchmarks and model families by leveraging established approaches from other fields that use DNNs, such as introducing targeted noise into the training dataset.","Information and Software Technology",2021,"Md Rafiqul Islam Rabin,Aftab Hussain,V. Hellendoorn,Mohammad Amin Alipour",8,93,0
"15f26375e2c02a4817be2da347638eeef9b9ecbc","https://www.semanticscholar.org/paper/15f26375e2c02a4817be2da347638eeef9b9ecbc",4,"Bayesian Active Summarization","This work introduces Bayesian Active Summarization (BAS), as a method of combining active learning methods with state-of-the-art summarization models, and suggests that BAS achieves better and more robust performance, compared to random selection, particularly for small and very small data annotation budgets.","SSRN Electronic Journal",2021,"Alexios Gidiotis,Grigorios Tsoumakas",2,34,0
"26128a9bea65c0ed48c96ebb97140e3dd69d1dd0","https://www.semanticscholar.org/paper/26128a9bea65c0ed48c96ebb97140e3dd69d1dd0",4,"COMPASS: a Creative Support System that Alerts Novelists to the Unnoticed Missing Contents","Variable Number MPP (VN-MPP), a new MPP task that removes the restriction to predict multiple missing sentences or to judge whether there are no missing sentences in the first place, is proposed and a creative writing support system, COMPASS, is developed.","Computer Speech &amp; Language",2022,"Yusuke Mori,Hiroaki Yamane,Ryohei Shimizu,Yusuke Mukuta,Tatsuya Harada",0,86,0
"dfdb6f57c4e9a070a1a98c583e63e08e66fd2105","https://www.semanticscholar.org/paper/dfdb6f57c4e9a070a1a98c583e63e08e66fd2105",4,"On Distinctive Image Captioning via Comparing and Reweighting","A distinctiveness metric—between-set CIDEr (CIDErBtw) is proposed to evaluate the distinctiveness of a caption with respect to those of similar images and reveals that the human annotations of each image in the MSCOCO dataset are not equivalent based on distinctiveness.","IEEE Transactions on Pattern Analysis and Machine Intelligence",2022,"Jiuniu Wang,Wenjia Xu,Qingzhong Wang,Antoni B. Chan",4,73,1
"672524688552788d319da3917dd7c7540cabc926","https://www.semanticscholar.org/paper/672524688552788d319da3917dd7c7540cabc926",4,"How to Approach Ambiguous Queries in Conversational Search: A Survey of Techniques, Approaches, Tools, and Challenges","This work provides an overview of characteristics of ambiguous queries and contributes to better understanding of the existing technologies and challenges in CSS focus on disambiguation of unclear queries from various dimensions.","ACM Computing Surveys",2022,"Kimiya Keyvan,J. Huang",5,192,0
"5421a2058de7d8d39a2d060a53265e600d8f053a","https://www.semanticscholar.org/paper/5421a2058de7d8d39a2d060a53265e600d8f053a",4,"Knowledge-grounded dialogue modelling with dialogue-state tracking, domain tracking, and entity extraction","","Computer Speech and Language",2022,"Taesuk Hong,Junhee Cho,Haeun Yu,Youngjoong Ko,Jungyun Seo",0,23,0
"26325fbf09743fcd17ff9cbcd2bca22b05b1d4f1","https://www.semanticscholar.org/paper/26325fbf09743fcd17ff9cbcd2bca22b05b1d4f1",4,"WikiDes: A Wikipedia-Based Dataset for Generating Short Descriptions from Paragraphs","WikiDes, a novel dataset to generate short descriptions of Wikipedia articles for the problem of text summarization, is introduced and a practical impact on Wikipedia and Wikidata is shown since there are thousands of missing descriptions.","Information Fusion",2022,"Hoang Thang Ta,Abu Bakar Siddiqur Rahman,Navonil Majumder,A. Hussain,Lotfollah Najjar,N. Howard,Soujanya Poria,Alexander Gelbukh",0,111,0
"641b906b4069661122af7a26ff27921982211b31","https://www.semanticscholar.org/paper/641b906b4069661122af7a26ff27921982211b31",4,"CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation","This work proposes a Chinese corpus, CORGI-PM, which contains 32.9k sentences with high-quality labels derived by following an annotation scheme speciﬁcally developed for gender bias in the Chinese context, and addresses three challenges for automatic textual gender bias mitigation.","ArXiv",2023,"Ge Zhang,Yizhi Li,Yao-Hwa Wu,Linyuan Zhang,Chenghua Lin,Jiayi Geng,Shizhuo Wang,Jie Fu",0,30,0
"220ddeb4dc43bc922289fec8b1b60d7226068b20","https://www.semanticscholar.org/paper/220ddeb4dc43bc922289fec8b1b60d7226068b20",4,"Parameter-Efficient Fine-Tuning Design Spaces","This work presents a parameter-efficient fine-tuning design paradigm and discovers design patterns that are applicable to different experimental settings and shows experimentally that these methods consistently and significantly outperform investigated parameter- efficient fine- Tuning strategies across different backbone models and different tasks in natural language processing.","ArXiv",2023,"Jiaao Chen,Aston Zhang,Xingjian Shi,Mu Li,Alexander J. Smola,Diyi Yang",0,45,0
"4c8461d82880037ed81dd1340c4e8e6d7456964b","https://www.semanticscholar.org/paper/4c8461d82880037ed81dd1340c4e8e6d7456964b",4,"GenPADS: Reinforcing politeness in an end-to-end dialogue system","A novel end-to-end dialogue system that combines a politeness classifier to extract polite information present in user’s and agent's utterances and a generation model to generate varying but semantically correct responses, which performs better than two considered baselines.","PLoS ONE",2023,"Kshitij Mishra,Mauajama Firdaus,Asif Ekbal",0,52,0
"8da051282822dd6c54234099d4ecade697ba7166","https://www.semanticscholar.org/paper/8da051282822dd6c54234099d4ecade697ba7166",4,"ReqGen: Keywords-Driven Software Requirements Generation","Experiments show that ReqGen outperforms six popular natural language generation approaches with respect to the hard constraint of keywords’ (phrases’) inclusion, BLEU, ROUGE, and syntax compliance.","Mathematics",2023,"Z. Zhao,Li Zhang,Xiaoli Lian,Xiao-qian Gao,Heyang Lv,Lina Shi",0,33,0
"590b7a6da46d28fdd2b268d6cefcb09e7a70de5d","https://www.semanticscholar.org/paper/590b7a6da46d28fdd2b268d6cefcb09e7a70de5d",4,"TikTalk: A Multi-Modal Dialogue Dataset for Real-World Chitchat","Experimental results demonstrate that integrat-ing vision and knowledge in response generation performs the best, although there is still a large room for future improvement.","ArXiv",2023,"Hongpeng Lin,Ludan Ruan,Wenke Xia,Peiyu Liu,Jing Wen,Yixin Xu,Di Hu,Ruihua Song,Wayne Xin Zhao,Qin Jin,Zhiwu Lu",0,46,0
"8ea84f2f7ad6edc6efc4dc256d6958f4920dc1c8","https://www.semanticscholar.org/paper/8ea84f2f7ad6edc6efc4dc256d6958f4920dc1c8",4,"Bottom-up and Top-down Object Inference Networks for Image Captioning","This work presents Bottom-up and Top-down Object inference Networks (BTO-Net), that novelly exploits the object sequence of interest as top-down signals to guide image captioning and obtains competitive performances on COCO benchmark.","ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)",2023,"Yingwei Pan,Yehao Li,Ting Yao,Tao Mei",0,70,0
"b3628b58bbed1d427182bf766cbf454b7c10a43a","https://www.semanticscholar.org/paper/b3628b58bbed1d427182bf766cbf454b7c10a43a",4,"Visual Writing Prompts: Character-Grounded Story Generation with Curated Image Sequences","A character-based story generation model driven by coherence as a strong baseline is proposed and generated stories are more coherent, visually grounded, and more diverse than stories generated with the current state-of-the-art model.","ArXiv",2023,"Xudong Hong,A. Sayeed,K. Mehra,V. Demberg,B. Schiele",0,42,0
"fab84ef4a2cee4d496d761a677efcbd290dab4ac","https://www.semanticscholar.org/paper/fab84ef4a2cee4d496d761a677efcbd290dab4ac",4,"Byte Pair Encoding for Symbolic Music","This paper shows how Byte Pair Encoding (BPE) can improve the results of deep learning models while improving its performances, and studies the impact of BPE on how models learn the embeddings, and shows that it can help to increase their isotropy, i.e., the uniformity of the variance of their positions in the space.","ArXiv",2023,"Nathan Fradet,Jean-Pierre Briot,F. Chhel,A. E. Seghrouchni,Nicolas Gutowski",0,47,0
"754e0d146b7969d06f3feded6e14d92b44c15337","https://www.semanticscholar.org/paper/754e0d146b7969d06f3feded6e14d92b44c15337",4,"Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand Challenge for Education","","ArXiv",2023,"George Boateng,V. Kumbol,E. E. Kaufmann",0,27,0
"ef68ac57708ab2745ea71e066868e0d4f1da8d6c","https://www.semanticscholar.org/paper/ef68ac57708ab2745ea71e066868e0d4f1da8d6c",4,"Zero-shot Clarifying Question Generation for Conversational Search","This work innovatively explore generating clarifying questions in a zero-shot setting to overcome the cold start problem and proposes a constrained clarifying question generation system which uses both question templates and query facets to guide the effective and precise question generation.","ArXiv",2023,"Zhenduo Wang,Yuancheng Tu,Corby Rosset,Nick Craswell,Ming Wu,Qingyao Ai",0,59,0
"595c5b22354bcab17f0534a41b9c19bbc3c6b9ad","https://www.semanticscholar.org/paper/595c5b22354bcab17f0534a41b9c19bbc3c6b9ad",4,"Generative Adversarial Neural Machine Translation for Phonetic Languages via Reinforcement Learning","This work proposes a novel improvement in Generative Adversarial Networks (GAN)-NMT by incorporating deep reinforcement learning-based optimised attention in generator and convolutional neural network in discriminator and creates the novel joint embedding of subwords and sub-phonetic representation of sentences as input to GAN.","IEEE Transactions on Emerging Topics in Computational Intelligence",2023,"Amit Kumar,A. Pratap,Anil Kumar Singh",0,40,0
"eb53979c96eacec543620af2b899a3772eb6d32f","https://www.semanticscholar.org/paper/eb53979c96eacec543620af2b899a3772eb6d32f",4,"Commonsense-Aware Prompting for Controllable Empathetic Dialogue Generation","A novel framework that improves empathetic dialogue generation using pre-trained language models by incorporating commonsense knowledge through prompt verbalization, and controlling dialoguegeneration using a strategy-driven future discriminator is proposed.","ArXiv",2023,"Yiren Liu,H. Kilicoglu",0,26,0
"257d7c8ab9d18d3cb93b9ec6d87aa66b28e610f4","https://www.semanticscholar.org/paper/257d7c8ab9d18d3cb93b9ec6d87aa66b28e610f4",4,"DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","To construct three-dimensional geometric relations, depth information is introduced and a depth-enhanced feature updating module is proposed to ameliorate OCR token features and generate more precise and comprehensive captions.","ArXiv",2023,"Dongsheng Xu,Qingbao Huang,Yiru Cai",0,45,0
"8856fef5cefdd97f2835b960ef657b4a757fe191","https://www.semanticscholar.org/paper/8856fef5cefdd97f2835b960ef657b4a757fe191",4,"Transform, Contrast and Tell: Coherent Entity-Aware Multi-Image Captioning","Experiments on three datasets show the proposed captioning model outperforms 6 baselines according to single-image captioning evaluations, and the generated captions are more coherent than that of baseline according to coherence evaluations and human evaluations.","ArXiv",2023,"Jingqiang Chen",0,46,0
"7fdfe07e7e6d6dd38efdab12a3e81d47325ad575","https://www.semanticscholar.org/paper/7fdfe07e7e6d6dd38efdab12a3e81d47325ad575",4,"Learning Translation Quality Evaluation on Low Resource Languages from Large Language Models","It is shown how knowledge can be distilled from Large Language Models (LLMs) to improve upon learned metrics without requiring human annotators, by creating synthetic datasets which can be mixed into existing datasets, requiring only a corpus of text in the target language.","ArXiv",2023,"Amirkeivan Mohtashami,M. Verzetti,Paul K. Rubenstein",0,17,0
"1d74875aa4f415cb2c60b17fd1eb3e4ae543bfe1","https://www.semanticscholar.org/paper/1d74875aa4f415cb2c60b17fd1eb3e4ae543bfe1",4,"Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models","This paper proposes REPEAT, a novel method for continual learning of code intelligence models that addresses the catastrophic forgetting problem with representative exemplars replay and adaptive parameter regularization.","ArXiv",2023,"Shuzheng Gao,Hongyu Zhang,Cuiyun Gao,Chaozheng Wang",0,62,0
"44f0eb7be111747f54a8669f74be0bb0dad96cff","https://www.semanticscholar.org/paper/44f0eb7be111747f54a8669f74be0bb0dad96cff",4,"An Empirical Comparison of Pre-Trained Models of Source Code","The first systematic empirical comparison of 19 recently- developed pre-trained models of source code on 13 SE tasks is performed, and a recently-developed 4-dimensional categorization of pre- trained models is adopted to gain additional insights into these models.","ArXiv",2023,"Changan Niu,Chuanyi Li,Vincent Ng,Dongxiao Chen,Jidong Ge,B. Luo",0,72,0
"5d896fb2f0da16060f22ed43e582464605237f28","https://www.semanticscholar.org/paper/5d896fb2f0da16060f22ed43e582464605237f28",4,"Training-free Lexical Backdoor Attacks on Language Models","This work proposes Training-Free Lexical Backdoor Attack (TFLexAttack) as the first training-free backdoor attack on language models by injecting lexical triggers into the tokenizer of a language model via manipulating its embedding dictionary using carefully designed rules.","ArXiv",2023,"Yujin Huang,Terry Yue Zhuo,Qiongkai Xu,Han Hu,Xingliang Yuan,Chunyang Chen",0,71,0
"75e44b9e4c084085008edb59ae7c3cad23f5fbe5","https://www.semanticscholar.org/paper/75e44b9e4c084085008edb59ae7c3cad23f5fbe5",4,"Few-Shot Table-to-Text Generation with Prompt Planning and Knowledge Memorization","Inspired by how humans descript tabular data with prior knowledge, a new framework is suggested: PromptMize, which targets table-to-text generation under few-shot settings and achieves remarkable performance in generating quality as judged by human and automatic evaluations.","ArXiv",2023,"Zhixin Guo,Minyxuan Yan,Jiexing Qi,Jianping Zhou,Ziwei He,Zhouhan Lin,Guanjie Zheng,Xinbing Wang",0,46,0
"535a3d95a743e1f4b591b5b2af3e778a6347158a","https://www.semanticscholar.org/paper/535a3d95a743e1f4b591b5b2af3e778a6347158a",4,"CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code","This paper proposes CodeBERTScore, an automatic evaluation metric for code generation, which builds on BERTScore and achieves a higher correlation with human preference and with functional correctness than all existing metrics.","ArXiv",2023,"Shuyan Zhou,Uri Alon,Sumit Agarwal,Graham Neubig",0,38,0
"3561b5b7a1982740c7127b8d2ab14d7e07c9c0cd","https://www.semanticscholar.org/paper/3561b5b7a1982740c7127b8d2ab14d7e07c9c0cd",4,"Enhancing User Personalization in Conversational Recommenders","This paper proposes a novel conversational recommendation framework with two unique features: a greedy NDCG attribute selector, to enhance user personalization in the interactive preference elicitation process by prioritizing attributes that most effectively represent the actual preference space of the user.","",2023,"Allen Lin,Ziwei Zhu,Jianling Wang,James Caverlee",0,40,0
"229578bcf5cbc33e502e41d3001aedfc548ace74","https://www.semanticscholar.org/paper/229578bcf5cbc33e502e41d3001aedfc548ace74",4,"EmoKbGAN: Emotion controlled response generation using Generative Adversarial Network for knowledge grounded conversation","This paper presents a method named EmoKbGAN for automatic response generation that makes use of the Generative Adversarial Network (GAN) in multiple-discriminator settings involving joint minimization of the losses provided by each attribute specific discriminator model (knowledge and emotion discriminator).","PLoS ONE",2023,"Deeksha Varshney,Asif Ekbal,Mrigank Tiwari,Ganesh Nagaraja",0,76,0
"0a9364ca06771d2b85da147a453bca0d02f8e248","https://www.semanticscholar.org/paper/0a9364ca06771d2b85da147a453bca0d02f8e248",4,"Multimodal Machines from a perspective of humans Ph.D Thesis Proposal","This thesis proposal focuses on highlighting the differences in the learning mechanisms of humans and deep learning systems and explores yet how recent work has established similarities between representations learnt by deeplearning systems and cognitive data collected from the human brain.","",2022,"Sunit Bhattacharya",0,152,0
"5840bf765be8c3bcedab63f43f5982ddba26eaf9","https://www.semanticscholar.org/paper/5840bf765be8c3bcedab63f43f5982ddba26eaf9",4,"SPRINT: S CALABLE S EMANTIC P OLICY P RE T RAINING VIA L ANGUAGE I NSTRUCTION R ELABELING","Experiments using a realistic household simulator show that agents pre-trained with SPRINT learn new long-horizon household tasks substantially faster than with previous pre-training approaches.","",2022,"",0,47,0
"c2536182c010c41941e8a031071a1880c34cec60","https://www.semanticscholar.org/paper/c2536182c010c41941e8a031071a1880c34cec60",4,"Unified Scaling Laws for Routed Language Models","This work derives and justifies scaling laws defined on parameter count and computational requirement which generalize those known for standard language models and describe the performance of a wide range of routing architectures trained via three different techniques.","International Conference on Machine Learning",2022,"Aidan Clark,Diego de Las Casas,Aurelia Guy,A. Mensch,Michela Paganini,Jordan Hoffmann,Bogdan Damoc,Blake A. Hechtman,Trevor Cai,Sebastian Borgeaud,George van den Driessche,Eliza Rutherford,T. Hennigan,Matthew G. Johnson,Katie Millican,Albin Cassirer,Chris Jones,Elena Buchatskaya,D. Budden,L. Sifre,Simon Osindero,Oriol Vinyals,Jack W. Rae,Erich Elsen,K. Kavukcuoglu,K. Simonyan",30,68,5
"aa4d9972af3264d032dbee58501ed4ac49477103","https://www.semanticscholar.org/paper/aa4d9972af3264d032dbee58501ed4ac49477103",4,"Scaling Laws and Interpretability of Learning from Repeated Data","It is shown that data repetition disproportionately damages copying and internal structures associated with generalization, such as induction heads, providing a possible mechanism for the shift from generalization to memorization.","ArXiv",2022,"Danny Hernandez,Tom B. Brown,Tom Conerly,Nova DasSarma,Dawn Drain,S. El-Showk,Nelson Elhage,Zac Hatfield-Dodds,T. Henighan,Tristan Hume,Scott Johnston,Benjamin Mann,C. Olah,Catherine Olsson,Dario Amodei,Nicholas Joseph,Jared Kaplan,Sam McCandlish",6,32,0
"18b0b58449120abc819aaaa175cb8af92009ff18","https://www.semanticscholar.org/paper/18b0b58449120abc819aaaa175cb8af92009ff18",4,"Know your audience: specializing grounded language models with the game of Dixit","This work forms a round of Dixit as a multi-agent image reference game where a (trained) speaker model is rewarded for describing a target image such that one (pretrained) listener model can correctly identify it from a pool of distractors, but another listener cannot.","ArXiv",2022,"Aaditya K Singh,David Ding,Andrew M. Saxe,Felix Hill,Andrew Kyle Lampinen",1,48,0
"eaef083b9d661f42cc0d89d9d8156218f33a91d9","https://www.semanticscholar.org/paper/eaef083b9d661f42cc0d89d9d8156218f33a91d9",4,"Long Range Language Modeling via Gated State Spaces","This work proposes a new layer named Gated State Space (GSS) and shows that it trains signiﬁcantly faster than the diagonal version of S4 on TPUs, is fairly competitive with several well-tuned Transformer-based baselines and exhibits zero-shot generalization to longer inputs while being straightforward to implement.","ArXiv",2022,"Harsh Mehta,Ankit Gupta,Ashok Cutkosky,Behnam Neyshabur",7,46,2
"63c670ba8018da0a7e33c34ffd84c2a3ca54b894","https://www.semanticscholar.org/paper/63c670ba8018da0a7e33c34ffd84c2a3ca54b894",4,"Language Models Can Teach Themselves to Program Better","This work shows how generating synthetic programming puzzles and solutions, veriﬁed for correctness by a Python interpreter, can be used to improve performance in solving test puzzles from P3, a public benchmark set of Python Programming Puzzles.","ArXiv",2022,"Patrick M. Haluptzok,Matthew Bowers,A. Kalai",3,46,1
"e221c769957a8eef2836a64cede88401129d86e9","https://www.semanticscholar.org/paper/e221c769957a8eef2836a64cede88401129d86e9",4,"Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP","It is demonstrated that simply gathering a large amount of data from the web is not the most effective way to build a pre-training dataset for robust generalization, necessitating further study into dataset design.","ArXiv",2022,"T. Nguyen,Gabriel Ilharco,Mitchell Wortsman,Sewoong Oh,Ludwig Schmidt",9,87,1
"8bd182f01c99e643c9a5a96832dc1a16b9cd10d0","https://www.semanticscholar.org/paper/8bd182f01c99e643c9a5a96832dc1a16b9cd10d0",4,"Domain-Specific Text Generation for Machine Translation","This work proposes leveraging state-of-the-art pretrained language models (LMs) for domain-specific data augmentation for MT, simulating the domain characteristics of either a small bilingual dataset, or the monolingual source text to be translated, to generate huge amounts of synthetic bilingual in-domain data.","Conference of the Association for Machine Translation in the Americas",2022,"Yasmin Moslem,Rejwanul Haque,John D. Kelleher,Andy Way",2,73,0
"d17bddf9dc329bb9ff7883642699b84055db06fc","https://www.semanticscholar.org/paper/d17bddf9dc329bb9ff7883642699b84055db06fc",4,"PLATO-K: Internal and External Knowledge Enhanced Dialogue Generation","Compared to the existing state-of-the-art Chinese dialogue model, the overall engagingness of PLATO-K is improved remarkably by 36.2% and 49.2%, and the knowledge issue is alleviated significantly in PLATo-K with such comprehensive internal and external knowledge enhancement.","ArXiv",2022,"Siqi Bao,H. He,Jun Xu,Hua Lu,Fan Wang,Hua Wu,Han Zhou,Wenquan Wu,Zheng-Yu Niu,Haifeng Wang",0,39,0
"ef58e99dbb90bebbdc6187b5cba94dd5973dbb16","https://www.semanticscholar.org/paper/ef58e99dbb90bebbdc6187b5cba94dd5973dbb16",4,"Retrieval-Augmented Multimodal Language Modeling","Retrieval-Augmented CM3, the first retrieval-augmented multimodal model that can retrieve and generate mixtures of text and images, is proposed and shows that RA-CM3 exhibits novel capabilities such as knowledge-intensive image generation and multimodals in-context.","ArXiv",2022,"Michihiro Yasunaga,Armen Aghajanyan,Weijia Shi,Rich James,J. Leskovec,Percy Liang,M. Lewis,Luke Zettlemoyer,Wen-tau Yih",3,46,1
"22775e58932cdfbd273a2a835a22c5d86800a458","https://www.semanticscholar.org/paper/22775e58932cdfbd273a2a835a22c5d86800a458",4,"Continuous diffusion for categorical data","CD is proposed, a framework for modelling categorical data with diﬀusion models that are continuous both in time and input space and demonstrates its eﬃcacy on several language modelling tasks.","ArXiv",2022,"S. Dieleman,Laurent Sartran,Arman Roshannai,Nikolay Savinov,Yaroslav Ganin,Pierre H. Richemond,A. Doucet,Robin Strudel,Chris Dyer,Conor Durkan,Curtis Hawthorne,Rémi Leblond,Will Grathwohl,J. Adler",6,99,4
"7c6fcb3f1577b2385342d054b94df7924a5cdd13","https://www.semanticscholar.org/paper/7c6fcb3f1577b2385342d054b94df7924a5cdd13",4,"ClueWeb22: 10 Billion Web Documents with Visual and Semantic Information","The newest iteration of the ClueWeb22 corpus is larger, more varied, of higher-quality, and aligned with the document distributions in commercial web search.","",2022,"Arnold Overwijk,Chenyan Xiong,X. Liu,Cameron VandenBerg,Jamie Callan",0,32,0
"7928253927fc11ba7da64b428b6b97dce096672c","https://www.semanticscholar.org/paper/7928253927fc11ba7da64b428b6b97dce096672c",4,"DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and Training Efficiency via Efficient Data Sampling and Routing","DeepSpeed Data Efficiency is presented, a framework that makes better use of data, increases training efficiency, and improves model quality, and takes extensibility, flexibility and composability into consideration, so that users can easily utilize the framework to compose multiple techniques and apply customized strategies.","ArXiv",2022,"Conglong Li,Z. Yao,Xiaoxia Wu,Minjia Zhang,Yuxiong He",0,72,0
"94c69cf028c27ee360c7cb8b0bdba6027ee52dbb","https://www.semanticscholar.org/paper/94c69cf028c27ee360c7cb8b0bdba6027ee52dbb",4,"Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language","Data2vec 2.0 beneﬁts from the rich contextualized target representations introduced in data2vec which enable a fast self-supervised learner.","ArXiv",2022,"Alexei Baevski,Arun Babu,Wei-Ning Hsu,Michael Auli",2,61,1
"ab972a92dd5ac31f8b8b026a64707bfeb3149397","https://www.semanticscholar.org/paper/ab972a92dd5ac31f8b8b026a64707bfeb3149397",4,"Do DALL-E and Flamingo Understand Each Other?","It is argued that the best text or caption for a given image is the text which would generate the image which is the most similar to that image, which results in the caption which is best aligned with the original text.","ArXiv",2022,"Hang Li,Jindong Gu,Rajat Koner,Sahand Sharifzadeh,Volker Tresp",0,49,0
"b118283afc5d8652de52cd13a5e287d76c5ec91f","https://www.semanticscholar.org/paper/b118283afc5d8652de52cd13a5e287d76c5ec91f",4,"Real or Fake Text?: Investigating Human Ability to Detect Boundaries Between Human-Written and Machine-Generated Text","There is substantial variance in annotator skill and that given proper incentives, annotators can improve at this task over time, and the RoFT dataset is released: a collection of over 21,000 human annotations paired with error classiﬁcations to encourage future work in human detection and evaluation of generated text.","ArXiv",2022,"Liam Dugan,Daphne Ippolito,Arun Kirubarajan,Sherry Shi,Chris Callison-Burch",2,24,0
"4b308ba40e67b0b4b25c6fde17195d5a456a2f41","https://www.semanticscholar.org/paper/4b308ba40e67b0b4b25c6fde17195d5a456a2f41",4,"Cramming: Training a Language Model on a Single GPU in One Day","This work investigates the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a single day on a single consumer GPU and investigates why scaling down is hard, and which modifications actually improve performance in this scenario.","ArXiv",2022,"Jonas Geiping,T. Goldstein",3,125,1
"b369b05f5386ce22dc7fa33c6f912d5c1cd27f14","https://www.semanticscholar.org/paper/b369b05f5386ce22dc7fa33c6f912d5c1cd27f14",4,"The Power of External Memory in Increasing Predictive Model Capacity","This work introduces a new method, alternating updates, that enables access to an increased token dimension without increasing the computation time, and demonstrates its effectiveness in language modeling.","ArXiv",2023,"Cenk Baykal,D. Cutler,Nishanth Dikkala,Nikhil Ghosh,R. Panigrahy,Xin Wang",0,47,0
"d5bf40a7aff69dcdf9317c8374012c08fa66f87b","https://www.semanticscholar.org/paper/d5bf40a7aff69dcdf9317c8374012c08fa66f87b",4,"Counting Carbon: A Survey of Factors Influencing the Emissions of Machine Learning","A survey of the carbon emissions of 95 ML models across time and different tasks in natural language processing and computer vision is presented, in terms of the energy sources used, the amount of CO2 emissions produced, how these emissions evolve acrosstime and how they relate to model performance.","",2023,"A. Luccioni,Alex Hernández-García",0,56,0
"71e7624755c6a6c024d733220918aa2b1a04f4ed","https://www.semanticscholar.org/paper/71e7624755c6a6c024d733220918aa2b1a04f4ed",4,"Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models","Chain-of-thought prompts are used to intro-duce structures from probabilistic models into large language models and show that they can improve paraphrase selection.","ArXiv",2022,"Ben Prystawski,P. Thibodeau,Noah D. Goodman",2,27,0
"8b97b25a0825b84feebe1b34968a8144bf5acdf0","https://www.semanticscholar.org/paper/8b97b25a0825b84feebe1b34968a8144bf5acdf0",4,"Knowledge-enhanced Neural Machine Reasoning: A Review","This survey provides an in-depth examination of recent advancements in the field, introducing a novel taxonomy that categorizes existing knowledge-enhanced methods into two primary categories and four subcategories and elucidate the current application domains.","ArXiv",2023,"Tanmoy Chowdhury,Chen Ling,Xuchao Zhang,Xujiang Zhao,Guang-ying Bai,Jian Pei,Haifeng Chen,Liang Zhao",0,72,0
"9d81bc8bebf1beb936427c224afb219b54a64f1e","https://www.semanticscholar.org/paper/9d81bc8bebf1beb936427c224afb219b54a64f1e",4,"Surface Form Competition: Why the Highest Probability Answer Isn’t Always Right","Domain Conditional Pointwise Mutual Information is introduced, an alternative scoring function that directly compensates for surface form competition by simply reweighing each option according to its a priori likelihood within the context of a specific task.","Conference on Empirical Methods in Natural Language Processing",2021,"Ari Holtzman,Peter West,Vered Schwartz,Yejin Choi,Luke Zettlemoyer",71,65,13
"91806ece16c0e5cfde5a653277a219ddd9bfe5a7","https://www.semanticscholar.org/paper/91806ece16c0e5cfde5a653277a219ddd9bfe5a7",4,"CheckDST: Measuring Real-World Generalization of Dialogue State Tracking Performance","This work introduces CheckDST, an instantiation of CheckList for DST that quantifies robustness with test set augmenta- 013 tions and new metrics that measure consistency, and compares state-of-the-art DST models.","ArXiv",2021,"Hyundong Justin Cho,Chinnadhurai Sankar,Christopher Lin,Kaushik Ram Sadagopan,Shahin Shayandeh,Asli Celikyilmaz,Jonathan May,A. Beirami",4,45,1
"c586320be1b7178893e7fe4d87e4527b73f0f250","https://www.semanticscholar.org/paper/c586320be1b7178893e7fe4d87e4527b73f0f250",4,"Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics","It is discovered that different classes of DST models have clear strengths and weaknesses, where generation models are more promising for handling language variety while span-based classification models are less robust to unseen entities and each model class has distinct patterns of failure.","Conference on Empirical Methods in Natural Language Processing",2021,"Hyundong Justin Cho,Chinnadhurai Sankar,Christopher Lin,Kaushik Ram Sadagopan,Shahin Shayandeh,Asli Celikyilmaz,Jonathan May,A. Beirami",1,52,0
"4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904","https://www.semanticscholar.org/paper/4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",4,"Few-shot Learning with Multilingual Language Models","This work trains multilingual generative language models on a corpus covering a diverse set of languages, and conducts an in-depth analysis of different multilingual prompting approaches, showing in particular that strong in-context few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples.","ArXiv",2021,"Xi Victoria Lin,Todor Mihaylov,Mikel Artetxe,Tianlu Wang,Shuohui Chen,Daniel Simig,Myle Ott,Naman Goyal,Shruti Bhosale,Jingfei Du,Ramakanth Pasunuru,Sam Shleifer,Punit Singh Koura,Vishrav Chaudhary,Brian O'Horo,Jeff Wang,Luke Zettlemoyer,Zornitsa Kozareva,Mona Diab,V. Stoyanov,Xian Li",50,88,3
"265d3e6c09816f744500924931aa977f0a8ba288","https://www.semanticscholar.org/paper/265d3e6c09816f744500924931aa977f0a8ba288",4,"WikiOmnia: filtration and evaluation of the generated QA corpus on the whole Russian Wikipedia","The WikiOmnia dataset is presented, a new publicly available set of QA pairs and corresponding Russian Wikipedia article summary sections, composed with a fully automated generation and filtration pipeline.","IEEE Games Entertainment Media Conference",2022,"D. Pisarevskaya,Tatiana Shavrina",0,46,0
"cbdb45fc16b0885905b91d84281c310e6cb49e9c","https://www.semanticscholar.org/paper/cbdb45fc16b0885905b91d84281c310e6cb49e9c",4,"Cross-Task Generalization via Natural Language Crowdsourcing Instructions","This work introduces NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances, and adopts generative pre-trained language models to encode task-specific instructions along with input and generate task output.","Annual Meeting of the Association for Computational Linguistics",2021,"Swaroop Mishra,Daniel Khashabi,Chitta Baral,Hannaneh Hajishirzi",116,54,15
"6bd91a3183ddb844641acb9f3fe9faec6a9ff617","https://www.semanticscholar.org/paper/6bd91a3183ddb844641acb9f3fe9faec6a9ff617",4,"Meta-learning via Language Model In-context Tuning","ICT leverages the inductive bias of pre-trained LMs to perform pattern matching, and outperforms MAML by an absolute 6% average AUC-ROC score on BinaryClfs, gaining more advantage with increasing model size.","Annual Meeting of the Association for Computational Linguistics",2021,"Yanda Chen,Ruiqi Zhong,Sheng Zha,G. Karypis,He He",30,60,4
"a0b777b25cdf0fc992568ca52a5c7bebf1ee987f","https://www.semanticscholar.org/paper/a0b777b25cdf0fc992568ca52a5c7bebf1ee987f",4,"Deep Transfer Learning & Beyond: Transformer Language Models in Information Systems Research","A review of existing IS literature reveals that suboptimal text mining techniques are prevalent and that the more advanced TLMs could be applied to enhance and increase IS research involving text data, and to enable new IS research topics, thus creating more value for the research community.","ACM Computing Surveys",2021,"Ross Gruetzemacher,D. Paradice",0,213,0
"7cbc2a7843411a1768ab762930707af0a3c33a19","https://www.semanticscholar.org/paper/7cbc2a7843411a1768ab762930707af0a3c33a19",4,"Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model","The infrastructure as well as the 3D parallelism methodology used to train the largest monolithic transformer based language model, Megatron-Turing NLG 530B (MT-NLG), with 530 billion parameters is presented.","ArXiv",2022,"Shaden Smith,M. Patwary,Brandon Norick,P. LeGresley,Samyam Rajbhandari,J. Casper,Zhun Liu,Shrimai Prabhumoye,George Zerveas,V. Korthikanti,Elton Zhang,Rewon Child,Reza Yazdani Aminabadi,J. Bernauer,Xia Song,M. Shoeybi,Yuxiong He,Michael Houston,Saurabh Tiwary,Bryan Catanzaro",194,69,15
"1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa","https://www.semanticscholar.org/paper/1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa",4,"Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework","Despite its simplicity and relatively small-scale training data, OFA achieves new SOTAs in a series of cross-modal tasks while attaining highly competitive performances on uni- modal tasks.","International Conference on Machine Learning",2022,"Peng Wang,An Yang,Rui Men,Junyang Lin,Shuai Bai,Zhikang Li,Jianxin Ma,Chang Zhou,Jingren Zhou,Hongxia Yang",148,106,41
"18e27c61ccc227fefc8a82b5732f08b6b41e0c84","https://www.semanticscholar.org/paper/18e27c61ccc227fefc8a82b5732f08b6b41e0c84",4,"Recommendation as Language Processing (RLP): A Unified Pretrain, Personalized Prompt & Predict Paradigm (P5)","A flexible and unified text-to-text paradigm called “Pretrain, Personalized Prompt, and Predict Paradigm” (P5) for recommendation, which unifies various recommendation tasks in a shared framework and will revolutionize the technical form of recommender systems towards universal recommendation engine.","ACM Conference on Recommender Systems",2022,"Shijie Geng,Shuchang Liu,Zuohui Fu,Yingqiang Ge,Yongfeng Zhang",20,85,1
"b399dcb2ce41a8389b7d1ad8689ee7641c4d12f3","https://www.semanticscholar.org/paper/b399dcb2ce41a8389b7d1ad8689ee7641c4d12f3",4,"WikiOmnia: generative QA corpus on the whole Russian Wikipedia","The WikiOmnia dataset is presented, a new publicly available set of QA-pairs and corresponding Russian Wikipedia article summary sections, composed with a fully automated generative pipeline, which includes every available article from Wikipedia for the Russian language.","ArXiv",2022,"D. Pisarevskaya,Tatiana Shavrina",0,44,0
"cb16b85891172572cd856142880b503db0c2bc61","https://www.semanticscholar.org/paper/cb16b85891172572cd856142880b503db0c2bc61",4,"What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment","This work uses the task of deciding whether a given string matches a regular expression to identify properties of tasks, instructions, and instances that make instruction learning challenging, and proposes Hard RegSet as a challenging instruction learning dataset and a controlled environment for studying instruction learning.","Conference on Empirical Methods in Natural Language Processing",2022,"Matthew Finlayson,Kyle Richardson,Ashish Sabharwal,Peter Clark",4,30,1
"c211f7516abf28bb751dce63043d09edec14b4b4","https://www.semanticscholar.org/paper/c211f7516abf28bb751dce63043d09edec14b4b4",4,"TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models","TemporalWiki is introduced, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, which verifies that factual knowledge in LMs can be safely updated with minimal training data via continual learning.","Conference on Empirical Methods in Natural Language Processing",2022,"Joel Jang,Seonghyeon Ye,C. Lee,Sohee Yang,Joongbo Shin,Janghoon Han,Gyeonghun Kim,Minjoon Seo",13,46,1
"07c70ca55793984ffdf31582a05170ef3d62381a","https://www.semanticscholar.org/paper/07c70ca55793984ffdf31582a05170ef3d62381a",4,"Prompt Consistency for Zero-Shot Task Generalization","This work takes advantage of the fact that multiple prompts can be used to specify a single task, and proposes to regularize prompt consistency, encouraging consistent predictions over this diverse set of prompts, to improve zero-shot performance.","Conference on Empirical Methods in Natural Language Processing",2022,"Chunting Zhou,Junxian He,Xuezhe Ma,Taylor Berg-Kirkpatrick,Graham Neubig",13,54,1
"1bcde55995a957b3e8a595d536b816cb8989cf1d","https://www.semanticscholar.org/paper/1bcde55995a957b3e8a595d536b816cb8989cf1d",4,"MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning","This work describes a neuro-symbolic architecture with multiple neural models, complemented by discrete knowledge and reasoning modules, dubbed the Modular Reasoning, Knowledge and Language (MRKL), and some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs’ MRKL system implementation.","ArXiv",2022,"E. Karpas,Omri Abend,Yonatan Belinkov,Barak Lenz,Opher Lieber,Nir Ratner,Y. Shoham,Hofit Bata,Yoav Levine,K. Leyton-Brown,Dor Muhlgay,N. Rozen,Erez Schwartz,Gal Shachaf,S. Shalev-Shwartz,A. Shashua,Moshe Tenenholtz",4,26,0
"2f291b0b59483e9c3c4a3391f34e6b29aff848a1","https://www.semanticscholar.org/paper/2f291b0b59483e9c3c4a3391f34e6b29aff848a1",4,"DeepStruct: Pretraining of Language Models for Structure Prediction","It is shown that a 10B parameter language model transfers non-trivially to most tasks and obtains state-of-the-art performance on 21 of 28 datasets that are evaluated.","Findings",2022,"Chenguang Wang,Xiao Liu,Zui Chen,Haoyun Hong,Jie Tang,Dawn Song",6,97,3
"e6296cf7c2c7b4578f1ae644edae4ceee5a5faea","https://www.semanticscholar.org/paper/e6296cf7c2c7b4578f1ae644edae4ceee5a5faea",4,"On Measuring Social Biases in Prompt-Based Multi-Task Learning","This paper uses an existing bias benchmark for the former BBQ and creates the first bias benchmark in natural language inference BBNLI with hand-written hypotheses while also converting each benchmark into the other form, suggesting that given two different formulations of essentially the same input, T0 conspicuously acts more biased in question answering form.","NAACL-HLT",2022,"Afra Feyza Akyurek,Sejin Paik,Muhammed Yusuf Kocyigit,S. Akbiyik,cSerife Leman Runyun,D. Wijaya",0,43,0
"5c78831b77d176f00679ae0654cc9eca0113b1a1","https://www.semanticscholar.org/paper/5c78831b77d176f00679ae0654cc9eca0113b1a1",4,"Few-shot Reranking for Multi-hop QA via Language Model Prompting","PromptRank, which relies on large language models prompting for multi-hop path reranking, first constructs an instruction-based prompt that includes a candidate document path and then computes the relevance score between a given question and the path based on the conditional likelihood of the question given the path prompt according to a language model.","",2022,"Muhammad Khalifa,L. Logeswaran,Moontae Lee,Ho Hin Lee,Lu Wang",0,48,0
"1791972b162aea075dbd07a8b5ba8760d9264f02","https://www.semanticscholar.org/paper/1791972b162aea075dbd07a8b5ba8760d9264f02",4,"Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task","The 3B-parameter zero-shot model outperforms all models, including ensembles, in the COLIEE 2021 test set and also achieves the best performance of a single model in theCOLIEE 2022 competition, second only to the ensemble composed of the 3B model itself and a smaller version of the same model.","ArXiv",2022,"G. Rosa,L. Bonifacio,Vitor Jeronymo,H. Abonizio,R. Lotufo,Rodrigo Nogueira",2,34,0
"fbb832181ebcdd45d7527502b860b7e421a65a1c","https://www.semanticscholar.org/paper/fbb832181ebcdd45d7527502b860b7e421a65a1c",4,"InPars: Unsupervised Dataset Generation for Information Retrieval","This work harnesses the few-shot capabilities of large pretrained language models as synthetic data generators for IR tasks and shows that models finetuned solely on these synthetic datasets outperform strong baselines such as BM25 as well as recently proposed self-supervised dense retrieval methods.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2022,"L. Bonifacio,H. Abonizio,Marzieh Fadaee,Rodrigo Nogueira",7,56,2
"2d3b6058370b804009fd7866098f4fca2d1894ca","https://www.semanticscholar.org/paper/2d3b6058370b804009fd7866098f4fca2d1894ca",4,"Reducing Retraining by Recycling Parameter-Efficient Prompts","This work proposes and investigates several approaches to “Prompt Re-cycling”, where a prompt trained on a source model is transformed to work with the new target model, and shows that recycling between models is possible.","ArXiv",2022,"Brian Lester,Joshua Yurtsever,Siamak Shakeri,Noah Constant",1,40,0
"12941d1b35059a85b3a135a8aa8f6cc3dd630e39","https://www.semanticscholar.org/paper/12941d1b35059a85b3a135a8aa8f6cc3dd630e39",4,"Changes from Classical Statistics to Modern Statistics and Data Science","This perspective addresses the urgent need to overcome those fundamental limitations and encourages extensions of classical probability theory, hypothesis testing and regression, Brownian motion, diffusion equations and stochastic differential equations from Euclidean space to non-Euclidan space.","ArXiv",2022,"Kai Zhang,Shan-Yu Liu,M. Xiong",0,136,0
"37f0f1f55f44bff84aac27a346dd47d0c6c136e3","https://www.semanticscholar.org/paper/37f0f1f55f44bff84aac27a346dd47d0c6c136e3",4,"GPS: Genetic Prompt Search for Efficient Few-Shot Learning","GPS is gradient-free and requires no update of model parameters but only a small validation set, which outperforms manual prompts by a large margin and is better than other parameter-efficient tuning methods such as prompt tuning.","Conference on Empirical Methods in Natural Language Processing",2022,"Hanwei Xu,Yujun Chen,Yulun Du,Nan Shao,Yang Wang,Haiyu Li,Zhilin Yang",0,26,0
"b4e3ce1c8d263cf028bec5ca0b837a88ff96a475","https://www.semanticscholar.org/paper/b4e3ce1c8d263cf028bec5ca0b837a88ff96a475",4,"Multi-Vector Retrieval as Sparse Alignment","This paper proposes A LIGNE R, a novel multi-vector retrieval model that learns sparsiﬁed pairwise alignments between query and document tokens and learns the sparse unary saliences with entropy-regularized linear programming, which outperforms other methods to achieve sparsity.","ArXiv",2022,"Yujie Qian,Jinhyuk Lee,Sai Meher Karthik Duddu,Zhuyun Dai,Siddhartha Brahma,Iftekhar Naim,Tao Lei,Vincent Zhao",3,36,0
"748a2700ec11f51560a69ec05c67ca9f97014be7","https://www.semanticscholar.org/paper/748a2700ec11f51560a69ec05c67ca9f97014be7",4,"EvEntS ReaLM: Event Reasoning of Entity States via Language Models","The results indicate that the prompting technique is especially useful for unseen attributes (out-of-domain) or when only limited data is available and that proper model prompting can dramatically improve performance of reported baseline results across multiple tasks.","Conference on Empirical Methods in Natural Language Processing",2022,"Evangelia Spiliopoulou,Artidoro Pagnoni,Yonatan Bisk,E. Hovy",0,45,0
"419146161a6ab37c3111593631b6c657f5da13ae","https://www.semanticscholar.org/paper/419146161a6ab37c3111593631b6c657f5da13ae",4,"TCBERT: A Technical Report for Chinese Topic Classification BERT","This work investigates supervised continued pre- training on BERT for Chinese topic classiﬁcation task and incorporates prompt-based learning and contrastive learning into the pre-training.","ArXiv",2022,"Ting Han,Kunhao Pan,Xinyu Chen,Dingjie Song,Yuchen Fan,Xinyu Gao,Ruyi Gan,Jiaxing Zhang",0,50,0
"cc43306e22dbfd5bc35251ab8c8ba37e4fc2a1b3","https://www.semanticscholar.org/paper/cc43306e22dbfd5bc35251ab8c8ba37e4fc2a1b3",4,"Legal Prompting: Teaching a Language Model to Think Like a Lawyer","This work takes the COLIEE entailment task based on the Japanese Bar exam for testing zero-shot/few-shot prompting approaches and shows that the best results are produced by prompts that are derived from legal reasoning techniques such as IRAC (Issue, Rule, Application, Conclusion).","ArXiv",2022,"Fang Yu,Lee Quartey,Frank Schilder",1,23,0
"bbe93c90b7b87939cd064c805858feca61a3234d","https://www.semanticscholar.org/paper/bbe93c90b7b87939cd064c805858feca61a3234d",4,"Self-Instruct: Aligning Language Model with Self Generated Instructions","S ELF -I NSTRUCT provides an almost annotation-free method for aligning pre-trained language models with instructions, and is released to facili-tate future studies on instruction tuning.","ArXiv",2022,"Yizhong Wang,Yeganeh Kordi,Swaroop Mishra,Alisa Liu,Noah A. Smith,Daniel Khashabi,Hannaneh Hajishirzi",6,54,3
"c49a0912595a1cc70aab63524f64ed08c92194a8","https://www.semanticscholar.org/paper/c49a0912595a1cc70aab63524f64ed08c92194a8",4,"Evolutionary-scale prediction of atomic level protein structure with a language model","It is shown that direct inference of structure from primary sequence using a large language model enables an order of magnitude speed-up in high resolution structure prediction, which results in prediction that is up to 60x faster than state-of-the-art while maintaining resolution and accuracy.","bioRxiv",2022,"Zeming Lin,Halil Akin,Roshan Rao,B. Hie,Zhongkai Zhu,Wenting Lu,Nikita Smetanin,Robert Verkuil,Ori Kabeli,Y. Shmueli,Allan dos Santos Costa,M. Fazel-Zarandi,Tom Sercu,Salvatore Candido,Alexander Rives",48,73,7
"2eb0e52354b7bbee820905189985877700651108","https://www.semanticscholar.org/paper/2eb0e52354b7bbee820905189985877700651108",4,"Multitask Instruction-based Prompting for Fallacy Recognition","This work shows how instruction-based prompting in a multitask setup based on the T5 model improves the results against approaches built for a specific dataset such as T5, BERT or GPT-3 and examines the effect of model size and prompt choice on model performance.","Conference on Empirical Methods in Natural Language Processing",2023,"Tariq Alhindi,Tuhin Chakrabarty,Elena Musi,S. Muresan",0,43,0
"b7270830eb423d6970490e7ab20c14732e9d7ae2","https://www.semanticscholar.org/paper/b7270830eb423d6970490e7ab20c14732e9d7ae2",4,"Efficient Language Model Training through Cross-Lingual and Progressive Transfer Learning","A cross-lingual and progressive transfer learning approach that transfers models from a source language, for which pre-trained models are publicly available, like English, to a new target language, called CLP-Transfer is introduced.","ArXiv",2023,"Malte Ostendorff,G. Rehm",0,47,0
"4043a936960de8e149dc208178fe1bcb157c7fa4","https://www.semanticscholar.org/paper/4043a936960de8e149dc208178fe1bcb157c7fa4",4,"Recent Advances in Natural Language Inference: A Survey of Benchmarks, Resources, and Approaches","An overview of recent benchmarks, relevant knowledge resources, and state-of-the-art learning and inference approaches in order to support a better understanding of this growing field of NLP is provided.","",2019,"Shane Storks,Qiaozi Gao,J. Chai",62,313,3
"53d5930ecd9dcc3eb79ef576f61fea248602e850","https://www.semanticscholar.org/paper/53d5930ecd9dcc3eb79ef576f61fea248602e850",4,"Grounded Compositional Outputs for Adaptive Language Modeling","This work proposes a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions, and is the first word-level language model with a size that does not depend on the training vocabulary.","Conference on Empirical Methods in Natural Language Processing",2020,"Nikolaos Pappas,Phoebe Mulcaire,Noah A. Smith",3,52,0
"907a77639069bb7dd270f017068745706133cffc","https://www.semanticscholar.org/paper/907a77639069bb7dd270f017068745706133cffc",4,"Inaccessible Neural Language Models Could Reinvigorate Linguistic Nativism","This work argues that this lack of accessibility could instill a nativist bias in researchers new to computational linguistics, and calls upon researchers to open source their LLM code wherever possible to allow both empircist and hybrid approaches to remain accessible.","ArXiv",2023,"Patrick Perrine",0,56,0
"c1ace33daf974d3d16752c7a8565f32a63b09c49","https://www.semanticscholar.org/paper/c1ace33daf974d3d16752c7a8565f32a63b09c49",4,"Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners","The goal of this work is to build ﬂexible video-language models that can generalize to various video-to-text tasks from few examples, such as domain-speciﬁc captioning, question answering, and future event prediction, which outperforms state-of-the-art supervised models trained on any video datasets.","ArXiv",2022,"Zhenhailong Wang,Manling Li,Ruochen Xu,Luowei Zhou,Jie Lei,Xudong Lin,Shuohang Wang,Ziyi Yang,Chenguang Zhu,Derek Hoiem,Shih-Fu Chang,Mohit Bansal,Heng Ji",9,74,2
"ace0745f4449f20e4f4297476941fcd7dc7ab05c","https://www.semanticscholar.org/paper/ace0745f4449f20e4f4297476941fcd7dc7ab05c",4,"Higher Cognition: A Mechanical Perspective","","Encyclopedia",2022,"Robert Friedman",0,69,0
"dd12f12015220d4beb2967fe23860d575e7a9e53","https://www.semanticscholar.org/paper/dd12f12015220d4beb2967fe23860d575e7a9e53",4,"Grounding Language with Visual Affordances over Unstructured Data","This work proposes a novel approach to learn general-purpose language-conditioned robot skills from unstructured, of-ine and reset-free data in the real world by exploiting a self-supervised visuo-lingual affordance model, which requires annotating as little as 1% of the total data with language.","ArXiv",2022,"Oier Mees,Jessica Borja-Diaz,W. Burgard",2,37,0
"f763cd0e3a9e14e1bf7ab0afacb9bbff30bbba29","https://www.semanticscholar.org/paper/f763cd0e3a9e14e1bf7ab0afacb9bbff30bbba29",4,"Using Both Demonstrations and Language Instructions to Efficiently Learn Robotic Tasks","This is the first work to show that simultaneously conditioning a multi-task robotic manipulation policy on both demonstration and language embeddings improves sample efﬁciency and generalization over conditioning on either modality alone.","ArXiv",2022,"Albert Yu,R. Mooney",0,52,0
"1fa589c76e14492dca7a544d58628c2a4dc55264","https://www.semanticscholar.org/paper/1fa589c76e14492dca7a544d58628c2a4dc55264",4,"Instruction-Following Agents with Jointly Pre-Trained Vision-Language Models","This work proposes a simple yet effective model for robots to solve instruction-following tasks in vision-based environments that outperforms all state-of-the-art pre-trained or trained-from-scratch methods in both single-task and multi-task settings.","ArXiv",2022,"Hao Liu,Lisa Lee,Kimin Lee,P. Abbeel",1,46,0
"af3a6deac815c7e41a58b15be74e5e7a1066b899","https://www.semanticscholar.org/paper/af3a6deac815c7e41a58b15be74e5e7a1066b899",4,"InstructRL: Simple yet Effective Instruction-Following Agents with Multimodal Transformer","This work proposes a simple yet effective model for robots to solve instruction-following tasks in vision-based environments that outperforms all state-of-the-art pre-trained or trained-from-scratch methods in both single-task and multi-task settings.","",2022,"Hao Liu,Lisa Lee,Kimin Lee,P. Abbeel",0,46,0
"df065b3cd3621211320d9900186243aa1d086067","https://www.semanticscholar.org/paper/df065b3cd3621211320d9900186243aa1d086067",4,"Open-vocabulary Semantic Segmentation with Frozen Vision-Language Models","This paper introduces Fusioner, with a lightweight, transformer-based fusion module, that pairs the frozen visual representation with language concept through a handful of image segmentation data, and demonstrates superior performance over previous models.","British Machine Vision Conference",2022,"Chao Ma,Yu-Hao Yang,Yanfeng Wang,Ya Zhang,Weidi Xie",3,55,0
"d7d6701a0c6a252c950f1d046c277157da5a463d","https://www.semanticscholar.org/paper/d7d6701a0c6a252c950f1d046c277157da5a463d",4,"Learning to Solve Voxel Building Embodied Tasks from Pixels and Natural Language Instructions","A new method is proposed that combines a language model and reinforcement learning for the task of building objects in a Minecraft-like environment according to the natural language instructions and generates a set of consistently achievable sub-goals from the instructions and then completes associated sub-tasks with a pre-trained RL policy.","ArXiv",2022,"Alexey Skrynnik,Zoya Volovikova,Marc-Alexandre Côté,Anton Voronov,Artem Zholus,Negar Arabzadeh,Shrestha Mohanty,Milagro Teruel,A. Awadallah,A. Panov,M. Burtsev,Julia Kiseleva",0,15,0
"5aaf780c63c87db6c90c7f96308cf90296c5b226","https://www.semanticscholar.org/paper/5aaf780c63c87db6c90c7f96308cf90296c5b226",4,"Zero-shot Image Captioning by Anchor-augmented Vision-Language Space Alignment","This work proposes Cross-modal Language Models (CLMs) to facilitate unsupervised cross- modal learning and proposes Anchor Augment to guide the generative model’s attention to the ﬁne-grained information in the representation of CLIP.","ArXiv",2022,"Junyan Wang,Yi Zhang,Ming Yan,J. Zhang,J. Sang",0,36,0
"d9c7e401ae1dce2c5836ad561adb5a4504a42176","https://www.semanticscholar.org/paper/d9c7e401ae1dce2c5836ad561adb5a4504a42176",4,"Doubly Right Object Recognition: A Why Prompt for Visual Rationales","By trans-ferring the rationales from language models into visual representations through a tailored dataset, it is shown that a “why prompt,” which adapts large visual representations to produce correct rationales, can be learned.","ArXiv",2022,"Chengzhi Mao,Revant Teotia,Amrutha Sundar,Sachit Menon,Junfeng Yang,Xin Eric Wang,Carl Vondrick",0,59,0
"ae766548699f27e669932de14e1c0f47b2828536","https://www.semanticscholar.org/paper/ae766548699f27e669932de14e1c0f47b2828536",4,"Prompting for Multimodal Hateful Meme Classification","This work proposes PromptHate, a simple yet effective prompt-based model that prompts pre-trained language models (PLMs) for hateful meme classification, and constructs simple prompts and provides a few in-context examples to exploit the implicit knowledge in the pre- trained RoBERTa language model for hateful memes classification.","Conference on Empirical Methods in Natural Language Processing",2023,"Rui Cao,R. Lee,Wen-Haw Chong,Jing Jiang",0,44,0
"6c194ca1bcee1fab2dfb289dadcdd9a829b736df","https://www.semanticscholar.org/paper/6c194ca1bcee1fab2dfb289dadcdd9a829b736df",4,"Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis","This work proposes an end-to-end vision and language model incorporating explicit knowledge graphs and introduces an interactive out-of-distribution (OOD) layer using implicit network operator that is used to filter noise that is brought by external knowledge base.","ArXiv",2023,"Zhu Wang,Sourav Medya,S. Ravi",0,51,0
"66eae7128c34dd7967d79224eb9dbc978773c3d0","https://www.semanticscholar.org/paper/66eae7128c34dd7967d79224eb9dbc978773c3d0",4,"I2D2: Inductive Knowledge Distillation with NeuroLogic and Self-Imitation","The key intellectual question is whether it is possible, if at all, to design a learning algorithm that does not beneﬁt from scale, yet leads to a competitive level of commonsense acquisition.","ArXiv",2022,"Chandra Bhagavatula,Jena D. Hwang,Doug Downey,Ronan Le Bras,Ximing Lu,Keisuke Sakaguchi,Swabha Swayamdipta,Peter West,Yejin Choi",0,33,0
"044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3","https://www.semanticscholar.org/paper/044e13d7dd4e0655eb76f0bd00b2c1bdb44e2be3",3,"Big Bird: Transformers for Longer Sequences","It is shown that BigBird is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model.","Neural Information Processing Systems",2020,"M. Zaheer,Guru Guruganesh,Kumar Avinava Dubey,J. Ainslie,Chris Alberti,Santiago Ontañón,Philip Pham,Anirudh Ravula,Qifan Wang,Li Yang,Amr Ahmed",828,117,139
"30eff53e981695c7296d258b8dc44b4c7b482a0c","https://www.semanticscholar.org/paper/30eff53e981695c7296d258b8dc44b4c7b482a0c",3,"A Discrete Hard EM Approach for Weakly Supervised Question Answering","This paper develops a hard EM learning scheme that computes gradients relative to the most likely solution at each update and significantly outperforms previous methods on six QA tasks, including absolute gains of 2–10%, and achieves the state-of-the-art on five of them.","Conference on Empirical Methods in Natural Language Processing",2019,"Sewon Min,Danqi Chen,Hannaneh Hajishirzi,Luke Zettlemoyer",122,46,20
"3fd92feb43d61645429ec4a2c80b1304a3c8bd69","https://www.semanticscholar.org/paper/3fd92feb43d61645429ec4a2c80b1304a3c8bd69",3,"A Mutual Information Maximization Approach for the Spurious Solution Problem in Weakly Supervised Question Answering","Extensive experiments show that this method significantly outperforms previous learning methods in terms of task performance and is more effective in training models to produce correct solutions.","Annual Meeting of the Association for Computational Linguistics",2021,"Zhihong Shao,Lifeng Shang,Qun Liu,Minlie Huang",5,37,0
"b9fa682deb66997ed27f3f47d8976c64f093be27","https://www.semanticscholar.org/paper/b9fa682deb66997ed27f3f47d8976c64f093be27",3,"MSReNet: Multi-step Reformulation for Open-Domain Question Answering","A new framework MSReNet is introduced for open-domain question answering where the question reformulator interacts with the term-based retrieval system, which can improve retrieval precision and QA performance.","Natural Language Processing and Chinese Computing",2020,"Weiguang Han,Min Peng,Qianqian Xie,Xiuzhen Zhang,Hua Wang",1,25,0
"7434fb6c79a50bfedd4ad1c872f9e4fb1f25571a","https://www.semanticscholar.org/paper/7434fb6c79a50bfedd4ad1c872f9e4fb1f25571a",3,"ERNIE-Doc: A Retrospective Long-Document Modeling Transformer","Two welldesigned techniques, namely the retrospective feed mechanism and the enhanced recurrence mechanism, enable ERNIE-DOC 1, which has a much longer effective context length, to capture the contextual information of a complete document.","Annual Meeting of the Association for Computational Linguistics",2021,"Siyu Ding,Junyuan Shang,Shuohuan Wang,Yu Sun,Hao Tian,Hua Wu,Haifeng Wang",15,49,0
"b53c510769760d2fbcb674ed14bacfe251ae0ebc","https://www.semanticscholar.org/paper/b53c510769760d2fbcb674ed14bacfe251ae0ebc",3,"Select and Trade: Towards Unified Pair Trading with Hierarchical Reinforcement Learning","A paradigm for automatic pair trading is proposed as a unified task rather than a two-step pipeline and a hierarchical reinforcement learning framework is designed to jointly learn and optimize two subtasks.","ArXiv",2023,"Weiguang Han,Boyi Zhang,Qianqian Xie,Min Peng,Yanzhao Lai,Jimin Huang",0,53,0
"f01c433acfaef63d7dfc168a507fdb09cd48032e","https://www.semanticscholar.org/paper/f01c433acfaef63d7dfc168a507fdb09cd48032e",3,"Narrative Question Answering with Cutting-Edge Open-Domain QA Techniques: A Comprehensive Study","The findings indicate that the event-centric questions dominate this task, which exemplifies the inability of existing QA models to handle event-oriented scenarios.","Transactions of the Association for Computational Linguistics",2021,"Xiangyang Mou,Chenghao Yang,Mo Yu,Bingsheng Yao,Xiaoxiao Guo,Saloni Potdar,Hui Su",6,42,0
"3467b97c35d7d9e8d94b0a490751880ccdbcc479","https://www.semanticscholar.org/paper/3467b97c35d7d9e8d94b0a490751880ccdbcc479",3,"Neural Code Summarization: How Far Are We?","A systematic and in-depth analysis of five state-of-the-art neural source code summarization models on three widely used datasets suggests that the BLEU metric has many variants and code pre-processing choices can have a large impact on the summarization performance.","ArXiv",2021,"Ensheng Shi,Yanlin Wang,Lun Du,Junjie Chen,Shi Han,Hongyu Zhang,Dongmei Zhang,Hongbin Sun",11,60,4
"343594d16840c3841e70ca603f500a79c433848b","https://www.semanticscholar.org/paper/343594d16840c3841e70ca603f500a79c433848b",3,"On the Evaluation of Neural Code Summarization","A systematic and in-depth analysis of 5 state-of-the-art neural code summarization models on 6 widely used BLEU variants, 4 pre-processing operations and their combinations, and 3 widely used datasets shows that some important factors have a great influence on the model evaluation, especially on the performance of models and the ranking among the models.","International Conference on Software Engineering",2021,"Ensheng Shi,Yanlin Wang,Lun Du,Junjie Chen,Shi Han,Hongyu Zhang,Dongmei Zhang,Hongbin Sun",12,71,1
"1e6345a73372f593a0bab78e66ee6c98a44feaed","https://www.semanticscholar.org/paper/1e6345a73372f593a0bab78e66ee6c98a44feaed",3,"EventNarrative: A large-scale Event-centric Dataset for Knowledge Graph-to-Text Generation","The aim of this paper is to help break new ground in event-centric research where data is lacking and to give researchers a well-deﬁned, large-scale dataset in order to better evaluate existing and future knowledge graph-to-text models.","NeurIPS Datasets and Benchmarks",2021,"A. Colas,A. Sadeghian,Yue Wang,D. Wang",3,56,0
"eca8c79f2a0c469e26af514481e72edb97a26a35","https://www.semanticscholar.org/paper/eca8c79f2a0c469e26af514481e72edb97a26a35",3,"A review on COLREGs-compliant navigation of autonomous surface vehicles: From traditional to learning-based approaches","","Journal of Automation and Intelligence",2022,"Liangmou Hu,Huosheng Hu,W. Naeem,Zidong Wang",0,99,0
"b1281b87f45b533d275c3cb262cdac8c52ef936a","https://www.semanticscholar.org/paper/b1281b87f45b533d275c3cb262cdac8c52ef936a",3,"Value Activation for Bias Alleviation: Generalized-activated Deep Double Deterministic Policy Gradients","This work theoretically and experimentally shows that the distance between the max operator and the generalized-activated weighting operator can be bounded and shows that simple activation functions are enough for amazing performance without any tricks and special design for activation function.","Neurocomputing",2021,"Jiafei Lyu,Yu Yang,Jiangpeng Yan,Xiu Li",0,47,0
"5df17c261a663dbc2ccabc212d75a03828e65fd0","https://www.semanticscholar.org/paper/5df17c261a663dbc2ccabc212d75a03828e65fd0",3,"Solving Full <math xmlns=""http://www.w3.org/1998/Math/MathML"" id=""M1"">
                     <mi>N</mi>
                     <mo>×</mo>
                     <mi>N</mi>
                     <mo>×</mo>
                     <mi>N</mi>
                  </math> Rubik’s Supercube Using Genetic Algorithm","An algorithm that uses an evolutionary approach to the problem of solving the Full Rubik, i.e., the orientation of all cubies, including the internal ones, not only according to face colors but to the same orientation in 3D space is presented.","International Journal of Computer Games Technology",2023,"R. Świta,Z. Suszyński",0,17,0
"521b4e26df0f1cf5763dece14cbb218df152dc59","https://www.semanticscholar.org/paper/521b4e26df0f1cf5763dece14cbb218df152dc59",3,"Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering","A new graph-based recurrent retrieval approach that learns to retrieve reasoning paths over the Wikipedia graph to answer multi-hop open-domain questions and achieves significant improvement in HotpotQA, outperforming the previous best model by more than 14 points.","International Conference on Learning Representations",2019,"Akari Asai,Kazuma Hashimoto,Hannaneh Hajishirzi,R. Socher,Caiming Xiong",203,46,33
"a9c2c295853fb35461b7fbbb60071d29238cb334","https://www.semanticscholar.org/paper/a9c2c295853fb35461b7fbbb60071d29238cb334",3,"Complex Factoid Question Answering with a Free-Text Knowledge Graph","Experiments show delft can answer entity-rich questions better than machine reading based models, bert-based answer ranking and memory networks and the novel graph neural network which reasons on the rich but noisy free-text evidence.","The Web Conference",2020,"Chen Zhao",30,61,6
"e88b18cde9f0b0be5dbf85c373720bc7d952f960","https://www.semanticscholar.org/paper/e88b18cde9f0b0be5dbf85c373720bc7d952f960",3,"F1 Is Not Enough! Models and Evaluation towards User-Centered Explainable Question Answering","A hierarchical model and a new regularization term are proposed to strengthen the answer-explanation coupling as well as two evaluation scores to quantify the coupling.","Conference on Empirical Methods in Natural Language Processing",2020,"Hendrik Schuff,Heike Adel,Ngoc Thang Vu",10,45,1
"fac6e5ab3eb90b3651757b9d7a7927ed9367ae5f","https://www.semanticscholar.org/paper/fac6e5ab3eb90b3651757b9d7a7927ed9367ae5f",3,"Latent Reasoning for Low-Resource Question Generation","A novel generative approach that optimizes the two-phase model without question decomposition data is proposed and outperforms competitive baselines on HOTPOTQA, a benchmark multi-hop question answering dataset.","Findings",2021,"Xinting Huang,Jianzhong Qi,Yu Sun,Rui Zhang",4,70,0
"21f74e2617d8d8f5fc117ff2ad6e58a540541f6d","https://www.semanticscholar.org/paper/21f74e2617d8d8f5fc117ff2ad6e58a540541f6d",3,"Compositional Generalization in Semantic Parsing: Pre-training vs. Specialized Architectures","It is shown that masked language model (MLM) pre-training rivals SCAN-inspired architectures on primitive holdout splits and establishes a new state of the art on the CFQ compositional generalization benchmark using MLM pre- training together with an intermediate representation.","ArXiv",2020,"Daniel Furrer,Marc van Zee,Nathan Scales,Nathanael Scharli",67,73,14
"986cc3d0e3afb23f84564ea9588b7b8e9c3e1dd6","https://www.semanticscholar.org/paper/986cc3d0e3afb23f84564ea9588b7b8e9c3e1dd6",3,"Hierarchical Poset Decoding for Compositional Generalization in Language","A novel hierarchical poset decoding paradigm for compositional generalization in language that enforces partial permutation invariance in semantics, thus avoiding overfitting to bias ordering information and results show that it outperforms current decoders.","Neural Information Processing Systems",2020,"Yinuo Guo,Zeqi Lin,Jian-Guang Lou,Dongmei Zhang",18,39,5
"cc0fc60e9b9d036acf53899c259574c8ce2aedfc","https://www.semanticscholar.org/paper/cc0fc60e9b9d036acf53899c259574c8ce2aedfc",3,"Compositional Generalization via Semantic Tagging","This work decomposes decoding into two phases where an input utterance is first tagged with semantic symbols representing the meanings of its individual words, and then a sequence-to-sequence model is used to predict the final meaning representation conditioning on the utterance and the predicted tag sequence.","Conference on Empirical Methods in Natural Language Processing",2020,"Hao Zheng,Mirella Lapata",19,36,1
"7344ed64d1717780422fd1d58fae85edc544d180","https://www.semanticscholar.org/paper/7344ed64d1717780422fd1d58fae85edc544d180",3,"Iterative Utterance Segmentation for Neural Semantic Parsing","A novel framework for boosting neural semantic parsers via iterative utterance segmentation that iterates between two neural modules: a segmenter for segmenting a span from the utterance, and a parser for mapping the span into a partial meaning representation.","AAAI Conference on Artificial Intelligence",2020,"Yinuo Guo,Zeqi Lin,Jian-Guang Lou,Dongmei Zhang",2,40,0
"f0787aace6a6d892140d9da85b49e76cb06f6862","https://www.semanticscholar.org/paper/f0787aace6a6d892140d9da85b49e76cb06f6862",3,"Automatic Knowledge Augmentation for Generative Commonsense Reasoning","A data-centric method that uses automatic knowledge augmentation to extend commonsense knowledge using a machine knowledge generator that can generate semi-golden sentences that improve the generative commonsense reasoning of a language model without architecture modiﬁcations.","ArXiv",2021,"Jaehyung Seo,Chanjun Park,Sugyeong Eo,Hyeonseok Moon,Heuiseok Lim",3,17,0
"a576512a7562597fd30719a834d5866d010ef6ab","https://www.semanticscholar.org/paper/a576512a7562597fd30719a834d5866d010ef6ab",3,"Compositional Generalization for Natural Language Interfaces to Web APIs","New compositional generalization tasks for NL2API are defined which explore the models’ ability to extrapolate from simple API calls in the training set to new and more complex API Calls in the inference phase.","ArXiv",2021,"Saghar Hosseini,A. Awadallah,Yu Su",1,33,1
"474c954231413f2a249f04272dbeda19cd8ff09b","https://www.semanticscholar.org/paper/474c954231413f2a249f04272dbeda19cd8ff09b",3,"Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion","This work proposes to address the out-of-domain generalization problem of domain specific phrases to composite operation over columns by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning.","Annual Meeting of the Association for Computational Linguistics",2022,"Chen Zhao,Yu Su,Adam Pauls,Emmanouil Antonios Platanios",5,40,2
"2aa1d4350e80613feed88d5a6337e79693f7aa57","https://www.semanticscholar.org/paper/2aa1d4350e80613feed88d5a6337e79693f7aa57",3,"KQA Pro: A Dataset with Explicit Compositional Programs for Complex Question Answering over Knowledge Base","Experimental results show that state-of-the-art KBQA methods cannot achieve promising results on KQA Pro as on current datasets, which suggests that K QA Pro is challenging and Complex KBZA requires further research efforts.","Annual Meeting of the Association for Computational Linguistics",2020,"S. Cao,Jiaxin Shi,Liangming Pan,L. Nie,Yutong Xiang,Lei Hou,Juanzi Li,Bin He,Hanwang Zhang",14,58,2
"997410e2bf80f25f73752dd6fd7122227385ed2d","https://www.semanticscholar.org/paper/997410e2bf80f25f73752dd6fd7122227385ed2d",3,"Measuring Compositional Consistency for Video Question Answering","A question decomposition engine that programmatically deconstructs a compositional question into a directed acyclic graph of sub-questions and finds that models either cannot reason correctly through most compositions or are reliant on incorrect reasoning to reach answers, frequently contradicting themselves or achieving high accuracies when failing at intermediate reasoning steps.","Computer Vision and Pattern Recognition",2022,"Mona Gandhi,Mustafa Omer Gul,Eva Prakash,Madeleine Grunde-McLaughlin,Ranjay Krishna,Maneesh Agrawala",2,57,0
"8969ea3d254e149aebcfd1ffc8f46910d7cb160e","https://www.semanticscholar.org/paper/8969ea3d254e149aebcfd1ffc8f46910d7cb160e",3,"Uncontrolled Lexical Exposure Leads to Overestimation of Compositional Generalization in Pretrained Models","It is argued that exposure to pre-training data may break distributional control across training and test to gauge compositional generalization, where certain lexical items only occur in limited contexts during training.","ArXiv",2022,"Najoung Kim,Tal Linzen,P. Smolensky",3,51,0
"a14505553eda5ae26380d4317d6358491f238e41","https://www.semanticscholar.org/paper/a14505553eda5ae26380d4317d6358491f238e41",3,"Generative adversarial interactive imitation learning for path following of autonomous underwater vehicle","","Ocean Engineering",2022,"Dongqian Jiang,Jie Huang,Zheng Fang,C. Cheng,Q. Sha,Bo He,Guangliang Li",2,40,0
"ae7def75a40073ed119fc9e93a9ecd6d58d3bab0","https://www.semanticscholar.org/paper/ae7def75a40073ed119fc9e93a9ecd6d58d3bab0",3,"Knowledge- and ambiguity-aware robot learning from corrective and evaluative feedback","An IIL method is proposed that improves the human–robot interaction for non-expert and imperfect teachers in two directions and enables the teachers to train with the flexibility of using corrective demonstrations, evaluative reinforcements, and implicit positive feedback.","Neural computing & applications (Print)",2023,"C. Celemin,J. Kober",0,16,0
"aea6e0d7f5baa18887fff60c5ff375a8654a4646","https://www.semanticscholar.org/paper/aea6e0d7f5baa18887fff60c5ff375a8654a4646",3,"Deep Reinforcement Learning for the Design of Musical Interaction","Overall, it was shown that the use of interactive machine learning techniques such as interactive deep reinforcement learning provide exciting new directions for research and have an added and complementary value next to standard ways of manual exploration.","",2018,"",0,84,0
"1b577cafcbda916ccf32a5e0291210afde5c663b","https://www.semanticscholar.org/paper/1b577cafcbda916ccf32a5e0291210afde5c663b",3,"THE IMPLICIT PREFERENCE INFORMATION","An algorithm based on Maximum Causal Entropy IRL is developed and it is found that information from the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.","",2018,"AN In",0,27,0
"3e6cde685fdf321d7edf9319f7b07c01ff79c11a","https://www.semanticscholar.org/paper/3e6cde685fdf321d7edf9319f7b07c01ff79c11a",3,"Reward learning from human preferences and demonstrations in Atari","This work trains a deep neural network to model the reward function and use its predicted reward to train an DQN-based deep reinforcement learning agent on 9 Atari games and achieves strictly superhuman performance on 2 games without using game rewards.","",2018,"Dandelion Mané",2,55,0
"01ee79fa125f532893ba50ad3c77cd4bf29de0ca","https://www.semanticscholar.org/paper/01ee79fa125f532893ba50ad3c77cd4bf29de0ca",3,"Directed Policy Gradient for Safe Reinforcement Learning with Human Advice","The technique, Directed Policy Gradient (DPG), allows a teacher or backup policy to override the agent before it acts undesirably, while allowing the agent to leverage human advice or directives to learn faster.","ArXiv",2018,"Hélène Plisnier,Denis Steckelmacher,T. Brys,Diederik M. Roijers,A. Nowé",0,16,0
"e911cb25e9ce6cc71fa7c854c69c6347279bcb71","https://www.semanticscholar.org/paper/e911cb25e9ce6cc71fa7c854c69c6347279bcb71",3,"Cycle-of-Learning for Autonomous Systems from Human Interaction","Two key concepts provided by the Cycle-of-Learning framework are how it handles the integration of the different human-interaction modalities (demonstration, intervention, and evaluation) and how to define the switching criteria between them.","ArXiv",2018,"Nicholas R. Waytowich,Vinicius G. Goecks,V. Lawhern",13,11,0
"325e1b7cec684c22bb3c2cf65205c77eaf55114f","https://www.semanticscholar.org/paper/325e1b7cec684c22bb3c2cf65205c77eaf55114f",3,"Reward learning from human preferences and demonstrations in Atari","This work trains a deep neural network to model the reward function and use its predicted reward to train an DQN-based deep reinforcement learning agent on 9 Atari games and achieves strictly superhuman performance on 2 games without using game rewards.","Neural Information Processing Systems",2018,"Borja Ibarz,J. Leike,Tobias Pohlen,Geoffrey Irving,S. Legg,Dario Amodei",157,58,19
"c6f913e4baa7f2c85363c0625c87003ad3b3a14c","https://www.semanticscholar.org/paper/c6f913e4baa7f2c85363c0625c87003ad3b3a14c",3,"Scalable agent alignment via reward modeling: a research direction","This work outlines a high-level research direction to solve the agent alignment problem centered around reward modeling: learning a reward function from interaction with the user and optimizing the learned reward function with reinforcement learning.","ArXiv",2018,"J. Leike,David Krueger,Tom Everitt,Miljan Martic,Vishal Maini,S. Legg",137,182,15
"4494395f9e8550e5516c44ef7ce2cb71b217374f","https://www.semanticscholar.org/paper/4494395f9e8550e5516c44ef7ce2cb71b217374f",3,"Learning from Human Feedback: A Comparison of Interactive Reinforcement Learning Algorithms","This thesis presents a general framework that can incorporate different kinds of human interaction and the environmental reward in an Interactive Reinforcement Learning algorithm and simplifies the combination of several, interactive and not interactive, algorithms.","",2019,"Von Menschlichem,Dorothea Koert,Tag der Einreichung,Erklärung zur Master-Thesis",0,49,0
"d35f9c78fc6d656d530aac2ed9f2aae6137b9041","https://www.semanticscholar.org/paper/d35f9c78fc6d656d530aac2ed9f2aae6137b9041",3,"I MPLICIT IN THE S TATE OF THE W ORLD","An algorithm based on Maximum Causal Entropy IRL is developed and it is found that information from the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.","",2019,"Rohin Shah",0,33,0
"5d60613c15de600dc321788b1953bf49f8eced50","https://www.semanticscholar.org/paper/5d60613c15de600dc321788b1953bf49f8eced50",3,"Preferences Implicit in the State of the World","An algorithm based on Maximum Causal Entropy IRL is developed and it is found that information from the initial state can be used to infer both side effects that should be avoided as well as preferences for how the environment should be organized.","International Conference on Learning Representations",2018,"Rohin Shah,Dmitrii Krasheninnikov,Jordan Alexander,P. Abbeel,A. Dragan",40,31,2
"78959e2e613bffabd11896a67a3cfc71793dde07","https://www.semanticscholar.org/paper/78959e2e613bffabd11896a67a3cfc71793dde07",3,"Yesterday's Reward is Today's Punishment: Contrast Effects in Human Feedback to Reinforcement Learning Agents","This work presents empirical evidence to show that human perception affected by contrast effects distorts their feedback to Reinforcement Learning agents, and provides a conceptual understanding of a source of inconsistency in human feedback, thus informing the design of human-agent interactions.","Adaptive Agents and Multi-Agent Systems",2020,"Divya Ramesh,Anthony Z. Liu,A. J. Echeverria,Jean Y. Song,Nicholas R. Waytowich,Walter S. Lasecki",0,29,0
"096758be2b50762474757b38c18f51938cad4f4e","https://www.semanticscholar.org/paper/096758be2b50762474757b38c18f51938cad4f4e",3,"Learning Human Objectives by Evaluating Hypothetical Behavior","An algorithm that safely and interactively learns a model of the user's reward function and actively synthesizes hypothetical behaviors from scratch by maximizing tractable proxies for the value of information, without interacting with the environment.","International Conference on Machine Learning",2019,"S. Reddy,A. Dragan,S. Levine,S. Legg,J. Leike",57,54,1
"14b7d4a34ba869e106d82d658e2973163a11eb12","https://www.semanticscholar.org/paper/14b7d4a34ba869e106d82d658e2973163a11eb12",3,"FRESH: Interactive Reward Shaping in High-Dimensional State Spaces using Human Feedback","This paper seeks to effectively integrate feedback signals supplied by a human operator with deep reinforcement learning algorithms in high-dimensional state spaces and uses an ensemble of neural networks with a shared network architecture to represent model uncertainty and the confidence of the neural network in its output.","Adaptive Agents and Multi-Agent Systems",2020,"Baicen Xiao,Qifan Lu,B. Ramasubramanian,Andrew Clark,L. Bushnell,R. Poovendran",16,51,2
"9f31b5dd1d9407de3ae8aa0f88bc8cfe9392f398","https://www.semanticscholar.org/paper/9f31b5dd1d9407de3ae8aa0f88bc8cfe9392f398",3,"Human-in-the-Loop Methods for Data-Driven and Reinforcement Learning Systems","Results presented in this work show that the reward signal that is learned based upon human interaction accelerates the rate of learning of reinforcement learning algorithms and that learning from a combination of human demonstrations and interventions is faster and more sample efficient when compared to traditional supervised learning algorithms.","ArXiv",2020,"Vinicius G. Goecks",8,213,0
"08bfe0db80f150bc2f8372b9a9817b7c844c1bca","https://www.semanticscholar.org/paper/08bfe0db80f150bc2f8372b9a9817b7c844c1bca",3,"Explanation Augmented Feedback in Human-in-the-Loop Reinforcement Learning","Explanation Augmented Feedback allows for explanatory information to be given as saliency maps from the human in addition to the binary feedback, and an ablation study is presented to confirm the hypothesis that augmenting binary feedback with state salient information gives a boost in performance.","ArXiv",2020,"L. Guan,Mudit Verma,S. Kambhampati",12,63,0
"1e273fb74ebe3d0cb860a301292cee066d058d12","https://www.semanticscholar.org/paper/1e273fb74ebe3d0cb860a301292cee066d058d12",3,"A Survey on Interactive Reinforcement Learning: Design Principles and Open Challenges","This paper elucidate the roles played by HCI researchers in interactive RL, identifying ideas and promising research directions, and proposes generic design principles that will provide researchers with a guide to effectively implement interactive RL applications.","Conference on Designing Interactive Systems",2020,"Christian Arzate Cruz,T. Igarashi",45,115,4
"8c6dc25db6c2e5e90b03d0ecd328b74e3f4cd0c4","https://www.semanticscholar.org/paper/8c6dc25db6c2e5e90b03d0ecd328b74e3f4cd0c4",3,"X 2 T : T RAINING AN X-TOT EXT T YPING I NTERFACE WITH O NLINE L EARNING FROM U SER F EEDBACK","This work proposes an algorithm called x-to-text (X2T) that trains a predictive model of this feedback signal, and uses this model to fine-tune any existing, default interface for translating user input into actions that select words or characters.","",2021,"Jensen Gao,S. Reddy",0,56,0
"364deb949f6ad1abee7f10079b48b61da9203579","https://www.semanticscholar.org/paper/364deb949f6ad1abee7f10079b48b61da9203579",3,"Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation","This paper focuses on the task of learning from feedback, in which the human trainer not only gives binary evaluative “good"" or “bad"" feedback for queried state-action pairs, but also provides a visual explanation by annotating relevant features in images.","Neural Information Processing Systems",2020,"L. Guan,Mudit Verma,Sihang Guo,Ruohan Zhang,Subbarao Kambhampati",18,52,4
"f9f340c8bd0712780148d0f431cd4914a515f4b1","https://www.semanticscholar.org/paper/f9f340c8bd0712780148d0f431cd4914a515f4b1",3,"Recent advances in leveraging human guidance for sequential decision-making tasks","This survey provides a high-level overview of five recent machine learning frameworks that primarily rely on human guidance apart from pre-specified reward functions or conventional, step-by-step action demonstrations.","Autonomous Agents and Multi-Agent Systems",2021,"Ruohan Zhang,F. Torabi,Garrett Warnell,P. Stone",13,232,4
"9c4badd7f983cc37aa4794433893649cc7440fdc","https://www.semanticscholar.org/paper/9c4badd7f983cc37aa4794433893649cc7440fdc",3,"Uncertainties based queries for Interactive policy learning with evaluations and corrections","","ICMI Companion",2021,"C. Celemin,J. Kober",0,9,0
"2a66fda232180a1701016ff5c15d1761ddfa2004","https://www.semanticscholar.org/paper/2a66fda232180a1701016ff5c15d1761ddfa2004",3,"X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback","This work proposes an algorithm called x-to-text (X2T) that trains a predictive model of this feedback signal, and uses this model to fine-tune any existing, default interface for translating user input into actions that select words or characters.","International Conference on Learning Representations",2022,"Jensen Gao,S. Reddy,G. Berseth,Nicholas Hardy,N. Natraj,K. Ganguly,A. Dragan,S. Levine",5,56,0
"40c099d10be5a7ff429ee13f4c3f8b49142b1587","https://www.semanticscholar.org/paper/40c099d10be5a7ff429ee13f4c3f8b49142b1587",3,"Human-in-the-Loop Reinforcement Learning for Adaptive Assistive Interfaces","","",2022,"Jensen Gao",0,101,0
"d3d1f85fe0f9461a570c6040e94adcb530dd5325","https://www.semanticscholar.org/paper/d3d1f85fe0f9461a570c6040e94adcb530dd5325",3,"A Dual Representation Framework for Robot Learning with Human Guidance","It is argued that learning is more efﬁcient if the agent is equipped with a high-level, symbolic representation and two novel learning algorithms based on this framework for learning from human evaluative feedback and from preference are proposed.","",2022,"Ruohan Zhang,Dhruva Bansal,Yilun Hao,Ayano Hiranaka,Jialu Gao,Chen Wang,Li Fei-Fei,Jiajun Wu",1,80,0
"fa5943a641a35d5a7afd545f5bdfd9e71cc56e1a","https://www.semanticscholar.org/paper/fa5943a641a35d5a7afd545f5bdfd9e71cc56e1a",3,"Combining Learning from Human Feedback and Knowledge Engineering to Solve Hierarchical Tasks in Minecraft","This work presents the solution that won first place and was awarded the most human-like agent in the 2021 NeurIPS Competition MineRL BASALT Challenge: Learning from Human Feedback in Minecraft, which challenged participants to use human data to solve four tasks defined only by a natural language description and no reward function.","Make",2021,"Vinicius G. Goecks,Nicholas R. Waytowich,David Watkins,Bharat Prakash",5,52,1
"a1189ba5d86d32bc5fecd32ee905f8ff4767cbdb","https://www.semanticscholar.org/paper/a1189ba5d86d32bc5fecd32ee905f8ff4767cbdb",3,"ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning","The results show that the method successfully learns to map 128-dimensional gaze features to 7-dimensional joint torques from sparse rewards in under 10 minutes of online training, and seamlessly helps users who employ different gaze strategies, while adapting to distributional shift in webcam inputs, tasks, and environments.","IEEE International Conference on Robotics and Automation",2022,"S. Chen,Jensen Gao,S. Reddy,G. Berseth,A. Dragan,S. Levine",3,66,0
"2b46e8f2f2339e4dfbc8c3db33b7a6fb65ee62ad","https://www.semanticscholar.org/paper/2b46e8f2f2339e4dfbc8c3db33b7a6fb65ee62ad",3,"Deep Reinforcement Learning from Policy-Dependent Human Feedback","The effectiveness of the Deep COACH algorithm is demonstrated in the rich 3D world of Minecraft with an agent that learns to complete tasks by mapping from raw pixels to actions using only real-time human feedback in 10-15 minutes of interaction.","ArXiv",2019,"Dilip Arumugam,Jun Ki Lee,S. Saskin,M. Littman",51,41,6
"69b68b2d83989680854ffa2d12321028bfbdb722","https://www.semanticscholar.org/paper/69b68b2d83989680854ffa2d12321028bfbdb722",3,"Robot Learning via Human Adversarial Games","In a manipulation task, it is shown that grasping success improves significantly when the robot trains with a human adversary as compared to training in a self-supervised manner.","IEEE/RJS International Conference on Intelligent RObots and Systems",2019,"Jiali Duan,Qian Wang,Lerrel Pinto,C.-C. Jay Kuo,S. Nikolaidis",7,37,1
"bd6f723c0f38e3a55ccbff305a34b8deff68a615","https://www.semanticscholar.org/paper/bd6f723c0f38e3a55ccbff305a34b8deff68a615",3,"Learning Behaviors from a Single Video Demonstration Using Human Feedback","This paper uses human feedback to construct a mapping between the internal state representation of the agent and the visual representation from the video, and shows the effectiveness of this method by teaching a hopper agent in the MuJoCo simulator to perform a backflip.","Adaptive Agents and Multi-Agent Systems",2019,"S. Gandhi,T. Oates,T. Mohsenin,Nicholas R. Waytowich",5,16,0
"894d12eb96d05976954dcd1a1e9b6270ebb54b92","https://www.semanticscholar.org/paper/894d12eb96d05976954dcd1a1e9b6270ebb54b92",3,"Learning from Observations Using a Single Video Demonstration and Human Feedback","This paper trains an autonomous agent using a single video demonstration and uses human feedback (using numerical similarity rating) to map the standard representation of the agent to the visual representation with a neural network.","ArXiv",2019,"S. Gandhi,T. Oates,T. Mohsenin,Nicholas R. Waytowich",1,35,0
"a87257e5ec7d4e20aed56b1dc726ab1dee1b2535","https://www.semanticscholar.org/paper/a87257e5ec7d4e20aed56b1dc726ab1dee1b2535",3,"Accelerating Human-Agent Collaborative Reinforcement Learning","This work uses a discrete Soft Actor-Critic agent on a real-time collaborative game with humans to examine how different allocations of on-line and off-line gradient updates impact the game performance and the total training time.","Petra",2021,"Fotios Lygerakis,M. Dagioglou,V. Karkaletsis",3,17,0
"6778d6a0f959cdcc42718ee9fc279fd1f00f3d88","https://www.semanticscholar.org/paper/6778d6a0f959cdcc42718ee9fc279fd1f00f3d88",3,"Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning","This paper proposes reward machines, a type of finite state machine that supports the specification of reward functions while exposing reward function structure, and describes different methodologies to exploit this structure to support learning, including automated reward shaping, task decomposition, and counterfactual reasoning with off-policy learning.","Journal of Artificial Intelligence Research",2020,"Rodrigo Toro Icarte,Toryn Q. Klassen,R. Valenzano,Sheila A. McIlraith",53,109,9
"243abd03e6fa267219d5afd82f387dddc0db26a3","https://www.semanticscholar.org/paper/243abd03e6fa267219d5afd82f387dddc0db26a3",3,"Accelerating the Learning of TAMER with Counterfactual Explanations","This work extends the HRL framework TAMER for evaluative feedback with the possibility to enhance human feedback with two different types of counterfactual explanations (action and state based) to improve the speed of learning.","International Conference on Development and Learning",2021,"Jakob Karalus,F. Lindner",0,31,0
"18d750263f1dfe43374e8791cefa580a511c2098","https://www.semanticscholar.org/paper/18d750263f1dfe43374e8791cefa580a511c2098",3,"Few-Shot Preference Learning for Human-in-the-Loop RL","Motivated by the success of metalearning, pre-train preference models on prior task data and quickly adapt them for new tasks using only a handful of queries, reducing the amount of online feedback needed to train manipulation policies in Meta-World by 20 ×, and demonstrating the effectiveness of this method on a real Franka Panda Robot.","ArXiv",2022,"Joey Hejna,Dorsa Sadigh",3,66,0
"ecdba129b97570c03c83fd6ab5037d9fe771f1b7","https://www.semanticscholar.org/paper/ecdba129b97570c03c83fd6ab5037d9fe771f1b7",3,"When is Realizability Sufficient for Off-Policy Reinforcement Learning?","These error bounds establish that oﬀ-policy reinforcement learning remains statistically viable even in absence of Bellman completeness, and characterize the intermediate situation between the favorable Bellman complete setting and the worst-case scenario where exponential lower bounds are in force.","ArXiv",2022,"A. Zanette",1,60,1
"9fa8733e68ad7e6e9135800a66606eb07503ba37","https://www.semanticscholar.org/paper/9fa8733e68ad7e6e9135800a66606eb07503ba37",3,"Deep Reinforcement Learning for Tehran Stock Trading","Single stock trading models are presented based on the fine-tuned state-of-the-art deep reinforcement learning algorithms (Deep Deterministic Policy Gradient and Advantage Actor Critic) and shows that the agent designed based on both algorithms is able to make intelligent decisions on historical data.","Journal of Novel Engineering Science and Technology",2022,"Neda Yousefi",0,20,0
"c64565f8deca0fad78dc5687a9ce7717e0f4fd22","https://www.semanticscholar.org/paper/c64565f8deca0fad78dc5687a9ce7717e0f4fd22",3,"Applying Deep Reinforcement Learning to the HP Model for Protein Structure Prediction","Deep reinforcement learning is applied to the HP model for protein folding and it is demonstrated that a DQN based on long short-term memory (LSTM) architecture greatly enhances the RL learning ability and significantly improves the search process.","Physica A: Statistical Mechanics and its Applications",2022,"Kaiyuan Yang,Houjing Huang,Olafs Vandans,A. Murali,Fujia Tian,R. Yap,Liang Dai",0,56,0
"8ab4acd34bebd1a901fa99ab0167f49be2a3ba74","https://www.semanticscholar.org/paper/8ab4acd34bebd1a901fa99ab0167f49be2a3ba74",3,"Real-time Bidding Strategy in Display Advertising: An Empirical Analysis","The problem and challenges of optimizing bidding strategies for individual advertisers in real-time bidding display advertising are described and several representative bidding strategies are introduced, especially the research advances andChallenges of reinforcement learning-based bidding strategies.","ArXiv",2022,"Mengjuan Liu,Zhengning Hu,Zhi Lai,Daiwei Zheng,Xuyun Nie",1,25,0
"0e872b44bf1d3abd03f3c882cc0f14a6b8c9374e","https://www.semanticscholar.org/paper/0e872b44bf1d3abd03f3c882cc0f14a6b8c9374e",3,"A Dynamic Deep Reinforcement Learning-Bayesian Framework for Anomaly Detection","A mathematical framework which utilizes a dynamic threshold for an anomaly classification algorithm in real-time in order to maximize the safety of a trip and shows that the POMDP model outperforms state-of-the-art benchmarks, especially under more difficult to detect anomaly profiles.","IEEE transactions on intelligent transportation systems (Print)",2022,"Jeremy Watts,F. van Wyk,Shahrbanoo Rezaei,Yiyang Wang,Neda Masoud,Anahita Khojandi",1,38,0
"2c8428e63bd02fae15dd72985678dd14e2982e48","https://www.semanticscholar.org/paper/2c8428e63bd02fae15dd72985678dd14e2982e48",3,"Learning to Transmit Fresh Information in Energy Harvesting Networks","Comparable AoI to the optimal is demonstrated and faster runtime of learning solvers is observed, verifying the efficacy of learning in terms of both optimality and computational energy efficiency for AoI-focused scheduling and resource allocation problems in wireless networks.","IEEE Transactions on Green Communications and Networking",2022,"Shiyang Leng,A. Yener",1,54,0
"0aec8ed21d4b34112679a39d7070f4503d61b9d8","https://www.semanticscholar.org/paper/0aec8ed21d4b34112679a39d7070f4503d61b9d8",3,"STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning","This work proposes a new quantitative semantics for STL having several desirable properties, making it suitable for reward generation, and establishes its new semantics to be the most suitable for synthesizing feedback con- trollers for complex continuous dynamical systems through reinforcement learning.","ArXiv",2022,"Nikhil Kumar Singh,I. Saha",0,36,0
"43d20b615cd65229d467ecb24e3f1eaba561d04e","https://www.semanticscholar.org/paper/43d20b615cd65229d467ecb24e3f1eaba561d04e",3,"Smoothing Policy Iteration for Zero-sum Markov Games","Results show that SPI can approximate the worst-case value function with a high accuracy and SaAC can stabilize the training process and improve the adversarial robustness in a large margin.","ArXiv",2022,"Yangang Ren,Yao Lyu,Wenxuan Wang,Sheng Li,Zeyang Li,Jingliang Duan",0,32,0
"52055da99bb0fdad22f8c11b96ca69f0d3d7f9e1","https://www.semanticscholar.org/paper/52055da99bb0fdad22f8c11b96ca69f0d3d7f9e1",3,"Reinforced Approximate Exploratory Data Analysis","A Deep Reinforcement Learning (DRL) based framework which can optimize the sample selection in order to keep the analysis and insight generation intact and can preserve the original insight generation while improving the interaction latency, compared to baseline methods.","ArXiv",2022,"Shaddy Garg,S. Mitra,Tong Yu,Yash Gadhia,Arjun Kashettiwar",0,46,0
"f0a0fb744c4764432062ad6305c97bfcc21e4f30","https://www.semanticscholar.org/paper/f0a0fb744c4764432062ad6305c97bfcc21e4f30",3,"On the Sample Complexity of Actor-Critic Method for Reinforcement Learning with Function Approximation","This work puts forth a new variant of actor-critic that employs Monte Carlo rollouts during the policy search updates, which results in controllable bias that depends on the number of critic evaluations, providing insight into the interplay between optimization and generalization in reinforcement learning.","Machine-mediated learning",2019,"Harshat Kumar,Alec Koppel,Alejandro Ribeiro",56,88,9
"3d45ef7217501a4e325809665d3d47949e041fa7","https://www.semanticscholar.org/paper/3d45ef7217501a4e325809665d3d47949e041fa7",3,"DeepAPP: A Deep Reinforcement Learning Framework for Mobile Application Usage Prediction","A deep reinforcement learning framework, named as DeepAPP, which learns a model-free predictive neural network from historical app usage data and reduces the prediction time of the state-of-the-art by 6.58× is presented.","IEEE Transactions on Mobile Computing",2019,"Zhihao Shen,Kang Yang,Xi Zhao,Jianhua Zou,Wan Du",30,64,0
"27ded4d32a8643b80545ef739a04528eeecf48fd","https://www.semanticscholar.org/paper/27ded4d32a8643b80545ef739a04528eeecf48fd",3,"Modelling penetration testing with reinforcement learning using capture‐the‐flag challenges: Trade‐offs between model‐free learning and a priori knowledge","This paper focuses its attention on simpliﬁed penetration testing problems expressed in the form of capture the ﬂag hacking challenges, and analyzes how model-free reinforcement learning algorithms may help to solve them.","IET Information Security",2020,"Fabio Massimo Zennaro,L. Erdődi",8,27,0
"8b452de8224ffadc5882da8de81c9dc7e16452fa","https://www.semanticscholar.org/paper/8b452de8224ffadc5882da8de81c9dc7e16452fa",3,"Using Distributed Reinforcement Learning for Resource Orchestration in a Network Slicing Scenario","This paper attacks the Network Slicing problem by exploiting a Deep Reinforcement Learning approach, based on a distributed architecture, and shows that this approach yields better performance than both a static allocation of system resources and an efficient empirical strategy.","IEEE/ACM Transactions on Networking",2021,"Federico Mason,G. Nencioni,A. Zanella",3,53,0
"288e5a79e73742f9ead3bfa9463891717414f6fd","https://www.semanticscholar.org/paper/288e5a79e73742f9ead3bfa9463891717414f6fd",3,"Addressing Hindsight Bias in Multigoal Reinforcement Learning","The bias-corrected HER (BHER), an efficient algorithm that corrects the hindsight bias in training and outperforms several state-of-the-art multigoal RL approaches in challenging robotics tasks.","IEEE Transactions on Cybernetics",2021,"Chenjia Bai,Lingxiao Wang,Yixin Wang,Zhaoran Wang,Rui Zhao,Chenyao Bai,Peng Liu",5,67,0
"c64a99ec780d5e1c6ba242a82e72e96eb0c3ef8a","https://www.semanticscholar.org/paper/c64a99ec780d5e1c6ba242a82e72e96eb0c3ef8a",3,"An information-theoretic perspective on intrinsic motivation in reinforcement learning: a survey","This work computationally revisit the notions of surprise, novelty, and skill-learning, and suggests that novelty and surprise can assist the building of a hierarchy of transferable skills which abstracts dynamics and makes the exploration process more robust.","Entropy",2022,"A. Aubret,L. Matignon,S. Hassas",3,193,0
"cb4bae3382fbccda5dc6eba7822feda858f5673f","https://www.semanticscholar.org/paper/cb4bae3382fbccda5dc6eba7822feda858f5673f",3,"Design and Planning of Flexible Mobile Micro-Grids Using Deep Reinforcement Learning","","Applied Energy",2022,"Cesare Caputo,M. Cardin,Pudong Ge,Fei Teng,A. Korre,E. A. Rio-Chanona",0,139,0
"6e97544840a37042c55c53f2808614d39a066f93","https://www.semanticscholar.org/paper/6e97544840a37042c55c53f2808614d39a066f93",3,"Deep Spectral Q-learning with Application to Mobile Health","A deep spectral Q- learning algorithm is proposed, which integrates principal component analysis (PCA) with deep Q-learning to handle the mixed frequency data and proves that the mean return under the estimated optimal policy converges to that under the optimal one and establishes its rate of convergence.","ArXiv",2023,"Yuhe Gao,C. Shi,R. Song",0,84,0
"675f12b6b4e70995af040127fe3171c6405d8c95","https://www.semanticscholar.org/paper/675f12b6b4e70995af040127fe3171c6405d8c95",3,"Why People Skip Music? On Predicting Music Skips using Deep Reinforcement Learning","Findings indicate that, overall, users’ behaviour features are the most discriminative in how the proposed DRL model predicts music skips, which suggests that a limited amount of user data should be collected and leveraged to predict skipping behaviour.","ArXiv",2023,"Francesco Meggetto,C. Revie,J. Levine,Yashar Moshfeghi",0,65,0
"fa6786bd22a1eb67a4e1f28719103ba0e0c2398d","https://www.semanticscholar.org/paper/fa6786bd22a1eb67a4e1f28719103ba0e0c2398d",3,"Planning for Learning Object Properties","This paper formalizes the problem of automatically training a neural network to recognize object properties as a symbolic planning problem (using PDDL), and uses planning techniques to produce a strategy for automating the training dataset creation and the learning process.","ArXiv",2023,"Leonardo Lamanna,L. Serafini,Mohamadreza Faridghasemnia,A. Saffiotti,A. Saetti,A. Gerevini,P. Traverso",0,42,0
"7235d95473b81585b4fc13e72fc77b2b7beca060","https://www.semanticscholar.org/paper/7235d95473b81585b4fc13e72fc77b2b7beca060",3,"Area-Driven FPGA Logic Synthesis Using Reinforcement Learning","This work applies reinforcement learning (RL) to determine a unique recipe of algorithms for each circuit, and shows that the RL agent is able to generalize, and perform beneficial logic synthesis optimizations across a variety of circuits.","Asia and South Pacific Design Automation Conference",2023,"Guanglei Zhou,J. Anderson",0,13,0
"ef751de5c8d41aedb39f931190bdaaff061c7803","https://www.semanticscholar.org/paper/ef751de5c8d41aedb39f931190bdaaff061c7803",3,"Toward Efficient Gradient-Based Value Estimation","To resolve the adverse effect of poor conditioning of MSBE on gradient based methods, a low complexity batch-free proximal method that approximately follows the Gauss-Newton direction and is asymptotically robust to parameterization is proposed.","ArXiv",2023,"Arsalan Sharifnassab,R. Sutton",0,56,0
"b6b89f6b99da3bab6cf5f6d376a140fd63c13efb","https://www.semanticscholar.org/paper/b6b89f6b99da3bab6cf5f6d376a140fd63c13efb",3,"Better Training of GFlowNets with Local Credit and Incomplete Trajectories","This paper considers the case where the energy function can be applied not just to terminal states but also to intermediate states, and shows how to reparameterize the GFlowNet state flow function to take advantage of the partial reward already accrued at each state.","ArXiv",2023,"L. Pan,Nikolay Malkin,Dinghuai Zhang,Y. Bengio",2,44,0
"e0f98307096ac8bff1c3302096d5c0771b9a7a9f","https://www.semanticscholar.org/paper/e0f98307096ac8bff1c3302096d5c0771b9a7a9f",3,"Deep Reinforcement Learning for Traffic Light Control in Intelligent Transportation Systems","This paper investigates deep reinforcement learning to control traffic lights, and both theoretical analysis and numerical experiments show that the intelligent behavior ``greenwave"" emerges naturally a grid road network, which is proved to be the optimal policy in an avenue with multiple cross streets.","ArXiv",2023,"Xiao-Yang Liu,Ming Zhu,S. Borst,A. Elwalid",0,65,0
"b75726d152584403d44a81d4de39ff8070736660","https://www.semanticscholar.org/paper/b75726d152584403d44a81d4de39ff8070736660",3,"Reinforcement learning approach to control an inverted pendulum: A general framework for educational purposes","This article proposes a general framework to reproduce successful experiments and simulations based on the inverted pendulum, a classic problem often used as a benchmark to evaluate control strategies and introduces two algorithms to give a comprehensive understanding of the approach and discuss its implementation on real systems.","PLoS ONE",2023,"Sardor Israilov,Li Fu,J. Sánchez-Rodríguez,F. Fusco,Guillaume Allibert,C. Raufaste,M. Argentina",0,30,0
"576a178c730490c4efdb4fc57049a683f6f5b8e3","https://www.semanticscholar.org/paper/576a178c730490c4efdb4fc57049a683f6f5b8e3",3,"Quantum Computing Provides Exponential Regret Improvement in Episodic Reinforcement Learning","An UCB based quantum algorithmic framework to facilitate learning of a finite-horizon MDP and achieves an exponential improvement in regret as compared to the classical counterparts, key to the significant regret improvement in quantum reinforcement learning.","",2023,"Bhargav Ganguly,Yulian Wu,Di Wang,V. Aggarwal",0,38,0
"c458282071810e433c841d572958113e4acdcca6","https://www.semanticscholar.org/paper/c458282071810e433c841d572958113e4acdcca6",3,"RLQ: Workload Allocation With Reinforcement Learning in Distributed Queues","This work formulate the task allocation problem in the Markov Decision Process framework, in which an agent assigns tasks to an available resource, and receives a numerical reward signal upon task completion, and implements and integrated with the popular Celery task queuing system for Python.","IEEE Transactions on Parallel and Distributed Systems",2023,"Alessandro Staffolani,Victor-Alexandru Darvariu,P. Bellavista,Mirco Musolesi",0,45,0
"9e6763597414d865237fdd065eed50bbc5ff14f5","https://www.semanticscholar.org/paper/9e6763597414d865237fdd065eed50bbc5ff14f5",3,"Limitations of Autoregressive Models and Their Alternatives","Standard autoregressive language models perform only polynomial-time computation to compute the probability of the next symbol, which means they cannot model distributions whose next-symbol probability is hard to compute.","North American Chapter of the Association for Computational Linguistics",2020,"Chu-Cheng Lin,Aaron Jaech,Xin Li,M. Gormley,Jason Eisner",10,53,2
"46c585ee9abf76779ea4b863d2da4358efd0d1d3","https://www.semanticscholar.org/paper/46c585ee9abf76779ea4b863d2da4358efd0d1d3",3,"Adaptive Semiparametric Language Models","A language model that combines a large parametric neural network with a non-parametric episodic memory component in an integrated architecture is presented and a gating function to adaptively combine multiple information sources to make a prediction is designed.","Transactions of the Association for Computational Linguistics",2021,"Dani Yogatama,Cyprien de Masson d'Autume,Lingpeng Kong",43,40,1
"b61de520bc1ae57abde895601b62b4f92d82c0b4","https://www.semanticscholar.org/paper/b61de520bc1ae57abde895601b62b4f92d82c0b4",3,"Pointer Value Retrieval: A new benchmark for understanding the limits of neural network generalization","This paper introduces a novel benchmark, Pointer Value Retrieval (PVR) tasks, that explore the limits of neural network generalization, and demonstrates that this task structure provides a rich testbed for understanding generalization.","ArXiv",2021,"Chiyuan Zhang,M. Raghu,J. Kleinberg,Samy Bengio",6,51,1
"4bc8851f2e2758326eb0d57f7d46ab9d74cfdf80","https://www.semanticscholar.org/paper/4bc8851f2e2758326eb0d57f7d46ab9d74cfdf80",3,"How BPE Affects Memorization in Transformers","It is demonstrated that the size of the subword vocabulary learned by Byte-Pair Encoding greatly affects both ability and tendency of standard Transformer models to memorize training data, even when the authors control for the number of learned parameters.","ArXiv",2021,"E. Kharitonov,Marco Baroni,D. Hupkes",10,67,0
"7a33cbd2381a9b353fb2006b1a759e884ff24cab","https://www.semanticscholar.org/paper/7a33cbd2381a9b353fb2006b1a759e884ff24cab",3,"∞-former: Infinite Memory Transformer","The ∞-former is proposed, which extends the vanilla transformer with an unbounded long-term memory and is able to model arbitrarily long contexts and maintain “sticky memories” while keeping a fixed computation budget.","Annual Meeting of the Association for Computational Linguistics",2022,"Pedro Henrique Martins,Zita Marinho,André F. T. Martins",11,38,2
"b987eaf762f3126358b1a5ab6c381c9b1839fe9d","https://www.semanticscholar.org/paper/b987eaf762f3126358b1a5ab6c381c9b1839fe9d",3,"Better Language Model with Hypernym Class Prediction","This study hypothesizes that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words and train large neural LMs by gradually annealing from predicting the class to token prediction during training.","",2022,"He Bai",0,40,0
"609e1c196fced582caf9113aa6a003b64d3cdcd6","https://www.semanticscholar.org/paper/609e1c196fced582caf9113aa6a003b64d3cdcd6",3,"Better Language Model with Hypernym Class Prediction","This study hypothesizes that class-based prediction leads to an implicit context aggregation for similar words and thus can improve generalization for rare words and train large neural LMs by gradually annealing from predicting the class to token prediction during training.","Annual Meeting of the Association for Computational Linguistics",2022,"He Bai,Tong Wang,Alessandro Sordoni,Peng Shi",2,39,0
"8ccd6ea80e3fb165213b95d5ff7e71b497befc0a","https://www.semanticscholar.org/paper/8ccd6ea80e3fb165213b95d5ff7e71b497befc0a",3,"A BERT-based Language Modeling Framework","A set of BERT-based language models are proposed, and a neural-based dynamic adaptation method is also introduced to combine these language models systematically and methodically to explore novel uses of a pre-trained model for language modeling.","Interspeech",2022,"Chin-Yueh Chien,K. Chen",0,51,0
"54abaf3108b7ca92e829f6797d5e73264c2350c1","https://www.semanticscholar.org/paper/54abaf3108b7ca92e829f6797d5e73264c2350c1",3,"Nearest Neighbor Language Models for Stylistic Controllable Generation","It is found that style-specific datastores improve generation performance, though results vary greatly across styles, and the effect of pretraining data and specific styles should be explored in future work.","IEEE Games Entertainment Media Conference",2022,"Severino Trotta,Lucie Flek,Charles F Welch",0,19,0
"37ba9c33025fb31f25436010e12c65a0bafc0e1f","https://www.semanticscholar.org/paper/37ba9c33025fb31f25436010e12c65a0bafc0e1f",3,"Meta-Learning Fast Weight Language Models","Fast Weight Layers are presented, a neural component that provides the benefits of dynamic evaluation much more efficiently by expressing gradient updates as linear attention and can also be applied at training time, so the model learns to make good use of gradient updates.","Conference on Empirical Methods in Natural Language Processing",2022,"Kevin Clark,Kelvin Guu,Ming-Wei Chang,Panupong Pasupat,G. Hinton,Mohammad Norouzi",0,24,0
"13388109ea0d1e332f11647f2d24655bfe08a5f3","https://www.semanticscholar.org/paper/13388109ea0d1e332f11647f2d24655bfe08a5f3",3,"Robust Meta-Representation Learning via Global Label Inference and Classification","This work discusses why pre-training yields more robust meta-representation and connects the theoretical analysis to existing works and empirical results, and introduces Meta Label Learning (MeLa), a novel meta-learning algorithm that learns task relations by inferring global labels across tasks.","ArXiv",2022,"Ruohan Wang,Isak Falk,M. Pontil,C. Ciliberto",0,76,0
"ac608a4a6b19b3208e560eee5daadb3cc18638a2","https://www.semanticscholar.org/paper/ac608a4a6b19b3208e560eee5daadb3cc18638a2",3,"Efficient Attention via Control Variates","This new framework reveals that exact softmax attention can be recovered from RFA by manipulating each control variate, resulting in a novel attention mechanism that significantly reduces the approximation gap while maintaining linear complexity.","ArXiv",2023,"Lin Zheng,Jianbo Yuan,Chong Wang,Lingpeng Kong",1,97,0
"755de63517a62ffdaeca33e3946e33354ea15920","https://www.semanticscholar.org/paper/755de63517a62ffdaeca33e3946e33354ea15920",3,"Open data and algorithms for open science in AI-driven molecular informatics","","Current Opinion in Structural Biology",2023,"Henning Otto Brinkhaus,Kohulan Rajan,Jonas Schaub,Achim Zielesny,Christoph Steinbeck",0,124,0
"8a7df164c4687e3c402b1cbf0ab404de49cfb75e","https://www.semanticscholar.org/paper/8a7df164c4687e3c402b1cbf0ab404de49cfb75e",3,"Rissanen Data Analysis: Examining Dataset Characteristics via Description Length","The method is called Rissanen Data Analysis (RDA) after the father of MDL, and its applicability on a wide variety of settings in NLP is showcased, ranging from evaluating the utility of generating subquestions before answering a question, to analyzing the value of rationales and explanations, to investigating the importance of different parts of speech, and uncovering dataset gender bias.","International Conference on Machine Learning",2021,"Ethan Perez,Douwe Kiela,Kyunghyun Cho",11,107,2
"1525c819ecaed99dad8117da1206eff3d470756d","https://www.semanticscholar.org/paper/1525c819ecaed99dad8117da1206eff3d470756d",3,"Benchmarks for Automated Commonsense Reasoning: A Survey","A survey of the development and uses of AI commonsense benchmarks, and it is argued that it is worthwhile to invest the work needed ensure that benchmark examples are consistently high quality.","ArXiv",2023,"E. Davis",1,168,0
"da7d67f9d3341754942a4c3f5da6eface2adf68e","https://www.semanticscholar.org/paper/da7d67f9d3341754942a4c3f5da6eface2adf68e",3,"Template Grounded Examples High level advice Key Elements VariablesSelector Reactive LearnerScriptLesson","This work presents experimental results for a deep reinforcement learning agent in a Minecraft-based game environment that show how such synthetic experiences improve performance, enabling the agent to achieve faster learning and higher rates of success.","",2018,"Eric,Yeh",0,61,0
"a5b66ee341cb990f7f70a124b5fab3316d3b7e27","https://www.semanticscholar.org/paper/a5b66ee341cb990f7f70a124b5fab3316d3b7e27",3,"ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension","This work presents a large-scale dataset, ReCoRD, for machine reading comprehension requiring commonsense reasoning, and demonstrates that the performance of state-of-the-art MRC systems fall far behind human performance.","ArXiv",2018,"Sheng Zhang,Xiaodong Liu,Jingjing Liu,Jianfeng Gao,Kevin Duh,Benjamin Van Durme",192,48,39
"c21a4d70d83e0f6eb2a9e1c41d034842dd561e47","https://www.semanticscholar.org/paper/c21a4d70d83e0f6eb2a9e1c41d034842dd561e47",3,"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge","This work presents CommonsenseQA: a challenging new dataset for commonsense question answering, which extracts from ConceptNet multiple target concepts that have the same semantic relation to a single source concept.","North American Chapter of the Association for Computational Linguistics",2019,"Alon Talmor,Jonathan Herzig,Nicholas Lourie,Jonathan Berant",517,43,144
"303edbd86773b68432fa2ccb7c223aa22abe08b3","https://www.semanticscholar.org/paper/303edbd86773b68432fa2ccb7c223aa22abe08b3",3,"Bridging the Gap: Converting Human Advice into Imagined Examples","This work presents experimental results for a deep reinforcement learning agent in a Minecraft-based game environment that show how such synthetic experiences improve performance, enabling the agent to achieve faster learning and higher rates of success.","",2019,"Eric,Yeh",4,64,0
"570163353e0a954d9e5829f6ae92ae09c3225041","https://www.semanticscholar.org/paper/570163353e0a954d9e5829f6ae92ae09c3225041",3,"Reinforcement Learning With Human Advice: A Survey","An overview of the existing methods for integrating human advice into a reinforcement learning process is provided and a taxonomy of the different forms of advice that can be provided to a learning agent is proposed.","Frontiers in Robotics and AI",2020,"Anis Najar,M. Chetouani",20,158,0
"8c8fe7c49ad0c3fc513c1dbf282ad91c49d1616f","https://www.semanticscholar.org/paper/8c8fe7c49ad0c3fc513c1dbf282ad91c49d1616f",3,"Answer Complex Questions: Path Ranker Is All You Need","A purely rank-based framework Thinking Path Re-Ranker (TPRR), which is comprised of Thinking Path Ranker ( TPR) for generating document sequences called ""a path"" and External Path Reranker (E PR) for selecting the best path from candidate paths generated by TPR.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2021,"Xinyu Zhang,Ke Zhan,Enrui Hu,Chengzhen Fu,Lan Luo,Hao Jiang,Yantao Jia,Fan Yu,Zhicheng Dou,Zhao Cao,Lei Chen",7,54,2
"f162b64756f01cdf04bc59c7592a77e4c8981656","https://www.semanticscholar.org/paper/f162b64756f01cdf04bc59c7592a77e4c8981656",3,"Question Answering over Knowledge Bases by Leveraging Semantic Parsing and Neuro-Symbolic Reasoning","A semantic parsing and reasoning-based Neuro-Symbolic Question Answering system that achieves state-of-the-art performance on QALD-9 and LC-QuAD 1.0 and integrates multiple, reusable modules that are trained specifically for their individual tasks and do not require end-to-end training data.","ArXiv",2020,"Pavan Kapanipathi,I. Abdelaziz,Srinivas Ravishankar,S. Roukos,Alexander G. Gray,Ramón Fernández Astudillo,Maria Chang,Cristina Cornelio,Saswati Dana,Achille Fokoue,Dinesh Garg,A. Gliozzo,Sairam Gurajada,Hima P. Karanam,Naweed Khan,Dinesh Khandelwal,Young-suk Lee,Yunyao Li,F. Luus,Ndivhuwo Makondo,Nandana Mihindukulasooriya,Tahira Naseem,S. Neelam,Lucian Popa,R. Reddy,Ryan Riegel,Gaetano Rossiello,Udit Sharma,G P Shrivatsa Bhargav,Mo Yu",22,46,0
"274b9cce94bc5ab6d30a62ecaeb424cce829af60","https://www.semanticscholar.org/paper/274b9cce94bc5ab6d30a62ecaeb424cce829af60",3,"Understanding Hard Negatives in Noise Contrastive Estimation","The contrastive loss is viewed as a biased estimator of the gradient of the cross-entropy loss, and it is shown both theoretically and empirically that setting the negative distribution to be the model distribution results in bias reduction.","North American Chapter of the Association for Computational Linguistics",2021,"Wenzheng Zhang,K. Stratos",21,37,4
"f5b64b831b2e8ef9143c94c4fd967061fc523b84","https://www.semanticscholar.org/paper/f5b64b831b2e8ef9143c94c4fd967061fc523b84",3,"BiBL: AMR Parsing and Generation with Bidirectional Bayesian Learning","This work proposes data-efficient Bidirectional Bayesian learning (BiBL) to facilitate bidirectional information transition by adopting a single-stage multitasking strategy so that the resulting model may enjoy much lighter training at the same time.","International Conference on Computational Linguistics",2022,"Ziming Cheng,Z. Li,Hai Zhao",0,34,0
"fad50ee368dac1a12c1b207f75bb3b647c896531","https://www.semanticscholar.org/paper/fad50ee368dac1a12c1b207f75bb3b647c896531",3,"Reasoning over Hybrid Chain for Table-and-Text Open Domain QA","A novel chain-centric pretraining method is proposed, to enhance the pre-trained model in identifying the cross-modality reasoning process and alleviating the data sparsity problem.","ArXiv",2022,"Wanjun Zhong,Junjie Huang,Qianchu Liu,Ming Zhou,Jiahai Wang,Jian Yin,Nan Duan",7,27,2
"5e793ce1e3003cd42144e45b7d8db06a60b58ca2","https://www.semanticscholar.org/paper/5e793ce1e3003cd42144e45b7d8db06a60b58ca2",3,"Generative Multi-hop Retrieval","This paper proposes an encoder-decoder model that performs multi-hop retrieval by simply generating the entire text sequences of the retrieval targets, which means the query and the documents interact in the language model’s parametric space rather than L2 or inner product space as in the bi-encoder approach.","Conference on Empirical Methods in Natural Language Processing",2022,"Hyunji Lee,Sohee Yang,Hanseok Oh,Minjoon Seo",4,44,0
"1715aa36ccc851310308630d4db61dcecf49a50d","https://www.semanticscholar.org/paper/1715aa36ccc851310308630d4db61dcecf49a50d",3,"Knowledge Guided Text Retrieval and Reading for Open Domain Question Answering","This work introduces an approach for open-domain question answering (QA) that retrieves and reads a passage graph, where vertices are passages of text and edges represent relationships that are derived from an external knowledge base or co-occurrence in the same article.","ArXiv",2019,"Sewon Min,Danqi Chen,Luke Zettlemoyer,Hannaneh Hajishirzi",72,41,8
"d703742740f8b6bec5173b6f0a8954f603cccd17","https://www.semanticscholar.org/paper/d703742740f8b6bec5173b6f0a8954f603cccd17",3,"Experimental IR Meets Multilinguality, Multimodality, and Interaction: 11th International Conference of the CLEF Association, CLEF 2020, Thessaloniki, Greece, September 22–25, 2020, Proceedings","This paper presents SberQuAD – a large Russian reading comprehension (RC) dataset created similarly to English SQuAD, which contains about 50K question-paragraph-answer triples and is seven times larger compared to the next competitor.","Conference and Labs of the Evaluation Forum",2020,"A. Arampatzis,E. Kanoulas,T. Tsikrika,S. Vrochidis,Hideo Joho,C. Lioma,Carsten Eickhoff,Aurélie Névéol,L. Cappellato,N. Ferro",1,509,0
"79cd9f77e5258f62c0e15d11534aea6393ef73fe","https://www.semanticscholar.org/paper/79cd9f77e5258f62c0e15d11534aea6393ef73fe",3,"Dense Passage Retrieval for Open-Domain Question Answering","This work shows that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework.","Conference on Empirical Methods in Natural Language Processing",2020,"Vladimir Karpukhin,Barlas Oğuz,Sewon Min,Patrick Lewis,Ledell Yu Wu,Sergey Edunov,Danqi Chen,Wen-tau Yih",1143,55,412
"379b94a0df51bd3725312ce7b69c6fa57afd8da2","https://www.semanticscholar.org/paper/379b94a0df51bd3725312ce7b69c6fa57afd8da2",3,"Meta Adaptive Neural Ranking with Contrastive Synthetic Supervision","This paper presents a meta-analyses of the reinforcement learning system called reinforcement learning, which automates the very labor-intensive and therefore time-heavy and expensive process of training reinforcement learning systems.","ArXiv",2020,"Si Sun,Yingzhuo Qian,Zhenghao Liu,Chenyan Xiong,Kaitao Zhang,Jie Bao,Zhiyuan Liu,Paul Bennett",4,53,0
"1c8e2d3c887692ce0cb78b09685ea46be5cb2611","https://www.semanticscholar.org/paper/1c8e2d3c887692ce0cb78b09685ea46be5cb2611",3,"An In-depth Analysis of Passage-Level Label Transfer for Contextual Document Ranking","It is found that direct transfer of relevance labels from documents to passages introduces label noise that strongly affects retrieval effectiveness for large training datasets and query processing times are adversely affected by fine-grained splitting schemes.","ArXiv",2021,"Koustav Rudra,Zeon Trevor Fernando,Avishek Anand",3,65,0
"23a7260e39b1a1638053dd40d57c560850622bea","https://www.semanticscholar.org/paper/23a7260e39b1a1638053dd40d57c560850622bea",3,"Hybrid Encoder: Towards Efficient and Precise Native AdsRecommendation via Hybrid Transformer Encoding Networks","","ArXiv",2021,"Junhan Yang,Zheng Liu,Bowen Jin,Jianxun Lian,Defu Lian,Akshay Soni,Eun Yong Kang,Yajun Wang,Guang-zhong Sun,Xing Xie",0,22,0
"fe935caed47ef090a306d6d09240f76adc43a420","https://www.semanticscholar.org/paper/fe935caed47ef090a306d6d09240f76adc43a420",3,"Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins","Ember is proposed, a system that abstracts and automates keyless joins to generalize context enrichment and allows users to develop nocode pipelines for five domains, including search, recommendation and question answering, and can exceed alternatives by up to 39% recall, with as little as a single line configuration change.","Proceedings of the VLDB Endowment",2021,"S. Suri,I. Ilyas,Christopher R'e,Theodoros Rekatsinas",7,81,1
"098354d529a26bd28a4371d02b110891f960a2ea","https://www.semanticscholar.org/paper/098354d529a26bd28a4371d02b110891f960a2ea",3,"Multi-level retrieval with semantic Axiomatic Fuzzy Set clustering for question answering","This paper proposes a coarse-to-fine unsupervised evidence sentences retrieval model based on the Axiomatic Fuzzy Sets clustering with both reasoning ability and interpretability for open-domain and multi-hop reading comprehension tasks that require complex multi-step reasoning processes.","Applied Soft Computing",2021,"Qi Lang,Xiaodong Liu,Yingjie Deng",4,54,0
"7a025a90cc36e668fb69f980ee809cd7d752854e","https://www.semanticscholar.org/paper/7a025a90cc36e668fb69f980ee809cd7d752854e",3,"Adaptive Information Seeking for Open-Domain Question Answering","A novel adaptive information-seeking strategy for open-domain question answering, namely AISO is proposed, which outperforms all baseline methods with predefined strategies in terms of both retrieval and answer evaluations.","Conference on Empirical Methods in Natural Language Processing",2021,"Yunchang Zhu,Liang Pang,Yanyan Lan,Huawei Shen,Xueqi Cheng",17,39,1
"08433ddb8c799c00008bc71a6252ee473585f7e3","https://www.semanticscholar.org/paper/08433ddb8c799c00008bc71a6252ee473585f7e3",3,"Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data","Experimental results show that this simple method can achieve significantly better performance on a variety of NLU and NLG tasks, including summarization, machine translation, language modeling, and question answering tasks.","Annual Meeting of the Association for Computational Linguistics",2022,"Shuo Wang,Yichong Xu,Yuwei Fang,Yang Liu,S. Sun,Ruochen Xu,Chenguang Zhu,Michael Zeng",21,48,7
"125b7393c02cbb61e77ce23673830e9523c1d5e3","https://www.semanticscholar.org/paper/125b7393c02cbb61e77ce23673830e9523c1d5e3",3,"Clickbait Spoiling via Question Answering and Passage Retrieval","A large-scale evaluation and error analysis on a new corpus of 5,000 manually spoiled clickbait posts shows that the spoiler type classifier achieves an accuracy of 80%, while the question answering model DeBERTa-large outperforms all others in generating spoilers for both types.","Annual Meeting of the Association for Computational Linguistics",2022,"Matthias Hagen,Maik Frobe,Artur Jurk,Martin Potthast",1,49,0
"ea1cc2e43cd3d0622381f8b0fe5e84d989c2350e","https://www.semanticscholar.org/paper/ea1cc2e43cd3d0622381f8b0fe5e84d989c2350e",3,"Multifaceted Improvements for Conversational Open-Domain Question Answering","A framework with Multifaceted Improvements for Conversational open-domain Question Answering (MICQA), which has three significant advantages: first, the proposed KL-divergence based regularization is able to lead to a better question understanding for retrieval and answer reading, and second, the added post-ranker module can push more relevant passages to the top placements and be selected for reader with a two-aspect constrains.","ArXiv",2022,"Tingting Liang,Yixuan Jiang,Congying Xia,Ziqiang Zhao,Yuyu Yin,Philip S. Yu",1,32,1
"832aa77be74d7d3a8b33b9abc0f48b8b7babac12","https://www.semanticscholar.org/paper/832aa77be74d7d3a8b33b9abc0f48b8b7babac12",3,"Tranception: protein fitness prediction with autoregressive transformers and inference-time retrieval","Tranception is introduced, a novel transformer architecture leveraging autoregressive predictions and retrieval of homologous sequences at inference to achieve state-of-the-art protein prediction performance, and ProteinGym is developed – an extensive set of multiplexed assays of variant effects, substantially increasing both the number and diversity of assays compared to existing benchmarks.","International Conference on Machine Learning",2022,"Pascal Notin,M. Dias,J. Frazer,Javier Marchena-Hurtado,Aidan N. Gomez,D. Marks,Y. Gal",18,111,3
"ba41674cec00fb383663151a5809ae051b959e0d","https://www.semanticscholar.org/paper/ba41674cec00fb383663151a5809ae051b959e0d",3,"Improving Wikipedia Verifiability with AI","A neural network based system, called Side, is developed to identify Wikipedia citations that are unlikely to support their claims, and subsequently recommend better ones from the web, and indicates that an AI-based system could be used, in tandem with humans, to improve the veriﬁability of Wikipedia.","ArXiv",2022,"Fabio Petroni,Samuel Broscheit,Aleksandra Piktus,Patrick Lewis,Gautier Izacard,Lucas Hosseini,Jane Dwivedi-Yu,M. Lomeli,Timo Schick,Pierre-Emmanuel Mazar'e,Armand Joulin,Edouard Grave,Sebastian Riedel",1,46,0
"2959cb37db73490f75c678e8f8a93fa742ab868e","https://www.semanticscholar.org/paper/2959cb37db73490f75c678e8f8a93fa742ab868e",3,"LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval","This work proposes to make a dense retriever align a well-performing lexicon-aware representation model and finds its improve-ment is complementary to the standard ranker distillation, which can further lift state-of-the-art performance.","ArXiv",2022,"Kai Zhang,Chongyang Tao,Tao Shen,Can Xu,Xiubo Geng,Binxing Jiao,Daxin Jiang",2,35,0
"0aadf207efbbc37e1c46ce22f859785b1cff86c4","https://www.semanticscholar.org/paper/0aadf207efbbc37e1c46ce22f859785b1cff86c4",3,"Pre-trained Language Model based Retrieval and Ranking for Web Search","Novel practices to perform expressive PLM-based semantic retrieval with a flexible poly-interaction scheme and cost-efficiently contextualize and rank web documents with a cheap yet powerful Pyramid-ERNIE architecture are presented.","ACM Transactions on the Web",2022,"Lixin Zou,Weixue Lu,Yiding Liu,Hengyi Cai,Xiaokai Chu,Dehong Ma,Daiting Shi,Yu Sun,Zhicong Cheng,Simiu Gu,Shuaiqiang Wang,Dawei Yin",2,112,0
"741a5536c2e58e1595e7396345f1e5d40a3aa775","https://www.semanticscholar.org/paper/741a5536c2e58e1595e7396345f1e5d40a3aa775",3,"CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for Efficient and Effective Multi-Vector Retrieval","CITADEL learns to route different token vectors to the predicted lexical “keys” such that a query token vector only interacts with document token vectors routed to the same key.","ArXiv",2022,"Minghan Li,Sheng-Chieh Lin,Barlas Oğuz,Asish Ghoshal,Jimmy Lin,Yashar Mehdad,Wen-tau Yih,Xilun Chen",3,48,0
"929ecaf5e6f8f706c736e64222e06a552aea0934","https://www.semanticscholar.org/paper/929ecaf5e6f8f706c736e64222e06a552aea0934",3,"Adam: Dense Retrieval Distillation with Adaptive Dark Examples","A DAM, a knowledge distillation framework that can better transfer the dark knowledge held in the teacher with A daptive D ark ex AM ples, is proposed and a self-paced distillation strategy that adaptively con-centrates on a subset of high-quality instances to conduct the authors' dark-example-based knowledgedistillation to help the student learn better is proposed.","ArXiv",2022,"Chang Liu,Chongyang Tao,Xiubo Geng,Tao Shen,Dongyan Zhao,Can Xu,Binxing Jiao,Daxin Jiang",0,50,0
"f6e82e8fa03874817adc69f7d42a7b8d2022bb1a","https://www.semanticscholar.org/paper/f6e82e8fa03874817adc69f7d42a7b8d2022bb1a",3,"CONCRETE: Improving Cross-lingual Fact-checking with Cross-lingual Retrieval","The proposed Cross-lingual Inverse Cloze Task (X-ICT), a self-supervised algorithm that creates training instances by translating the title of a passage, is presented, a first fact-checking framework augmented with cross-lingually retrieval that aggregates evidence retrieved from multiple languages through a cross-lingsual retriever.","International Conference on Computational Linguistics",2022,"Kung-Hsiang Huang,ChengXiang Zhai,Heng Ji",2,39,0
"da4409b332cfec82229649d7fc69cb87209bddb6","https://www.semanticscholar.org/paper/da4409b332cfec82229649d7fc69cb87209bddb6",3,"CatAlyst: Domain-Extensible Intervention for Preventing Task Procrastination Using Large Generative Models","","ArXiv",2023,"Riku Arakawa,Hiromu Yakura,Masataka Goto",0,86,0
"492987781038027ccf869b6992f48eb14022bac2","https://www.semanticscholar.org/paper/492987781038027ccf869b6992f48eb14022bac2",3,"""No, to the Right"" - Online Language Corrections for Robotic Manipulation via Shared Autonomy","This work presents a framework for incorporating and adapting to natural language corrections – “to the right”, or “no, towards the book” – as the robot executes, and shows that this corrections-aware approach obtains higher task completion rates, and is subjectively preferred by users because of its reliability, precision, and ease of use.","ArXiv",2023,"Yuchen Cui,Siddharth Karamcheti,Raj Palleti,Nidhya Shivakumar,Percy Liang,Dorsa Sadigh",1,51,0
"1076327ad3849b234abce6da9066dc61d05cdd90","https://www.semanticscholar.org/paper/1076327ad3849b234abce6da9066dc61d05cdd90",3,"Multiview Compressive Coding for 3D Reconstruction","This work introduces a simple framework that operates on 3D points of single objects or whole scenes coupled with category-agnostic large-scale training from diverse RGB-D videos and introduces a model that learns to compress the input appearance and geometry to predict the 3D structure by querying a 3D-aware decoder.","ArXiv",2023,"Chaozheng Wu,Justin Johnson,J. Malik,Christoph Feichtenhofer,Georgia Gkioxari",0,83,0
"becc067db5fc1e4d7f34bf680945c94335f51c3a","https://www.semanticscholar.org/paper/becc067db5fc1e4d7f34bf680945c94335f51c3a",3,"Regeneration Learning: A Learning Paradigm for Data Generation","Regeneration learning can be a widely-used paradigm for data generation (e.g., text generation, speech recognition, speech synthesis, music composition, image generation, and video generation) and can provide valuable insights into developing data generation methods.","ArXiv",2023,"Xu Tan,Tao Qin,Jiang Bian,Tie-Yan Liu,Y. Bengio",0,91,0
"0824e6f75e18325a79b11e3e4a118409e3297f97","https://www.semanticscholar.org/paper/0824e6f75e18325a79b11e3e4a118409e3297f97",3,"ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts","The ProtDescribe dataset is built to augment protein sequences with text descriptions of their functions and other important properties, and the ProtST framework is proposed to enhance pre-training and understanding by biomedical scientists.","ArXiv",2023,"Minghao Xu,Xinyu Yuan,Santiago Miret,Jian Tang",0,53,0
"a07b92339321bdc7604467333d6bdbeea69147a8","https://www.semanticscholar.org/paper/a07b92339321bdc7604467333d6bdbeea69147a8",3,"InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt","This study attempts to use natural language as style prompt to control the styles in the synthetic speech, e.g. “Sigh tone in full of sad mood with some helpless feeling”, and proposes an expressive TTS model, named as InstructTTS, which is novel in the sense of following aspects.","ArXiv",2023,"Dongchao Yang,Songxiang Liu,Rongjie Huang,Guangzhi Lei,Chao Weng,H. Meng,Dong Yu",0,75,0
"600d3ad507c581cd143f363d8d55042da53ef142","https://www.semanticscholar.org/paper/600d3ad507c581cd143f363d8d55042da53ef142",3,"UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers","Experiments on multiple generative and discriminative vision-language tasks, including Visual Reasoning, Image Caption, Visual Question Answer, Image-Text Retrieval, Text-Image Retrival, and Image Classiﬁcation, demonstrate the effectiveness and versatility of the proposed UPop framework.","ArXiv",2023,"Dachuan Shi,Chaofan Tao,Ying Jin,Zhendong Yang,Chun Yuan,Jiaqi Wang",0,44,0
"be148b81922706c831cfb0d48ea528af47c7acb4","https://www.semanticscholar.org/paper/be148b81922706c831cfb0d48ea528af47c7acb4",3,"The geometry of hidden representations of large transformer models","It is shown that the semantic complexity of the dataset emerges at the end of the first peak, and is suggested to use the ID profile as an unsupervised proxy to identify the layers which are more suitable for downstream learning tasks.","ArXiv",2023,"L. Valeriani,Diego Doimo,F. Cuturello,A. Laio,A. Ansuini,A. Cazzaniga",0,37,0
"ddce9cfee35ee4f36f2720c095cb33293f11f62e","https://www.semanticscholar.org/paper/ddce9cfee35ee4f36f2720c095cb33293f11f62e",3,"Learning to Scale Temperature in Masked Self-Attention for Image Inpainting","An image inpainting framework with a multi-head temperature masked self-attention mechanism, which provides stable and efficient temperature learning and uses multiple distant contextual information for high quality image inPainting is presented.","ArXiv",2023,"Xiang Zhou,Yuan Zeng,Yi Gong",0,53,0
"f367ce68505e01d0452fe4be113e27f7a98c9d6d","https://www.semanticscholar.org/paper/f367ce68505e01d0452fe4be113e27f7a98c9d6d",3,"LAD: Language Augmented Diffusion for Reinforcement Learning","This paper demonstrates the comparable performance of LAD with the state-of-the-art on the CALVIN language robotics benchmark with a much simpler architecture that contains no inductive biases special-ized to robotics, achieving an average success rate of 72% compared to the best performance of 76%.","",2022,"Pamela Mishkin",1,37,0
"bbd181612924aaf94b12d3c74383538f1c80e68f","https://www.semanticscholar.org/paper/bbd181612924aaf94b12d3c74383538f1c80e68f",3,"Tackling AlfWorld with Action Attention and Common Sense from Pretrained LMs","A novel question answering framework to simplify observations and an agent that handles arbitrary roll-out length and action space size based on action attention is implemented and achieved on the Alfworld benchmark for indoor instruction following.","",2022,"Yue Wu,So Yeon Min,Yonatan Bisk,R. Salakhutdinov,Shrimai Prabhumoye",0,14,0
"b7d27c5af2d314f6ec45b6d88984fb45220eb379","https://www.semanticscholar.org/paper/b7d27c5af2d314f6ec45b6d88984fb45220eb379",3,"Bootstrapped Transformer for Offline Reinforcement Learning","This paper proposes a novel algorithm named Bootstrapped Transformer, which incorporates the idea of bootstrapping and leverages the learned model to self-generate more ofﬂine data to further boost the sequence model training.","ArXiv",2022,"Kerong Wang,Hanye Zhao,Xufang Luo,Kan Ren,Weinan Zhang,Dongsheng Li",5,54,2
"a9e6380ec7e0a9c336606e94e07705dee9391fef","https://www.semanticscholar.org/paper/a9e6380ec7e0a9c336606e94e07705dee9391fef",3,"Robot Task Planning and Situation Handling in Open Worlds","A novel algorithm (COWP) for open-world task planning and situation handling that dynamically augments the robot’s action knowledge with task-oriented common sense based on the current task at hand and robot skills is introduced.","ArXiv",2022,"Yan Ding,Xiaohan Zhang,S. Amiri,Nieqing Cao,Hao Yang,Chad Esselink,Shiqi Zhang",1,36,0
"a02ab0f0a5b00f506de5b826209a99fe33236c1b","https://www.semanticscholar.org/paper/a02ab0f0a5b00f506de5b826209a99fe33236c1b",3,"Learning Automata-Based Task Knowledge Representation from Large-Scale Generative Language Models","A novel algorithm named GLM2FSA is proposed, which obtains high-level task knowledge represented in a finite state automaton (FSA) from a given brief description of the task goal and can be directly utilized in formal verification.","ArXiv",2022,"Yunhao Yang,Jean-Raphael Gaglione,U. Topcu",0,28,0
"364f0dd472a79af2c647da70d3d3f8c1c4128f36","https://www.semanticscholar.org/paper/364f0dd472a79af2c647da70d3d3f8c1c4128f36",3,"A Song of Ice and Fire: Analyzing Textual Autotelic Agents in ScienceWorld","The importance of selectivity from the social peer's feedback is shown; that experience replay needs to over-sample examples of rare goals; and that following self-generated goal sequences where the agent's competence is intermediate leads to significant improvements in final performance.","ArXiv",2023,"Laetitia Teodorescu,Eric Yuan,Marc-Alexandre Côté,P. Oudeyer",0,42,0
"bcaf0a460e5a2f1ac48902071652d570023219f4","https://www.semanticscholar.org/paper/bcaf0a460e5a2f1ac48902071652d570023219f4",3,"ON MEMORY IN HUMAN AND ARTIFICIAL LANGUAGE PROCESSING SYSTEMS","The separation of computation and storage is considered as necessary, desired properties of the storage system are suggested, and the benefit of integrating different types of human memory into next-generation language processing systems are discussed.","",2020,"Aida Nematzadeh,Sebastian Ruder,Dani Yogatama",13,51,0
"3410e91c55ec78e4ec94b6a56897945e136d7cd8","https://www.semanticscholar.org/paper/3410e91c55ec78e4ec94b6a56897945e136d7cd8",3,"Progress in Neural NLP: Modeling, Learning, and Reasoning","The importance of reasoning is emphasized in this paper because it is important for building interpretable and knowledge-driven neural NLP models to handle complex tasks.","Engineering",2020,"Ming Zhou,Nan Duan,Shujie Liu,H. Shum",60,110,2
"336ee50043b916c9e932338c02fd1abc87a6e849","https://www.semanticscholar.org/paper/336ee50043b916c9e932338c02fd1abc87a6e849",3,"Compositional Generalization by Learning Analytical Expressions","A refreshing view that connects a memory-augmented neural model with analytical expressions, to achieve compositional generalization is presented, fitting well with the cognitive argument while still being trained in an end-to-end manner via a hierarchical reinforcement learning algorithm.","Neural Information Processing Systems",2020,"Qian Liu,Shengnan An,Jian-Guang Lou,Bei Chen,Zeqi Lin,Yan Gao,Bin Zhou,Nanning Zheng,Dongmei Zhang",44,44,8
"ec31d9dcdd984f9546a6d0ad3cecf33699247140","https://www.semanticscholar.org/paper/ec31d9dcdd984f9546a6d0ad3cecf33699247140",3,"with KNN-Based Composite Memory for Dialog","This work proposes augmenting generative Transformer neural networks with KNN-based Information Fetching modules, and applies these modules to generative dialog modeling, a challenging task where information must be flexibly retrieved and incorporated to maintain the topic and flow of conversation.","",2020,"Angela Fan,Claire Gardent,Chloé Braud,Antoine Bordes",0,47,0
"d642868ce4325ebf3026c0aa0c497a079f112a8d","https://www.semanticscholar.org/paper/d642868ce4325ebf3026c0aa0c497a079f112a8d",3,"On the Binding Problem in Artificial Neural Networks","This paper proposes a unifying framework that revolves around forming meaningful entities from unstructured sensory inputs, maintaining this separation of information at a representational level (representation), and using these entities to construct new inferences, predictions, and behaviors (composition).","ArXiv",2020,"Klaus Greff,Sjoerd van Steenkiste,J. Schmidhuber",110,393,13
"8905f3dcd215fbc3d56839b6f52a43d77ac59fe8","https://www.semanticscholar.org/paper/8905f3dcd215fbc3d56839b6f52a43d77ac59fe8",3,"Augmenting Transformers with KNN-Based Composite Memory for Dialog","This work proposes augmenting generative Transformer neural networks with KNN-based Information Fetching modules, and applies these modules to generative dialog modeling, a challenging task where information must be flexibly retrieved and incorporated to maintain the topic and flow of conversation.","International Conference on Topology, Algebra and Categories in Logic",2020,"Angela Fan,Claire Gardent,Chloé Braud,Antoine Bordes",47,51,6
"2c0a266f9cb88bb914c138ece0deaab8cf528f78","https://www.semanticscholar.org/paper/2c0a266f9cb88bb914c138ece0deaab8cf528f78",3,"Neural Sequence-to-grid Module for Learning Symbolic Rules","A neural sequence-to-grid (seq2grid) module, an input preprocessor that automatically segments and aligns an input sequence into a grid and enhances TextCNN to solve the bAbI QA tasks without external memory is proposed.","AAAI Conference on Artificial Intelligence",2021,"Segwang Kim,Hyoungwook Nam,Joonyoung Kim,Kyomin Jung",4,36,1
"64a29bee2e1ad29547d590a3cc26274f4c537145","https://www.semanticscholar.org/paper/64a29bee2e1ad29547d590a3cc26274f4c537145",3,"Not All Memories are Created Equal: Learning to Forget by Expiring","It is demonstrated that Expire-Span can help models identify and retain critical information and show it can achieve strong performance on reinforcement learning tasks specifically designed to challenge this functionality, and it is shown that it trains faster and uses less memory.","International Conference on Machine Learning",2021,"Sainbayar Sukhbaatar,Da Ju,Spencer Poff,Stephen Roller,Arthur D. Szlam,J. Weston,Angela Fan",16,50,1
"b1a49877c4f8636f0c51e09cccbf2777a6bf8c96","https://www.semanticscholar.org/paper/b1a49877c4f8636f0c51e09cccbf2777a6bf8c96",3,"Mutation Testing of Deep Reinforcement Learning Based on Real Faults","This paper builds on the existing approach of MT in order to propose a framework, RLMutation, for MT applied to RL and finds that even with a relatively small number of test cases and operators, it can generate HOM with interesting properties which can enhance testing capability in RL systems.","ArXiv",2023,"Florian Tambon,Vahid Majdinasab,Amin Nikanjam,F. Khomh,G. Antoniol",0,36,0
"d08a6a41e2b16928a1dc93b259bffbe37dae021d","https://www.semanticscholar.org/paper/d08a6a41e2b16928a1dc93b259bffbe37dae021d",3,"Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation","This work proposes mask-and-fill and keyword-guided approaches that generate negative examples for training more robust dialogue systems and proposes approaches for automatically creating adversarial negative training data to help ranking and evaluation models learn features beyond content similarity.","Findings",2021,"Prakhar Gupta,Yulia Tsvetkov,Jeffrey P. Bigham",12,93,2
"392b2698f147470348e40cb2426edbcd629c5037","https://www.semanticscholar.org/paper/392b2698f147470348e40cb2426edbcd629c5037",3,"Narrative Incoherence Detection","With pre-training on large-scale data and cycle-consistent sentence embedding, the extended sentence-level model can achieve comparable detection accuracy to the tokenlevel model and enables simultaneous incoherence detection and infilling/modification suggestions.","ArXiv",2020,"Deng Cai,Yizhe Zhang,Yichen Huang,Wai Lam,Bill Dolan",3,53,0
"da5d78b3e3a1544fde98fba86088e1215e97cbe8","https://www.semanticscholar.org/paper/da5d78b3e3a1544fde98fba86088e1215e97cbe8",3,"All NLP Tasks Are Generation Tasks: A General Pretraining Framework","This architecture has three major benefits: it performs well on classification, unconditional generation, and conditional generation tasks with one single pretrained model; it outperforms BERT-like models on classification due to improved pretrain-finetune consistency; and it naturally handles variable-length blank filling which is crucial for many downstream tasks.","ArXiv",2021,"Zhengxiao Du,Yujie Qian,Xiao Liu,Ming Ding,J. Qiu,Zhilin Yang,Jie Tang",29,37,3
"ea45423c8f44025a276f6e88aafffbf87a898c89","https://www.semanticscholar.org/paper/ea45423c8f44025a276f6e88aafffbf87a898c89",3,"Language Model Augmented Relevance Score","This paper proposes Language Model Augmented Relevance Score (MARS), a new context-aware metric for NLG evaluation that leverages off-the-shelf language models, guided by reinforcement learning, to create augmented references that consider both the generation context and available human references.","Annual Meeting of the Association for Computational Linguistics",2021,"Ruibo Liu,Jason Wei,Soroush Vosoughi",7,67,2
"3156551194f47dc1bd40c06ed3e716e2fb3a816c","https://www.semanticscholar.org/paper/3156551194f47dc1bd40c06ed3e716e2fb3a816c",3,"Visual Explanation of Deep Q-Network for Robot Navigation by Fine-tuning Attention Branch","Experimental results with robot navigation task show that the proposed method can generate interpretable attention maps for a visual explanation of deep RL models.","ArXiv",2022,"Yuya Maruyama,Hiroshi Fukui,Tsubasa Hirakawa,Takayoshi Yamashita,H. Fujiyoshi,K. Sugiura",0,34,0
"402f0232ed92ae6c3384767064352306db471db8","https://www.semanticscholar.org/paper/402f0232ed92ae6c3384767064352306db471db8",3,"Bridging Scenarios in Reinforcement Learning with Continuously Generated Relaying Predictive Models","Experimental results show that CRPM helps to avoid sub-optimal policies and outperforms other algorithms in both the source and target scenarios and helps to improve the classical model-free algorithm by considering it as a particular case of transfer learning in the same domain.","2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)",2022,"Kuo Li,Qing-Shan Jia",0,31,0
"c9c1864f29e9ce1f0ad22389694998e53c78df62","https://www.semanticscholar.org/paper/c9c1864f29e9ce1f0ad22389694998e53c78df62",3,"Implementation of Quantum Deep Reinforcement Learning Using Variational Quantum Circuits","Variational Quantum Circuits (VQC) is explored for Deep Q network-based Reinforcement Learning by remodeling the target network and experience replay into a representation of VQC, and the reduction in model parameters is reduced to achieve better results than classical neural networks.","2022 International Conference on Trends in Quantum Computing and Emerging Business Technologies (TQCEBT)",2022,"S. Lokes,C. S. J. Mahenthar,S. Kumaran,Palaniyappan Sathyaprakash,Vaithiyashankar Jayakumar",0,17,0
"8b4d4d0602ad72f26f3c16c03251240f80f3c83c","https://www.semanticscholar.org/paper/8b4d4d0602ad72f26f3c16c03251240f80f3c83c",3,"DanZero: Mastering GuanDan Game with Reinforcement Learning","This paper proposes the first AI program DanZero for GuanDan, whose rules are similar to DouDizhu but much more complicated, and trains it using a distributed framework and reveals the outstanding performance of DanZero.","ArXiv",2022,"Yudong Lu,Jian Zhao,Youpeng Zhao,Wen-gang Zhou,Houqiang Li",0,28,0
"8cb7e8c8c95b03085ebe0447322481c71810baa5","https://www.semanticscholar.org/paper/8cb7e8c8c95b03085ebe0447322481c71810baa5",3,"Approximate Optimal Filter Design for Vehicle System through Actor-Critic Reinforcement Learning","","Automotive Innovation",2022,"Yuming Yin,S. Li,Kaiming Tang,Wenhan Cao,Wei Wu,Hongbo Li",0,25,0
"768c0c51da0b7627334e460c78f2f408722ca9bf","https://www.semanticscholar.org/paper/768c0c51da0b7627334e460c78f2f408722ca9bf",3,"Virtual Network Embedding with Virtual Nodes Ranking and Multi Points Sampling","A trainable virtual network node ranking method leveraging a graph neural network to provide a more reasonable virtual node mapping sequence and a multi-record point sampling strategy that can collect samples from multiple record points is designed to reduce the correlation of samples in the training set and obtain the global optimal solution in the embedding process.","International Conference on Advanced Cloud and Big Data",2022,"Ying Yuan,Yichen Yang,Cong Wang",0,23,0
"ba56b43c34d6161effed557880b10b5db074afca","https://www.semanticscholar.org/paper/ba56b43c34d6161effed557880b10b5db074afca",3,"Variants of Bellman equation on reinforcement learning problems","These algorithms include MonteCarlo method, Temporal-Difference learning, Sarsa algorithm, Q-learning algorithm, Deep Q-Networks, Hamilton-Jacobi-Bellman equation and others are reviewed and the complexity of each algorithm is compared.","Other Conferences",2022,"Zhen-Yi Zhao",1,11,0
"5b0f149e28d2373e77dc4686b74833c94360438b","https://www.semanticscholar.org/paper/5b0f149e28d2373e77dc4686b74833c94360438b",3,"Roadmap of AlphaGo to AlphaStar: Problems and challenges","This paper focuses on the in-depth analysis of the internal connections of Alpha series from the perspective of the problems and challenges solved to give an insight for the future development of reinforcement learning.","Other Conferences",2022,"Yuhan Rong",0,13,0
"a520a24ce27684e1fd87b3fe96e9b05a3e727dd5","https://www.semanticscholar.org/paper/a520a24ce27684e1fd87b3fe96e9b05a3e727dd5",3,"Applying Artificial Intelligence in Cryptocurrency Markets: A Survey","This survey paper aims to review the current research trends in applications of supervised and reinforcement learning models in cryptocurrency price prediction and highlights potential research gaps and possible areas for improvement.","Algorithms",2022,"R. Amirzadeh,A. Nazari,D. Thiruvady",0,115,0
"2e7e6a00bdc3f8c11ab3b29314ff8180c57d245b","https://www.semanticscholar.org/paper/2e7e6a00bdc3f8c11ab3b29314ff8180c57d245b",3,"Credit-cognisant reinforcement learning for multi-agent cooperation","This paper introduces the concept of credit-cognisant rewards (CCRs), which allows an agent to perceive the effect its actions had on the environment as well as on its co-agents, and shows that by manipulating these experiences and constructing the reward contained within them to include the rewards received by all the agents within the same action sequence, this paper is able to improve the performance of independent deep Q-learning aswell as deep recurrent Q- learning.","ArXiv",2022,"F. Bredell,H. Engelbrecht,J. C. Schoeman",0,33,0
"f1574b6146699cf5000fda0619a625eb1cdc4ddd","https://www.semanticscholar.org/paper/f1574b6146699cf5000fda0619a625eb1cdc4ddd",3,"A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning","This work proposes the Adaptive Coding Spiking Framework (ACSF) for SNN-based DRL and achieves low latency and great energy efﬁciency at the same time.","ArXiv",2022,"Lang Qin,Rui Yan,Huajin Tang",0,36,0
"8ef263292d9863df2130182aeb13d1d5ed3ea199","https://www.semanticscholar.org/paper/8ef263292d9863df2130182aeb13d1d5ed3ea199",3,"Explainable and Safe Reinforcement Learning for Autonomous Air Mobility","A fully explainable DRL framework wherein the coupled Q value learning model is decompose into a safety-awareness and efﬁciency one and the safety Q learning module provides rich information about the safety situation of environments.","ArXiv",2022,"Leihao Wang,Hongyu Yang,Yi Lin,S. Yin,Yuankai Wu",0,54,0
"cb37811b39fe829f1e2691a15eaa6a9253ecc42a","https://www.semanticscholar.org/paper/cb37811b39fe829f1e2691a15eaa6a9253ecc42a",3,"Continuous Episodic Control","Results on several sparse-reward continuous control environments show that the proposed CEC method learns faster than state-of-the-art model- free RL and memory-augmented RL algorithms, while main-taining good long-run performance as well.","ArXiv",2022,"Zhao Yang,Thomas M. Moerland,M. Preuss,Aske Plaat",0,16,0
"d141ccecf969606ea62ad286b97a233cd0147b94","https://www.semanticscholar.org/paper/d141ccecf969606ea62ad286b97a233cd0147b94",3,"A Policy Optimization Algorithm Based on Sample Adaptive Reuse and Dual-Clipping for Robotic Action Control","","SSRN Electronic Journal",2022,"Li-yang Zhao,Tianqing Chang,J. Zhang,Lei Zhang,Kaixuan Chu,Libin Guo,D. Kong",0,15,0
"f93e975281750006b9d12f483d1c7d1121830e08","https://www.semanticscholar.org/paper/f93e975281750006b9d12f483d1c7d1121830e08",3,"Kick-motion Training with DQN in AI Soccer Environment","Using the RCS eliminates the necessity for the agent to know all the (state) information of entire soccer information and reduces the dimension of the state that the agent needs to know to perform kick-motion, and consequently alleviates COD.","ArXiv",2022,"B. Park,J. Lee,Taeyoung Kim,Dongsoo Har",1,14,0
"63689edecc451d08571f02603eb113a9477a2587","https://www.semanticscholar.org/paper/63689edecc451d08571f02603eb113a9477a2587",3,"Artificial intelligence meets radar resource management: A comprehensive background and literature review","","IET Radar, Sonar &amp; Navigation",2022,"U. Hashmi,Sunila Akbar,R. Adve,P. Moo,Jack Ding",0,77,0
"73d12fae628e897a6c855f23ef1e5bb4b352839b","https://www.semanticscholar.org/paper/73d12fae628e897a6c855f23ef1e5bb4b352839b",3,"Accelerating Self-Imitation Learning from Demonstrations via Policy Constraints and Q-Ensemble","A learning from demonstrations method named A-SILfD is proposed, which treats expert demonstrations as the agent’s successful experiences and uses experiences to constrain policy improvement and prevents performance degradation due to large estimation errors in the Q-function by the ensemble Q-functions.","ArXiv",2022,"C. Li",0,55,0
"2e90470adf2f4d8ce4659602d6db8a191eeaf3b5","https://www.semanticscholar.org/paper/2e90470adf2f4d8ce4659602d6db8a191eeaf3b5",3,"Q-learning–based practical disturbance compensation control for hypersonic flight vehicle","","Proceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering",2022,"Xu Li,Ziyi Zhang,Yuehui Ji,Junjie Liu,Qiang Gao",0,35,0
"c15794a8b381da90a46f137aab3387b66a215617","https://www.semanticscholar.org/paper/c15794a8b381da90a46f137aab3387b66a215617",3,"Off-Policy Reinforcement Learning with Loss Function Weighted by Temporal Difference Error","A novel method is proposed that introduces a weighting factor for each experience when calculating the loss function at the learning stage and can be combined with prioritization methods for non-uniform sampling to improve sampling efficiency and increase the performance of TD-based off-policy RL algorithms.","ArXiv",2022,"Bumgeun Park,Taeyoung Kim,Woohyeon Moon,L. Vecchietti,Dongsoo Har",0,49,0
"a7692a6748be022dfd9534310b339c15919a9f56","https://www.semanticscholar.org/paper/a7692a6748be022dfd9534310b339c15919a9f56",3,"Twin attentive deep reinforcement learning for multi-agent defensive convoy","","International Journal of Machine Learning and Cybernetics",2022,"Dongyu Fan,Haikuo Shen,Lijing Dong",0,22,0
"2b49156cf855dbb39768ae0ba7d7cb9263d17e5c","https://www.semanticscholar.org/paper/2b49156cf855dbb39768ae0ba7d7cb9263d17e5c",3,"Informed Machine Learning – A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems","A taxonomy is introduced that serves as a classification framework for informed machine learning approaches and considers the source of knowledge, its representation, and its integration into the machine learning pipeline.","IEEE Transactions on Knowledge and Data Engineering",2019,"Laura von Rueden,S. Mayer,Katharina Beckh,B. Georgiev,Sven Giesselbach,R. Heese,Birgit Kirsch,Julius Pfrommer,Annika Pick,Rajkumar Ramamurthy,Michal Walczak,J. Garcke,C. Bauckhage,Jannis Schuecker",208,198,11
"6110486edc5a9268cdde48c7c4f67a7782a7d61b","https://www.semanticscholar.org/paper/6110486edc5a9268cdde48c7c4f67a7782a7d61b",3,"Dynamic Programming Principles for Mean-Field Controls with Learning","It is shown that multiagent systems with mean-field approximation and learning can be recast as general forms of reinforcement learning problems, where the state variable is replaced by the probability distribution.","Operational Research",2019,"Haotian Gu,Xin Guo,Xiaoli Wei,Renyuan Xu",8,54,0
"51cc21e3e0b18171c40dcb886684ddc97a06ae20","https://www.semanticscholar.org/paper/51cc21e3e0b18171c40dcb886684ddc97a06ae20",3,"Self reward design with fine-grained interpretability","The framework introduced in this paper is called the Self Reward Design (SRD), inspired by the Inverse Reward Design, and this interpretable design can solve the problem by pure design (although imperfectly) and be optimized like a standard DNN.","Scientific Reports",2021,"Erico Tjoa,G. Cuntai",1,31,0
"5912f6344c91f27cb6b9384099b18b5b7d65903c","https://www.semanticscholar.org/paper/5912f6344c91f27cb6b9384099b18b5b7d65903c",3,"Deep Reinforcement Learning for Preparation of Thermal and Prethermal Quantum States","","Physical Review Applied",2022,"Shotaro Z. Baba,N. Yoshioka,Y. Ashida,T. Sagawa",1,102,1
"85b7b2cc34275d9eccb2518ff573b12ad1f537d5","https://www.semanticscholar.org/paper/85b7b2cc34275d9eccb2518ff573b12ad1f537d5",3,"Inference and dynamic decision-making for deteriorating systems with probabilistic dependencies through Bayesian networks and deep reinforcement learning","A deep decentralized multi-agent actor-critic reinforcement learning approach, in which the policies are approximated by actor neural networks guided by a critic network, providing optimal management strategies directly at the system level.","Reliability Engineering &amp; System Safety",2022,"P. G. Morato,C. Andriotis,K. Papakonstantinou,P. Rigo",2,63,0
"43ac57f2d339912e8cedd40ff7522c519ddadae8","https://www.semanticscholar.org/paper/43ac57f2d339912e8cedd40ff7522c519ddadae8",3,"Goals, usefulness and abstraction in value-based choice","The computational and biological principles that enable the brain to compute the usefulness of an option or action by creating abstractions that flexibly adapt to changing goals are outlined.","Trends in Cognitive Sciences",2022,"B. De Martino,A. Cortese",2,137,0
"300d7d9f2c785ffc81f5eb1c9f7458a985929d05","https://www.semanticscholar.org/paper/300d7d9f2c785ffc81f5eb1c9f7458a985929d05",3,"Transfer reinforcement learning method with multi-label learning for compound fault recognition","","Advanced Engineering Informatics",2023,"Zisheng Wang,Qing Zhang,Lv Tang,Tielin Shi,Jianping Xuan",0,44,0
"9ee43603374933e597f04a34141d423cd7b8e92d","https://www.semanticscholar.org/paper/9ee43603374933e597f04a34141d423cd7b8e92d",3,"Data Valuation Without Training of a Model","A training-free data valuation score, called complexity-gap score, is provided, which is a data-centric score to quantify the inﬂuence of individual instances in generalization of two-layer overparameterized neural networks and can quantify irregularity of the instances.","ArXiv",2023,"Nohyun Ki,Hoyong Choi,Hye Won Chung",0,36,0
"d2dfa69439bab536c2355d9d80227ee7d0c8cb83","https://www.semanticscholar.org/paper/d2dfa69439bab536c2355d9d80227ee7d0c8cb83",3,"Nondeterministic efficient cooling with a near-unit probability","","",2023,"Jia-shun Yan,J. Jing",0,42,0
"ffacd7cdf3ed40dcfe24aa6cb5b9a72898301a70","https://www.semanticscholar.org/paper/ffacd7cdf3ed40dcfe24aa6cb5b9a72898301a70",3,"Value Enhancement of Reinforcement Learning via Efficient and Robust Trust Region Optimization","This paper proposes a novel value enhancement method to improve the performance of a given initial policy computed by existing state-of-the-art RL algorithms, and is generally applicable to any parametrized policy that belongs to certain pre-specified function class (e.g., deep neural networks).","ArXiv",2023,"C. Shi,Zhengling Qi,Jianing Wang,Fan Zhou",0,66,0
"120b5bd6444cdbc8b91cfb16d304cfce59150dfe","https://www.semanticscholar.org/paper/120b5bd6444cdbc8b91cfb16d304cfce59150dfe",3,"Planning Automated Driving with Accident Experience Referencing and Common-sense Inferencing","This work presents the concept of an Automated Driving Strategical Brain (ADSB): a framework of a scene perception and scene safety evaluation system that works at a higher abstraction level, incorporating experience referencing, common-sense inferring and goal-and-value judging capabilities, to provide a contextual perspective for decision making within automated driving planning.","ArXiv",2023,"Shaobo Qiu,Ji Li,Guoxi Chen,Hong Wang,Boqi Li",0,45,0
"af069d9670df16a01c3d5df77baebdf42d9e256f","https://www.semanticscholar.org/paper/af069d9670df16a01c3d5df77baebdf42d9e256f",3,"Off-the-Grid MARL: a Framework for Dataset Generation with Baselines for Cooperative Offline Multi-Agent Reinforcement Learning","OG-MARL is released, a framework for generating offline multi-agent reinforcement learning datasets and algorithms that provide settings that are characteristic of real-world systems, including complex dynamics, non-stationarity, partial observability, suboptimality and sparse rewards.","ArXiv",2023,"Claude Formanek,Asad Jeewa,J. Shock,Arnu Pretorius",0,46,0
"b3d09c2d9384dd78364d53e9b3411d6a99363648","https://www.semanticscholar.org/paper/b3d09c2d9384dd78364d53e9b3411d6a99363648",3,"An integrated solution of deep reinforcement learning for automatic IMRT treatment planning in non-small-cell lung cancer","The feasibility of this integrated solution in automatic treatment planning based on the Eclipse TPS is demonstrated and contributes to improving the efficiency of the overall planning workflow and reducing the variation of plan quality in different regions and treatment centers.","Frontiers in Oncology",2023,"Hanlin Wang,X. Bai,Yajuan Wang,Yanfei Lu,Binbing Wang",0,36,0
"19c9c9393b6cd38ad800ef3369bcc544740ed9ea","https://www.semanticscholar.org/paper/19c9c9393b6cd38ad800ef3369bcc544740ed9ea",3,"Helixer–de novo Prediction of Primary Eukaryotic Gene Models Combining Deep Learning and a Hidden Markov Model","Helixer is a fully applicable, fast and user friendly tool for predicting primary gene models from DNA sequence alone and its quality is state-of-the-art, with predictions scoring closer by most measures to the references than to predictions from other de novo tools.","bioRxiv",2023,"Felix Holst,Anthony M. Bolger,Christopher Günther,Janina Maß,Sebastian Triesch,Felicitas Kindel,Niklas Kiel,N. Saadat,O. Ebenhöh,B. Usadel,R. Schwacke,Marie E. Bolger,A. Weber,Alisandra K. Denton",0,42,0
"b4023250016e424ec5df5207d8823a035e02daa0","https://www.semanticscholar.org/paper/b4023250016e424ec5df5207d8823a035e02daa0",3,"Temporal Video-Language Alignment Network for Reward Shaping in Reinforcement Learning","This work proposes a natural language-based reward shaping approach that maps trajectories from the Montezuma's Revenge game environment to corresponding natural language instructions using an extension of the LanguagE-Action Reward Network (LEARN) framework.","ArXiv",2023,"Ziyuan Cao,Reshma A. Ramachandra,K. Yu",0,32,0
"6bbf2b090d3741068728d6cc30bc4cab15271360","https://www.semanticscholar.org/paper/6bbf2b090d3741068728d6cc30bc4cab15271360",3,"COACH: Cooperative Robot Teaching","This work formalizes cooperative robot teaching as a Markov game, consisting of four key elements: the target task, the student model, the teacher model, and the interactive teaching-learning process.","",2023,"Cunjun Yu,Yiqing Xu,Linfeng Li,David Hsu",0,61,0
"e5e477903869e6dee6e0de5d10c7fb463bf4b471","https://www.semanticscholar.org/paper/e5e477903869e6dee6e0de5d10c7fb463bf4b471",3,"When neuro-robots go wrong: A review","","Frontiers in Neurorobotics",2023,"M. S. Khan,J. Olds",0,160,0
"961e8d410bd263849a2f58c8028bed3d0fdf68c7","https://www.semanticscholar.org/paper/961e8d410bd263849a2f58c8028bed3d0fdf68c7",3,"Questions to Guide the Future of Artificial Intelligence Research","This article proposes leading questions to guide the future of artificial intelligence research and states that there are clear computational principles on which the brain operates but the problem is finding these computational needles in a haystack of biological complexity.","ArXiv",2019,"J. Ott",3,115,0
"778620f68c2dadfa6154fe20a2e771945fda0ec5","https://www.semanticscholar.org/paper/778620f68c2dadfa6154fe20a2e771945fda0ec5",3,"Embedding Synthetic Off-Policy Experience for Autonomous Driving via Zero-Shot Curricula","A method to predict the inherent difﬁculty of a driving situation given data collected from a set of autonomous vehicles deployed on public roads is presented and can be used in a zero-shot transfer to generate curricula for an imitation-learning based planning agent.","ArXiv",2022,"Eli Bronstein,S. Srinivasan,Supratik Paul,Aman Sinha,Matthew O'Kelly,Payam Nikdel,Shimon Whiteson",1,47,0
"5bb567f9b6ecdac86345495871636fde48adc410","https://www.semanticscholar.org/paper/5bb567f9b6ecdac86345495871636fde48adc410",3,"Off-Policy Deep Reinforcement Learning Algorithms for Handling Various Robotic Manipulator Tasks","Three reinforcement learning algorithms; DDPG, TD3 and SAC have been used to train Fetch robotic manipulator for four diﬀerent tasks in MuJoCo simulation environment and the e-ciency and the speed of these three algorithms are analyzed in a controlled environment.","ArXiv",2022,"Altun Rzayev,Vahid Tavakol Aghaei",0,0,0
"6af2b4051ae785501674c26f3bf89313e8849814","https://www.semanticscholar.org/paper/6af2b4051ae785501674c26f3bf89313e8849814",3,"How to Train your Decision-Making AIs","These are examples of sequential decision tasks, in which the AI agent needs to make a sequence of decisions to achieve its goal.","",2022,"Ruohan Zhang,Dhruva Bansal",0,22,0
"7b6dd8542906a8014ba4924efdc7213d5e0a0711","https://www.semanticscholar.org/paper/7b6dd8542906a8014ba4924efdc7213d5e0a0711",3,"How to Train Your Agent: Active Learning from Human Preferences and Justifications in Safety-critical Environments","This model, JPAL-HA, proposes an efficient mechanism to harness human preferences and justifications to significantly improve safety during the learning process without increasing the number of interactions with a user.","Adaptive Agents and Multi-Agent Systems",2022,"Ilias Kazantzidis,T. Norman,Yali Du,Christopher T. Freeman",3,23,0
"4ec50cee2f70e97c00d294985a924a56081a8573","https://www.semanticscholar.org/paper/4ec50cee2f70e97c00d294985a924a56081a8573",3,"Democratizing RL Research by Reusing Prior Computation","As deep RL research move towards more complex and challenging benchmarks, the computational barrier to entry in RL research would be even substantially higher, due to the inefficiency of tabula rasa RL.","",2022,"",0,24,0
"7cfa93c3d646d57c4a1f52538549db474877df0c","https://www.semanticscholar.org/paper/7cfa93c3d646d57c4a1f52538549db474877df0c",3,"What Can Knowledge Bring to Machine Learning?—A Survey of Low-shot Learning for Structured Data","The fundamental factors of low-shot learning technologies are reviewed, with a focus on the operation of structured knowledge under different low- shot conditions, and the prospects and gaps of industrial applications and future research directions are pointed out.","ACM Transactions on Intelligent Systems and Technology",2021,"Yang Hu,Adriane P. Chapman,Guihua Wen,Dame Wendy Hall",6,343,2
"1c35807e1a4c24e2013fa0a090cee9cc4716a5f5","https://www.semanticscholar.org/paper/1c35807e1a4c24e2013fa0a090cee9cc4716a5f5",3,"Reinforcement Learning with Action-Free Pre-Training from Videos","A framework that learns representations useful for understanding the dynamics via generative pretraining on videos that improves both performances and sample-efﬁciency of vision-based RL in a variety of manipulation and locomotion tasks is introduced.","International Conference on Machine Learning",2022,"Younggyo Seo,Kimin Lee,Stephen James,P. Abbeel",20,117,0
"ed04974e0ba9556291d9645221d4905fb0e32838","https://www.semanticscholar.org/paper/ed04974e0ba9556291d9645221d4905fb0e32838",3,"DouZero+: Improving DouDizhu AI by Opponent Modeling and Coach-guided Learning","The integration of the above two techniques into DouZero, the DouDizhu AI system achieves better performance and ranks top in the Botzone leaderboard among more than 400 AI agents, including DouZero.","2022 IEEE Conference on Games (CoG)",2022,"Youpeng Zhao,Jian Zhao,Xu Hu,Wen-gang Zhou,Houqiang Li",2,45,0
"b1362b8a11b1984378b91162195e10e369f6b012","https://www.semanticscholar.org/paper/b1362b8a11b1984378b91162195e10e369f6b012",3,"Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation","This paper proposes the ﬁrst optimistic model-based algorithm for PbRL with general function approximation, which estimates the model using value-targeted regression and calculates the exploratory policies by solving an optimistic planning problem.","International Conference on Machine Learning",2022,"Xiaoyu Chen,Han Zhong,Zhuoran Yang,Zhaoran Wang,Liwei Wang",1,53,0
"470bd6813d303d4ea776def788d215caaa8e772f","https://www.semanticscholar.org/paper/470bd6813d303d4ea776def788d215caaa8e772f",3,"History Compression via Language Models in Reinforcement Learning","The new method, HELM, enables actor-critic network architectures that contain a pretrained language Transformer for history representation as a memory module that is much more sample efﬁcient than competitors.","International Conference on Machine Learning",2022,"Fabian Paischer,Thomas Adler,Vihang Patil,Angela Bitto-Nemling,Markus Holzleitner,S. Lehner,Hamid Eghbal-zadeh,S. Hochreiter",6,103,0
"3dfa5b1cc516cb0a8d8f3e435f42edd38c9ae1ad","https://www.semanticscholar.org/paper/3dfa5b1cc516cb0a8d8f3e435f42edd38c9ae1ad",3,"Performative Reinforcement Learning","This work considers a regularized version of the reinforcement learning problem and shows that repeatedly optimizing this objective converges to a performatively stable policy under reasonable assumptions on the transition dynamics.","ArXiv",2022,"Debmalya Mandal,Stelios Triantafyllou,Goran Radanovic",2,58,0
"5718a058c096adb0fd92829d202adffde30df771","https://www.semanticscholar.org/paper/5718a058c096adb0fd92829d202adffde30df771",3,"Learning Task Embeddings for Teamwork Adaptation in Multi-Agent Reinforcement Learning","This work discusses the problem of teamwork adaptation in which a team of agents needs to adapt their policies to solve novel tasks with limited limitedtuning and proposes three MATE training paradigms: independent MATE, centralised MATES, and mixed MATE which vary in the information used for the task encoding.","ArXiv",2022,"Lukas Schäfer,Filippos Christianos,A. Storkey,Stefano V. Albrecht",2,50,0
"02cf7fa57f11add4a45f27e549ded4449c24553c","https://www.semanticscholar.org/paper/02cf7fa57f11add4a45f27e549ded4449c24553c",3,"Ablation Study of How Run Time Assurance Impacts the Training and Performance of Reinforcement Learning Agents","By studying multiple RTA approaches in both on-policy and o-policy RL algorithms, this work seeks to understand which RTA methods are most e-ective, whether the agents become dependent on the RTA, and the importance of reward shaping versus safe exploration in RL agent training.","ArXiv",2022,"Nathaniel Hamilton,Kyle Dunlap,Taylor T. Johnson,Kerianne L. Hobbs",0,48,0
"420a3be9533a232cab0dfb28185b4619fae919f5","https://www.semanticscholar.org/paper/420a3be9533a232cab0dfb28185b4619fae919f5",3,"The applicability of reinforcement learning for the automatic generation of state preparation circuits","This work approaches the problem of state preparation using reinforcement learning on an agent that is trained to only prepare a single fixed quantum state, and then trains a single network to prepare arbitrary quantum states to some degree of success, despite a complete lack of structure in the training data set.","GECCO Companion",2022,"Thomas Gabor,Maximilian Zorn,C. Linnhoff-Popien",0,23,0
"1fc6c125450e6ee549e8617da0cdc216dacdc7d0","https://www.semanticscholar.org/paper/1fc6c125450e6ee549e8617da0cdc216dacdc7d0",3,"The Game of Hidden Rules: A New Kind of Benchmark Challenge for Machine Learning","The Game of Hidden Rules (GOHR) is introduced, a novel benchmark environment that offers an enormous range of ML challenges and enables precise examination of how task elements inﬂuence practical difﬁculty contribute to overall performance for the machine learner.","ArXiv",2022,"Eric Pulick,S. Bharti,Yiding Chen,V. Menkov,Yonatan Dov Mintz,Paul Kantor,Vicki M. Bier",0,29,0
"046ba0b7c12126e0a4e75dac6eacdcc864907d28","https://www.semanticscholar.org/paper/046ba0b7c12126e0a4e75dac6eacdcc864907d28",3,"Flowsheet synthesis through hierarchical reinforcement learning and graph neural networks","A reinforcement learning algorithm for chemical process design based on a state-of-the-art actor-critic logic that represents chemical processes as graphs and uses graph convolutional neural networks to learn from process graphs is proposed.","ArXiv",2022,"Laura Stops,Roel Leenhouts,Qitong Gao,Artur M. Schweidtmann",5,68,0
"c5d49a31eede6a10ff95e55468701afe4b977d81","https://www.semanticscholar.org/paper/c5d49a31eede6a10ff95e55468701afe4b977d81",3,"Autonomous Vehicles Roundup Strategy by Reinforcement Learning with Prediction Trajectory","Simulation experiments show that the convergence speed and win rate of MADDPG algorithm based on trajectory prediction and artificial potential field is significantly improved, and it also has strong adaptability to various task scenarios.","Cybersecurity and Cyberforensics Conference",2022,"Jiayang Ni,Rubing Ma,Hua Zhong,Bo Wang",0,10,0
"becdb3a4ec34089ac8f34b647aa92365ba901db4","https://www.semanticscholar.org/paper/becdb3a4ec34089ac8f34b647aa92365ba901db4",3,"Contrastive UCB: Provably Efficient Contrastive Self-Supervised Learning in Online Reinforcement Learning","This work provides the first provably efficient online RL algorithm that incorporates contrastive learning for representation learning, and theoretically proves that the algorithm recovers the true representations and simultaneously achieves sample efficiency in learning the optimal policy and Nash equilibrium in MDPs and MGs.","International Conference on Machine Learning",2022,"Shuang Qiu,Lingxiao Wang,Chenjia Bai,Zhuoran Yang,Zhaoran Wang",4,57,0
"a3ebbc1349916276812e5ded51211184a4013f7b","https://www.semanticscholar.org/paper/a3ebbc1349916276812e5ded51211184a4013f7b",3,"Hierarchical Multi-agent Model for Reinforced MedicalResource Allocation with Imperfect Information","A hierarchical reinforcement learning framework with several specially designed components is proposed, which design an recurrent neural network based framework to utilize the imperfect information obtained from the environment and a multi-agents voting method, which modifies the decision making process considering the randomness during model training and thus improves the performance.","ACM Transactions on Intelligent Systems and Technology",2022,"Qianyue Hao,Fengli Xu,Lin Chen,Pan Hui,Yong Li",0,64,0
"cdb4a04a095eb7e2c2aa67aec17602aa599fe3c5","https://www.semanticscholar.org/paper/cdb4a04a095eb7e2c2aa67aec17602aa599fe3c5",3,"Optimistic MLE - A Generic Model-based Algorithm for Partially Observable Sequential Decision Making","It is proved that OMLE learns the near-optimal policies of an enormously rich class of sequential decision making problems in a polynomial number of samples, which unifies the existing understandings of model-based RL in both fully observable and partially observable settings.","ArXiv",2022,"Qinghua Liu,Praneeth Netrapalli,Csaba Szepesvari,Chi Jin",3,57,2
"3997273c28eda260784e1a35c763f74de892c166","https://www.semanticscholar.org/paper/3997273c28eda260784e1a35c763f74de892c166",3,"Skill-Based Reinforcement Learning with Intrinsic Reward Matching","Intrinsic Reward Matching (IRM), which uniﬁes these two phases of learning via the skill discriminator, is presented, and is demonstrated that IRM is competitive with previous skill selection methods on the Unsupervised Reinforcement Learning Benchmark and enables to utilize pretrained skills far more effectively on challenging tabletop manipulation tasks.","ArXiv",2022,"Ademi Adeniji,Amber Xie,P. Abbeel",1,31,0
"b6035d63a6c26faca2be4f6f4a040bb95ce11705","https://www.semanticscholar.org/paper/b6035d63a6c26faca2be4f6f4a040bb95ce11705",3,"CUP: Critic-Guided Policy Reuse","A novel policy reuse algorithm called Critic-gUided Policy reuse (CUP), which avoids training any extra components and efﬁciently reuses source policies and outperforms baseline algorithms.","ArXiv",2022,"Jin Zhang,Siyuan Li,Chongjie Zhang",0,39,0
"203a1c0e5025489a52c030adbbc102a787685ee6","https://www.semanticscholar.org/paper/203a1c0e5025489a52c030adbbc102a787685ee6",3,"Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity","An insight into the mechanisms through which reward shaping can signiﬁcantly improve the complexity of reinforcement learning while retaining asymptotic performance is provided.","ArXiv",2022,"Abhishek Gupta,Aldo Pacchiano,Yuexiang Zhai,S. Kakade,S. Levine",3,52,1
"11aead34bac158d61eff1e78f23350f3e7ffb461","https://www.semanticscholar.org/paper/11aead34bac158d61eff1e78f23350f3e7ffb461",3,"Evaluation of Neural Network Verification Methods for Air-to-Air Collision Avoidance","A new closed loop extension of this benchmark, which consists of a set of ten closed loop properties selected to evaluate the safety of an ownship aircraft in the presence of a co-altitude intruder aircraft, is proposed.","Journal of Air Transportation",2022,"Diego Manzanas Lopez,Taylor T. Johnson,Stanley Bak,Hoang-Dung Tran,Kerianne L. Hobbs",0,51,0
"cd4bb728ba816c8e3721c5f45e784399db2eb699","https://www.semanticscholar.org/paper/cd4bb728ba816c8e3721c5f45e784399db2eb699",3,"Adversarial Policies Beat Superhuman Go AIs","This work attacks the state-of-the-art Go-playing AI system, Kata go, by training adversarial policies that play against frozen KataGo victims, demonstrating that even superhuman AI systems may harbor surprising failure modes.","",2022,"Tony Tong Wang,A. Gleave,Nora Belrose,Tom Tseng,Joseph Miller,Kellin Pelrine,Michael Dennis,Yawen Duan,V. Pogrebniak,S. Levine,Stuart Russell",1,50,1
"96fa28ba8b6282f443eda96a24a709bdadcabd7e","https://www.semanticscholar.org/paper/96fa28ba8b6282f443eda96a24a709bdadcabd7e",3,"Complex relationship graph abstraction for autonomous air combat collaboration: A learning and expert knowledge hybrid approach","","Expert systems with applications",2022,"Haiyin Piao,Yue Han,Hechang Chen,Xuanqi Peng,Songyuan Fan,Yang Sun,Chen Liang,Zhimin Liu,Zhixiao Sun,Deyun Zhou",0,26,0
"080f2ef96cf82a379c5db91ed270cb37d7f82bcf","https://www.semanticscholar.org/paper/080f2ef96cf82a379c5db91ed270cb37d7f82bcf",3,"Scalable Multi-Agent Reinforcement Learning through Intelligent Information Aggregation","InforMARL is proposed, a novel architecture for multi-agent reinforcement learning (MARL) which uses local information intelligently to compute paths for all the agents in a decentralized manner and can be used in conjunction with any standard MARL algorithm.","ArXiv",2022,"Siddharth Nayak,Kenneth M. F. Choi,Wenqi Ding,Sydney I. Dolan,Karthik Gopalakrishnan,H. Balakrishnan",2,63,0
"83caa4b447b816526587927e2b15a9c260dd2398","https://www.semanticscholar.org/paper/83caa4b447b816526587927e2b15a9c260dd2398",3,"Achieving mouse-level strategic evasion performance using real-time computational planning","This algorithm allows us to achieve mouse- level predator evasion performance with orders of magnitude less computation than a widespread algorithm for planning in the situations of partial observability that typify predator-prey interactions.","ArXiv",2022,"German Espinosa,Gabrielle E. Wink,Alexander T. Lai,D. Dombeck,M. A. MacIver",0,34,0
"db0a787b6c42b993d7fec9f27408b2a85db1ccaf","https://www.semanticscholar.org/paper/db0a787b6c42b993d7fec9f27408b2a85db1ccaf",3,"Wasserstein gradient flows policy optimization via input convex neural networks","A large-scale Wasserstein gradient flow RL method is got by introducing input convex neural networks (ICNNs) to improve the Jordan-Kinderlehrer-otto (JKO) scheme.","Other Conferences",2022,"Yixuan Wang",0,26,0
"ebdbdfdc68a7dc0581154e951920327167700c98","https://www.semanticscholar.org/paper/ebdbdfdc68a7dc0581154e951920327167700c98",3,"Agent-State Construction with Auxiliary Inputs","This work presents a series of ex-amples illustrating the diﬀerent ways of using auxiliary inputs for reinforcement learning, and shows that these auxiliary inputs can be used to discriminate between observations that would otherwise be aliased, leading to more expressive features that smoothly interpolate between dif-ferent states.","ArXiv",2022,"Ruo Yu Tao,Adam White,Marlos C. Machado",0,37,0
"37b7c079efcf5f4d77b0957c3d72c198d785e138","https://www.semanticscholar.org/paper/37b7c079efcf5f4d77b0957c3d72c198d785e138",3,"Value-based CTDE Methods in Symmetric Two-team Markov Game: from Cooperation to Team Competition","The results suggest that training against multiple evolving strategies achieves the best results when, for scoring their performances, teams are faced with several strategies.","ArXiv",2022,"Pascal Leroy,J. Pisane,D. Ernst",0,44,0
"627785cd6b768feda87d3f43e457c1824e3d9a8c","https://www.semanticscholar.org/paper/627785cd6b768feda87d3f43e457c1824e3d9a8c",3,"The Impact of Batch Deep Reinforcement Learning on Student Performance: A Simple Act of Explanation Can Go A Long Way","","International Journal of Artificial Intelligence in Education",2022,"Markel Sanz Ausin,Mehak Maniktala,T. Barnes,Min Chi",0,28,0
"ed7801b29273ec3208fcbddd04a712cd80e86cb6","https://www.semanticscholar.org/paper/ed7801b29273ec3208fcbddd04a712cd80e86cb6",3,"Automatic Discovery of Multi-perspective Process Model using Reinforcement Learning","An automatic discovery framework of a multi-perspective process model based on deep Q-Learning that can automatically perform process model discovery steps, conformance check steps, and enhancements steps and a new method that further optimizes the experience replay (ER) method to improve the learning performance of reinforcement learning agents.","ArXiv",2022,"Sunghyun Sim,Ling Liu,Hyerim Bae",0,39,0
"87361e44f253a3044b02b947c0a2370ff4f1e3e7","https://www.semanticscholar.org/paper/87361e44f253a3044b02b947c0a2370ff4f1e3e7",3,"Towards Improving Exploration in Self-Imitation Learning using Intrinsic Motivation","In this work intrinsic motivation is used to encourage the agent to explore the environment based on its curiosity, whereas imitation learning allows repeating the most promising experiences to accelerate the learning process.","IEEE Symposium Series on Computational Intelligence",2022,"Alain Andres,Esther Villar-Rodriguez,J. Ser",0,37,0
"a905c861cae2b128ac4dc24614714987cbcab130","https://www.semanticscholar.org/paper/a905c861cae2b128ac4dc24614714987cbcab130",3,"DeepRepair: Style-Guided Repairing for Deep Neural Networks in the Real-World Operational Environment","A style-guided data augmentation for repairing DNN in the operational environment is proposed, which learns and introduces the unknown failure patterns within the failure samples into the training data via the style transfer.","IEEE Transactions on Reliability",2022,"Bing Yu,Hua Qi,Guo Qing,Felix Juefei-Xu,Xiaofei Xie,L. Ma,Jianjun Zhao",10,106,0
"0102c2b64cedd427ac003df1a22daa097f94567e","https://www.semanticscholar.org/paper/0102c2b64cedd427ac003df1a22daa097f94567e",3,"Negotiation and honesty in artificial intelligence methods for the board game of Diplomacy","","Nature Communications",2022,"János Kramár,Tom Eccles,I. Gemp,A. Tacchetti,Kevin R. McKee,Mateusz Malinowski,T. Graepel,Yoram Bachrach",1,66,0
"0a0399f30ae2b2c9b27de5fbdd180a3374b70c37","https://www.semanticscholar.org/paper/0a0399f30ae2b2c9b27de5fbdd180a3374b70c37",3,"Towards New Generation, Biologically Plausible Deep Neural Network Learning","A biologically plausible learning method that takes advantage of various biological processes, such as Hebbian synaptic plasticity, and includes both supervised and unsupervised elements is described and its lesser resilience to additive, zero mean Gaussian noise is found.","The Scientist",2022,"Anirudh Apparaju,Ognjen Arandjelovíc",0,27,0
"eea6b8c0d500df2a8fce7f23d5c6988de6b9749d","https://www.semanticscholar.org/paper/eea6b8c0d500df2a8fce7f23d5c6988de6b9749d",3,"A Hierarchical Deep Reinforcement Learning Framework for 6-DOF UCAV Air-to-Air Combat","A general hierarchical framework to resolve the within-vision-range (WVR) air-to-air combat problem under 6 dimensions of degree (6-DOF) dynamics is proposed and an effective reward function is designed to accurately track various macro behavior.","ArXiv",2022,"Jiajun Chai,Wenzhang Chen,Yuanheng Zhu,Zonggui Yao,Dongbin Zhao",0,43,0
"b65118061650446bdd79087def417e6a4de7ecdf","https://www.semanticscholar.org/paper/b65118061650446bdd79087def417e6a4de7ecdf",3,"PrefRec: Preference-based Recommender Systems for Reinforcing Long-term User Engagement","This work proposes a novel paradigm, Pre ference-based Rec ommender systems (PrefRec), which allows RL recommender systems to learn from preferences about users’ historical behaviors rather than explicitly defined rewards, and designs an effective optimization method for PrefRec, which uses an additional value function, expectile regression and reward model pre-training to improve the performance.","ArXiv",2022,"Wanqi Xue,Qingpeng Cai,Zhenghai Xue,Shuo Sun,Shuchang Liu,Dong Zheng,Peng Jiang,Bo An",0,48,0
"4f248a4292976fd5451cc282226addfb369f5c82","https://www.semanticscholar.org/paper/4f248a4292976fd5451cc282226addfb369f5c82",3,"AI-Based Military Decision Support Using Natural Language","A combined approach where human knowledge and responsibility collaborate with an AI system is proposed where the orders and actions imposed by AI are given in natural language in order to validate and evaluate the reasoning of AI.","Online World Conference on Soft Computing in Industrial Applications",2022,"Michael Möbius,Daniel Kallfass,Thomas Doll,Dietmar Kunde",0,12,0
"b58ef62a34bdbcd357824c9e58d89cbbcc0e2375","https://www.semanticscholar.org/paper/b58ef62a34bdbcd357824c9e58d89cbbcc0e2375",3,"Evaluating Model-free Reinforcement Learning toward Safety-critical Tasks","This paper proposes Unrolling Safety Layer (USL), a joint method that combines safety optimization and safety pro- jection and explicitly enforces hard constraints via the deep unrolling architecture and enjoys struc- tural advantages in navigating the trade-off between reward improvement and constraint satisfaction.","ArXiv",2022,"Linrui Zhang,Q. Zhang,Li Shen,Bo Yuan,Xueqian Wang,Dacheng Tao",1,34,1
"cbe7ace2d80209f1bfb62af318cae24ff147cb52","https://www.semanticscholar.org/paper/cbe7ace2d80209f1bfb62af318cae24ff147cb52",3,"An Adaptive Updating Method of Target Network Based on Moment Estimates for Deep Reinforcement Learning","","Neural Processing Letters",2022,"Miaoping Sun,Zequan Yang,Xunhua Dai,X. Nian,Hongyun Xiong,Haibo Wang",0,17,0
"5c41258c2e90372e363f6bb3519b27a76b66ab48","https://www.semanticscholar.org/paper/5c41258c2e90372e363f6bb3519b27a76b66ab48",3,"A Data-Efficient Training Method for Deep Reinforcement Learning","A data-efficient training method is proposed in which a DQN is used as a base algorithm, and an elaborate curriculum is designed for the agent in the simulation scenario to accelerate the training process.","Electronics",2022,"Wenhui Feng,Chongzhao Han,Feng Lian,Xia Liu",0,19,0
"9fd98c158005a3770b6c378f7b97b754937b5d54","https://www.semanticscholar.org/paper/9fd98c158005a3770b6c378f7b97b754937b5d54",3,"Investigation of reinforcement learning for shape optimization of profile extrusion dies","This work investigates the impact of utilizingerent agents on the training progress and the potential of wall time saving by utilizing multiple environments during training and the utilization of Reinforcement Learning as a learning-based optimization algorithm.","ArXiv",2022,"C. Fricke,D. Wolff,Marco Kemmerling,S. Elgeti",0,43,0
"ab8674f284e7ce8fe08433003b7d641bcb9f88f5","https://www.semanticscholar.org/paper/ab8674f284e7ce8fe08433003b7d641bcb9f88f5",3,"Certificates of quantum many-body properties assisted by machine learning","This work proposes a novel approach combining the power of relaxation techniques with deep reinforcement learning in order to find the best possible bounds within a limited computational budget, and provides tools to generalize the approach to other common applications in the field of quantum information processing.","Physical Review Research",2021,"Borja Requena,G. Muñoz-Gil,M. Lewenstein,V. Dunjko,Jordi Tura i Brugués",2,120,0
"85750b05dc461645d756ff4839475e0ae319449b","https://www.semanticscholar.org/paper/85750b05dc461645d756ff4839475e0ae319449b",3,"Machine and quantum learning for diamond-based quantum applications","","Materials for Quantum Technology",2022,"Dylan G. Stone,C. Bradac",0,150,0
"83434a8e9796fb78472358b8b4d4444db61d19db","https://www.semanticscholar.org/paper/83434a8e9796fb78472358b8b4d4444db61d19db",3,"Artificial Intelligence and Machine Learning for Quantum Technologies","This perspective article showcases in illustrative examples how scientists in the past few years have started to use machine learning and more broadly methods of artiﬁcial intelligence to analyze quantum measurements, estimate the parameters of quantum devices, discover new quantum experimental setups, protocols, and feedback strategies, and generally improve aspects of quantum computing, quantum communication, and quantum simulation.","Physical Review A",2022,"M. Krenn,Jonas Landgraf,T. Foesel,F. Marquardt",4,154,0
"aa6fbabb6c4fe2058615462243a89fe40568e262","https://www.semanticscholar.org/paper/aa6fbabb6c4fe2058615462243a89fe40568e262",3,"Scalable Planning and Learning Framework Development for Swarm-to-Swarm Engagement Problems","This work proposes a reinforcement learning (RL) based framework to decompose to large-scale swarm engagement problems into a number of independent multi-agent pursuit-evasion games and verifies the approach in large- scale swarm-to-swarm engagement simulations.","AIAA SCITECH 2023 Forum",2022,"Umut Demir,A. Satir,Gulay Goktas Sever,Cansu Yikilmaz,N. K. Ure",0,25,0
"f2b2981f7d9439d734acbd0edbd8ad6e7af77a2b","https://www.semanticscholar.org/paper/f2b2981f7d9439d734acbd0edbd8ad6e7af77a2b",3,"Mystique: Accurate and Scalable Production AI Benchmarks Generation","Mystique is an accurate and scalable framework for production AI benchmark generation that leverages the PyTorch execution graph (EG), a new feature that captures the runtime information of AI models at the granularity of operators, in a graph format, together with their metadata.","ArXiv",2022,"Mingyu Liang,Wenyin Fu,Louis Feng,Zhongyi Lin,P. Panakanti,Srinivas Sridharan,Christina Delimitrou",0,42,0
"8a03a51b01eddf21bbe2a0a71ec8186c6e65ace1","https://www.semanticscholar.org/paper/8a03a51b01eddf21bbe2a0a71ec8186c6e65ace1",3,"MERLIN: Multi-agent offline and transfer learning for occupant-centric energy flexible operation of grid-interactive communities using smart meter data and CityLearn","","ArXiv",2022,"K. Nweye,S. Sankaranarayanan,Z. Nagy",0,53,0
"1cceaba216f0392e11269883e5cbd24b1ef732d7","https://www.semanticscholar.org/paper/1cceaba216f0392e11269883e5cbd24b1ef732d7",3,"Robust Lane Change Decision Making for Autonomous Vehicles: An Observation Adversarial Reinforcement Learning Approach","The proposed observation adversarial reinforcement learning approach for robust lane change decision making of autonomous vehicles can not only enhance the performance of an autonomous vehicle but also improve the robustness of lane change policies against adversarial observation perturbations.","IEEE Transactions on Intelligent Vehicles",2023,"Xiangkun He,Haohan Yang,Zhongxu Hu,Chen Lv",11,38,0
"b7823997fb185f208b6a6723b60413ff179d2639","https://www.semanticscholar.org/paper/b7823997fb185f208b6a6723b60413ff179d2639",3,"Standing on the Shoulders of AI Giants","","Computer",2023,"Hsiao-Ying Lin",0,12,0
"49adfa7a7031446f8b58a913f1c777b9819ba922","https://www.semanticscholar.org/paper/49adfa7a7031446f8b58a913f1c777b9819ba922",3,"Achieving efficient interpretability of reinforcement learning via policy distillation and selective input gradient regularization.","This work proposes an approach of Distillation with selective Input Gradient Regularization (DIGR) which uses policy distillation and input gradient regularization to produce new policies that achieve both high interpretability and computation efficiency in generating saliency maps.","Neural Networks",2023,"Jinwei Xing,Takashi Nagata,Xinyun Zou,E. Neftci,J. Krichmar",0,36,0
"cf3bd470c716ddca24f0a26b85b4bdccd5bc2797","https://www.semanticscholar.org/paper/cf3bd470c716ddca24f0a26b85b4bdccd5bc2797",3,"Deep reinforcement learning empowers automated inverse design and optimization of photonic crystals for nanoscale laser cavities","L2DO can achieve over two orders of magnitude higher sample-efficiency without suffering from the three issues above and confirms the potential of deep RL algorithms to surpass human designs and marks a solid step towards a fully automated AI framework for photonics inverse design.","Nanophotonics",2023,"Renjie Li,Ceyao Zhang,Wentao Xie,Yuanhao Gong,Feilong Ding,Hui Dai,Zihan Chen,F. Yin,Zhaoyu Zhang",0,44,0
"72fdfb106c47e27e0ccd42760dd67af720dc255f","https://www.semanticscholar.org/paper/72fdfb106c47e27e0ccd42760dd67af720dc255f",3,"Learning to Participate through Trading of Reward Shares","This paper proposes a method inspired by the stock market, where agents have the opportunity to participate in other agents’ returns by acquiring reward shares, and shows that this mechanism promotes cooperative policies among independently trained agents in social dilemma situations.","ArXiv",2023,"M. Kölle,Tim Matheis,Philipp Altmann,Kyrill Schmid",0,25,0
"cb0912e8d780b7b5e8651df0baaa20b56f4fd6ff","https://www.semanticscholar.org/paper/cb0912e8d780b7b5e8651df0baaa20b56f4fd6ff",3,"Single-Trajectory Distributionally Robust Reinforcement Learning","This work proposes distributionally robust Q-learning with single trajectory (DRQ) , and its average-reward variant named differential DRQ, and provides asymptotic convergence guarantees and experiments for both settings, demonstrating their superiority in the perturbed environments against the non-robust ones.","ArXiv",2023,"Zhipeng Liang,Xiaoteng Ma,J. Blanchet,Jiheng Zhang,Zhengyuan Zhou",0,46,0
"b05345d5b1593f383c544ac77c079ab2641ec542","https://www.semanticscholar.org/paper/b05345d5b1593f383c544ac77c079ab2641ec542",3,"Turbulence control in plane Couette flow using low-dimensional neural ODE-based models and deep reinforcement learning","This work obtains a 25-dimensional DManD model of the dynamics by combining an autoencoder and neural ordinary diﬀerential equation, and trains an RL control agent, yielding a 440-fold speedup over training on the DNS, with equivalent control performance.","ArXiv",2023,"Alec J. Linot,Kevin Zeng,M. Graham",0,65,0
"8dbd7e096e0338b7470acab318786a6756ece6f7","https://www.semanticscholar.org/paper/8dbd7e096e0338b7470acab318786a6756ece6f7",3,"Intelligent Decision-Making and Human Language Communication Based on Deep Reinforcement Learning in a Wargame Environment","This article creatively incorporates deep learning and natural language processing technologies in the warg game field to transform game context situation maps into textual suggestions in wargame confrontation.","IEEE Transactions on Human-Machine Systems",2023,"Yuxiang Sun,Bo Yuan,Qinlin Xiang,Jiawei Zhou,Jiahui Yu,Di Dai,Xianzhong Zhou",0,32,0
"086a7c3cbd9992923f626efda1f412f8694f33a8","https://www.semanticscholar.org/paper/086a7c3cbd9992923f626efda1f412f8694f33a8",3,"DCM: Deep complementary energy method based on the principle of minimum complementary energy","The result shows the advantage of the proposed DCM is suitable for dealing with problems of dominated displacement boundary conditions, which is proved by mathematical derivations, as well as with numerical experiments.","ArXiv",2023,"Yizheng Wang,Jia Sun,Zaiyuan Lu,Pipi Hu,Yinghua Liu",0,62,0
"45f32b26dc754ed293ac1add3b233f5ad6822518","https://www.semanticscholar.org/paper/45f32b26dc754ed293ac1add3b233f5ad6822518",3,"Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation","An iterative-best-response type algorithm that can learn pure Markov Nash equilibria in independent linear Markov potential games and an algorithm with $\widetilde$ sample complexity to learn Markov CCE, which improves the state-of-the-art result in Daskalakis et al. 2022.","ArXiv",2023,"Qiwen Cui,K. Zhang,S. Du",0,73,0
"6e1b7a851ecdff764b066bcc28d6130779eb098e","https://www.semanticscholar.org/paper/6e1b7a851ecdff764b066bcc28d6130779eb098e",3,"TiZero: Mastering Multi-Agent Football with Curriculum Learning and Self-Play","This paper develops a multi-agent system to play the full 11 vs. 11 game mode, without demonstrations, and introduces several innovations, including adaptive curriculum learning, a novel self-play strategy, and an objective that optimizes the policies of multiple agents jointly.","",2023,"Fanqing Lin,Shiyu Huang,Tim Pearce,Wenze Chen,Weijuan Tu",0,47,0
"b832551eca18725cfd982aaece5711878099824b","https://www.semanticscholar.org/paper/b832551eca18725cfd982aaece5711878099824b",3,"GAIL-PT: An intelligent penetration testing framework with generative adversarial imitation learning","","Computers &amp; Security",2023,"Jinyin Chen,Shulong Hu,Haibin Zheng,Changyou Xing,Guomin Zhang",0,37,0
"410e793147cc3787a135b9e8c2a3250d8e2a2f66","https://www.semanticscholar.org/paper/410e793147cc3787a135b9e8c2a3250d8e2a2f66",3,"Modeling collective motion for fish schooling via multi-agent reinforcement learning","","Ecological Modelling",2023,"X. Wang,Shuo Liu,Yifan Yu,Shengzhi Yue,Yingru Liu,Fumin Zhang,Yuanshan Lin",0,41,0
"9125b3f152d792257a51745e7af6d191d05b54a0","https://www.semanticscholar.org/paper/9125b3f152d792257a51745e7af6d191d05b54a0",3,"Interactive Learning with Corrective Feedback for Policies based on Deep Neural Networks","This work approaches an alternative Interactive Machine Learning strategy for training DNN policies based on human corrective feedback, with a method called Deep COACH (D-COACH), which takes advantage of the knowledge and insights of human teachers as well as the power of DNNs, but also has no need of a reward function.","International Symposium on Experimental Robotics",2018,"Rodrigo Pérez-Dattari,C. Celemin,Javier Ruiz-del-Solar,J. Kober",12,14,1
"4b61c25a86083c20730c9b12737ac6ac4178c364","https://www.semanticscholar.org/paper/4b61c25a86083c20730c9b12737ac6ac4178c364",3,"An Introduction to Deep Reinforcement Learning","This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques and particular focus is on the aspects related to generalization and how deep RL can be used for practical applications.","Found. Trends Mach. Learn.",2018,"Vincent François-Lavet,Peter Henderson,Riashat Islam,Marc G. Bellemare,Joelle Pineau",679,355,42
"f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751","https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751",3,"Deep Reinforcement Learning","This work discusses deep reinforcement learning in an overview style, focusing on contemporary work, and in historical contexts, with background of artificial intelligence, machine learning, deep learning, and reinforcement learning (RL), with resources.","Reinforcement Learning for Cyber-Physical Systems",2018,"Yuxi Li",297,890,19
"156a84996911a2116bdddd89aade6921e3e68d22","https://www.semanticscholar.org/paper/156a84996911a2116bdddd89aade6921e3e68d22",3,"Model-Free Reinforcement Learning for Real-World Robots","This thesis considers real-world tasks that may benefit from Reinforcement Learning, and for which there is no simulator available, and introduces the model-free actor-critic Bootstrapped Dual Policy Iteration algorithm (BDPI), a formalism that allows an agent to learn partially-observable tasks in a sample-efficient way.","",2020,"Denis Steckelmacher",0,200,0
"40848b41ed8c9c255ecd8a920006877691b52d03","https://www.semanticscholar.org/paper/40848b41ed8c9c255ecd8a920006877691b52d03",3,"WILDS: A Benchmark of in-the-Wild Distribution Shifts","WILDS is presented, a benchmark of in-the-wild distribution shifts spanning diverse data modalities and applications, and is hoped to encourage the development of general-purpose methods that are anchored to real-world distribution shifts and that work well across different applications and problem settings.","International Conference on Machine Learning",2020,"P. W. Koh,Shiori Sagawa,H. Marklund,Sang Michael Xie,Marvin Zhang,Akshay Balsubramani,Weihua Hu,Michihiro Yasunaga,Richard L. Phillips,Sara Beery,J. Leskovec,A. Kundaje,E. Pierson,S. Levine,Chelsea Finn,Percy Liang",496,424,87
"266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2","https://www.semanticscholar.org/paper/266cc7ff4856b6a2ce9cc0a3e5f6c155ecc448a2",3,"Can Wikipedia Help Offline Reinforcement Learning?","This work looks to take advantage of this formulation of reinforcement learning as sequence modeling and investigate the transferability of pre-trained sequence models on other domains when ﬁnetuned on ofﬂine RL tasks (control, games), and proposes techniques to improve transfer between these domains.","ArXiv",2022,"Machel Reid,Yutaro Yamada,S. Gu",42,67,8
"0bda4b0246e2ad07e83da9fd904b92bc8fe831d9","https://www.semanticscholar.org/paper/0bda4b0246e2ad07e83da9fd904b92bc8fe831d9",3,"Structured Output Feedback Control for Linear Quadratic Regulator Using Policy Gradient Method","To solve the static output feedback control for Linear Quadratic Regulator problems with structured constraints under the assumption that system parameters are un- known, the policy gradient algorithm based on the gradient projection method is proposed and its global convergence to ε -stationary points is shown.","",2022,"Shokichi Takakura,Kazuhiro Sato",1,36,0
"30d51a26086a6632d2ed0edd882054b46e8519a9","https://www.semanticscholar.org/paper/30d51a26086a6632d2ed0edd882054b46e8519a9",3,"Automating reinforcement learning architecture design for code optimization","SuperSonic is a new open-source framework to allow compiler developers to integrate RL into compilers easily, regardless of their RL expertise, and shows that SuperSonic consistently improves hand-tuned methods by delivering better overall performance.","International Conference on Compiler Construction",2022,"Huanting Wang,Zhanyong Tang,Chen Zhang,Jiaqi Zhao,Chris Cummins,H. Leather,Z. Wang",4,89,0
"651468a69da74dab716cebbd179a5cbb8e672c14","https://www.semanticscholar.org/paper/651468a69da74dab716cebbd179a5cbb8e672c14",3,"Self-Imitation Learning from Demonstrations","Self-Imitation Learning (SIL), a recent RL algorithm that exploits agent’s past good experience, is extended to the LfD setup by initializing its replay buffer with demonstrations and shows the superiority of SIL over existing L fD algorithms in settings of suboptimal demonstrations and sparse rewards.","ArXiv",2022,"Georgiy Pshikhachev,Dmitry Ivanov,Vladimir Egorov,A. Shpilman",4,55,2
"0b3ca2a700085a877c560e20558566536f18d5a2","https://www.semanticscholar.org/paper/0b3ca2a700085a877c560e20558566536f18d5a2",3,"Modular Lifelong Reinforcement Learning via Neural Composition","This work explores a particular form of composition based on neural modules and presents a set of RL problems that intuitively admit compositional solutions and demonstrates that neural composition indeed captures the underlying structure of this space of problems.","International Conference on Learning Representations",2022,"Jorge Armando Mendez Mendez,H. V. Seijen,Eric Eaton",7,55,1
"96cd3bf5094e26ba6c367c8486d57fb21e570770","https://www.semanticscholar.org/paper/96cd3bf5094e26ba6c367c8486d57fb21e570770",3,"Efficiently Detecting Non-Stationary Opponents: A Bayesian Policy Reuse Approach under Partial Observability","It is demonstrated that Bayes-Lab outperforms existing state-of-the-art methods in terms of detection accuracy, accumulative rewards, and episodic rewards in a predator–prey scenario.","Applied Sciences",2022,"Yu Wang,Ke Fu,Hao Chen,Quan Liu,Jian Huang,Zhongjie Zhang",0,54,0
"649e713a760143f49c20ed4019fbf5434f89b596","https://www.semanticscholar.org/paper/649e713a760143f49c20ed4019fbf5434f89b596",3,"Safety-informed mutations for evolutionary deep reinforcement learning","","GECCO Companion",2022,"Enrico Marchesini,Chris Amato",2,39,0
"95aa4c864c05bcb942fa7fab4611b43ebad30c3a","https://www.semanticscholar.org/paper/95aa4c864c05bcb942fa7fab4611b43ebad30c3a",3,"Learning to Utilize Curiosity: A New Approach of Automatic Curriculum Learning for Deep RL","The CMCL algorithm is compared with other baseline algorithms in cooperative-competitive environments, and the experimental simulation results show that the CMCL method can improve the training performance and robustness of multi-agent deep reinforcement learning algorithms.","Mathematics",2022,"Zeyang Lin,Jun Lai,Xi-liang Chen,Lei Cao,Jun Wang",1,25,0
"ab94fcda889acf9a0f3fd4901723ac11e9587c3a","https://www.semanticscholar.org/paper/ab94fcda889acf9a0f3fd4901723ac11e9587c3a",3,"Decentralized Coordination in Partially Observable Queueing Networks","This work implemented a communication channel for agents to share their information in order to reduce the packet drop rate in a discrete-time queueing network and shows empirically that ATVC is able to infer the true state of the queues and leads to a policy which outperforms existing baselines.","Global Communications Conference",2022,"Jiekai Jia,Anam Tahir,H. Koeppl",0,35,0
"a5398f5186bf45be39dbeb25d3635d7e10ac3831","https://www.semanticscholar.org/paper/a5398f5186bf45be39dbeb25d3635d7e10ac3831",3,"Longitudinal deep truck: Deep longitudinal model with application to sim2real deep reinforcement learning for heavy‐duty truck control in the field","A two‐layer gray‐box deep learning model is developed to capture longitudinal dynamics of heavy‐duty trucks while abstracting their complexity and an approach to properly break the nested feedback loops in the model for training is presented.","Journal of Field Robotics",2022,"Saleh Albeaik,Trevor Wu,Ganesh Vurimi,Fang-Chieh Chou,Xiao-Yun Lu,A. Bayen",0,49,0
"85dea9ee99e7d11bee0c82c857ab355e36638c13","https://www.semanticscholar.org/paper/85dea9ee99e7d11bee0c82c857ab355e36638c13",3,"Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in Hex","This work investigates AlphaZero’s internal representations in the game of Hex using two evaluation techniques from natural language processing (NLP): model probing and behavioral tests, and finds that MCTS discovers concepts before the neural network learns to encode them.","ArXiv",2022,"Charles Lovering,J. Forde,G. Konidaris,Elizabeth-Jane Pavlick,M. Littman",0,83,0
"fdb655f285562ff144ad8eff27c30e332d626ee7","https://www.semanticscholar.org/paper/fdb655f285562ff144ad8eff27c30e332d626ee7",3,"RL-Recruiter+: Mobility-Predictability-Aware Participant Selection Learning for From-Scratch Mobile Crowdsensing","A novel framework based on reinforcement learning, named RL-Recruiter+, which is able to make a good sequence of participant selection decisions for each sensing slot with the gradual accumulation of mobility trajectories over time, and outperforms the baseline approaches under various settings.","IEEE Transactions on Mobile Computing",2022,"Yunfan Hu,Jiangtao Wang,Bo Wu,S. Helal",2,52,0
"193c40c22c2a727a0fcc11486c42b61285e92ee3","https://www.semanticscholar.org/paper/193c40c22c2a727a0fcc11486c42b61285e92ee3",3,"A review on reinforcement learning for contact-rich robotic manipulation tasks","","Robotics and Computer-Integrated Manufacturing",2023,"Íñigo Elguea-Aguinaco,Antonio Serrano-Muñoz,D. Chrysostomou,Ibai Inziarte-Hidalgo,S. Bøgh,N. Arana-Arexolaleiba",1,152,0
"5e78af2f7da1228d650c35105fec76ef4ef9dcc9","https://www.semanticscholar.org/paper/5e78af2f7da1228d650c35105fec76ef4ef9dcc9",3,"Intelligent Computing: The Latest Advances, Challenges and Future","The first comprehensive survey of literature on intelligent computing is presented, covering its theory fundamentals, the technological fusion of intelligence and computing, important applications, challenges, and future perspectives, which will provide a comprehensive reference and cast valuable insights into intelligent computing for academic and industrial researchers and practitioners.","Intelligent Computing",2022,"Shiqiang Zhu,Ting Yu,Tao Xu,Hongyang Chen,S. Dustdar,S. Gigan,D. Gunduz,E. Hossain,Yaochu Jin,Feng Lin,Bo Liu,Zhiguo Wan,Ji Zhang,Zhifeng Zhao,Wentao Zhu,Zuoning Chen,T. Durrani,Huaimin Wang,Jiangxing Wu,Tongyi Zhang,Yunhe Pan",1,358,0
"5312086d943766689b4ff52760878828c7ce2f9b","https://www.semanticscholar.org/paper/5312086d943766689b4ff52760878828c7ce2f9b",3,"GrAVITree: Graph-based Approximate Value Function In a Tree","GrAVITree is introduced, a tree- and sampling-based algorithm to compute a near-optimal value function and corresponding feedback policy for indeﬁnite time- horizon, terminal state-constrained nonlinear optimal control problems, suitable for arbitrary nonlinear control systems with both state and input constraints.","ArXiv",2023,"Patrick H. Washington,David Fridovich-Keil,M. Schwager",0,38,0
"4a5255dbdaba6d36dca55289f2ab299e78cab09e","https://www.semanticscholar.org/paper/4a5255dbdaba6d36dca55289f2ab299e78cab09e",3,"How to train a self-driving vehicle: On the added value (or lack thereof) of curriculum learning and replay buffers","The main results show that curriculum learning indeed offers an additional benefit over a vanilla reinforcement learning approach (using Deep-Q Learning), but the replay buffer actually has a detrimental effect in most (but not all) combinations of data generation approaches the authors considered here.","Frontiers in Artificial Intelligence",2023,"S. Mahmoud,E. Billing,Henrik Svensson,Serge Thill",0,49,0
"017844bd5429a27c46b434903dc0e60ebf215f90","https://www.semanticscholar.org/paper/017844bd5429a27c46b434903dc0e60ebf215f90",3,"Visual Imitation Learning with Patch Rewards","This work proposes Adversarial Imitation Learning with Patch Rewards (PatchAIL), which employs a patch-based discriminator to measure the expertise of different local parts from given images and provide patch rewards.","ArXiv",2023,"Minghuan Liu,Tairan He,Weinan Zhang,Shuicheng Yan,Zhongwen Xu",0,45,0
"d0d7c8fe3452c16218b6989015467f345eca8790","https://www.semanticscholar.org/paper/d0d7c8fe3452c16218b6989015467f345eca8790",3,"Offline Learning of Closed-Loop Deep Brain Stimulation Controllers for Parkinson Disease Treatment","An offline reinforcement learning framework is introduced, allowing the use of past clinical data to train an RL policy to adjust the stimulation amplitude in real time, with the goal of reducing energy use while maintaining the same level of treatment (i.e., control) efficacy as cDBS.","ArXiv",2023,"Qitong Gao,Stephen L. Schimdt,Afsana Chowdhury,Guangyu Feng,Jennifer J. Peters,Katherine Genty,W. Grill,Dennis A. Turner,M. Pajic",0,65,0
"7346e08cb0e22a3b3c34aeff594d6c82595b1eb0","https://www.semanticscholar.org/paper/7346e08cb0e22a3b3c34aeff594d6c82595b1eb0",3,"Sequence generation for multi-task scheduling in cloud manufacturing with deep reinforcement learning","","Journal of manufacturing systems",2023,"Yaoyao Ping,Yongkui Liu,Lin Zhang,Lihui Wang,Xun Xu",0,56,0
"320959db43db08185cfbabe655e044c2a378ed39","https://www.semanticscholar.org/paper/320959db43db08185cfbabe655e044c2a378ed39",3,"Virtual to Real-World Transfer Learning: A Systematic Review","This systematic review defines (a) transfer learning; (b) discusses the recent research conducted; (c) the current status of transfer learning and finally, (d) discusses how transfer learning can bridge the gap between the virtual and the real.","Electronics",2021,"Mahesh Ranaweera,Q. Mahmoud",7,78,0
"3032844d6ac6882ccb03e7a2c22a0026b210ac05","https://www.semanticscholar.org/paper/3032844d6ac6882ccb03e7a2c22a0026b210ac05",3,"What Matters in Learning from Offline Human Demonstrations for Robot Manipulation","This study analyzes the most critical challenges when learning from offline human data for manipulation and highlights opportunities for learning from human datasets, such as the ability to learn proficient policies on challenging, multi-stage tasks beyond the scope of current reinforcement learning methods.","Conference on Robot Learning",2021,"Ajay Mandlekar,Danfei Xu,J. Wong,Soroush Nasiriany,Chen Wang,Rohun Kulkarni,Li Fei-Fei,S. Savarese,Yuke Zhu,Roberto Mart'in-Mart'in",78,90,16
"ca6096142016a2ba8133f6cb2c04ad30f5eae730","https://www.semanticscholar.org/paper/ca6096142016a2ba8133f6cb2c04ad30f5eae730",3,"Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning","A training set-up that achieves fast policy generation for real-world robotic tasks by using massive parallelism on a single workstation GPU is presented and a novel game-inspired curriculum that is well suited for training with thousands of simulated robots in parallel is presented.","ArXiv",2021,"N. Rudin,David Hoeller,Philipp Reist,M. Hutter",99,32,16
"41e43d9c766128cdd715c64fbd30e0c9fdf14652","https://www.semanticscholar.org/paper/41e43d9c766128cdd715c64fbd30e0c9fdf14652",3,"From Motor Control to Team Play in Simulated Humanoid Football","This work optimized teams of agents to play simulated football via reinforcement learning, constraining the solution space to that of plausible movements learned using human motion capture data, resulting in a team of coordinated humanoid football players that exhibit complex behavior at different scales, quantified by a range of analysis and statistics.","Sci. Robotics",2021,"Siqi Liu,Guy Lever,Zhe Wang,J. Merel,S. Eslami,Daniel Hennes,Wojciech M. Czarnecki,Yuval Tassa,Shayegan Omidshafiei,A. Abdolmaleki,Noah Siegel,Leonard Hasenclever,Luke Marris,S. Tunyasuvunakool,H. F. Song,Markus Wulfmeier,Paul Muller,Tuomas Haarnoja,Brendan D. Tracey,K. Tuyls,T. Graepel,N. Heess",38,165,2
"efbc2c6306ff1f3bfa282fc62f8467764fd41c25","https://www.semanticscholar.org/paper/efbc2c6306ff1f3bfa282fc62f8467764fd41c25",3,"Accelerated Policy Learning with Parallel Differentiable Simulation","A high-performance differentiable simulator and a new policy learning algorithm (SHAC) that can effectively leverage simulation gradients, even in the presence of non-smoothness are presented.","International Conference on Learning Representations",2022,"Jie Xu,Viktor Makoviychuk,Yashraj S. Narang,Fabio Ramos,W. Matusik,Animesh Garg,M. Macklin",12,56,2
"0c845688166c07cb095ed0dbd55da817f34a4cfb","https://www.semanticscholar.org/paper/0c845688166c07cb095ed0dbd55da817f34a4cfb",3,"Learning to guide multiple heterogeneous actors from a single human demonstration via automatic curriculum learning in StarCraft II","The results show that an agent trained via automated curriculum learning can outperform state-of- the-art deep reinforcement learning baselines and match the performance of the human expert in a simulated command and control task in StarCraft II modeled over a real military scenario.","Defense + Commercial Sensing",2022,"Nicholas R. Waytowich,J. Hare,Vinicius G. Goecks,Mark R. Mittrick,J. Richardson,Anjon Basak,Derrik E. Asher",0,21,0
"d30b069c54b06c7749b83fbdf050c17fdea374d9","https://www.semanticscholar.org/paper/d30b069c54b06c7749b83fbdf050c17fdea374d9",3,"AACC: Asymmetric Actor-Critic in Contextual Reinforcement Learning","This paper formalizes the task of adapting to changing environmental dynamics in RL as a generalization problem using Contextual Markov Decision Processes (CMDPs) and proposes the Asymmetric Actor-Critic in Contextual RL (AACC) as an end-to-end actor-critic method to deal with such generalization tasks.","ArXiv",2022,"Wangyang Yue,Yuan Zhou,Xiaochuan Zhang,Yuchen Hua,Zhiyuan Wang,Guang Kou",0,35,0
"8a7dbe1a807c948eb1b6496c22e12f8ba03c94ff","https://www.semanticscholar.org/paper/8a7dbe1a807c948eb1b6496c22e12f8ba03c94ff",3,"Robot Learning on the Job: Human-in-the-Loop Autonomy and Learning During Deployment","Sirius is presented, a principled framework for humans and robots to collaborate through a division of work where partially autonomous robots are tasked with handling a major portion of decision-making where they work reliably; meanwhile, human operators monitor the process and intervene in challenging situations.","ArXiv",2022,"Huihan Liu,Soroush Nasiriany,Lance Zhang,Zhiyao Bao,Yuke Zhu",0,63,0
"174bf19aa934e9ba2016a1837cfe667b13a05953","https://www.semanticscholar.org/paper/174bf19aa934e9ba2016a1837cfe667b13a05953",3,"Adaptive Actuation of Magnetic Soft Robots Using Deep Reinforcement Learning","The first case of using strategies entirely generated by reinforcement learning to control real MSRs is presented, which can be used to establish a route for the creation of highly adaptive design framework.","Advanced Intelligent Systems",2022,"Jianpeng Yao,Quanliang Cao,Yuwei Ju,Yuxuan Sun,Ruiqi Liu,Xiaotao Han,Liang Li",0,61,0
"8424082e3bf4792462eb112d7ebcecf5b0dc3613","https://www.semanticscholar.org/paper/8424082e3bf4792462eb112d7ebcecf5b0dc3613",3,"Reasoning with Transformer-based Models: Deep Learning, but Shallow Reasoning","This survey paper discusses the performance of transformers on different reasoning tasks, including mathematical reasoning, commonsense reasoning, and logical reasoning.","Conference on Automated Knowledge Base Construction",2021,"Chadi Helwe,C. Clavel,Fabian M. Suchanek",15,95,4
"21ec9c0f869bdb33b06c7dbc8880169db0397d08","https://www.semanticscholar.org/paper/21ec9c0f869bdb33b06c7dbc8880169db0397d08",3,"UNICORN on RAINBOW: A Universal Commonsense Reasoning Model on a New Multitask Benchmark","Two new ways to evaluate commonsense models are proposed, emphasizing their generality on new tasks and building on diverse, recently introduced benchmarks, and a novel evaluation, the cost equivalent curve, is proposed, that sheds new insight on how the choice of source datasets, pretrained language models, and transfer learning methods impacts performance and data efficiency.","AAAI Conference on Artificial Intelligence",2021,"Nicholas Lourie,Ronan Le Bras,Chandra Bhagavatula,Yejin Choi",64,77,14
"50a00638b8fb2037bf8d06ef7b1f52ae4299f8a1","https://www.semanticscholar.org/paper/50a00638b8fb2037bf8d06ef7b1f52ae4299f8a1",3,"Question Answering for the Curated Web: Tasks and Methods in QA over Knowledge Bases and Text Collections","","Synthesis Lectures on Information Concepts Retrieval and Services",2021,"Rishiraj Saha Roy,Avishek Anand",9,66,0
"04052cfab34af874498726209225216bb3b89d3d","https://www.semanticscholar.org/paper/04052cfab34af874498726209225216bb3b89d3d",3,"GENIE: Toward Reproducible and Standardized Human Evaluation for Text Generation","This work considers design choices for the annotation interface used to elicit human judgments and their impact on reproducibility, and develops an automated mechanism for maintaining annotator quality via a probabilistic model that detects and excludes noisy annotators.","Conference on Empirical Methods in Natural Language Processing",2021,"Daniel Khashabi,Gabriel Stanovsky,Jonathan Bragg,Nicholas Lourie,Jungo Kasai,Yejin Choi,Noah A. Smith,Daniel S. Weld",1,71,0
"9b4d73e7087e2ddc26f0eb3a6412436aa50e4c76","https://www.semanticscholar.org/paper/9b4d73e7087e2ddc26f0eb3a6412436aa50e4c76",3,"The Defeat of the Winograd Schema Challenge","The history of the Winograd Schema Challenge is reviewed, and a number of AI systems, based on large pre-trained transformer-based language models and fine-tuned on these kinds of problems, achieved better than 90% accuracy.","ArXiv",2022,"Vid Kocijan,E. Davis,Thomas Lukasiewicz,G. Marcus,L. Morgenstern",5,97,0
"5b44101b2372a33ec06e15ce4d20ad9a15518325","https://www.semanticscholar.org/paper/5b44101b2372a33ec06e15ce4d20ad9a15518325",3,"UnifiedQA-v2: Stronger Generalization via Broader Cross-Format Training","This work presents UNIFIEDQA-v2, a QA model built with the same process as UNifiedQA, except that it utilizes more supervision – roughly 3× the number of datasets used for UNIFIED QA.","ArXiv",2022,"Daniel Khashabi,Yeganeh Kordi,Hannaneh Hajishirzi",19,50,6
"79032fc08981bbb0ae9ae353f399f0df8bdd25ee","https://www.semanticscholar.org/paper/79032fc08981bbb0ae9ae353f399f0df8bdd25ee",3,"Near-Negative Distinction: Giving a Second Life to Human Evaluation Datasets","This paper proposes a new and simple automatic evaluation method for NLG called Near-Negative Distinction (NND) that repurposes prior human annotations into NND tests that can give a second life to human annotations and provide low-cost NLG evaluation.","Conference on Empirical Methods in Natural Language Processing",2022,"Philippe Laban,Chien-Sheng Wu,Wenhao Liu,Caiming Xiong",0,54,0
"1f1b01cb09e557e6a1e6b0292cb84a67839c2e1a","https://www.semanticscholar.org/paper/1f1b01cb09e557e6a1e6b0292cb84a67839c2e1a",3,"Lamarckian Platform: Pushing the Boundaries of Evolutionary Reinforcement Learning towards Asynchronous Commercial Games","An open-source platform featuring support for evolutionary reinforcement learning scalable to distributed computing resources and an asynchronous Markov Decision Process interface and an object-oriented software architecture with decoupled modules is introduced.","IEEE Transactions on Games",2022,"Hui Bai,R. Shen,Yue Lin,Bo Xu,Ran Cheng",1,61,0
"15e5935c79433cc132e347c963a22ad86ee682b8","https://www.semanticscholar.org/paper/15e5935c79433cc132e347c963a22ad86ee682b8",3,"Parallel Reinforcement Learning Simulation for Visual Quadrotor Navigation","A simulation framework, built on AirSim, which provides efﬁcient parallel training of RL agents and Ape-X is modiﬂed to incorporate decentralised training of AirSim environments to make use of numerous networked computers.","ArXiv",2022,"Jack D. Saunders,Sajad Saeedi,Wenbin Li",0,32,0
"bd1173bfa8955222517cd8b6f6831dac4400cc67","https://www.semanticscholar.org/paper/bd1173bfa8955222517cd8b6f6831dac4400cc67",3,"Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation","Diversity in Regulation is proposed, training diverse policies with regulated behaviors to discover desired patterns that generalize to downstream environments with various discrepancies and indicates that this method attains improvements over other diversity-driven counterparts.","ArXiv",2022,"Kang Xu,Yan Ma,Wei Li,Bingsheng Wei",0,61,0
"35f8eb09776abebad8a963b59978d673ab97301a","https://www.semanticscholar.org/paper/35f8eb09776abebad8a963b59978d673ab97301a",3,"Understanding Hindsight Goal Relabeling from a Divergence Minimization Perspective","This paper proposes a novel framework to understand hindsight goal relabeling from a divergence minimization perspective and explains the puz-zling phenomenon wherein a reward of {− 1 , 0 } results in signiﬁcantly better performance than a { 0, 1 } reward for goal reaching.","",2022,"Lunjun Zhang,Bradly C. Stadie",0,68,0
"d4087ce0cbf828f05ea5d7494eee3b0d36a13cb9","https://www.semanticscholar.org/paper/d4087ce0cbf828f05ea5d7494eee3b0d36a13cb9",3,"Learning Low-Frequency Motion Control for Robust and Dynamic Robot Locomotion","It is shown that low-frequency policies are less sensitive to actuation latencies and variations in system dynamics, and to the extent that a successful sim-to-real transfer can be performed even without any dynamics randomization or actuation modeling.","ArXiv",2022,"Siddhant Gangapurwala,Luigi Campanaro,I. Havoutis",0,42,0
"8ccf4d4e3a611113b6529ccaee33ca3ead7b256b","https://www.semanticscholar.org/paper/8ccf4d4e3a611113b6529ccaee33ca3ead7b256b",3,"Optimal Tasking of Ground-Based Sensors for Space Situational Awareness Using Deep Reinforcement Learning","This work successfully applied deep reinforcement learning (DRL) to overcome the curse of dimensionality and optimally task a ground-based sensor and trained several DRL agents that outperformed myopic policies in both objective metrics of RSOs’ state uncertainties and the number of unique RSO's observed over a 90-min observation window.","Italian National Conference on Sensors",2022,"Peng Mun Siew,R. Linares",2,30,0
"3827bf251a52cd80489a6578c8e05f1521b7a69e","https://www.semanticscholar.org/paper/3827bf251a52cd80489a6578c8e05f1521b7a69e",3,"Resilient Mechanism Against Byzantine Failure for Distributed Deep Reinforcement Learning","A resilient mechanism for mitigating the influence of Byzantine workers on DDRL-based systems is proposed and a resilient distributed A3C (ReD-A3C) is implemented, which outperforms available Byzantine tolerant approaches.","IEEE International Symposium on Software Reliability Engineering",2022,"Mingyue Zhang,Zhi Jin,Jian Hou,Renwei Luo",0,34,0
"d7fdbaa9483daf72a6c712f08efe3e04f0047509","https://www.semanticscholar.org/paper/d7fdbaa9483daf72a6c712f08efe3e04f0047509",3,"Probabilistic Safeguard for Reinforcement Learning Using Safety Index Guided Gaussian Process Models","This paper presents an integrated model learning and safe control framework to safeguard any agent, where its dynamics are learned as Gaussian processes and guarantees almost zero safety violation on various continuous control tasks.","ArXiv",2022,"Weiye Zhao,Tairan He,Changliu Liu",2,38,0
"1c6035ba208d64d119b7cf6a895f9e71d662b90c","https://www.semanticscholar.org/paper/1c6035ba208d64d119b7cf6a895f9e71d662b90c",3,"Generative Augmented Flow Networks","GAFlowNets is proposed, a novel learning framework to incorporate intermediate rewards by intrinsic motivation to tackle the exploration problem in sparse reward environments and is scalable to a more complex and large-scale molecule generation domain, where it achieves consistent and signiﬁcant performance improvement.","ArXiv",2022,"L. Pan,Dinghuai Zhang,Aaron C. Courville,Longbo Huang,Y. Bengio",6,24,0
"db7d94055535a116c30e61dd7b83eb37ac0defed","https://www.semanticscholar.org/paper/db7d94055535a116c30e61dd7b83eb37ac0defed",3,"Towards a Theoretical Foundation of Policy Optimization for Learning Control Policies","A number of recently-developed theoretical results on the optimization landscape, global convergence, and sample complexity of gradient-based methods for various continuous control problems such as the linear quadratic regulator (LQR), H ∞ control, risk-sensitive control, linear Quadratic Gaussian control, and output feedback synthesis are reviewed.","ArXiv",2022,"B. Hu,K. Zhang,N. Li,M. Mesbahi,Maryam Fazel,Tamer Bacsar",6,168,0
"4bbbb6ee03d35a7c032a21ed98d9c53609f8a348","https://www.semanticscholar.org/paper/4bbbb6ee03d35a7c032a21ed98d9c53609f8a348",3,"In-Hand Object Rotation via Rapid Motor Adaptation","This work designs and learns a simple adaptive controller that can be directly deployed to a real robot hand to rotate dozens of objects with diverse sizes, shapes, and weights over the z -axis via rapid online adaptation of the robot's controller to the object properties using only proprioception history.","ArXiv",2022,"Haozhi Qi,Ashish Kumar,R. Calandra,Yinsong Ma,J. Malik",1,38,0
"d27be7f60b256d5dc8facb1337aede953b8ca9ef","https://www.semanticscholar.org/paper/d27be7f60b256d5dc8facb1337aede953b8ca9ef",3,"Behavior policy learning: Learning multi-stage tasks via solution sketches and model-based controllers","This paper proposes Behavior Policy Learning (BPL) that effectively combines only few solution sketches, model-based controllers, and simulations to effectively solve multi-stage tasks without strong knowledge about the underlying task.","Frontiers in Robotics and AI",2022,"Konstantinos Tsinganos,Konstantinos Chatzilygeroudis,Denis Hadjivelichkov,Theodoros Komninos,E. Dermatas,D. Kanoulas",0,45,0
"c3355f238b34edfb4ad5d375801d3b61f631d5c5","https://www.semanticscholar.org/paper/c3355f238b34edfb4ad5d375801d3b61f631d5c5",3,"Real World Offline Reinforcement Learning with Realistic Data Source","It is posited that data collected from safe operations of closely related tasks are more practical data sources for real-world robot learning and that ORL algorithms can generalize from leveraging ofﬂine heterogeneous data sources and outperform imitation learning.","ArXiv",2022,"G. Zhou,Liyiming Ke,S. Srinivasa,Abhi Gupta,A. Rajeswaran,Vikash Kumar",1,56,0
"e5f03282c562f3c51ae1b874a5d2e1071fe351d4","https://www.semanticscholar.org/paper/e5f03282c562f3c51ae1b874a5d2e1071fe351d4",3,"Learning multi-agent cooperation","The AI Arena is introduced: a scalable framework with flexible abstractions for associating agents with policies and policies with learning algorithms that enable AI research for complex operating environments that incorporate distributed, heterogeneous teams of agents.","Frontiers in Neurorobotics",2022,"Corban G. Rivera,Edward W. Staley,A. Llorens",0,29,0
"091a4fb606011b0ffa8a9a9cb64eee161bae4036","https://www.semanticscholar.org/paper/091a4fb606011b0ffa8a9a9cb64eee161bae4036",3,"Just Round: Quantized Observation Spaces Enable Memory Efficient Learning of Dynamic Locomotion","This paper evaluates the approach using four simulated robot locomotion tasks and two state-of-the-art DRL algorithms, finding that observation space quantization reduces overall memory costs by as much as 4 .","ArXiv",2022,"Lev Grossman,B. Plancher",0,44,0
"cdd2b92a54bda70ead0f95e2695f8ed77122724f","https://www.semanticscholar.org/paper/cdd2b92a54bda70ead0f95e2695f8ed77122724f",3,"Towards an Interpretable Hierarchical Agent Framework using Semantic Goals","This work introduces an interpretable hierarchical agent framework by combining planning and semantic goal directed reinforce- ment learning, which assumes access to certain spatial and haptic predicates and construct a simple and powerful semantic goal space.","ArXiv",2022,"Bharat Prakash,Nicholas R. Waytowich,T. Oates,T. Mohsenin",1,22,0
"db182e410abd8ac1bf6d569cda0f1193d36ef1e4","https://www.semanticscholar.org/paper/db182e410abd8ac1bf6d569cda0f1193d36ef1e4",3,"Indoor Target-Driven Visual Navigation based on Spatial Semantic Information","An end-to-end target-driven visual navigation method, which uses Spatial Semantic Information (SSI) to navigate the agent to the target, is presented and to fully integrate the spatial and semantic information in the scene, visual information is encoded into an 8-D spatial context vector.","International Conference on Information Photonics",2022,"Jiaojie Yan,Qieshi Zhang,Jun Cheng,Ziliang Ren,Tianbo Li,Zhuo Yang",0,24,0
"5d83896a08584a3018fcc8b4031cc4a39450e3f1","https://www.semanticscholar.org/paper/5d83896a08584a3018fcc8b4031cc4a39450e3f1",3,"CLUTR: Curriculum Learning via Unsupervised Task Representation Learning","This work introduces CLUTR: a novel curriculum learning algorithm that decouples task representation and curriculum learning into a two-stage optimization that outperforms PAIRED in terms of generalization and sample efficiency in the challenging CarRacing and navigation environments.","ArXiv",2022,"Abdus Salam Azad,Izzeddin Gur,Aleksandra Faust,P. Abbeel,I. Stoica",0,39,0
"6600be062e90ac6834dab1b33f5459087df14d2b","https://www.semanticscholar.org/paper/6600be062e90ac6834dab1b33f5459087df14d2b",3,"RMBench: Benchmarking Deep Reinforcement Learning for Robotic Manipulator Control","RMBench is presented, the first benchmark for robotic manipulations, which have high-dimensional continuous action and state spaces, and soft Actor- Critic outperforms most algorithms in average reward and stability, and an algorithm combined with data augmentation may facilitate learning policies.","ArXiv",2022,"Yanfei Xiang,Xin Wang,Shu Hu,Bin Zhu,Xiao-lin Huang,Xi Wu,Siwei Lyu",1,55,0
"5c2ee755a616e76241313659f9009a859889cda9","https://www.semanticscholar.org/paper/5c2ee755a616e76241313659f9009a859889cda9",3,"Trust Region Policy Optimization with Optimal Transport Discrepancies: Duality and Algorithm for Continuous Actions","Optimal transport discrepancies are explored to define trust regions, and a novel algorithm – Optimal Transport Trust Region Policy Optimization (OT-TRPO) – is proposed for continuous state-action spaces to show that optimal transport discrepancies can offer an advantage over state-of-the-art approaches.","ArXiv",2022,"Antonio Terpin,Nicolas Lanzetti,Batuhan Yardim,F. Dörfler,Giorgia Ramponi",0,48,0
"5c926e61729fb37fd4f635bd42760aa20faf07ec","https://www.semanticscholar.org/paper/5c926e61729fb37fd4f635bd42760aa20faf07ec",3,"Task Decoupling in Preference-based Reinforcement Learning for Personalized Human-Robot Interaction","This work decouple the task from preference in human-robot interaction, and utilizes a sketchy task reward derived from task priori to instruct robots to conduct more effective task exploration and incorporates prior knowledge of the task into preference-based RL.","IEEE/RJS International Conference on Intelligent RObots and Systems",2022,"Mingjiang Liu,Chunlin Chen",0,33,0
"4f945ce66f8086acd68f02874c3d0cbc20f42480","https://www.semanticscholar.org/paper/4f945ce66f8086acd68f02874c3d0cbc20f42480",3,"Multi-Agent Path Finding via Tree LSTM","A novel network architecture, TreeLSTM, is creatively applied to MAPF and together with several other RL techniques, including reward shaping, multiple-phase training, and centralized control, the solution is comparable to the top 2-3 OR methods.","ArXiv",2022,"Yuhao Jiang,Kunjie Zhang,Qimai Li,Jiaxin Chen,Xiaolong Zhu",0,15,0
"4521c33ad2f84385498bcd8d21db420f36805523","https://www.semanticscholar.org/paper/4521c33ad2f84385498bcd8d21db420f36805523",3,"Avalon: A Benchmark for RL Generalization Using Procedurally Generated Worlds","Avalon is a set of tasks in which embodied agents in highly diverse procedural 3D worlds must survive by navigating terrain, hunting or gathering food, and avoiding hazards, suggesting Avalon is challenging enough to advance the quest for generalizable RL.","ArXiv",2022,"Joshua Albrecht,A. Fetterman,Bryden Fogelman,Ellie Kitanidis,Bartosz Wr'oblewski,Nicole Seo,Michael Rosenthal,Maksis Knutins,Zachary Polizzi,James B. Simon,Kanjun Qiu",1,44,0
"fb090d312f6f33b7f9bb44f04f81304fb7a11bac","https://www.semanticscholar.org/paper/fb090d312f6f33b7f9bb44f04f81304fb7a11bac",3,"Learning Deep Sensorimotor Policies for Vision-based Autonomous Drone Racing","This work uses contrastive learning to extract robust feature representations from the input images and leverage a two-stage learning-by- cheating framework for training a neural network policy that directly infers control commands with feature representations learned from raw images, forgoing the need for globally-consistent state estimation, trajectory planning, and handcrafted control design.","ArXiv",2022,"Jia-Wei Fu,Yunlong Song,Y. Wu,F. Yu,D. Scaramuzza",2,37,0
"1e1d13b81f8138276e97a5932c61e3e834d8665f","https://www.semanticscholar.org/paper/1e1d13b81f8138276e97a5932c61e3e834d8665f",3,"Efficient Language-Guided Reinforcement Learning for Resource-Constrained Autonomous Systems","An energy-efficient architecture, which is designed to receive both images and text inputs as a step toward designing reinforcement learning agents that can understand human language and act in real-world environments is proposed.","IEEE Micro",2022,"Aidin Shiri,Mozhgan Navardi,Tejaswini Manjunath,Nicholas R. Waytowich,T. Mohsenin",2,15,0
"f2d65fdc50df42aabae7491d2a8c25c75a35bf64","https://www.semanticscholar.org/paper/f2d65fdc50df42aabae7491d2a8c25c75a35bf64",3,"Fair Virtual Network Function Mapping and Scheduling Using Proximal Policy Optimization","A deep reinforcement learning method based on offline proximal policy optimization, which dynamically determines the mapping and scheduling decision based on the state of unfinished service chains, is proposed, which is scalable to the number of service chains and can be enhanced by Monte Carlo tree search.","IEEE Transactions on Communications",2022,"Zhenran Kuai,Tianyu Wang,Shaowei Wang",0,30,0
"c934669e8c0816b4ffbf8fe3cebabb6779e3ec80","https://www.semanticscholar.org/paper/c934669e8c0816b4ffbf8fe3cebabb6779e3ec80",3,"Regret Analysis for RL using Renewal Bandit Feedback","A new perspective on model-based learning in MDPs using ideas from renewal theory is presented and a naive algorithm based on this reformulation of the problem of controlling a Markov chain to a renewal reward process with bandit feedback is provided.","Information Theory Workshop",2022,"Sujay Bhatt,Guanhua Fang,P. Li,G. Samorodnitsky",0,38,0
"56211d8b1c94032312b3ce4fd1f06bf81db8d7a7","https://www.semanticscholar.org/paper/56211d8b1c94032312b3ce4fd1f06bf81db8d7a7",3,"HMDRL: Hierarchical Mixed Deep Reinforcement Learning to Balance Vehicle Supply and Demand","Experimental results demonstrate that HMDRL outperforms all the other methods to reposition idle vehicles and aims to improve the training effect by avoiding sparse rewards.","IEEE transactions on intelligent transportation systems (Print)",2022,"Jinhao Xi,F. Zhu,Peijun Ye,Yisheng Lv,Haina Tang,Fei-yue Wang",1,53,0
"e8a2929e2ba75768865feb4b172e15aec45b37c5","https://www.semanticscholar.org/paper/e8a2929e2ba75768865feb4b172e15aec45b37c5",3,"Leveraging Fully Observable Policies for Learning under Partial Observability","This work proposes a method for partially observable reinforcement learning that uses a fully observable policy (which it is called a state expert) during ofﬂine training to improve online performance and outperforms pure imitation, pure reinforcement learning, the sequential or parallel combination of both types, and a recent state-of-the-art method in the same setting.","ArXiv",2022,"Hai Nguyen,Andrea Baisero,Dian Wang,Chris Amato,Robert W. Platt",1,48,0
"1b6fd3b9be019af0747fe195a46941bbf116614c","https://www.semanticscholar.org/paper/1b6fd3b9be019af0747fe195a46941bbf116614c",3,"Optimal Behavior Prior: Data-Efficient Human Models for Improved Human-AI Collaboration","It is shown that using optimal behavior as a prior for human models makes these models vastly more data-efﬁcient and able to generalize to new environments and leads to better human-AI collaboration performance compared to using models based on real human data alone.","ArXiv",2022,"Mesut Yang,Micah Carroll,A. Dragan",0,46,0
"19ca582aea8819a25357342dae5efd367765e8c5","https://www.semanticscholar.org/paper/19ca582aea8819a25357342dae5efd367765e8c5",3,"Policy-Based Reinforcement Learning for Assortative Matching in Human Behavior Modeling","A modeling approach based on Multi-Agent Reinforcement Learning (MARL) is proposed, adding a multi-head attention function to the A3C algorithm to enhance learning effectiveness, which simulates human behavior in certain scenarios through various environmental parameter settings and agent action strategies.","ArXiv",2022,"O. Deng,Q. Jin",0,12,0
"c8a7a5af3dae60a6732316beecd602c880c985d4","https://www.semanticscholar.org/paper/c8a7a5af3dae60a6732316beecd602c880c985d4",3,"An efficient training strategy for multi-agent reinforcement learning in card games","The experiment found that the gradual promotion training strategy can effectively improve the winning rate and average reward of the agent and is an extremely convenient and easy training strategy to implement.","Other Conferences",2022,"Jiyuan Shen",0,38,0
"490b6db3ce7cf9743c5a7c3125ab9dca240ce907","https://www.semanticscholar.org/paper/490b6db3ce7cf9743c5a7c3125ab9dca240ce907",3,"Deep Reinforcement Learning with Vector Quantized Encoding","A novel method for clustering state features in deep reinforcement learning (RL) methods to prove their interpretability and its impact on robustness and generalization of deep RL is investigated.","ArXiv",2022,"Liang Zhang,Justin Lieffers,A. Pyarelal",0,41,0
"c25933713708bca9a7a2c1379e9783c88a3afdd3","https://www.semanticscholar.org/paper/c25933713708bca9a7a2c1379e9783c88a3afdd3",3,"Legged Locomotion in Challenging Terrains using Egocentric Vision","This paper presents the first end-to-end locomotion system capable of traversing stairs, curbs, stepping stones, and gaps on a medium-sized quadruped robot using a single front-facing depth camera.","ArXiv",2022,"Ananye Agarwal,Ashish Kumar,Jitendra Malik,Deepak Pathak",6,91,0
"ea14465601f45bf50a148563c73c4d6e1971dcb1","https://www.semanticscholar.org/paper/ea14465601f45bf50a148563c73c4d6e1971dcb1",3,"Redeeming Intrinsic Rewards via Constrained Optimization","A principled constrained policy optimization procedure that automatically tunes the importance of the intrinsic reward is proposed, which results in superior exploration that does not require manual tuning to balance the intrinsic rewards against the task reward.","ArXiv",2022,"E. Chen,Zhang-Wei Hong,J. Pajarinen,Pulkit Agrawal",1,37,0
"022c285ba675ae5ef5f9b0c755a625dcb1aa8ca3","https://www.semanticscholar.org/paper/022c285ba675ae5ef5f9b0c755a625dcb1aa8ca3",3,"Pandering in a Flexible Representative Democracy","A novel formal model of pandering, or strategic preference reporting by candidates seeking to be elected, is introduced, and the resilience of two democratic voting systems to pandering within a single round and across multiple rounds is examined.","ArXiv",2022,"Xiaolin Sun,Jacob Masur,Ben Abramowitz,Nicholas Mattei,Zizhan Zheng",0,45,0
"87ed4d733690c38aa2287b53ad2d72f14946d0b1","https://www.semanticscholar.org/paper/87ed4d733690c38aa2287b53ad2d72f14946d0b1",3,"Automating Rigid Origami Design","","ArXiv",2022,"Jeremia Geiger,Karolis Martinkus,Oliver Richter,Roger Wattenhofer",0,36,0
"89294e0b8bc32c563291f261f1172fdc11214f4b","https://www.semanticscholar.org/paper/89294e0b8bc32c563291f261f1172fdc11214f4b",3,"Noisy Symbolic Abstractions for Deep RL: A case study with Reward Machines","This work forms the problem of policy learning in Reward Machines with noisy symbolic abstractions as a special class of POMDP optimization problem, and investigates several methods to address the problem, building on existing and new techniques.","ArXiv",2022,"Andrew C. Li,Zizhao Chen,Pashootan Vaezipoor,Toryn Q. Klassen,Rodrigo Toro Icarte,Sheila A. McIlraith",0,52,0
"ec25b1b13c5e74c919abb0dd000cae964f13b0fe","https://www.semanticscholar.org/paper/ec25b1b13c5e74c919abb0dd000cae964f13b0fe",3,"SafeLight: A Reinforcement Learning Method toward Collision-free Traffic Signal Control","This work incorporates road safety standards as enforcement to ensure the safety of existing reinforcement learning methods, aiming toward operating intersections with zero collisions, and proposes a safety-enhanced residual reinforcement learning method (SafeLight), which can significantly reduce collisions while increasing traffic mobility.","ArXiv",2022,"Wenlu Du,J. Ye,Jingyi Gu,Jing Li,Hua Wei,Gui-Liu Wang",0,46,0
"aa13a24ce0f242fb328603c83d456eafba177dbe","https://www.semanticscholar.org/paper/aa13a24ce0f242fb328603c83d456eafba177dbe",3,"Examining Policy Entropy of Reinforcement Learning Agents for Personalization Tasks","This effort is focused on examining the behavior of reinforce- ment learning systems in personalization environments and detailing the differences in policy entropy associated with the type of learning algorithm utilized, demonstrating that Policy Optimization agents often possess low-entropy policies during training and Q-Learning agents are far less susceptible to such behavior.","ArXiv",2022,"A. Dereventsov,Andrew Starnes,C. Webster",0,55,0
"8225ac1bec34a645d45d903642a8af59b3367cc2","https://www.semanticscholar.org/paper/8225ac1bec34a645d45d903642a8af59b3367cc2",3,"Tackling Visual Control via Multi-View Exploration Maximization","MEM can signiﬁcantly promote the sample-e-ciency and generalization ability of the RL agent, facilitating solving real-world problems with high-dimensional observations and spare-reward space and outperform the benchmarking schemes with simple architecture and higher eﬃciency.","ArXiv",2022,"Mingqi Yuan,Xin Jin,Bo Li,Wenjun Zeng",1,56,0
"d8753089a4a57cc5b147d461d8e2c3585f0e8a38","https://www.semanticscholar.org/paper/d8753089a4a57cc5b147d461d8e2c3585f0e8a38",3,"Dynamic Bipedal Turning through Sim-to-Real Reinforcement Learning","This work applies a recurrent policy to execute four-step, 90° turns trained using reference data generated from optimized single rigid body model trajectories and presents a training framework using epilogue terminal rewards for learning specific behaviors from pre-computed trajectory data.","IEEE-RAS International Conference on Humanoid Robots",2022,"Fangzhou Yu,Ryan Batke,Jeremy Dao,J. Hurst,Kevin R. Green,Alan Fern",0,31,0
"90cd4aa3176e3f176a81c1fc834cb8352ffe2564","https://www.semanticscholar.org/paper/90cd4aa3176e3f176a81c1fc834cb8352ffe2564",3,"End-to-End Mobile Robot Navigation using a Residual Deep Reinforcement Learning in Dynamic Human Environments","An architecture based on convolutional units and residual blocks being able to enhance adaptability to unseen and dynamic human environments is reported, which outperformed the state-of-the-art baselines SOADRL and NAVREP.","IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications",2022,"Abdullah Ahmed,Yasser F. O. Mohammad,V. Parque,Haitham El-Hussieny,S. Ahmed",0,17,0
"d052b40fb39024c8858b28fd644d63c4cf2cb22f","https://www.semanticscholar.org/paper/d052b40fb39024c8858b28fd644d63c4cf2cb22f",3,"DeepADMR: A Deep Learning based Anomaly Detection for MANET Routing","The DeepADMR performance in the presence of channel disruptions, high mobility levels, and network sizes beyond the training environments, which shows its effectiveness.","IEEE Military Communications Conference",2022,"Alex Yahja,Saeed Kaviani,Bo Ryu,Jae H. Kim,Kevin Larson",0,25,0
"5f76d20ce2fe6c655de9ddde525ac339d66190ca","https://www.semanticscholar.org/paper/5f76d20ce2fe6c655de9ddde525ac339d66190ca",3,"Enhancing Robot Task Completion Through Environment and Task Inference: A Survey from the Mobile Robot Perspective","The first extensive investigation of mobile robot inference problems in unknown environments with limited sensor and communication range is presented and a new taxonomy to classify the different environment and task inference methods for single- and multi-robot systems is proposed.","Journal of Intelligent and Robotic Systems",2022,"A. H. Tan,G. Nejat",0,182,0
"c6209b74d296b3db01e41372976b044158f2d205","https://www.semanticscholar.org/paper/c6209b74d296b3db01e41372976b044158f2d205",3,"Karolos: An Open-Source Reinforcement Learning Framework for Robot-Task Environments","Karolos is introduced, a RL framework developed for robotic applications, with a particular focus on transfer scenarios with varying robot-task combinations reﬂected in a modular environment architecture that provides implementations of state-of-the-art RL algorithms along with common learning-facilitating enhancements.","ArXiv",2022,"Christian Bitter,Timo Thun,Tobias Meisen",0,31,0
"7595d53e249d9e6e43049b81ae02d347ac08b836","https://www.semanticscholar.org/paper/7595d53e249d9e6e43049b81ae02d347ac08b836",3,"Deep Reinforcement Learning With Part-Aware Exploration Bonus in Video Games","The effectiveness of introducing prior learned features for existing prediction-based exploration methods is demonstrated and an attention map mechanism is designed to discretize learned features, thereby updating the learned feature and meanwhile reducing the impact of randomness on intrinsic rewards caused by the learning process of features.","IEEE Transactions on Games",2022,"Pei Xu,Qiyue Yin,Junge Zhang,Kaiqi Huang",1,35,0
"1e9a22488bd872b9f1ee71216e2d6848c266e15d","https://www.semanticscholar.org/paper/1e9a22488bd872b9f1ee71216e2d6848c266e15d",3,"DRAS: Deep Reinforcement Learning for Cluster Scheduling in High Performance Computing","This work presents an automated HPC scheduling agent named DRAS (Deep Reinforcement Agent for Scheduling) by leveraging deep reinforcement learning and demonstrates that DRAS outperforms the existing heuristic and optimization approaches by up to 50%.","IEEE Transactions on Parallel and Distributed Systems",2022,"Yuping Fan,Boyang Li,Dustin Favorite,Naunidh Singh,T. Childers,P. Rich,W. Allcock,M. Papka,Z. Lan",0,38,0
"4cb0fc6739f79b7dc06d448624e930e40a7064f4","https://www.semanticscholar.org/paper/4cb0fc6739f79b7dc06d448624e930e40a7064f4",3,"Policy Learning for Active Target Tracking over Continuous SE(3) Trajectories","A novel model-based policy gradient algorithm for tracking dynamic targets using a mobile robot, equipped with an onboard sensor with limited view, to obtain a continuous control policy for the mobile robot to collect sensor measurements that reduce uncertainty in the target states, measured by the target distribution entropy.","ArXiv",2022,"Pengzhi Yang,Shumon Koga,Arash Asgharivaskasi,Nikolay A. Atanasov",0,35,0
"0212f5f26397d64a9df4c532c912dbcc6df94dab","https://www.semanticscholar.org/paper/0212f5f26397d64a9df4c532c912dbcc6df94dab",3,"Distributed Reinforcement Learning for Low-delay Uplink User Scheduling in Multicell Networks","The results illustrate that the proposed algorithm outperforms standard schedulers, such as Proportional Fair and MaxWeight and that information exchange is crucial for challenging problem instances,such as topologies with many devices on the cell edge and/or high traffic demands.","Global Communications Conference",2022,"A. Destounis,D. Tsilimantos",0,22,0
"583f72e9fd06cf2a028a1f871b852410734ec4b9","https://www.semanticscholar.org/paper/583f72e9fd06cf2a028a1f871b852410734ec4b9",3,"A Mobile Robot Experiment System with Lightweight Simulator Generator for Deep Reinforcement Learning Algorithm","A fast simulator generation method using linear approximate kinematics model and bake-based lidar rendering methods to generate a fast approximate simulator used in the pre-experimental stage to solve the problem of data cost is proposed.","IEEE International Conference on Robotics and Biomimetics",2022,"Yunfei Xiang,Jiantao Qiu,Jincheng Yu,Jiahao Tang,Guangjun Ge,Yu Wang,Huazhong Yang",0,22,0
"74ac29cf04ea3b55ebf30fa34a23d86ea1f1b590","https://www.semanticscholar.org/paper/74ac29cf04ea3b55ebf30fa34a23d86ea1f1b590",3,"Structure-Aware Policy to Improve Generalization among Various Robots and Environments","A novel DRL generalization method called GNN-embedding is proposed, which incorporates the robot hardware and the environment simultaneously withGNN-based policy network and learnable embedding vectors of tasks and improves the generalization performance of existing DRL robot policies.","IEEE International Conference on Robotics and Biomimetics",2022,"Wei-qing Xu,Yue Gao,Buqing Nie",0,24,0
"776975b39a1672dad9203d9bc469d05cbe44d35e","https://www.semanticscholar.org/paper/776975b39a1672dad9203d9bc469d05cbe44d35e",3,"Multiple Subgoals-guided Hierarchical Learning in Robot Navigation","This work introduces multiple subgoals-guided navigation (MSGN) which consists of a high-level multiple subGoals Planner and a low-level goal-conditioned RL Controller which could alleviate the suboptimal subgoal problem by transferring the subgoal selection process to the RL agent.","IEEE International Conference on Robotics and Biomimetics",2022,"Shan Luo,L. Schomaker",0,23,0
"e150cfc540712807193f2ae10284338a8efeea58","https://www.semanticscholar.org/paper/e150cfc540712807193f2ae10284338a8efeea58",3,"Cooperative Guidance Strategy for Active Defense Spacecraft with Imperfect Information via Deep Reinforcement Learning","","ArXiv",2022,"Li Zhi,Haizhao Liang,Jinze Wu,Jianying Wang,Yu Zheng",0,27,0
"fcab3c0dd4e03ce3e664e422a22f8309049e91f4","https://www.semanticscholar.org/paper/fcab3c0dd4e03ce3e664e422a22f8309049e91f4",3,"Trajectory planning of a manipulator based on the DDPG algorithm","The findings demonstrate that the DDPG method converges easier than the AC algorithm, and that the directed reward function can help the manipulator avoid obstacles.","Other Conferences",2022,"Xiangyu Jing,C. Zang,Yuqi Liu,Yu Liu,Changqing Xia",0,18,0
"a38167796e525c5c384050f5a3a281274beb0f78","https://www.semanticscholar.org/paper/a38167796e525c5c384050f5a3a281274beb0f78",3,"Reinforcement Learning and Mixed-Integer Programming for Power Plant Scheduling in Low Carbon Systems: Comparison and Hybridisation","","ArXiv",2022,"C. O'Malley,Patrick de Mars,Luis Badesa,G. Strbac",0,31,0
"ce0acbba6d2feb2870ab4a3ce72067429c358a40","https://www.semanticscholar.org/paper/ce0acbba6d2feb2870ab4a3ce72067429c358a40",3,"Deep Reinforcement Learning for Queue-Time Management in Semiconductor Manufacturing","This work proposes a deep Reinforcement Learning (RL) method to manage releasing lots into the queue time constraint and shows that the RL method outperforms the baselines in five performance metrics including the number of queue-time violations and makespan, while requiring negligible online compute time.","Online World Conference on Soft Computing in Industrial Applications",2022,"Harel Yedidsion,Prafulla Dawadi,David Norman,E. Zarifoglu",0,25,0
"5df105539a7185b6422586aae9c40e7144b9def9","https://www.semanticscholar.org/paper/5df105539a7185b6422586aae9c40e7144b9def9",3,"Behavior analysis of emergent rule discovery for cooperative automated driving using deep reinforcement learning","The simulation results showed that reinforcement learning achieves rational control of the overtaking behavior and indicates that the proposed multi-agent learning method with an extended own-vehicle environment has the potential to learn automated vehicle control with cooperative behavior automatically.","Artificial Life and Robotics",2022,"Tomohiro Harada,Johei Matsuoka,K. Hattori",0,27,0
"1d8c10f09a97b699706967d7315ce368b1047263","https://www.semanticscholar.org/paper/1d8c10f09a97b699706967d7315ce368b1047263",3,"Anticipatory Fictitious Play","This paper presents a simple modiﬁcation of ﬁctitious play which is a strict improvement over the original: it has the same theoretical worst-case convergence rate, is equally applicable in a machine learning context, and enjoys superior empirical performance.","ArXiv",2022,"Alex Cloud,Albert Wang,W. Kerr",0,26,0
"d04c8caaddd159ff6696babec6f09ec13b4e81b5","https://www.semanticscholar.org/paper/d04c8caaddd159ff6696babec6f09ec13b4e81b5",3,"Hyperparameters in Contextual RL are Highly Situational","It is shown that agents in contextual RL require different hyperparameters if they are shown how environmental factors change, further highlighting the need for research into how hyperparameter learning and generalization in RL is handled.","ArXiv",2022,"Theresa Eimer,C. Benjamins,M. Lindauer",2,33,0
"89bfce65591e1f26df76c90be0fc5cb2629dcba7","https://www.semanticscholar.org/paper/89bfce65591e1f26df76c90be0fc5cb2629dcba7",3,"Deep Reinforcement Learning for Heat Pump Control","","ArXiv",2022,"T. Rohrer,Lilli Frison,Lukas Kaupenjohann,K. Scharf,Elke Hergenröther",0,24,0
"e8cd8e1ee73ce6059c1a08acd5cc088fee2e7a29","https://www.semanticscholar.org/paper/e8cd8e1ee73ce6059c1a08acd5cc088fee2e7a29",3,"Stock Trading Optimization through Model-based Reinforcement Learning with Normalizing Fl (preprint)","This paper demonstrates normalizing flows is adopted to simulated high-dimensional joint probability of the complex trading environment, and develops a novel model based reinforcement learning framework to better understand the intrinsic mechanisms of quantitative online trading.","",2023,"Huifang Huang,Ting Gao,Pengbo Li,Jinqiu Guo,P. Zhang",0,47,0
"387aed1f28d352fffa04e6d18c0ec46de6f8133e","https://www.semanticscholar.org/paper/387aed1f28d352fffa04e6d18c0ec46de6f8133e",3,"Reinforcement Learning From Hierarchical Critics","The proposed RL from the hierarchical critics (RLHC) algorithm outperforms the benchmark on these four competitive tasks under four experimental scenarios consisting of tennis, soccer, banana collection, and crawler competitions within the Unity environment.","IEEE Transactions on Neural Networks and Learning Systems",2019,"Zehong Cao,Chin-Teng Lin",11,19,0
"f92baa1d3bb07c6972b5a712100205154079bbd8","https://www.semanticscholar.org/paper/f92baa1d3bb07c6972b5a712100205154079bbd8",3,"Development and Validation of an AI-Driven Model for the La Rance Tidal Barrage: A Generalisable Case Study","","Applied Energy",2022,"Túlio Marcondes Moreira,Jackson Geraldo de Faria,Pedro O. S. Vaz de Melo,G. Medeiros-Ribeiro",0,84,0
"c2dd4b8436443c05033317b1a13f82f5e1a18ee5","https://www.semanticscholar.org/paper/c2dd4b8436443c05033317b1a13f82f5e1a18ee5",3,"Machine Learning for Computer Systems and Networking: A Survey","This article attempts to shed light on recent literature that appeals for machine learning-based solutions to traditional problems in computer systems and networking, and introduces a taxonomy based on a set of major research problem domains.","ACM Computing Surveys",2022,"Marios Evangelos Kanakis,R. Khalili,Lin Wang",2,207,0
"2c607661939027d81677df9aa86b78c44fce1bca","https://www.semanticscholar.org/paper/2c607661939027d81677df9aa86b78c44fce1bca",3,"Deep reinforcement learning for optimizing well settings in subsurface systems with uncertain geology","","Journal of Computational Physics",2022,"Y. Nasir,L. Durlofsky",0,57,0
"7881b5fef0489ba1404094e81a11983ed241aa7d","https://www.semanticscholar.org/paper/7881b5fef0489ba1404094e81a11983ed241aa7d",3,"Joint Power Allocation and Rate Control for Rate Splitting Multiple Access Networks with Covert Communications","This work first proposes a stochastic optimization framework that allows the transmitter to adaptively adjust its power and transmission rates allocated to users, and thereby maximizing the sum-rate and fairness of the system under the presence of an adversary, and develops a highly effective learning algorithm that can help the transmitter find the optimal policy.","IEEE Transactions on Communications",2022,"Nguyen Quang Hieu,D. Hoang,D. Niyato,Diep N. Nguyen,Dong In Kim,A. Jamalipour",1,35,0
"761b0d169c18cde007a1557463576bcaf3cfc0b6","https://www.semanticscholar.org/paper/761b0d169c18cde007a1557463576bcaf3cfc0b6",3,"When Virtual Reality Meets Rate Splitting Multiple Access: A Joint Communication and Computation Approach","A novel multicast approach is proposed to cluster users into different groups based on a Field-of-View metric and transmit multicast streams in a hierarchical manner and a deep reinforcement learning approach is presented to obtain the solution for the optimization problem.","IEEE Journal on Selected Areas in Communications",2022,"Nguyen Quang Hieu,Diep N. Nguyen,D. Hoang,E. Dutkiewicz",1,30,0
"28f8ac5fedd09594d4c28d2038bda46e44330cd4","https://www.semanticscholar.org/paper/28f8ac5fedd09594d4c28d2038bda46e44330cd4",3,"DashBot: Insight-Driven Dashboard Generation Based on Deep Reinforcement Learning","This work proposes using deep reinforcement learning to generate analytical dashboards that can use well-established visualization knowledge and the estimation capacity of reinforcement learning, and uses visualization knowledge to construct a training environment and rewards for agents to explore and imitate human exploration behavior with a well-designed agent network.","IEEE Transactions on Visualization and Computer Graphics",2022,"Dazhen Deng,Aoyu Wu,Huamin Qu,Yingcai Wu",5,82,1
"9f7b9d7b294095d1a4f0153a7140ed05541e383a","https://www.semanticscholar.org/paper/9f7b9d7b294095d1a4f0153a7140ed05541e383a",3,"PPO-Based PDACB Traffic Control Scheme for Massive IoV Communications","Proximal policy optimization (PPO) algorithm as a unique deep reinforcement learning (DRL) method is utilized in this paper, which can obtain continuous action space and solve for the optimal ACB factors without estimating backlog of nodes.","IEEE transactions on intelligent transportation systems (Print)",2023,"Haijun Zhang,Minghui Jiang,Xiangnan Liu,X. Wen,Ning Wang,Keping Long",0,35,0
"700322cb828c52714749e1882291bf7b6397a92d","https://www.semanticscholar.org/paper/700322cb828c52714749e1882291bf7b6397a92d",3,"S-MFRL: Spiking Mean Field Reinforcement Learning for Dynamic Resource Allocation of D2D Networks","Results show that the designed S-MFAC and S-MFPPO outperform both AC and PPO in terms of convergence rate, access rate, time-averaged overall throughput, and collision probability and the optimization process of resource allocation becomes tractable as the number of D2D users increases.","IEEE Transactions on Vehicular Technology",2023,"P. Ye,Yuan-Gen Wang,Weixuan Tang",0,41,0
"85d4cf8e1bacdc77aa45a901415a843d40b25192","https://www.semanticscholar.org/paper/85d4cf8e1bacdc77aa45a901415a843d40b25192",3,"Deep Reinforcement Learning of Semi-Active Suspension Controller for Vehicle Ride Comfort","","IEEE Transactions on Vehicular Technology",2023,"Daekyun Lee,S. Jin,Chibum Lee",0,62,0
"ca8511ea5d9b3ab954a578222a4b54d6d7644130","https://www.semanticscholar.org/paper/ca8511ea5d9b3ab954a578222a4b54d6d7644130",3,"Emergent behaviour and neural dynamics in artificial agents tracking odour plumes","This work trains artificial recurrent neural network agents using deep reinforcement learning to locate the source of simulated odour plumes that mimic features of plumes in a turbulent flow and produces trajectories that mimic real insect behaviours.","Nature Machine Intelligence",2023,"Satpreet H. Singh,Floris van Breugel,Rajesh P. N. Rao,Bingni W. Brunton",0,100,0
"73b4b216f03a2e507de2ffe7476d663eb063f9f3","https://www.semanticscholar.org/paper/73b4b216f03a2e507de2ffe7476d663eb063f9f3",3,"Multi-Agent Reinforcement Learning for Fast-Timescale Demand Response of Residential Loads","","ArXiv",2023,"Vincent Mai,Philippe Maisonneuve,Tianyu Zhang,Hadi Nekoei,L. Paull,Antoine Lesage-Landry",0,57,0
"73090396539710dc3a735a09b334ae8d8890170c","https://www.semanticscholar.org/paper/73090396539710dc3a735a09b334ae8d8890170c",3,"SoK: Adversarial Machine Learning Attacks and Defences in Multi-Agent Reinforcement Learning","A novel perspective to understand the manner of perpetrating an AML attack, by deﬁning Attack Vectors is proposed, and two new frameworks to address a gap in current modelling frameworks are developed.","ArXiv",2023,"Maxwell Standen,Junae Kim,Claudia Szabo",0,117,0
"24f4a82476142c3d0b48da9855fe0698585485aa","https://www.semanticscholar.org/paper/24f4a82476142c3d0b48da9855fe0698585485aa",3,"Effective Diversity in Unsupervised Environment Design","A principled approach to adaptively identify diverse environments based on a novel distance measure relevant to environment design is provided and empirically demonstrate the versatility and effectiveness of the method in comparison to multiple leading approaches for unsupervised environment design on three distinct benchmark prob-lems used in literature.","ArXiv",2023,"WenJu Sun,Pradeep Varakantham,Dexun Li",0,34,0
"c35b61b07bdf6671e062c8c44b0e8939efb71436","https://www.semanticscholar.org/paper/c35b61b07bdf6671e062c8c44b0e8939efb71436",3,"AccDecoder: Accelerated Decoding for Neural-enhanced Video Analytics","AccDecoder is presented, a novel accelerated decoder for real-time and neural- enhanced video analytics that can select a few frames adaptively via Deep Reinforcement Learning (DRL) to enhance the quality by neural super-resolution and then up-scale the unselected frames that reference them, which leads to 6-21% accuracy improvement.","ArXiv",2023,"Tingting Yuan,Liang Mi,Weijun Wang,Haipeng Dai,Xiaoming Fu",0,56,0
"6f3e605a6f9a6b26138c2b2f83d2bbbe4b972e5f","https://www.semanticscholar.org/paper/6f3e605a6f9a6b26138c2b2f83d2bbbe4b972e5f",3,"Stock Trading Optimization through Model-based Reinforcement Learning with Normalizing Flows","This paper demonstrates normalizing flows is adopted to simulated high-dimensional joint probability of the complex trading environment, and develops a novel model based reinforcement learning framework to better understand the intrinsic mechanisms of quantitative online trading.","",2023,"Huifang Huang,Ting Gao,Pengbo Li,Jinqiu Guo,P. Zhang",0,47,0
"da5862ad8495e4622bbbb6413523216a5455d620","https://www.semanticscholar.org/paper/da5862ad8495e4622bbbb6413523216a5455d620",3,"Language-guided Task Adaptation for Imitation Learning","A novel setting, wherein an agent needs to learn a task from a demonstration of a related task with the difference between the tasks communicated in natural language is introduced, and a framework that uses a transformer-based model to reason about the entities in the tasks and their relationships is proposed.","ArXiv",2023,"Prasoon Goyal,R. Mooney,S. Niekum",0,55,0
"cee43aad6a4039b2d412bc27dadde41040e8f3e0","https://www.semanticscholar.org/paper/cee43aad6a4039b2d412bc27dadde41040e8f3e0",3,"Intrinsic Motivation in Model-based Reinforcement Learning: A Brief Review","","ArXiv",2023,"A. Latyshev,A. Panov",0,34,0
"b65e9e7f500437a01848ac6fde6692e6b241de85","https://www.semanticscholar.org/paper/b65e9e7f500437a01848ac6fde6692e6b241de85",3,"AutoCost: Evolving Intrinsic Cost for Zero-violation Reinforcement Learning","Inspired by the analysis, this paper proposes AutoCost, a simple yet effective framework that automatically searches for cost functions that help constrained RL to achieve zero- violation performance and compares the performance of augmented agents that use the authors' cost function to provide additive intrinsic costs with baseline Agents that use the same policy learners but with only extrinsic costs.","ArXiv",2023,"Tairan He,Weiye Zhao,Changliu Liu",1,52,0
"89f6e05ed3bd4fe01ffd4e7290ea7111d51683e6","https://www.semanticscholar.org/paper/89f6e05ed3bd4fe01ffd4e7290ea7111d51683e6",3,"Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning","An intrinsic reward toolkit is developed that intelligently and adaptively provides high-quality intrinsic rewards to enhance exploration in reinforcement learning (RL) and can outperform the benchmarking schemes and achieve superior performance with simple architecture.","ArXiv",2023,"Mingqi Yuan,Bo Li,Xin Jin,Wenjun Zeng",0,43,0
"19f5b9767a5f4e30d3258cb52f080d7b29577e1b","https://www.semanticscholar.org/paper/19f5b9767a5f4e30d3258cb52f080d7b29577e1b",3,"A Deep Reinforcement Learning Framework for Optimizing Congestion Control in Data Centers","This work uses multi- agent reinforcement learning to design a system for automatic and dynamic tuning of congestion control parameters at end- hosts in a data center that has the potential to mitigate the problems of static parameters.","ArXiv",2023,"Shiva Ketabi,Hongkai Chen,Haiwei Dong,Y. Ganjali",0,18,0
"b39a47797df8fe3c6d21a2c0af4658aedd66fadb","https://www.semanticscholar.org/paper/b39a47797df8fe3c6d21a2c0af4658aedd66fadb",3,"Sample Efficient Deep Reinforcement Learning via Local Planning","An algorithmic framework that resets the environment to an observed state which has high uncertainty, instead of sampling according to the initial-state distribution, and can achieve super-human performance on the notoriously hard Atari game, Montezuma’s Revenge, with a simple (distributional) double DQN.","ArXiv",2023,"Dong Yin,S. Thiagarajan,Nevena Lazic,Nived Rajaraman,Botao Hao,Csaba Szepesvari",0,42,0
"34d2b456fd6045e13067b6126560f77e4b2a9738","https://www.semanticscholar.org/paper/34d2b456fd6045e13067b6126560f77e4b2a9738",3,"Enabling surrogate-assisted evolutionary reinforcement learning via policy embedding","A PE-SAERL Framework is proposed to at the first time enable surrogate-assisted evolutionary reinforcement learning via policy embedding (PE) and empirical results show that the proposed method can perform more efficiently than the four state-of-the-art algorithms.","ArXiv",2023,"Lan Tang,Xiaxi Li,Jinyuan Zhang,Guiying Li,Peng Yang,Ke Tang",0,33,0
"363fad5eddf482dba0a65a62eabfec81c6be58ec","https://www.semanticscholar.org/paper/363fad5eddf482dba0a65a62eabfec81c6be58ec",3,"Two-Stream Fused Fuzzy Deep Neural Network for Multiagent Learning","Fuzzy MA2C is presented which integrates 2s-FDNN into multiagent deep RL to deal with uncertain communication informations for improving the robustness and generalization under partially observed environments and can achieve superior performance against existing RL algorithms.","IEEE transactions on fuzzy systems",2023,"Baofu Fang,Caiming Zheng,Hao Wang,Tingting Yu",0,34,0
"f8bce9b9aa7900dfddf8c1ce3f2a71211ad82f0f","https://www.semanticscholar.org/paper/f8bce9b9aa7900dfddf8c1ce3f2a71211ad82f0f",3,"Task Placement and Resource Allocation for Edge Machine Learning: A GNN-based Multi-Agent Reinforcement Learning Paradigm","TapFinger is proposed, a distributed scheduler for edge clusters that minimizes the total completion time of ML tasks through co-optimizing task placement and fine-grained multi-resource allocation and the integration of Bayes' theorem and masking schemes.","ArXiv",2023,"Yihong Li,Xiaoxi Zhang,Tian Zeng,Jingpu Duan,Chuanxi Wu,Di Wu,Xu Chen",0,54,0
"037d5ef2da31b6e5f4d7e18a49ebd4c679b4b121","https://www.semanticscholar.org/paper/037d5ef2da31b6e5f4d7e18a49ebd4c679b4b121",3,"Safe reinforcement learning under temporal logic with reward design and quantum action selection","An advanced Reinforcement Learning (RL) method, incorporating reward-shaping, safety value functions, and a quantum action selection algorithm is proposed, which can synthesize a finite policy that maximizes the probability of satisfying a complex task.","Scientific Reports",2023,"Mingyu Cai,Shaoping Xiao,Junchao Li,Z. Kan",0,44,0
"5261f5a46ad372e15f755cd6df141d5840019c5b","https://www.semanticscholar.org/paper/5261f5a46ad372e15f755cd6df141d5840019c5b",3,"Average-Constrained Policy Optimization","The Average-Constrained Policy Optimization (ACPO) algorithm is inspired by the famed PPO-type algorithms based on trust region methods, and basic sensitivity theory for average MDPs is developed, and the corresponding bounds are used in the design of the algorithm.","ArXiv",2023,"Akhil Agnihotri,R. Jain,Haipeng Luo",0,46,0
"d99f23bd44f88d769a8892206581aea5d556975f","https://www.semanticscholar.org/paper/d99f23bd44f88d769a8892206581aea5d556975f",3,"Locally Constrained Policy Optimization for Online Reinforcement Learning in Non-Stationary Input-Driven Environments","Locally Constrained Policy Optimization (LCPO) is presented, an on-policy RL approach that combats CF by anchoring policy outputs on old experiences while optimizing the return on current experiences.","ArXiv",2023,"Pouya Hamadanian,Arash Nasr-Esfahany,Siddartha Sen,Malte Schwarzkopf,MohammadIman Alizadeh",0,50,0
"1d872bdcf8fd5bb8b033ece24eb31cba5d9476c9","https://www.semanticscholar.org/paper/1d872bdcf8fd5bb8b033ece24eb31cba5d9476c9",3,"Adaptive Aggregation for Safety-Critical Control","This work proposes an adaptive aggregation framework for safety-critical control by aggregating the multiple source tasks and a target task through the attention network and utilizing a safeguard to achieve fewer safety violations.","ArXiv",2023,"Huiliang Zhang,Di Wu,B. Boulet",0,41,0
"ef213d6543cd995ac6b1dfde7d08a7a120232391","https://www.semanticscholar.org/paper/ef213d6543cd995ac6b1dfde7d08a7a120232391",3,"Towards Skilled Population Curriculum for Multi-Agent Reinforcement Learning","A novel automatic curriculum learning framework, Skilled Population Curriculum (SPC), is introduced, which adapts curriculum learning to multi-agent coordination and endow the student with population-invariant communication and a hierarchical skill set, allowing it to learn cooperation and behavior skills from distinct tasks with varying numbers of agents.","ArXiv",2023,"R. Wang,Longtao Zheng,Wei Qiu,Bowei He,Bo An,Zinovi Rabinovich,Yujing Hu,Yingfeng Chen,Tangjie Lv,Changjie Fan",0,69,0
"18e8c09f269a9970b6a32c57aed979b96aec9535","https://www.semanticscholar.org/paper/18e8c09f269a9970b6a32c57aed979b96aec9535",3,"Zero-shot Sim2Real Adaptation Across Environments","A Reverse Action Transformation (RAT) policy is proposed which learns to imitate simulated policies in the real-world and can then be deployed on top of a Universal Policy Network to achieve zero-shot adaptation to new environments.","ArXiv",2023,"B. L. Semage,Thommen George Karimpanal,S. Rana,S. Venkatesh",0,37,0
"e216f0a7cd4b87ee8d04c6eed3a58992021b8142","https://www.semanticscholar.org/paper/e216f0a7cd4b87ee8d04c6eed3a58992021b8142",3,"Novel Model-free Optimal Active Vibration Control Strategy Based on Deep Reinforcement Learning","","Structural Control & Health Monitoring",2023,"Yi-Ang Zhang,Songye Zhu",0,35,0
"5e2d38b3770025aa7b1d1c12f86d355c25bd8717","https://www.semanticscholar.org/paper/5e2d38b3770025aa7b1d1c12f86d355c25bd8717",3,"An Investigation into Pre-Training Object-Centric Representations for Reinforcement Learning","This paper investigates the effectiveness of OCR pre-training for image-based reinforcement learning via empirical experiments and examines the critical aspects of incorporating OCRpre-training in RL, including performance in a visually complex environment and the appropriate pooling layer to aggregate the object representations.","ArXiv",2023,"Jaesik Yoon,Yi-Fu Wu,Heechul Bae,Sungjin Ahn",0,47,0
"4bafa3ede603e5d3ad107002e66d0daa23a89741","https://www.semanticscholar.org/paper/4bafa3ede603e5d3ad107002e66d0daa23a89741",3,"Verifying Generalization in Deep Learning","This work puts forth a novel objective for formal verification, with the potential for mitigating the risks associated with deploying DNN-based systems in the wild, and establishes the usefulness of the approach, and, in particular, its superiority over gradient-based methods.","ArXiv",2023,"Guy Amir,O. Maayan,Tom Zelazny,Guy Katz,Michael Schapira",0,117,0
"6a4f1c742e7851ed6c7cb73b3ecf82c460ad0ad2","https://www.semanticscholar.org/paper/6a4f1c742e7851ed6c7cb73b3ecf82c460ad0ad2",3,"Cross-domain Random Pre-training with Prototypes for Reinforcement Learning","CRPTpro is proposed, a Cross-domain self-supervised Random Pre-Training framework with prototypes for image-based RL that employs cross-domain random policy to easily and quickly sample diverse data from multiple domains, to improve pre-training efficiency.","ArXiv",2023,"Xin Liu,Yaran Chen,Haoran Li,Boyu Li,Dong Zhao",0,39,0
"638f7e0c3d1a2cc2c57f2ebcfd7669c0e1993e5f","https://www.semanticscholar.org/paper/638f7e0c3d1a2cc2c57f2ebcfd7669c0e1993e5f",3,"Improving robot navigation in crowded environments using intrinsic rewards","This work proposes using intrinsic rewards to balance between exploration and exploitation and explore depending on the uncertainty of the states instead of on the time the agent has been trained, encouraging the agent to get more curious about unknown states.","",2023,"Diego Martinez-Baselga,L. Riazuelo,L. Montano",0,38,0
"adb68e8d5fa63618fe68127b8963eb0d5016543e","https://www.semanticscholar.org/paper/adb68e8d5fa63618fe68127b8963eb0d5016543e",3,"Learning Hierarchical Resource Allocation and Multi-agent Coordination of 5G mobile IAB Nodes","A hierarchical multi-agent reinforcement with a two-level structure is adopted on in-band relaying networks, which conduct access and backhaul links on the same frequency band with severe constraints on co-channel interference, to address the complex problem of dynamic relay node positioning, user association, andBackhaul capacity allocation.","",2023,"Mohamed Sana,B. Miscopein",0,16,0
"ff106b68484cc45a296390d14bb2cb88b75a1e0d","https://www.semanticscholar.org/paper/ff106b68484cc45a296390d14bb2cb88b75a1e0d",3,"CERiL: Continuous Event-based Reinforcement Learning","This paper presents a method to train on event streams derived from standard RL environments, thereby solving the proposed continuous time RL problem and shows the advantages of event streams over less-frequent RGB images.","",2023,"Celyn Walters,Simon Hadfield",0,16,0
"74dd51db773ea883d9804d1845345a46ab908ccd","https://www.semanticscholar.org/paper/74dd51db773ea883d9804d1845345a46ab908ccd",3,"A Task-Agnostic Regularizer for Diverse Subpolicy Discovery in Hierarchical Reinforcement Learning","A task-agnostic regularizer for learning diverse subpolicies in HRL is proposed that can improve upon the state-of-the-art performance on all three HRL domains without modifying any existing hyperparameters, indicating the wide applicability and robustness of the approach.","IEEE Transactions on Systems, Man, and Cybernetics: Systems",2023,"Liangyu Huo,Zulin Wang,Mai Xu,Yuhang Song",0,41,0
"03da1b6759f70c10e49b33a0ee914cb893d6f949","https://www.semanticscholar.org/paper/03da1b6759f70c10e49b33a0ee914cb893d6f949",3,"Learning Algebraic Representation for Systematic Generalization in Abstract Reasoning","This work showcases a prototype with algebraic representation for the abstract spatial-temporal reasoning task of Raven’s Progressive Matrices and presents the ALgebra-Aware Neuro-Semi-Symbolic (ALANS) learner, a hybrid approach to improve systematic generalization in reasoning.","European Conference on Computer Vision",2021,"Chi Zhang,Sirui Xie,Baoxiong Jia,Y. Wu,Song-Chun Zhu,Yixin Zhu",3,80,0
"6c1f6ede9b786e1ffdaab91bf346817f61706912","https://www.semanticscholar.org/paper/6c1f6ede9b786e1ffdaab91bf346817f61706912",3,"Reinforcement-Learning-Guided Source Code Summarization Using Hierarchical Attention","This paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows into a deep reinforcement learning (DRL) framework for comment generation.","IEEE Transactions on Software Engineering",2022,"Wenhua Wang,Yuqun Zhang,Yulei Sui,Yao Wan,Zhou Zhao,Jian Wu,Philip S. Yu,Guandong Xu",50,97,4
"f4159f7eadf44d4bdebff486f008797f5225bf14","https://www.semanticscholar.org/paper/f4159f7eadf44d4bdebff486f008797f5225bf14",3,"Beyond the Policy Gradient Theorem for Efficient Policy Updates in Actor-Critic Algorithms","This paper discovers that the policy gradient theorem prescribes policy updates that are slow to unlearn because of their structural symmetry with respect to the value target, and introduces a modiﬁed policy update devoid of that symmetry, and proves its guarantees of convergence to global optimality in O ( t − 1 ) under classic assumptions.","International Conference on Artificial Intelligence and Statistics",2022,"R. Laroche,R. Tachet",2,45,0
"06b10851b7a53316b3b6588017c9f3b9aae8c7cb","https://www.semanticscholar.org/paper/06b10851b7a53316b3b6588017c9f3b9aae8c7cb",3,"Hierarchical Reinforcement Learning: A Survey and Open Research Challenges","This survey paper introduces a selection of problem-specific approaches, which provided insight in how to utilize often handcrafted abstractions in specific task settings, and introduces the Options framework, which provides a more generic approach, allowing abstractions to be discovered and learned semi-automatically.","Machine Learning and Knowledge Extraction",2022,"Matthias Hutsebaut-Buysse,Kevin Mets,S. Latré",7,257,0
"583f317cca19be32a7dc0d5378ad6725ad43e91b","https://www.semanticscholar.org/paper/583f317cca19be32a7dc0d5378ad6725ad43e91b",3,"A Survey on Reinforcement Learning Methods in Character Animation","This paper surveys the modern Deep Reinforcement Learning methods and discusses their possible applications in Character Animation, from skeletal control of a single, physically‐based character to navigation controllers for individual agents and virtual crowds, and describes the practical side of training DRL systems.","Computer graphics forum (Print)",2022,"Ariel Kwiatkowski,Eduardo Alvarado,Vicky S. Kalogeiton,C. K. Liu,Julien Pettr'e,M. V. D. Panne,Marie-Paule Cani",4,141,0
"6274b8a642bde8ab24e71a26fcb361982f5b1543","https://www.semanticscholar.org/paper/6274b8a642bde8ab24e71a26fcb361982f5b1543",3,"Strategic Maneuver and Disruption with Reinforcement Learning Approaches for Multi-Agent Coordination","","The Journal of Defence Modeling and Simulation: Applications, Methodology, Technology",2022,"Derrik E. Asher,Anjon Basak,Rolando Fernandez,P. Sharma,Erin G. Zaroukian,Christopher D. Hsu,M. Dorothy,Thomas Mahre,Gerardo Galindo,Luke Frerichs,J. Rogers,J. Fossaceca",1,61,0
"4203aad01afe1dadab9d35845ae89b74a99fb2eb","https://www.semanticscholar.org/paper/4203aad01afe1dadab9d35845ae89b74a99fb2eb",3,"Efficient Bayesian Policy Reuse with a Scalable Observation Model in Deep Reinforcement Learning","An improved BPR method is proposed to achieve more efﬁcient policy transfer in deep reinforcement learning (DRL) by expanding the scalable observation model in a plug-and-play fashion, which can avoid negative transfer when faced with new unknown tasks.","ArXiv",2022,"Donghan Xie,Zhi Wang,Chunlin Chen,D. Dong",0,46,0
"1ee71262c4525bca44c6da5b8e1321a67a484953","https://www.semanticscholar.org/paper/1ee71262c4525bca44c6da5b8e1321a67a484953",3,"Dexterous Manipulation for Multi-Fingered Robotic Hands With Reinforcement Learning: A Review","The purpose is to present a comprehensive review of the techniques for dexterous manipulation with multi-fingered robotic hands, such as the model-based approach without learning in early years, and the latest research and methodologies focused on the method based on reinforcement learning and its variations.","Frontiers in Neurorobotics",2022,"Chunmiao Yu,Peng Wang",1,130,0
"447ad78823fbf3369e72e8d1c36467f76f8dc427","https://www.semanticscholar.org/paper/447ad78823fbf3369e72e8d1c36467f76f8dc427",3,"RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning","RamBO is presented, a novel approach to model-based oﬄine RL that addresses the problem as a two-player zero sum game against an adversarial environment model, resulting in a PAC performance guarantee and a pessimistic value function which lower bounds the value function in the true environment.","ArXiv",2022,"Marc Rigter,Bruno Lacerda,N. Hawes",7,84,1
"ba27837c477884223d291da6df43abfced973d04","https://www.semanticscholar.org/paper/ba27837c477884223d291da6df43abfced973d04",3,"Learning Mean Field Games: A Survey","A general framework for classical iterative methods (based on best-response computation or policy evaluation) to solve Mean Field Games in an exact way is presented and how RL can be used to learn MFG solutions in a model-free way is explained.","ArXiv",2022,"M. Laurière,Sarah Perrin,M. Geist,O. Pietquin",7,227,0
"6d846a7601c4be41034b9316d7c256f639085d9f","https://www.semanticscholar.org/paper/6d846a7601c4be41034b9316d7c256f639085d9f",3,"Deep Hierarchical Planning from Pixels","Director is introduced, a practical method for learning hierarchical behaviors directly from pixels by planning inside the latent space of a learned world model, and the decisions are interpretable because the world model can decode goals into images for visualization.","ArXiv",2022,"Danijar Hafner,Kuang-Huei Lee,Ian S. Fischer,P. Abbeel",9,59,0
"44f76721abb22837f73976c021a69714c76943e1","https://www.semanticscholar.org/paper/44f76721abb22837f73976c021a69714c76943e1",3,"Uncertainty Aware Model Integration on Reinforcement Learning","This paper proposes to use the confidence of the model simulations to the integrated learning process so that the agent avoids updating its policy based on uncertain simulations by the model, and applies the Monte Carlo dropout technique to the state transition model.","IEEE International Joint Conference on Neural Network",2022,"Takashi Nagata,Jinwei Xing,Tsutomu Kumazawa,E. Neftci",0,25,0
"2638b7afd079233c7dbce5f389a92edb1d8f3f31","https://www.semanticscholar.org/paper/2638b7afd079233c7dbce5f389a92edb1d8f3f31",3,"Interactive Imitation Learning in Robotics based on Simulations","This thesis implements IIL algorithms in four simulation scenarios and conducts extensive experiments, aiming at providing exhaustive information about IIL methods both in action space and state space as well as comparison with RL methods.","ArXiv",2022,"Xinyi Liu",0,32,0
"cb66cdc34a15ac2819b827a8368db8d0301f906d","https://www.semanticscholar.org/paper/cb66cdc34a15ac2819b827a8368db8d0301f906d",3,"Reinforcement learning in spacecraft control applications: Advances, prospects, and challenges","","Annual Reviews in Control",2022,"M. Tipaldi,R. Iervolino,Paolo Roberto Massenio",5,125,0
"c003663a61b3a210db77200202557805b3d326fa","https://www.semanticscholar.org/paper/c003663a61b3a210db77200202557805b3d326fa",3,"Stochastic cubic-regularized policy gradient method","","Knowledge-Based Systems",2022,"Pengfei Wang,Hongyu Wang,Nenggan Zheng",1,47,1
"728b8f104849432cc2763d0c1c9115e6e5b79b07","https://www.semanticscholar.org/paper/728b8f104849432cc2763d0c1c9115e6e5b79b07",3,"Extracting Relevant Information from User's Utterances in Conversational Search and Recommendation","A model based on reinforcement learning, namely RelInCo, is proposed, which takes the user's utterances and the context of the conversation and classifies each word in the users' utterances as belonging to the relevant or non-relevant class.","Knowledge Discovery and Data Mining",2022,"Ali Montazeralghaem,James Allan",2,47,0
"18a736a92ff5ff214fb91589326da4c1f55453f5","https://www.semanticscholar.org/paper/18a736a92ff5ff214fb91589326da4c1f55453f5",3,"Global Convergence of Two-timescale Actor-Critic for Solving Linear Quadratic Regulator","","ArXiv",2022,"Xuyang Chen,Jingliang Duan,Yingbin Liang,Lin Zhao",1,65,0
"a08752bbc4abef0e70e7f61a296990ce58609cd6","https://www.semanticscholar.org/paper/a08752bbc4abef0e70e7f61a296990ce58609cd6",3,"Deep Anomaly Detection and Search via Reinforcement Learning","This paper proposes Deep Anomaly Detection and Search (DADS), which applies Reinforcement Learning (RL) to bal- ance exploitation and exploration of labeled data and under-exploration of unlabeled data and shows that DADS can efﬁciently and precisely search anomalies from unlabeling data and learn from them, thus achieving good performance.","ArXiv",2022,"Chao Chen,Dawei Wang,Feng Mao,Zongzhang Zhang,Yang Yu",0,38,0
"68e305ee1e80a4750c16b2cdd52658f005e09009","https://www.semanticscholar.org/paper/68e305ee1e80a4750c16b2cdd52658f005e09009",3,"Survey on Machine Learning for Traffic-Driven Service Provisioning in Optical Networks","This survey provides a comprehensive review of the state of the art on machine learning (ML)-based techniques at the optical layer for trafﬁc-driven service provisioning.","ArXiv",2022,"T. Panayiotou,M. Michalopoulou,G. Ellinas",0,180,0
"93ecc6fef75a3254bd800a97c0bb05515884d686","https://www.semanticscholar.org/paper/93ecc6fef75a3254bd800a97c0bb05515884d686",3,"An Adaptive Threshold for the Canny Edge Detection with Actor-Critic Algorithm","A spatio-temporal fusion network (STFN) that could extract temporal and spatial information using a temporal network and a spatial network is proposed that shows excellent performance in an environment different from training and is shown through experiments with various public datasets.","ArXiv",2022,"Keong-Hun Choi,J. Ha",0,41,0
"6590ff0c6ac7fcb51a55e19b13913dc31eaebcb5","https://www.semanticscholar.org/paper/6590ff0c6ac7fcb51a55e19b13913dc31eaebcb5",3,"Deep reinforcement learning for automated search of model parameters: photo-fenton wastewater disinfection case study","This work presents a proximal policy optimization agent that learns to optimize in a real case study such as the modeling of the photo-fenton disinfection process, which involves a number of parameters that have to be adjusted to minimize the error of the model with respect to the experimental data collected in several trials.","Neural computing & applications (Print)",2022,"S. Hernández-García,Alfredo Cuesta-Infante,José Moreno-SanSegundo,A. S. Montemayor",0,51,0
"3f50fd0db14f42da5a27c62bc29c8e14264981a0","https://www.semanticscholar.org/paper/3f50fd0db14f42da5a27c62bc29c8e14264981a0",3,"Pareto Actor-Critic for Equilibrium Selection in Multi-Agent Reinforcement Learning","","ArXiv",2022,"Filippos Christianos,Georgios Papoudakis,Stefano V. Albrecht",2,31,1
"84de39c1e7f3f2652b5704648ff06ca301342f71","https://www.semanticscholar.org/paper/84de39c1e7f3f2652b5704648ff06ca301342f71",3,"Reward Shaping for User Satisfaction in a REINFORCE Recommender","This work proposes to jointly learn a policy network and a satisfaction imputation network, postulate that reward shaping in RL recommender agents is powerful for driving satisfying user experiences, and uses both ofﬂine analysis and live experiments in an industrial large-scale recommendation platform to demonstrate the promise.","ArXiv",2022,"Konstantina Christakopoulou,Can Xu,Sai Zhang,Sriraj Badam,Trevor Potter,Daniel Li,Hao Wan,Xinyang Yi,Ya Le,Chris Berg,E. B. Dixon,Ed H. Chi,Minmin Chen",1,35,0
"93d628899dc7389c97f20c1214d9af963d28055f","https://www.semanticscholar.org/paper/93d628899dc7389c97f20c1214d9af963d28055f",3,"An End-to-End Curriculum Learning Approach for Autonomous Driving Scenarios","This work combines Curriculum Learning with Deep Reinforcement Learning to learn without any prior domain knowledge, an end-to-end competitive driving policy for the CARLA autonomous driving simulator, and is the first to provide consistent results of the driving policy on all towns available in CARLA.","IEEE transactions on intelligent transportation systems (Print)",2022,"Luca Anzalone,Paola Barra,Silvio Barra,Aniello Castiglione,M. Nappi",1,44,0
"2df437fe675c89a00dc0a7c3a31fa46ed3d94c9d","https://www.semanticscholar.org/paper/2df437fe675c89a00dc0a7c3a31fa46ed3d94c9d",3,"A Video Summarization Model Based on Deep Reinforcement Learning with Long-Term Dependency","This paper introduces an unsupervised auxiliary summarization loss module with LSTM and a swish activation function to capture the long-term dependencies for video summarization, which can be easily integrated with various networks.","Italian National Conference on Sensors",2022,"Xu Wang,Yujie Li,Haoyu Wang,Longzhao Huang,Shuxue Ding",0,61,0
"e0baf5c65a4913fc6e0b6b56be848def11867f47","https://www.semanticscholar.org/paper/e0baf5c65a4913fc6e0b6b56be848def11867f47",3,"Deep Intrinsically Motivated Exploration in Continuous Control","This paper adapt the existing theories on animal motivational systems into the reinforcement learning paradigm and introduces a novel and scalable directed exploration strategy that extends to larger and more diverse state spaces, dramatically improves the baselines, and outperforms the undirected strategies.","ArXiv",2022,"Baturay Saglam,S. Kozat",1,47,0
"57c04d33366a8c7d797cd413efa5d263131c2fb8","https://www.semanticscholar.org/paper/57c04d33366a8c7d797cd413efa5d263131c2fb8",3,"Policy Gradients for Probabilistic Constrained Reinforcement Learning","This work relates this notion of safety to the notion of average safety often considered in the literature by providing theoretical bounds in terms of their safety and performance by considering a continuous navigation problem to empirically illustrate the advantages of working with probabilistic constraints as compared to average constraints.","ArXiv",2022,"Weiqin Chen,D. Subramanian,Santiago Paternain",0,41,0
"c2bd6bf1c2250561f954a04a7061f6d6bf9ff855","https://www.semanticscholar.org/paper/c2bd6bf1c2250561f954a04a7061f6d6bf9ff855",3,"Faster Last-iterate Convergence of Policy Optimization in Zero-Sum Markov Games","This paper focuses on the most basic setting of competitive multi-agent RL, namely two-player zero-sum Markov games, and proposes a single-loop policy optimization method with symmetric updates from both agents, which achieves a last-iterate linear convergence to the quantal response equilibrium of the regularized problem.","ArXiv",2022,"Shicong Cen,Yuejie Chi,S. Du,Lin Xiao",7,59,0
"61d56ece2d19f4bfeb322c92085fb28521e169da","https://www.semanticscholar.org/paper/61d56ece2d19f4bfeb322c92085fb28521e169da",3,"Neural-Symbolic Recursive Machine for Systematic Generalization","The proposed Neural-Symbolic Recursive Machine (NSR) demonstrates stronger generalization than pure neural networks due to its symbolic representation and inductive biases, and demonstrates better transferability than existing neural-symbolic approaches due to less domain-speciﬁc knowledge required.","ArXiv",2022,"Qing Li,Yixin Zhu,Yitao Liang,Y. Wu,Song-Chun Zhu,Siyuan Huang",0,48,0
"090657e0c4369380c762b2bdffe3c92449015c76","https://www.semanticscholar.org/paper/090657e0c4369380c762b2bdffe3c92449015c76",3,"Scaling up stochastic gradient descent for non-convex optimisation","A unified distributed and parallel implementation of SGD (named DPSGD) that relies on both asynchronous distribution and lock-free parallelism is proposed by combining two strategies into a unified framework, able to strike a better trade-off between local computation and communication.","Machine-mediated learning",2022,"S. Mohamad,Hamad Alamri,A. Bouchachia",0,80,0
"0830ff278815709600f249ed488ffe3718e6f7a1","https://www.semanticscholar.org/paper/0830ff278815709600f249ed488ffe3718e6f7a1",3,"Optimal Action Space Search: An Effective Deep Reinforcement Learning Method for Algorithmic Trading","This paper proposes an end-to-end DRL method that explores solutions on the whole graph via a probabilistic dynamic programming algorithm and can generate stable trading strategies for both high-frequency and low-frequency trading, significantly outperforming the baseline DRL methods on annualized return and Sharpe ratio.","International Conference on Information and Knowledge Management",2022,"Zhongjie Duan,Cen Chen,Dawei Cheng,Yuqi Liang,Weining Qian",0,51,0
"3be669b4156e8247c3082ca2afb2c29041e0e930","https://www.semanticscholar.org/paper/3be669b4156e8247c3082ca2afb2c29041e0e930",3,"On the convergence of policy gradient methods to Nash equilibria in general stochastic games","This work examines the long-run behavior of policy gradient methods with respect to Nash equilibrium policies that are second-order stationary and shows that SOS policies are locally attracting with high probability, and that policy gradient trajectories with gradient estimates provided by the Reinforce algorithm achieve an O (1 / √ n ) distance-squared convergence rate if the method’s step-size is chosen appropriately.","ArXiv",2022,"Angeliki Giannou,Kyriakos Lotidis,P. Mertikopoulos,Emmanouil-Vasileios Vlatakis-Gkaragkounis",0,61,0
"44918fd3ddd5eb3b48b86a0f6bff4007957443ab","https://www.semanticscholar.org/paper/44918fd3ddd5eb3b48b86a0f6bff4007957443ab",3,"Finite-time analysis of single-timescale actor-critic","This analysis develops a novel framework that evaluates and controls the error propagation between actor and critic in a systematic way and compares favorably to the existing literature on analyzing actor-critic in terms of considering the most practical settings and requiring weaker assumptions.","ArXiv",2022,"Xuyang Chen,Lin Zhao",1,37,0
"df46d3985445ed5a0ed46782e191223796c37c58","https://www.semanticscholar.org/paper/df46d3985445ed5a0ed46782e191223796c37c58",3,"Krylov-Bellman boosting: Super-linear policy evaluation in general state spaces","The Krylov–Bellman Boosting algorithm alternates between boosting the Bellman residual using non-parametric regression, and estimating the value function via the least-squares temporal diﬀerence procedure applied with a feature set that grows adaptively over time.","ArXiv",2022,"Eric Xia,M. Wainwright",0,70,0
"bfa97f55991cdf42f65e9607d47a34a86180b2e9","https://www.semanticscholar.org/paper/bfa97f55991cdf42f65e9607d47a34a86180b2e9",3,"A Bibliometric Analysis and Review on Reinforcement Learning for Transportation Applications","A bibliometric analysis is conducted to identify the development of RL-based methods for transportation applications, typical journals/conferences, and leading topics in the industry in recent ten years by categorizing methods with respect to the application domains.","ArXiv",2022,"Can Li,Lei Bai,L. Yao,S. Waller,Wei Liu",0,173,0
"339550fa989a2d7000fce319a3af68704fd6d289","https://www.semanticscholar.org/paper/339550fa989a2d7000fce319a3af68704fd6d289",3,"Towards High-Quality CGRA Mapping with Graph Neural Networks and Reinforcement Learning","This paper integrates the routing explorations into the mapping process and makes it have more opportunities to find a globally optimized solution, and introduces graph neural network based reinforcement learning to predict a placement distribution over different resource nodes for all operations in a DDG.","International Conference on Computer Aided Design",2022,"Yan Zhuang,Zhihao Zhang,Dajiang Liu",0,23,0
"f0d8b48343ed0a7b503899a8191bbe501641f5b1","https://www.semanticscholar.org/paper/f0d8b48343ed0a7b503899a8191bbe501641f5b1",3,"Solving non-permutation flow-shop scheduling problem via a novel deep reinforcement learning approach","","Computers & Operations Research",2022,"Zhenyu Wang,Bin Cai,Jun Yu Li,Deheng Yang,Yang Zhao,Huan Xie",0,41,0
"8faa5de0401ff49eda52f15c7b7d4da9bc78cf23","https://www.semanticscholar.org/paper/8faa5de0401ff49eda52f15c7b7d4da9bc78cf23",3,"Deep reinforcement learning-based critical element identification and demolition planning of frame structures","It is proved that the Q values produced by the reinforcement learning agent can make up for the deficiencies of existing indices, and can be directly used as the quantitative index for the decision-making for determining the most expected collapse scenario, i.e., the sequence of element removals.","Frontiers of Structural and Civil Engineering",2022,"Shaojun Zhu,M. Ohsaki,Kazuki Hayashi,Shaohan Zong,Xiao Guo",0,61,0
"dfdada90e09ca1b17b4c72362f833dc3f8d7f29a","https://www.semanticscholar.org/paper/dfdada90e09ca1b17b4c72362f833dc3f8d7f29a",3,"Connecting Stochastic Optimal Control and Reinforcement Learning","This article connects the optimal control problem to reinforcement learning since both share the same underlying framework namely a Markov decision process (MDP) and shows how the MDP can be formulated for the optimal Control problem.","",2022,"J. Quer,Enric Ribera Borrell",0,47,0
"65ca4c3768bc98ccf6a4676467fc443bad7ce7bf","https://www.semanticscholar.org/paper/65ca4c3768bc98ccf6a4676467fc443bad7ce7bf",3,"Designing mechanically tough graphene oxide materials using deep reinforcement learning","The present research showcases the impact of functional group distribution on GO properties, and illustrates the effectiveness and data efficiency of the deep RL approach to design mechanically tough GOs.","npj Computational Materials",2022,"Bowen Zheng,Zeyu Zheng,Grace X. Gu",0,53,0
"47d4c14cc0878841febeeed5b3ee46a4a44e566f","https://www.semanticscholar.org/paper/47d4c14cc0878841febeeed5b3ee46a4a44e566f",3,"Graph Reinforcement Learning Application to Co-operative Decision-Making in Mixed Autonomy Traffic: Framework, Survey, and Challenges","Results show that the GRL methods can well optimize the performance of multi-agent decision-making for CAVs in mixed autonomy trafﬁc compared to the DRL methods.","ArXiv",2022,"Qi Liu,Xueyuan Li,Zirui Li,Jingda Wu,Guodong Du,Xinlu Gao,Fan Yang,Shihua Yuan",0,110,0
"ede0f8aedce15acf87f207431268a17ba5bcb206","https://www.semanticscholar.org/paper/ede0f8aedce15acf87f207431268a17ba5bcb206",3,"GreenDRL: managing green datacenters using deep reinforcement learning","This work design and evaluate GreenDRL, a system that combines a deep RL agent with simple heuristics to manage workload, energy consumption, and cooling in the presence of onsite generation of renewable energy to minimize brown energy consumption and cost and shows that deep RL is a promising technique for building efficient management systems for green datacenters.","ACM Symposium on Cloud Computing",2022,"Kuo Zhang,Peijian Wang,Ning Gu,Thu D. Nguyen",0,45,0
"d49c110efd463d6096e0a6cf05b3ea3e49588a4b","https://www.semanticscholar.org/paper/d49c110efd463d6096e0a6cf05b3ea3e49588a4b",3,"A Unified Mutual Supervision Framework for Referring Expression Segmentation and Generation","A unified mutual supervision framework that enables two tasks to improve each other by solving their bottleneck problems is proposed and significantly outperforms all existing methods on REG and RES tasks under the same setting.","ArXiv",2022,"Shijia Huang,Feng Li,Hao Zhang,Siyi Liu,Lei Zhang,Liwei Wang",0,68,0
"1e245b05a218fb0b555bc6883983b649b82310cc","https://www.semanticscholar.org/paper/1e245b05a218fb0b555bc6883983b649b82310cc",3,"A Deep Reinforcement Learning Framework for Multi-Stage Optimized Object Detection","An optimized method upon a deep reinforcement learning framework along with multi-stage approaches for object detection as well as train two intelligent agents for a more accurate search of objects and localize them in images is proposed.","International Conference on Robotics and Mechatronics",2022,"Sobhan Siamak,E. Mansoori",0,38,0
"1029f62fb8f895a62695c0c08812221527e5bc5f","https://www.semanticscholar.org/paper/1029f62fb8f895a62695c0c08812221527e5bc5f",3,"Debiasing Meta-Gradient Reinforcement Learning by Learning the Outer Value Function","This paper identifies a bias in the meta-gradient of current meta- gradient RL approaches, and proposes a simple solution to eliminate this bias by using an alternative, outer value function in the estimation of the outer loss.","ArXiv",2022,"Clément Bonnet,L. Midgley,Alexandre Laterre",1,29,0
"c59aaa7eccc125c82488243a71e7840cede38032","https://www.semanticscholar.org/paper/c59aaa7eccc125c82488243a71e7840cede38032",3,"Transfer RL via the Undo Maps Formalism","This work characterizes the discrepancy in environments by means of (potentially complex) transformation between their state spaces, and thus posing the problem of transfer as learning to undo this transformation, and introduces a novel optimization objective based on an optimal transport distance between two distributions over trajectories.","ArXiv",2022,"Abhi Gupta,Theodore H. Moskovitz,David Alvarez-Melis,Aldo Pacchiano",0,26,0
"6faf5f82a546a28f0575a473b01df4f758c350d7","https://www.semanticscholar.org/paper/6faf5f82a546a28f0575a473b01df4f758c350d7",3,"Reinforcement Learning for Multi-Truck Vehicle Routing Problems","This work develops new extensions to encoder-decoder models for vehicle routing that allow for complex supply chains and shows how the model, even if trained only for a small number of trucks, can be embedded into a large supply chain to yield viable solutions.","ArXiv",2022,"R. Correll,Sean J. Weinberg,F. Sanches,T. Ide,Takafumi Suzuki",1,15,0
"61760432c8af40c57a4dea0e7e40e2d866140e01","https://www.semanticscholar.org/paper/61760432c8af40c57a4dea0e7e40e2d866140e01",3,"An Energy-aware, Fault-tolerant, and Robust Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems","A distributed homogeneous multi-agent architecture is proposed, where all patrolling agents execute identical policies locally based on their local observations and shared information that provides a fault-tolerant and robust patrolling system that can tolerate agent failures and allow supplementary agents to be added to replace failed agents or to increase the overall patrol performance.","",2022,"Chenhao Tong,A. Harwood,M. A. Rodriguez,R. Sinnott",0,36,0
"2667a8960c1f07e57729cddfe91bca10ce6a4979","https://www.semanticscholar.org/paper/2667a8960c1f07e57729cddfe91bca10ce6a4979",3,"Multi-Agent Patrolling with Battery Constraints through Deep Reinforcement Learning","This work proposes an approach based on a distributed, model-free deep reinforcement learning based multi-agent patrolling strategy that provides a robust patrolling system that can tolerate agent failures and allow supplementary agents to be added to replace failed agents or to increase the overall patrol performance.","ArXiv",2022,"Chenhao Tong,A. Harwood,Maria A. Rodriguez,R. Sinnott",0,37,0
"5b4919511da477630737174fa988101d598bf09d","https://www.semanticscholar.org/paper/5b4919511da477630737174fa988101d598bf09d",3,"Risk-Sensitive Reinforcement Learning with Exponential Criteria","This work studies the effect of exponential criteria on the risk-sensitivity of the policy of a reinforcement learning agent, and develops variants of the Monte Carlo Policy Gradient algorithm and the online (temporal-difference) Actor-Critic algorithm.","ArXiv",2022,"Erfaun Noorani,Christos N. Mavridis,J. Baras",1,59,0
"8a195693047aa27b58924241d2da706cf41d62a3","https://www.semanticscholar.org/paper/8a195693047aa27b58924241d2da706cf41d62a3",3,"Annotated History of Modern AI and Deep Learning","The history of modern artificial intelligence (AI) which is dominated by artificial neural networks (NNs) and deep learning, both conceptually closer to the old field of cybernetics than to what's been called AI since 1956 is focused on.","ArXiv",2022,"Juergen Schmidhuber",0,468,0
"dd4a3b4ec42de0a46d16a49a4375723996f5f6fd","https://www.semanticscholar.org/paper/dd4a3b4ec42de0a46d16a49a4375723996f5f6fd",3,"Stock Market Prediction via Deep Learning Techniques: A Survey","This poster presents a probabilistic procedure to identify the neurons in the brain that secrete During the Yangtze River blackout, a process known as “red-plating”.","",2022,"Jinan Zou,Qi Zhao,Yang Jiao,Hai Cao,Yanxi Liu,Qingsen Yan,Ehsan Abbasnejad,Lingqiao Liu,Javen Qinfeng Shi",0,162,0
"7cf43ee9ab155834aed3dc8e3429128783090705","https://www.semanticscholar.org/paper/7cf43ee9ab155834aed3dc8e3429128783090705",3,"Variance Reduction for Score Functions Using Optimal Baselines","","ArXiv",2022,"Ronan Keane,H. Gao",0,19,0
"aa118b8e6e31457bc2c3de895a1e298b381a3428","https://www.semanticscholar.org/paper/aa118b8e6e31457bc2c3de895a1e298b381a3428",3,"Learning One Abstract Bit at a Time Through Self-Invented Experiments Encoded as Neural Networks","An empirical analysis of the automatic generation of interesting experiments is presented and it is shown that self-invented experiments in a reinforcement-providing environment and show that they lead to effective exploration.","ArXiv",2022,"Vincent Herrmann,Louis Kirsch,J. Schmidhuber",0,87,0
"ea02c73891d267c21e937f4bcfaaef4f623f2e08","https://www.semanticscholar.org/paper/ea02c73891d267c21e937f4bcfaaef4f623f2e08",3,"MR-Selection: A Meta-Reinforcement Learning Approach for Zero-Shot Hyperspectral Band Selection","A novel zero-shot band selection method, called MR-Selection, is proposed for HSI classification, which formalizes zero- shot band selection as a metalearning problem, where advantage actor–critic algorithm-based reinforcement learning (A2C-RL) is designed to extract the metaknowledge in the band selection tasks of various seen hyperspectral datasets through a shared agent.","IEEE Transactions on Geoscience and Remote Sensing",2023,"Jie Feng,Gaiqin Bai,Di Li,Xiangrong Zhang,Ronghua Shang,Licheng Jiao",0,56,0
"4210f34f30ae38de65c199a6bd9d3875ba5bbd30","https://www.semanticscholar.org/paper/4210f34f30ae38de65c199a6bd9d3875ba5bbd30",3,"A N E NERGY - AWARE , F AULT - TOLERANT , AND R OBUST D EEP R EINFORCEMENT L EARNING BASED APPROACH FOR M ULTI - AGENT P ATROLLING P ROBLEMS","A distributed homogeneous multi-agent architecture is proposed, where all patrolling agents execute identical policies locally based on their local observations and shared information that provides a fault-tolerant and robust patrolling system that can tolerate agent failures and allow supplementary agents to be added to replace failed agents or to increase the overall patrol performance.","",,"",0,0,0
"58ed7613df5b9f5a425e31bcbecb885e4d2d18c6","https://www.semanticscholar.org/paper/58ed7613df5b9f5a425e31bcbecb885e4d2d18c6",3,"Tensor networks for unsupervised machine learning","","Physical Review E",2021,"Jing Liu,Sujie Li,Jiang Zhang,Pan Zhang",7,48,0
"9f4f1b5559155e88d141f804770314e7098264f0","https://www.semanticscholar.org/paper/9f4f1b5559155e88d141f804770314e7098264f0",3,"Interpretable Learned Emergent Communication for Human-Agent Teams","This work develops agent-only teams that communicate sparsely via the scheme of Enforcers that enables high agent- only and human-agent team performance and develops a prototype-based method that produces meaningful discrete tokens that enable human partners to learn agent communication faster and better than a one-hot baseline.","IEEE Transactions on Cognitive and Developmental Systems",2022,"Seth Karten,Mycal Tucker,Huao Li,Siva Kailas,Michael Lewis,K. Sycara",1,50,0
"60d6e0ed45ce062bd6dddc7a5ce48718c075f9a5","https://www.semanticscholar.org/paper/60d6e0ed45ce062bd6dddc7a5ce48718c075f9a5",3,"Opportunities for reinforcement learning in stochastic dynamic vehicle routing","","Computers & Operations Research",2022,"F. D. Hildebrandt,Barrett W. Thomas,Marlin W. Ulmer",1,79,0
"4100c4690bd90c46bd292d08699071b04cc5107b","https://www.semanticscholar.org/paper/4100c4690bd90c46bd292d08699071b04cc5107b",3,"Deep reinforcement learning for irrigation scheduling using high-dimensional sensor feedback","A general framework and actionable procedure is proposed that allow researchers to formulate their own optimisation problems and implement solution algorithms based on deep reinforcement learning and is applicable to a wide range of cropping systems with realistic Optimisation problems.","ArXiv",2023,"Yuji Saikai,A. Peake,K. Chenu",0,34,0
"3e224b785aae67e0bd4277adbec9bbf063b9f303","https://www.semanticscholar.org/paper/3e224b785aae67e0bd4277adbec9bbf063b9f303",3,"DeepDLP: Deep Reinforcement Learning based Framework for Dynamic Liner Trade Pricing","A Deep Reinforcement Learning (RL) Framework for Liner Trade Problem (DeepDLP) to identify price strategy based on the characteristics of liner trade environment is designed and the outcome shows that DeepDLP outperforms baselines and validates the significance of the designs.","International Conference on Ubiquitous Information Management and Communication",2023,"Xue Li,Yongyi Hu,Yumeng Bai,Xiaofeng Gao,Guihai Chen",0,23,0
"35c4531a6466ccfb6505a6298c080d5260a93f04","https://www.semanticscholar.org/paper/35c4531a6466ccfb6505a6298c080d5260a93f04",3,"Learning to View: Decision Transformers for Active Object Detection","This paper uses reinforcement learning (RL) methods to control the robot in order to obtain images that maximize the detection quality and provides exhaustive analyses of the reward distribution and observation space.","ArXiv",2023,"Wenhao Ding,Nathalie Majcherczyk,Mohit Deshpande,Xuewei Qi,Ding Zhao,R. Madhivanan,Arnie Sen",0,35,0
"967a9a1a70c81a3d2118c55b08d080776559db43","https://www.semanticscholar.org/paper/967a9a1a70c81a3d2118c55b08d080776559db43",3,"Approximating Nash equilibrium for anti-UAV jamming Markov game using a novel event-triggered multi-agent reinforcement learning.","A novel event-triggered multi-agent proximal policy optimization algorithm with Beta strategy (ETMAPPO) is proposed in this paper, which aims to reduce the dimension of information transmission and improve the efficiency of policy convergence.","Neural Networks",2023,"Zikai Feng,Mengxing Huang,Yuanyuan Wu,Di Wu,Jinde Cao,I. Korovin,Sergey Gorbachev,N. Gorbacheva",0,35,0
"6ca1057501f8c2ac06d068cf9f1a8a984f87f60f","https://www.semanticscholar.org/paper/6ca1057501f8c2ac06d068cf9f1a8a984f87f60f",3,"Two-Stage Constrained Actor-Critic for Short Video Recommendation","This paper formulate the problem of short video recommendation as a Constrained Markov Decision Process (CMDP) and proposes a novel two-stage constrained actor-critic method, which significantly outperforms other baselines in terms of both watch time and interactions.","ArXiv",2023,"Qingpeng Cai,Zhenghai Xue,Chi Zhang,Wanqi Xue,Shuchang Liu,Ruohan Zhan,Xueliang Wang,Tianyou Zuo,Wentao Xie,Dong Zheng,Peng Jiang,Kun Gai",1,49,0
"069553a928fb2e5c40200e8763b148ea35d00973","https://www.semanticscholar.org/paper/069553a928fb2e5c40200e8763b148ea35d00973",3,"A Comparison of Reinforcement Learning and Deep Trajectory Based Stochastic Control Agents for Stepwise Mean-Variance Hedging","","",2023,"Ali Fathi,B. Hientzsch",0,49,0
"faeb99b4ef2d6040ec4c7ee053a07918c1cead97","https://www.semanticscholar.org/paper/faeb99b4ef2d6040ec4c7ee053a07918c1cead97",3,"BERT Embeddings Can Track Context in Conversational Search","This work used a Transformer-based re-ranking method and expanded this architecture to use the conversational context and showed the advantages of using the context present in the natural language utterances and in the neural embeddings generated throughout the conversation.","ArXiv",2021,"Rafael Ferreira,David Semedo,João Magalhães",0,39,0
"656165e23c99097cd61d23f660cab480b85fd20d","https://www.semanticscholar.org/paper/656165e23c99097cd61d23f660cab480b85fd20d",3,"Open-domain conversational search assistants: the Transformer is all you need","This work proposes a complete open-domain abstractive conversational search agent pipeline to address two major challenges: first, conversation context-aware search and second, abstractive search-answers generation.","Information Retrieval Journal",2022,"Rafael Ferreira,Mariana Leite,David Semedo,João Magalhães",1,64,0
"0d2c76843f43d6f7219c7c3ad69a17beac19205b","https://www.semanticscholar.org/paper/0d2c76843f43d6f7219c7c3ad69a17beac19205b",3,"Conversational Entity Linking: Problem Definition and Datasets","This paper analyzes a large number of dialogues from existing conversational datasets and annotates references to concepts, named entities, and personal entities using crowdsourcing to identify the main characteristics of conversational entity linking.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2021,"Hideaki Joko,Faegheh Hasibi,K. Balog,A. D. Vries",8,63,0
"44be4baa91754c7e738d0bee828dd88d7042e2ee","https://www.semanticscholar.org/paper/44be4baa91754c7e738d0bee828dd88d7042e2ee",3,"DialDoc 2022 Shared Task: Open-Book Document-grounded Dialogue Modeling","The paper presents the results of the Shared Task hosted by the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering co-located at ACL 2022, to build goal-oriented information-seeking conversation systems that are grounded in the domain documents.","Workshop on Document-grounded Dialogue and Conversational Question Answering",2022,"Song Feng,S. Patel,H. Wan",1,24,0
"da402a19b509405c7c83f052a5bb7f86159cc586","https://www.semanticscholar.org/paper/da402a19b509405c7c83f052a5bb7f86159cc586",3,"Embedding-based Zero-shot Retrieval through Query Generation","This work considers the embedding-based two-tower architecture as the neural retrieval model and proposes a novel method for generating synthetic training data for retrieval, which produces remarkable results, significantly outperforming BM25 on 5 out of 6 datasets tested.","ArXiv",2020,"Davis Liang,Peng Xu,Siamak Shakeri,C. D. Santos,Ramesh Nallapati,Zhiheng Huang,Bing Xiang",20,43,2
"e30514dd14a6f150ee96f5d0f8e238bd5662168a","https://www.semanticscholar.org/paper/e30514dd14a6f150ee96f5d0f8e238bd5662168a",3,"Using the Hammer Only on Nails: A Hybrid Method for Evidence Retrieval for Question Answering","This work uses a routing classifier that learns when to direct incoming questions to BM25 vs. USE-QA for evidence retrieval using very simple statistics, which can be efficiently extracted from the top candidate evidence sentences produced by a BM25 model.","ArXiv",2020,"Zhengzhong Liang,Yiyun Zhao,M. Surdeanu",0,30,0
"be68cd5d7f14e0b735cd5e9ab0c9e99c3ce290c9","https://www.semanticscholar.org/paper/be68cd5d7f14e0b735cd5e9ab0c9e99c3ce290c9",3,"RECONSIDER: Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering","A simple and effective re-ranking approach (RECONSIDER) for span-extraction tasks, that improves upon the performance of large pre-trained MRC models, and achieves a new state of the art on four QA tasks.","ArXiv",2020,"Srini Iyer,Sewon Min,Yashar Mehdad,Wen-tau Yih",12,23,0
"15f6bf7a9eae8890e7cff47bbc2483a77a5d7e9f","https://www.semanticscholar.org/paper/15f6bf7a9eae8890e7cff47bbc2483a77a5d7e9f",3,"Neural Passage Retrieval with Improved Negative Contrast","The effects of negative sampling in dual encoder models used to retrieve passages for automatic question answering are explored and a new state-of-the-art level of performance is established on two of the open-domain question answering datasets that are evaluated.","ArXiv",2020,"Jing Lu,Gustavo Hernández Ábrego,Ji Ma,Jianmo Ni,Yinfei Yang",19,32,3
"68d6fcf840a4112914f808bdb721aefc0cabeb6b","https://www.semanticscholar.org/paper/68d6fcf840a4112914f808bdb721aefc0cabeb6b",3,"Context-Aware Answer Extraction in Question Answering","With experiments on reading comprehension, it is shown that BLANC outperforms the state-of-the-art QA models, and the performance gap increases as the number of answer text occurrences increases.","Conference on Empirical Methods in Natural Language Processing",2020,"Yeon Seonwoo,Ji-Hoon Kim,Jung-Woo Ha,Alice H. Oh",11,24,1
"11adf5397466ecbec178f01ef644143d43138d09","https://www.semanticscholar.org/paper/11adf5397466ecbec178f01ef644143d43138d09",3,"Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text","A novel reading comprehension model KMQA is proposed, which can fully exploit the structural medical knowledge and the reference medical plain text and passes the exam with 61.8% accuracy rate on the test set.","Conference on Empirical Methods in Natural Language Processing",2020,"Dongfang Li,Baotian Hu,Qingcai Chen,Weihua Peng,Anqi Wang",20,53,7
"436364d3acec28652f6b48ccc65c21a61f7848f8","https://www.semanticscholar.org/paper/436364d3acec28652f6b48ccc65c21a61f7848f8",3,"Unified Open-Domain Question Answering with Structured and Unstructured Knowledge","This work homogenizes all sources by reducing them to text, and applies recent, powerful retriever-reader models which have so far been limited to text sources only to show that knowledge-base QA can be greatly improved when reformulated in this way.","ArXiv",2020,"Barlas Oğuz,Xilun Chen,Vladimir Karpukhin,Stanislav Peshterliev,Dmytro Okhonko,M. Schlichtkrull,Sonal Gupta,Yashar Mehdad,S. Yih",29,45,4
"8d48441fcf5dd900955036761972cecd18110813","https://www.semanticscholar.org/paper/8d48441fcf5dd900955036761972cecd18110813",3,"NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned","The motivation and organization of the competition is described, the best submissions are reviewed, and system predictions are analyzed to inform a discussion of evaluation for open-domain QA.","Neural Information Processing Systems",2021,"Sewon Min,Jordan L. Boyd-Graber,Chris Alberti,Danqi Chen,Eunsol Choi,Michael Collins,Kelvin Guu,Hannaneh Hajishirzi,Kenton Lee,Jennimaria Palomaki,Colin Raffel,Adam Roberts,T. Kwiatkowski,Patrick Lewis,Yuxiang Wu,Heinrich Kuttler,Linqing Liu,Pasquale Minervini,Pontus Stenetorp,Sebastian Riedel,Sohee Yang,Minjoon Seo,Gautier Izacard,Fabio Petroni,Lucas Hosseini,Nicola De Cao,Edouard Grave,Ikuya Yamada,Sonse Shimaoka,Masatoshi Suzuki,Shumpei Miyawaki,Shun Sato,Ryo Takahashi,Jun Suzuki,Martin Fajcik,Martin Docekal,Karel Ondrej,P. Smrz,Hao Cheng,Yelong Shen,Xiaodong Liu,Pengcheng He,Weizhu Chen,Jianfeng Gao,Barlas Oğuz,Xilun Chen,Vladimir Karpukhin,Stanislav Peshterliev,Dmytro Okhonko,M. Schlichtkrull,Sonal Gupta,Yashar Mehdad,Wen-tau Yih",43,64,0
"0558e6575cbed16a63761a906bbaf91c7843a78d","https://www.semanticscholar.org/paper/0558e6575cbed16a63761a906bbaf91c7843a78d",3,"Reader-Guided Passage Reranking for Open-Domain Question Answering","A simple and effective passage reranking method, named ReaderguIDEd Reranker (RIDER), which does not involve training and reranks the retrieved passages solely based on the top predictions of the reader before reranking, which outperforms state-of-the-art transformer-based supervised rerankers.","Findings",2021,"Yuning Mao,Pengcheng He,Xiaodong Liu,Yelong Shen,Jianfeng Gao,Jiawei Han,Weizhu Chen",16,27,2
"2dd273342715da6742fc84b619bf4d798620f206","https://www.semanticscholar.org/paper/2dd273342715da6742fc84b619bf4d798620f206",3,"Using the Hammer only on Nails: A Hybrid Method for Representation-Based Evidence Retrieval for Question Answering","This work introduces a hybrid approach for representation-based evidence retrieval that combines the advantages of both IR directions, and shows that the proposed routing strategy is considerably faster than neural methods, with a runtime that is up to 5 times faster than USE-QA.","European Conference on Information Retrieval",2021,"Zhengzhong Liang,Yiyun Zhao,M. Surdeanu",0,34,0
"cd2f3398727bf3d5ccef42b33ad9097aeb1c44f1","https://www.semanticscholar.org/paper/cd2f3398727bf3d5ccef42b33ad9097aeb1c44f1",3,"xMoCo: Cross Momentum Contrastive Learning for Open-Domain Question Answering","This paper proposes a new contrastive learning method called Cross Momentum Contrastive learning (xMoCo), for learning a dual-encoder model for question-passage matching that efficiently maintains a large pool of negative samples like the original MoCo and enables using separate encoders for questions and passages.","Annual Meeting of the Association for Computational Linguistics",2021,"Nan Yang,Furu Wei,Binxing Jiao,Daxin Jiang,Linjun Yang",19,22,4
"5be217c678916543884c354654263f27c0a6bd9f","https://www.semanticscholar.org/paper/5be217c678916543884c354654263f27c0a6bd9f",3,"Less is More: Pretrain a Strong Siamese Encoder for Dense Text Retrieval Using a Weak Decoder","A new self-learning method that pre-trains the autoencoder using a weak decoder, with restricted capacity and attention flexibility to push the encoder to provide better text representations, which significantly boosts the effectiveness and few-shot ability of dense retrieval models.","Conference on Empirical Methods in Natural Language Processing",2021,"Shuqi Lu,Di He,Chenyan Xiong,Guolin Ke,Waleed Malik,Zhicheng Dou,Paul Bennett,Tie-Yan Liu,Arnold Overwijk",32,36,10
"60e292b7cef1507cb779385080cfaeac8849a78e","https://www.semanticscholar.org/paper/60e292b7cef1507cb779385080cfaeac8849a78e",3,"Cluster-Former: Clustering-based Sparse Transformer for Question Answering","Cluster-Former is proposed, a novel clusteringbased sparse Transformer to perform attention across chunked sequences that allows information integration beyond local windows, which is especially beneficial for question answering (QA) tasks that rely on long-range dependencies.","Findings",2021,"Shuohang Wang,Luowei Zhou,Zhe Gan,Yen-Chun Chen,Yuwei Fang,Siqi Sun,Yu Cheng,Jingjing Liu",9,40,3
"c3a3665d0891abdc1cbdf244fcc3ba55acc67ea1","https://www.semanticscholar.org/paper/c3a3665d0891abdc1cbdf244fcc3ba55acc67ea1",3,"Representing Long Documents with Contextualized Passage Embeddings","In experiments, it is found that PE+BDE is competitive with token-level or sentence-level models and sometimes even better, and improves over a Longformer-based model by +14 accuracy points for plagiarism detection.","",2021,"",0,27,0
"d4b95b37bcec7f5b09f02c60e5e12bb13aa86866","https://www.semanticscholar.org/paper/d4b95b37bcec7f5b09f02c60e5e12bb13aa86866",3,"Preprint. Under review","Experimental results show that AR2 consistently and significantly outperforms existing dense retriever methods and achieves new state-of-the-art results on all of them.","",2021,"Hang Zhang,Yeyun Gong,Yelong Shen,Jiancheng Lv,Nan Duan,Weizhu Chen",0,50,0
"196e1b5ee39219904427dbe636d154559d4f84b3","https://www.semanticscholar.org/paper/196e1b5ee39219904427dbe636d154559d4f84b3",3,"Zero-shot Neural Passage Retrieval via Domain-targeted Synthetic Question Generation","Empirically, it is shown that this is an effective strategy for building neural passage retrieval models in the absence of large training corpora and depending on the domain, this technique can even approach the accuracy of supervised models.","Conference of the European Chapter of the Association for Computational Linguistics",2021,"Ji Ma,I. Korotkov,Yinfei Yang,K. Hall,Ryan T. McDonald",50,72,7
"6606f7b9938dcc0e03dba45359dd04cb15018f13","https://www.semanticscholar.org/paper/6606f7b9938dcc0e03dba45359dd04cb15018f13",3,"Robust Question Answering Through Sub-part Alignment","This work model question answering as an alignment problem, decomposing both the question and context into smaller units based on off-the-shelf semantic representations, and align the question to a subgraph of the context in order to find the answer.","North American Chapter of the Association for Computational Linguistics",2020,"Jifan Chen,Greg Durrett",8,54,0
"30602e3382df3abedb5f225b55b7efce8580f74d","https://www.semanticscholar.org/paper/30602e3382df3abedb5f225b55b7efce8580f74d",3,"ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data","This work aims to formulate a task, construct a dataset, and provide benchmarks for developing methods for event forecasting with large volumes of unstructured text data, and introduces ForecastQA, a question-answering dataset consisting of 10,392 event forecasting questions, which have been collected and verified via crowdsourcing efforts.","Annual Meeting of the Association for Computational Linguistics",2020,"Woojeong Jin,Suji Kim,Rahul Khanna,Dong-Ho Lee,Fred Morstatter,A. Galstyan,Xiang Ren",12,59,1
"030d7d7ae48a9f81700b2c1f7cf835235777b8e7","https://www.semanticscholar.org/paper/030d7d7ae48a9f81700b2c1f7cf835235777b8e7",3,"Relevance-guided Supervision for OpenQA with ColBERT","This work proposes a weak supervision strategy that iteratively uses ColBERT to create its own training data, which greatly improves OpenQA retrieval on both Natural Questions and TriviaQA, and the resulting end-to-end Open QA system attains state-of-the-art performance on both of those datasets.","Transactions of the Association for Computational Linguistics",2020,"O. Khattab,Christopher Potts,M. Zaharia",51,43,11
"cb58542c94ce83b09f5d3809e69518ba52709c92","https://www.semanticscholar.org/paper/cb58542c94ce83b09f5d3809e69518ba52709c92",3,"Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets","A detailed study of the test sets of three popular open-domain benchmark datasets finds that 30% of test-set questions have a near-duplicate paraphrase in their corresponding train sets, and that simple nearest-neighbor models outperform a BART closed-book QA model.","Conference of the European Chapter of the Association for Computational Linguistics",2020,"Patrick Lewis,Pontus Stenetorp,Sebastian Riedel",124,30,23
"4b3de90c18b451f3929b143f11461d060df56e5d","https://www.semanticscholar.org/paper/4b3de90c18b451f3929b143f11461d060df56e5d",3,"Rethinking the Objectives of Extractive Question Answering","This work demonstrates that using the objective with independence assumption for modelling the span probability P (a_s , a_e) of span starting at position a_s and ending at positiona_e has adverse effects, and proposes a compound objective, composed from the joint probability while still keeping the objectivewith independence assumption as an auxiliary objective.","Workshop on Machine Reading for Question Answering",2020,"Martin Fajcik,Josef Jon,Santosh Kesiraju,P. Smrz",7,41,0
"08f501ea41cafa359c99269612579f5cac43c744","https://www.semanticscholar.org/paper/08f501ea41cafa359c99269612579f5cac43c744",3,"XOR QA: Cross-lingual Open-Retrieval Question Answering","This work constructs a large-scale dataset built on 40K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for and introduces a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingually document retrieval from multilingual and English resources.","North American Chapter of the Association for Computational Linguistics",2020,"Akari Asai,Jungo Kasai,J. Clark,Kenton Lee,Eunsol Choi,Hannaneh Hajishirzi",61,48,20
"6027ef3b4e5585b45db0b9d333956425d3972351","https://www.semanticscholar.org/paper/6027ef3b4e5585b45db0b9d333956425d3972351",3,"Differentiable Open-Ended Commonsense Reasoning","DrFact is proposed, an efficient Differentiable model for multi-hop Reasoning over knowledge Facts, which outperforms strong baseline methods by a large margin and is evaluated to evaluate OpenCSR methods.","North American Chapter of the Association for Computational Linguistics",2020,"Bill Yuchen Lin,Haitian Sun,Bhuwan Dhingra,M. Zaheer,Xiang Ren,William W. Cohen",27,34,4
"17ccd81f77d8cf798f12608ade1d838ffb96b66c","https://www.semanticscholar.org/paper/17ccd81f77d8cf798f12608ade1d838ffb96b66c",3,"Answering Ambiguous Questions through Generative Evidence Fusion and Round-Trip Prediction","The proposed round-trip prediction is a model-agnostic general approach for answering ambiguous open-domain questions, which improves the state-of-the-art Refuel as well as several baseline models.","Annual Meeting of the Association for Computational Linguistics",2020,"Yifan Gao,Henghui Zhu,Patrick Ng,C. D. Santos,Zhiguo Wang,Feng Nan,Dejiao Zhang,Ramesh Nallapati,Andrew O. Arnold,Bing Xiang",7,29,4
"1283ca87e6215b7393eba1653a4a2e4bf28d2868","https://www.semanticscholar.org/paper/1283ca87e6215b7393eba1653a4a2e4bf28d2868",3,"Learning Dense Representations of Phrases at Scale","This work shows for the first time that it can learn dense representations of phrases alone that achieve much stronger performance in open-domain QA and proposes a query-side fine-tuning strategy, which can support transfer learning and reduce the discrepancy between training and inference.","Annual Meeting of the Association for Computational Linguistics",2020,"Jinhyuk Lee,Mujeen Sung,Jaewoo Kang,Danqi Chen",58,52,9
"1c6f7579ca91da348273d8be200b3c9e3a77718e","https://www.semanticscholar.org/paper/1c6f7579ca91da348273d8be200b3c9e3a77718e",3,"Rider: Reader-Guided Passage Reranking for Open-Domain Question Answering","A simple and effective passage reranking method, named ReaderguIDEd Reranker (RIDER), which does not involve training and reranks the retrieved passages solely based on the top predictions of the reader before reranking, which outperforms state-of-the-art transformer-based supervised rerankers.","",2021,"Yuning Mao,Pengcheng He,Xiaodong Liu,Yelong Shen,Jianfeng Gao,Jiawei Han,Weizhu Chen",0,27,0
"346081161bdc8f18e2a4c4af7f51d35452b5cb01","https://www.semanticscholar.org/paper/346081161bdc8f18e2a4c4af7f51d35452b5cb01",3,"Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies","This work introduces StrategyQA, a question answering benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy, and proposes a data collection procedure that combines term-based priming to inspire annotators, careful control over the annotator population, and adversarial filtering for eliminating reasoning shortcuts.","Transactions of the Association for Computational Linguistics",2021,"Mor Geva,Daniel Khashabi,Elad Segal,Tushar Khot,D. Roth,Jonathan Berant",97,28,27
"789b5441743c2e38cf4c38749ed820c0671d81b1","https://www.semanticscholar.org/paper/789b5441743c2e38cf4c38749ed820c0671d81b1",3,"Muppet: Massive Multi-task Representations with Pre-Finetuning","It is shown that pre-finetuning consistently improves performance for pretrained discriminators and generation models on a wide range of tasks while also significantly improving sample efficiency during fine-tuning, and that large-scale multi-tasking is crucial.","Conference on Empirical Methods in Natural Language Processing",2021,"Armen Aghajanyan,Anchit Gupta,Akshat Shrivastava,Xilun Chen,Luke Zettlemoyer,Sonal Gupta",125,78,20
"87c7a320cefdfa9924052e945f6eab423c9b1446","https://www.semanticscholar.org/paper/87c7a320cefdfa9924052e945f6eab423c9b1446",3,"Do Question Answering Modeling Improvements Hold Across Benchmarks?","It is found that human-constructed benchmarks have high concurrence amongst themselves, even if their passage and question distributions are very different, which indicates that, despite years of intense community focus on a small number of benchmarks, the modeling improvements studied hold broadly.","",2021,"Nelson F. Liu,Tony Lee,Robin Jia,Percy Liang",0,51,0
"972a74968d2522908b06c5bd1e26266194c5a9ee","https://www.semanticscholar.org/paper/972a74968d2522908b06c5bd1e26266194c5a9ee",3,"Decontextualization: Making Sentences Stand-Alone","It is argued that decontextualization is an important subtask in many downstream applications, and that the definitions and resources provided can benefit tasks that operate on sentences that occur in a richer context.","Transactions of the Association for Computational Linguistics",2021,"Eunsol Choi,Jennimaria Palomaki,Matthew Lamm,T. Kwiatkowski,Dipanjan Das,Michael Collins",37,33,5
"1e9ff5f2e9aa3e6c01bc89c81ba16442f1b5938d","https://www.semanticscholar.org/paper/1e9ff5f2e9aa3e6c01bc89c81ba16442f1b5938d",3,"Less is More: Pre-train a Strong Text Encoder for Dense Retrieval Using a Weak Decoder","A new selflearning method that pre-trains the autoencoder using a weak decoder, with restricted capacity and attention flexibility to push the encoder to provide better text representations, which significantly boosts the effectiveness and few-shot ability of dense retrieval models.","",2021,"Shuqi Lu,Di He,Chenyan Xiong,Guolin Ke,Waleed Malik,Zhicheng Dou,Paul Bennett,Tie-Yan Liu,Arnold Overwijk",3,33,0
"facefd2fc4b718c6a0d8096b4eb02866028a04c2","https://www.semanticscholar.org/paper/facefd2fc4b718c6a0d8096b4eb02866028a04c2",3,"Weakly-Supervised Open-Retrieval Conversational Question Answering","This work introduces a learned weak supervision approach that can identify a paraphrased span of the known answer in a passage of a passage in the open-retrieval ConvQA setting under a weak supervision setting.","European Conference on Information Retrieval",2021,"Chen Qu,Liu Yang,Cen Chen,W. Bruce Croft,Kalpesh Krishna,Mohit Iyyer",7,57,3
"5b4dc3b099b9f500392b4fb0de86876feedc522b","https://www.semanticscholar.org/paper/5b4dc3b099b9f500392b4fb0de86876feedc522b",3,"Open Domain Question Answering over Tables via Dense Retrieval","This work tackles open-domain QA over tables for the first time, and shows that retrieval can be improved by a retriever designed to handle tabular context, and presents an effective pre-training procedure for this retriever.","North American Chapter of the Association for Computational Linguistics",2021,"Jonathan Herzig,Thomas Müller,Syrine Krichene,Julian Martin Eisenschlos",30,26,6
"443f889a2d4da14e930586e9416068f91c93a5bb","https://www.semanticscholar.org/paper/443f889a2d4da14e930586e9416068f91c93a5bb",3,"Mitigating False-Negative Contexts in Multi-document Question Answering with Retrieval Marginalization","A new parameterization of set-valued retrieval that handles unanswerable queries is developed, and it is shown that marginalizing over this set during training allows a model to mitigate false negatives in supporting evidence annotations.","Conference on Empirical Methods in Natural Language Processing",2021,"Ansong Ni,Matt Gardner,Pradeep Dasigi",6,35,0
"681b2120803ca621620341ef3da2c041f8e0ea02","https://www.semanticscholar.org/paper/681b2120803ca621620341ef3da2c041f8e0ea02",3,"Designing a Minimal Retrieve-and-Read System for Open-Domain Question Answering","The results indicate that retrieve-and-read can be a viable option even in a highly constrained serving environment such as edge devices, as it is shown that it can achieve better accuracy than a purely parametric model with comparable docker-level system size.","North American Chapter of the Association for Computational Linguistics",2021,"Sohee Yang,Minjoon Seo",5,26,1
"cea1f8894cb73f6b1ece7f465bad18fb4b79168d","https://www.semanticscholar.org/paper/cea1f8894cb73f6b1ece7f465bad18fb4b79168d",3,"Simple and Efficient ways to Improve REALM","This work proposes REALM++, where it improves upon the training and inference setups and introduces better supervision signal for improving performance, without any architectural changes, and achieves ~5.5% absolute accuracy gains over the baseline while being faster to train.","Workshop on Machine Reading for Question Answering",2021,"Vidhisha Balachandran,Ashish Vaswani,Yulia Tsvetkov,Niki Parmar",4,27,0
"9668781de7fdb513cb1c7fef3f0cbf06c892c9cd","https://www.semanticscholar.org/paper/9668781de7fdb513cb1c7fef3f0cbf06c892c9cd",3,"Efficient Retrieval Optimized Multi-task Learning","This paper proposes a novel Retrieval Optimized Multi-task (ROM) framework for jointly training self-supervised tasks, knowledge retrieval, and extractive question answering that achieves comparable or better performance than recent methods on QA, while drastically reducing the number of parameters.","ArXiv",2021,"He Fun,S. Gandhi,Sujith Ravi",3,19,0
"c435fdeff9d3b30c3bece24429123d23da147992","https://www.semanticscholar.org/paper/c435fdeff9d3b30c3bece24429123d23da147992",3,"RECONSIDER: Improved Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering","A successful re-ranking approach (RECONSIDER) for span-extraction tasks that improves upon the performance of MRC models, even beyond large-scale pre-training.","North American Chapter of the Association for Computational Linguistics",2021,"Srini Iyer,Sewon Min,Yashar Mehdad,Wen-tau Yih",9,23,1
"60163eab80666401862f16c01a799368ddd8be8d","https://www.semanticscholar.org/paper/60163eab80666401862f16c01a799368ddd8be8d",3,"Investigating the Effect of Background Knowledge on Natural Questions","The results suggest that fact retrieval is a bottleneck for integrating KBs into real world QA datasets and propose and analyze a simple, model-agnostic approach for incorporating KB paths into text-based QA systems.","Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out",2021,"Vidhisha Balachandran,Bhuwan Dhingra,Haitian Sun,Michael Collins,W. Cohen",1,20,0
"5b2a13b85ef9d3ad61639c3b400e447f3217ec98","https://www.semanticscholar.org/paper/5b2a13b85ef9d3ad61639c3b400e447f3217ec98",3,"Answer Generation for Retrieval-based Question Answering Systems","This work proposes to generate answers from a set of AS2 top candidates by training a sequence to sequence transformer model to generate an answer from a candidate set.","Findings",2021,"Chao-Chun Hsu,Eric Lind,Luca Soldaini,Alessandro Moschitti",7,28,0
"15493bbb5387d60e7c77cee34528acd3acae7b65","https://www.semanticscholar.org/paper/15493bbb5387d60e7c77cee34528acd3acae7b65",3,"Efficient Passage Retrieval with Hashing for Open-domain Question Answering","BPR is a memory-efficient neural retrieval model that integrates a learning-to-hash technique into the state-of-the-art Dense Passage Retriever to represent the passage index using compact binary codes rather than continuous vectors.","Annual Meeting of the Association for Computational Linguistics",2021,"Ikuya Yamada,Akari Asai,Hannaneh Hajishirzi",43,27,8
"4291fe672cf6dc73e237ca0942fa49beb8c98711","https://www.semanticscholar.org/paper/4291fe672cf6dc73e237ca0942fa49beb8c98711",3,"Evaluating Entity Disambiguation and the Role of Popularity in Retrieval-Based NLP","It is found that the retrievers exhibit popularity bias, significantly under-performing on rarer entities that share a name, e.g., they are twice as likely to retrieve erroneous documents on queries for the less popular entity under the same name.","Annual Meeting of the Association for Computational Linguistics",2021,"Anthony Chen,Pallavi Gudipati,S. Longpre,Xiao Ling,Sameer Singh",18,44,4
"068eb6b3797d5807b744d9326e7ebb50769e4b4d","https://www.semanticscholar.org/paper/068eb6b3797d5807b744d9326e7ebb50769e4b4d",3,"A Neural Model for Joint Document and Snippet Ranking in Question Answering for Large Document Collections","This work presents an architecture for joint document and snippet ranking, the two middle stages, which leverages the intuition that relevant documents have good snippets and good snippets come from relevant documents and can be used with any neural text relevance ranker.","Annual Meeting of the Association for Computational Linguistics",2021,"Dimitris Pappas,Ion Androutsopoulos",2,56,0
"0c8ffa9e192a4f9a90dd57aefe47289a3357f51d","https://www.semanticscholar.org/paper/0c8ffa9e192a4f9a90dd57aefe47289a3357f51d",3,"Semantic Answer Similarity for Evaluating Question Answering Models","SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, is presented and it is found that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on two newly created datasets and one dataset from related work.","Workshop on Machine Reading for Question Answering",2021,"Julian Risch,Timo Moller,Julian Gutsch,Malte Pietsch",15,35,6
"ef76276f9ef929496f03282fa85ae1bbcdc69767","https://www.semanticscholar.org/paper/ef76276f9ef929496f03282fa85ae1bbcdc69767",3,"Robust Retrieval Augmented Generation for Zero-shot Slot Filling","A novel approach to zero-shot slot filling that extends dense passage retrieval with hard negatives and robust training procedures for retrieval augmented generation models and demonstrates the robustness of the system showing its domain adaptation capability on a new variant of the TACRED dataset for slot filling.","Conference on Empirical Methods in Natural Language Processing",2021,"Michael R. Glass,Gaetano Rossiello,Md. Faisal Mahbub Chowdhury,A. Gliozzo",15,36,1
"1973f251069086d850bde83fabfb05ceaf7b8859","https://www.semanticscholar.org/paper/1973f251069086d850bde83fabfb05ceaf7b8859",3,"Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting","This article proposes two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting, which expand conversational queries using important terms extracted from the conversational context with frequency-based signals and reformulation into natural queries with a pretrained sequence-to-sequence model.","ACM Trans. Inf. Syst.",2021,"Sheng-Chieh Lin,Jheng-Hong Yang,Rodrigo Nogueira,Ming-Feng Tsai,Chuan-Ju Wang,Jimmy J. Lin",19,127,3
"e3480d9395e692833b722b2e957d51139985f310","https://www.semanticscholar.org/paper/e3480d9395e692833b722b2e957d51139985f310",3,"General-Purpose Question-Answering with Macaw","The M ACAW system is described, and a variety of question types where it produces surprisingly good answers are illustrated, well outside the training setup, offering insights into the limitations of pretrained language models.","ArXiv",2021,"Oyvind Tafjord,Peter Clark",33,25,8
"395aae6e7a79e5760457ca38e868acc970016230","https://www.semanticscholar.org/paper/395aae6e7a79e5760457ca38e868acc970016230",3,"MATE: Multi-view Attention for Table Transformer Efficiency","MATE is proposed, a novel Transformer architecture designed to model the structure of web tables that uses sparse attention in a way that allows heads to efficiently attend to either rows or columns in a table.","Conference on Empirical Methods in Natural Language Processing",2021,"Julian Martin Eisenschlos,Maharshi Gor,Thomas Müller,William W. Cohen",32,37,9
"1e8672dfcb2be6e371dc5ccbe3845a6ba9716955","https://www.semanticscholar.org/paper/1e8672dfcb2be6e371dc5ccbe3845a6ba9716955",3,"Extract, Integrate, Compete: Towards Verification Style Reading Comprehension","A novel Extract-Integrate-Compete approach is proposed, which iteratively selects complementary evidence with a novel query updating mechanism and adaptively distills supportive evidence, followed by a pairwise competition to push models to learn the subtle difference among similar text pieces.","Conference on Empirical Methods in Natural Language Processing",2021,"Chen Zhang,Yuxuan Lai,Yansong Feng,Dongyan Zhao",3,26,0
"bde10a2d3dfd138ea6a83f14c17ea3c3f9ac6db0","https://www.semanticscholar.org/paper/bde10a2d3dfd138ea6a83f14c17ea3c3f9ac6db0",3,"A Survey of Knowledge Enhanced Pre-trained Models","A comprehensive overview of KEPTMs in NLP and CV is provided and the progress of pre-trained models and knowledge representation learning is introduced.","ArXiv",2021,"Jian Yang,Gang Xiao,Yulong Shen,Wei Jiang,Xinyu Hu,Ying Zhang,Jinghui Peng",11,189,0
"ef5a79368dddf07a368347c64c289bfaaa587fa5","https://www.semanticscholar.org/paper/ef5a79368dddf07a368347c64c289bfaaa587fa5",3,"Perhaps PTLMs Should Go to School – A Task to Assess Open Book and Closed Book QA","This goal is to deliver a new task and leaderboard to stimulate research on question answering and pre-trained language models (PTLMs) to understand a significant instructional document, e.g., an introductory college textbook or a manual.","Conference on Empirical Methods in Natural Language Processing",2021,"Manuel R. Ciosici,Joe Cecil,Alex Hedges,Dong-Ho Lee,Marjorie Freedman,R. Weischedel",2,36,0
"0effb07e34ed93ec11b1f2371ec80781e0268561","https://www.semanticscholar.org/paper/0effb07e34ed93ec11b1f2371ec80781e0268561",3,"Encoder Adaptation of Dense Passage Retrieval for Open-Domain Question Answering","Different combinations of DPR’s question and passage encoder learned from five benchmark QA datasets on both indomain and out-of-domain questions are inspected to answer the question how an in-distribution question/passage encoder would generalize if paired with an OOD passage/question encoder from another domain.","ArXiv",2021,"Minghan Li,Jimmy J. Lin",5,34,0
"d835d95e252c315103b435cc21a350ebc8d52616","https://www.semanticscholar.org/paper/d835d95e252c315103b435cc21a350ebc8d52616",3,"Cross-Lingual G EN QA: Open-Domain Question Answering with Answer Sentence Generation","This paper introduces G EN -T Y D I QA, an extension of the TyDiQA dataset with well-formed and complete answers for Arabic, Bengali, English, Japanese, and Russian questions and presents the first Cross-Lingual answer sentence generation system (C ROSS -L INGUAL G EN QA).","",2022,"Benjamin Muller,Luca Soldaini,Rik Koncel-Kedziorski,Eric Lind,Alessandro Moschitti",1,64,0
"bce1bcccf00bb5790792aec7fcbfbf1b8485b759","https://www.semanticscholar.org/paper/bce1bcccf00bb5790792aec7fcbfbf1b8485b759",3,"Representation Decoupling for Open-Domain Passage Retrieval","This work proposes to solve the influence of conflicts in the widely used CL strategy in ODPR by decoupling the passage representations into contextual sentence-level ones, and design specific CL strategies to mediate these conflicts.","ArXiv",2021,"Bohong Wu,Zhuosheng Zhang,Jinyuan Wang,Hai Zhao",2,38,0
"375348cb132d8e1bc96e1302e025954f4e12d888","https://www.semanticscholar.org/paper/375348cb132d8e1bc96e1302e025954f4e12d888",3,"Question Rewriting for Open-Domain Conversational QA: Best Practices and Limitations","While conversation history modeling with dense representations outperforms QR, it is shown the advantages to apply both jointly, as QR boosts the performance especially when limited history turns are considered.","International Conference on Information and Knowledge Management",2021,"Marco Del Tredici,Gianni Barlacchi,Xiaoyu Shen,Weiwei Cheng,A. Gispert",5,35,0
"1f49d34277d6eb3503fad0608e0251b9861172b7","https://www.semanticscholar.org/paper/1f49d34277d6eb3503fad0608e0251b9861172b7",3,"DuReaderretrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine","The experiment results demonstrate that DuReaderretrieval is challenging and there is still plenty of room for the community to improve, e.g. the generalization across domains, salient phrase and syntax mismatch between query and paragraph and robustness.","",2022,"Yifu Qiu,Hongyu Li,Yingqi Qu,Ying Chen,Qiaoqiao She,Jing Liu,Huaqin Wu",0,46,0
"6716b7ec2e5ccb8efbcbc22c9a640a6ae523a860","https://www.semanticscholar.org/paper/6716b7ec2e5ccb8efbcbc22c9a640a6ae523a860",3,"R3 : Refined Retriever-Reader pipeline for Multidoc2dial","This paper proposes several improvements over the baseline’s retriever-reader architecture to aid in modeling goal-oriented dialogues grounded in multiple documents in MultiDoc2Dial.","Workshop on Document-grounded Dialogue and Conversational Question Answering",2022,"Srijan Bansal,Suraj Tripathi,Sumit Agarwal,Sireesh Gururaja,Aditya Srikanth Veerubhotla,Ritam Dutt,T. Mitamura,Eric Nyberg",0,33,0
"3a6b2244ed6dcf68b213d584a274b61866f9726d","https://www.semanticscholar.org/paper/3a6b2244ed6dcf68b213d584a274b61866f9726d",3,"Zero-shot cross-lingual open domain question answering","This paper employs a passage reranker, the fusion-in-decoder technique for generation, and a wiki data entity-based post-processing system to tackle the inability to generate entities across all languages.","MIA",2022,"Sumit Agarwal,Suraj Tripathi,T. Mitamura,C. Rosé",1,23,0
"699b440c004332b70b6aae5a2bd83b96bbb1e3a1","https://www.semanticscholar.org/paper/699b440c004332b70b6aae5a2bd83b96bbb1e3a1",3,"Ask Me Anything in Your Native Language","This work presents a novel approach based on single encoder for query and passage for retrieval from multi-lingual collection, together with cross-lingUAL generative reader that achieves a new state of the art in both retrieval and end-to-end tasks on the XOR TyDi dataset.","North American Chapter of the Association for Computational Linguistics",2022,"Nikita Sorokin,Dmitry Abulkhanov,Irina Piontkovskaya,Valentin Malykh",1,29,1
"8752a918fc1a772e15798dcf7f3a75891f545e95","https://www.semanticscholar.org/paper/8752a918fc1a772e15798dcf7f3a75891f545e95",3,"Recovering Gold from Black Sand: Multilingual Dense Passage Retrieval with Hard and False Negative Samples","Experimental results show that mHFN outperforms strong sparse, dense and hybrid baselines and achieves new state-of-the-art performance on all languages.","Conference on Empirical Methods in Natural Language Processing",2022,"Tianhao Shen,Mingtong Liu,Ming Zhou,Deyi Xiong",0,41,0
"b9e68e3467cc7db36c740dd5cd53f338be311d21","https://www.semanticscholar.org/paper/b9e68e3467cc7db36c740dd5cd53f338be311d21",3,"LinkBERT: Language Model Pretraining with Document Link Knowledge","LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks, outperforms BERT on diverse downstream tasks across two domains: a general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain ( pretrained on PubMed with citation links).","",2022,"Michihiro Yasunaga,J. Leskovec,Percy Liang",0,79,0
"d57c76963c5d134191b7bc7681f9c87513d97e2d","https://www.semanticscholar.org/paper/d57c76963c5d134191b7bc7681f9c87513d97e2d",3,"Link-BERT: Pretraining a Language Model with Document Links","This work proposes LinkBERT, an LM pretraining method that leverages links between documents that outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain ( pretrained on PubMed with citation links).","",2022,"Michihiro Yasunaga,J. Leskovec,Percy Liang",0,83,0
"c41f1f9621c6e2dc7ae44a3f72660ec27e5f8acd","https://www.semanticscholar.org/paper/c41f1f9621c6e2dc7ae44a3f72660ec27e5f8acd",3,"Towards Robust Neural Retrieval with Source Domain Synthetic Pre-Finetuning","This paper empirically shows that pre-finetuning DPR with additional synthetic data in its source domain (Wikipedia), which is generated using a fine-tuned sequence-to-sequence generator, can be a low-cost yet effective first step towards its generalization.","International Conference on Computational Linguistics",2022,"Revanth Gangi Reddy,Vikas Yadav,Md Arafat Sultan,M. Franz,Vittorio Castelli,Heng Ji,Avirup Sil",2,23,1
"59641c10ed7431a3cf841f308367dc2dc0281b74","https://www.semanticscholar.org/paper/59641c10ed7431a3cf841f308367dc2dc0281b74",3,"What Makes Good In-Context Examples for GPT-3?","This work proposes to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt, and evaluates the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline.","Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out",2021,"Jiachang Liu,Dinghan Shen,Yizhe Zhang,Bill Dolan,L. Carin,Weizhu Chen",155,54,32
"8a3ef7e6aea5083cef6fe13d7642714031547d38","https://www.semanticscholar.org/paper/8a3ef7e6aea5083cef6fe13d7642714031547d38",3,"QAConv: Question Answering on Informative Conversations","A new question answering (QA) dataset that uses conversations as a knowledge source, focusing on informative conversations, including business emails, panel discussions, and work channels, that provides a new training and evaluation testbed to facilitate QA on conversations research.","Annual Meeting of the Association for Computational Linguistics",2021,"C. Wu,Andrea Madotto,Wenhao Liu,Pascale Fung,Caiming Xiong",12,49,1
"c132c485fe164f54dc8bdbe9a228500174badd5e","https://www.semanticscholar.org/paper/c132c485fe164f54dc8bdbe9a228500174badd5e",3,"Domain-matched Pre-training Tasks for Dense Retrieval","This work demonstrates that, with the right pre-training setup, large bi-encoder models on a recently released set of 65 million synthetically generated questions and 200 million post-comment pairs from a preexisting dataset of Reddit conversations can be overcome.","NAACL-HLT",2021,"Barlas Oğuz,Kushal Lakhotia,Anchit Gupta,Patrick Lewis,Vladimir Karpukhin,Aleksandra Piktus,Xilun Chen,Sebastian Riedel,Wen-tau Yih,Sonal Gupta,Yashar Mehdad",45,49,4
"29a3c6968888d8078d21ff5b7d9e6d78c470fdb0","https://www.semanticscholar.org/paper/29a3c6968888d8078d21ff5b7d9e6d78c470fdb0",3,"Unsupervised Corpus Aware Language Model Pre-training for Dense Passage Retrieval","","Annual Meeting of the Association for Computational Linguistics",2021,"Luyu Gao,Jamie Callan",107,37,23
"e364737a7694141d1bc5024fc06983c648b676d1","https://www.semanticscholar.org/paper/e364737a7694141d1bc5024fc06983c648b676d1",3,"Slot Filling for Biomedical Information Extraction","This work presents a slot filling approach to the task of biomedical IE, effectively replacing the need for entity and relation-specific training data, allowing for zero-shot settings, and provides a fresh perspective on how to solve biomedical IE tasks, in the absence of relevant training data.","Workshop on Biomedical Natural Language Processing",2021,"Yannis Papanikolaou,Francine Bennett",1,35,0
"606957402ee0741ed130c6a03ec7f20d30b7083f","https://www.semanticscholar.org/paper/606957402ee0741ed130c6a03ec7f20d30b7083f",3,"Adversarial Retriever-Ranker for dense text retrieval","Experimental results show that AR2 consistently and signiﬁcantly outperforms existing dense retriever methods and achieves new state-of-the-art results on all of them.","International Conference on Learning Representations",2021,"Hang Zhang,Yeyun Gong,Yelong Shen,Jiancheng Lv,Nan Duan,Weizhu Chen",44,54,11
"3f90c820417b4a770bbf74cd0bd7da0ded91f63b","https://www.semanticscholar.org/paper/3f90c820417b4a770bbf74cd0bd7da0ded91f63b",3,"Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?","This work introduces the Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical matching capacity of a sparse model, and shows that a dense Lexical Model {\Lambda} can be trained to imitate a sparse one.","Conference on Empirical Methods in Natural Language Processing",2021,"Xilun Chen,Kushal Lakhotia,Barlas Oğuz,Anchit Gupta,Patrick Lewis,Stanislav Peshterliev,Yashar Mehdad,Sonal Gupta,Wen-tau Yih",30,43,10
"14edf1e81b2d8496c8bd88de94aa20d03efabaa2","https://www.semanticscholar.org/paper/14edf1e81b2d8496c8bd88de94aa20d03efabaa2",3,"Cross-Lingual Open-Domain Question Answering with Answer Sentence Generation","A cross-lingual generative model that produces full-sentence answers by exploiting passages written in multiple languages, including languages different from the question, outperforms answer sentence selection baselines for all 5 languages and monolingualGenerative pipelines for three out of five languages studied.","AACL",2021,"Benjamin Muller,Luca Soldaini,Rik Koncel-Kedziorski,Eric Lind,Alessandro Moschitti",0,69,0
"2ab72b5bd8121664a64cdc0e95c3b2037ac4759d","https://www.semanticscholar.org/paper/2ab72b5bd8121664a64cdc0e95c3b2037ac4759d",3,"Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval","This work introduces an in-passage negative sampling strategy to encourage a diverse generation of sentence representations within the same passage, and presents a refined model on the basis of a smaller granularity, contextual sentences, to alleviate the concerned conflicts.","Annual Meeting of the Association for Computational Linguistics",2021,"Bohong Wu,Zhuosheng Zhang,Jinyuan Wang,Hai Zhao",4,37,0
"9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e","https://www.semanticscholar.org/paper/9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e",3,"Large Dual Encoders Are Generalizable Retrievers","Experimental results show that the dual encoders, Generalizable T5-based dense Retrievers (GTR), outperform previous sparse and dense retrievers on the BEIR dataset significantly and the ablation study finds that GTR is very data efficient, as it only needs 10% of MS Marco supervised data to match the out-of-domain performance of using all supervised data.","Conference on Empirical Methods in Natural Language Processing",2021,"Jianmo Ni,Chen Qu,Jing Lu,Zhuyun Dai,Gustavo Hern'andez 'Abrego,Ji Ma,Vincent Zhao,Yi Luan,Keith B. Hall,Ming-Wei Chang,Yinfei Yang",47,40,19
"56b30c6bd9dc4a2416ab3b74ad97dbb7a2904229","https://www.semanticscholar.org/paper/56b30c6bd9dc4a2416ab3b74ad97dbb7a2904229",3,"WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation","This work introduces a novel approach for dataset creation based on worker and AI collaboration, which brings together the generative strength of language models and the evaluation strength of humans, and demonstrates the promise of leveraging natural language generation techniques and re-imagining the role of humans in the dataset creation process.","Conference on Empirical Methods in Natural Language Processing",2022,"Alisa Liu,Swabha Swayamdipta,Noah A. Smith,Yejin Choi",52,78,7
"15031e6a94f9d6d19f74740c224a5523ec64d975","https://www.semanticscholar.org/paper/15031e6a94f9d6d19f74740c224a5523ec64d975",3,"Improving Biomedical Information Retrieval with Neural Retrievers","This paper proposes a template-based question generation method that can be leveraged to train neural retriever models, and introduces the ``Poly-DPR'' model which encodes each context into multiple context vectors.","AAAI Conference on Artificial Intelligence",2022,"Man Luo,Arindam Mitra,Tejas Gokhale,Chitta Baral",9,49,0
"eef99f7811e987d57d9d0371facf1b0fd0fbc2ed","https://www.semanticscholar.org/paper/eef99f7811e987d57d9d0371facf1b0fd0fbc2ed",3,"LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval","This paper proposes LaPraDoR, a pretrained dual-tower dense retriever that does not require any supervised data for training, and proposes Lexicon-Enhanced Dense Retrieval (LEDR) as a simple yet effective way to enhance dense retrieval with lexical matching.","Findings",2022,"Canwen Xu,Daya Guo,Nan Duan,Julian McAuley",15,70,3
"4544a639fde8c1c387a2a01a3d7560163dbf6f99","https://www.semanticscholar.org/paper/4544a639fde8c1c387a2a01a3d7560163dbf6f99",3,"Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering","It is demonstrated that the hyperlink-based structures of dual-link and co-mention can provide effective relevance signals for large-scale pre-training that better facilitate downstream passage retrieval.","Annual Meeting of the Association for Computational Linguistics",2022,"Jiawei Zhou,Xiaoguang Li,Lifeng Shang,Lan Luo,Ke Zhan,Enrui Hu,Xinyu Zhang,Hao Jiang,Zhao Cao,Fan Yu,Xin Jiang,Qun Liu,Lei Chen",7,30,0
"e150dc483f7a23c5c5972cdf42f904982b055793","https://www.semanticscholar.org/paper/e150dc483f7a23c5c5972cdf42f904982b055793",3,"Choose Your QA Model Wisely: A Systematic Study of Generative and Extractive Readers for Question Answering","This first attempt to systematically study the comparison of extractive and generative readers for question answering explores nine transformer-based large pre-trained language models (PrLMs) as backbone architectures and organizes the findings under two main categories: keeping the architecture invariant, and varying the underlying PrLMs.","SPANLP",2022,"Man Luo,Kazuma Hashimoto,Semih Yavuz,Zhiwei Liu,Chitta Baral,Yingbo Zhou",6,32,0
"00b28e5f100aa35e83487b17013b8235cdf45c3c","https://www.semanticscholar.org/paper/00b28e5f100aa35e83487b17013b8235cdf45c3c",3,"Multi-View Document Representation Learning for Open-Domain Dense Retrieval","A simple yet effective method of generating multiple embeddings through viewers to represent documents and enforce them to align with different queries is proposed, and a global-local loss with annealed temperature is proposed to encourage the multiple viewers to better aligned with different potential queries.","Annual Meeting of the Association for Computational Linguistics",2022,"Shunyu Zhang,Yaobo Liang,Ming Gong,Daxin Jiang,Nan Duan",13,39,2
"a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f","https://www.semanticscholar.org/paper/a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f",3,"LinkBERT: Pretraining Language Models with Document Links","This work proposes LinkBERT, an LM pretraining method that leverages links between documents that outperforms BERT on various downstream tasks across two domains: the general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain ( pretrained on PubMed with citation links).","Annual Meeting of the Association for Computational Linguistics",2022,"Michihiro Yasunaga,J. Leskovec,Percy Liang",40,99,12
"61116b638538bdf8ecf3d8accc50af6587e8c567","https://www.semanticscholar.org/paper/61116b638538bdf8ecf3d8accc50af6587e8c567",3,"Knowledge Base Index Compression via Dimensionality and Precision Reduction","This work systematically investigates reducing the size of the KB index by means of dimensionality (sparse random projections, PCA, autoencoders) and numerical precision reduction and shows that PCA is an easy solution that requires very little data and is only slightly worse than autoen coders, which are less stable.","SPANLP",2022,"Vilém Zouhar,Marius Mosbach,Miaoran Zhang,D. Klakow",1,38,0
"0e9e00c48b171ec13063bfcc6395809be91d5e8b","https://www.semanticscholar.org/paper/0e9e00c48b171ec13063bfcc6395809be91d5e8b",3,"GNN-encoder: Learning a Dual-encoder Architecture via Graph Neural Networks for Passage Retrieval","A GNN-encoder model is proposed in which query (passage) information is fused into passage ( query) representations via graph neural networks that are constructed by queries and their top retrieved passages to achieve both efficiency and efficacy in passage retrieval.","Conference on Empirical Methods in Natural Language Processing",2022,"Jiduan Liu,Jiahao Liu,Yang Yang,Jingang Wang,Wei Wu,Dongyan Zhao,Rui Yan",3,58,1
"347dd049d9f8ab6cc2f72a8c872e2a5856dd2039","https://www.semanticscholar.org/paper/347dd049d9f8ab6cc2f72a8c872e2a5856dd2039",3,"Answer Consolidation: Formulation and Benchmarking","This paper forms the problem of answer consolidation, where answers are partitioned into multiple groups, each representing different aspects of the answer set, and finds a comprehensive and non-redundant set of answers can be constructed by picking one answer from each group.","North American Chapter of the Association for Computational Linguistics",2022,"Wenxuan Zhou,Qiang Ning,Heba Elfardy,Kevin Small,Muhao Chen",4,48,1
"68db9cd6374537f8c0b1dddc6e49e51ebeeb7304","https://www.semanticscholar.org/paper/68db9cd6374537f8c0b1dddc6e49e51ebeeb7304",3,"Better Retrieval May Not Lead to Better Question Answering","This work shows that for StrategyQA, a challenging open-domain QA dataset that requires multi-hop reasoning, this common approach to improve the quality of the retrieved context from the IR stage is surprisingly ineffective.","ArXiv",2022,"Zhengzhong Liang,Tushar Khot,Steven Bethard,M. Surdeanu,Ashish Sabharwal",0,27,0
"eea2129457fcd78c4071a9020355a2fe1da4d2fd","https://www.semanticscholar.org/paper/eea2129457fcd78c4071a9020355a2fe1da4d2fd",3,"SKILL: Structured Knowledge Infusion for Large Language Models","This work proposes a method to infuse structured knowledge into large language models, by directly training T5 models on factual triples of knowledge graphs (KGs), and shows that models pre-trained on Wikidata KG with this method outperform the T5 baselines on FreebaseQA and WikiHop, as well as theWikidata-answerable subset of TriviaQ a and NaturalQuestions.","North American Chapter of the Association for Computational Linguistics",2022,"Fedor Moiseev,Zhe Dong,Enrique Alfonseca,Martin Jaggi",3,40,0
"4010435fee6379f9edb53a8148ad1f6094ab2936","https://www.semanticscholar.org/paper/4010435fee6379f9edb53a8148ad1f6094ab2936",3,"ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval","This paper introduces a self on-the-ﬂy distillation method that can effectively distill late interaction and in-corporates a cascade distillation process to further improve the performance with a cross-encoder teacher.","ArXiv",2022,"Yuxiang Lu,Yiding Liu,Jiaxiang Liu,Yunsheng Shi,Zhengjie Huang,Shi Feng,Yu Sun,Hao Tian,Hua Wu,Shuaiqiang Wang,Dawei Yin,Haifeng Wang",18,54,3
"37ba5946527629cf538a4675476f824da99dfe35","https://www.semanticscholar.org/paper/37ba5946527629cf538a4675476f824da99dfe35",3,"Table Retrieval May Not Necessitate Table-specific Model Design","The task of table retrieval is focused on, and it is found that DPR performs well without any table-specific design and training, and even achieves superior results compared to DTR when fine-tuned on properly linearized tables.","SUKI",2022,"Zhiruo Wang,Zhengbao Jiang,Eric Nyberg,Graham Neubig",1,49,0
"34ff09ddf6ae64299564cb673044055b4615fc3c","https://www.semanticscholar.org/paper/34ff09ddf6ae64299564cb673044055b4615fc3c",3,"Domain Adaptation for Memory-Efficient Dense Retrieval","It is shown that binary embedding models like BPR and JPQ can perform signif-icantly worse than baselines once there is a domain-shift involved, and a modi-cation to the training procedure is proposed and combined with a corpus speciﬁc generative procedure which allow the adaptation of BPRand JPQ to any corpus without requiring labeled training data.","ArXiv",2022,"Nandan Thakur,Nils Reimers,Jimmy Lin",7,64,0
"0a361ee0eb2fcefb048d2b03bfa1cf515bf24113","https://www.semanticscholar.org/paper/0a361ee0eb2fcefb048d2b03bfa1cf515bf24113",3,"Optimizing Test-Time Query Representations for Dense Retrieval","T OU R is introduced, which further optimizes instance-level query representations guided by signals from test-time retrieval results and improves the end-to-end open-domain QA accuracy signiﬁcantly, as well as passage retrieval performance.","",2022,"Mujeen Sung,Jungsoo Park,Jaewoo Kang,Danqi Chen,Jinhyuk Lee",0,43,0
"3eada4005e2ee43205b8d39a80b8a2883f254a21","https://www.semanticscholar.org/paper/3eada4005e2ee43205b8d39a80b8a2883f254a21",3,"A Neural Corpus Indexer for Document Retrieval","This paper proposes Neural Corpus Indexer (NCI), a sequence-to-sequence network that generates relevant document identifiers directly for a designated query and leverages tailored techniques including query generation, semantic document identifiers, and consistency-based regularization.","ArXiv",2022,"Yujing Wang,Ying Hou,Hong Wang,Ziming Miao,Shibin Wu,Hao Sun,Qi Chen,Yuqing Xia,Chengmin Chi,Guoshuai Zhao,Zheng Liu,Xing Xie,Hao Sun,Weiwei Deng,Qi Zhang,Mao Yang",6,61,2
"b5c80cd17a3be2c2f9cb02974e140ac361f417ff","https://www.semanticscholar.org/paper/b5c80cd17a3be2c2f9cb02974e140ac361f417ff",3,"QA Is the New KR: Question-Answer Pairs as Knowledge Bases","It is argued that the proposed type of KB has many of the key advantages of a traditional symbolic KB: in particular, it consists of small modular components, which can be combined compositionally to answer complex queries, including relational queries and queries involving “multi-hop” inferences.","ArXiv",2022,"Wenhu Chen,William W. Cohen,Michiel de Jong,Nitish Gupta,Alessandro Presta,Pat Verga,J. Wieting",1,53,0
"c7ef24986470d06824d097d688fb0d942464d850","https://www.semanticscholar.org/paper/c7ef24986470d06824d097d688fb0d942464d850",3,"MIA 2022 Shared Task: Evaluating Cross-lingual Open-Retrieval Question Answering for 16 Diverse Languages","The results of the Workshop on Multilingual Information Access 2022 Shared Task, evaluating cross-lingual open-retrieval question answering (QA) systems in 16 typologically diverse languages are presented, with the best system obtains particularly significant improvements in Tamil.","MIA",2022,"Akari Asai,S. Longpre,Jungo Kasai,Chia-Hsuan Lee,Rui Zhang,Junjie Hu,Ikuya Yamada,J. Clark,Eunsol Choi",1,48,0
"4ed96488b4cea6c40401d3ccbd4a9bc5d98237c4","https://www.semanticscholar.org/paper/4ed96488b4cea6c40401d3ccbd4a9bc5d98237c4",3,"Cross-Lingual QA as a Stepping Stone for Monolingual Open QA in Icelandic","A bilingual Icelandic/English language model is trained to embed English context and Icelandic questions following methodology introduced with DensePhrases, and the resulting system is an open domain cross-lingual QA system between Icelandic and English.","MIA",2022,"Vésteinn Snæbjarnarson,H. Einarsson",0,35,0
"c39b47fe533744437ee24116de5f5fe5c31c1b59","https://www.semanticscholar.org/paper/c39b47fe533744437ee24116de5f5fe5c31c1b59",3,"MIA 2022 Shared Task Submission: Leveraging Entity Representations, Dense-Sparse Hybrids, and Fusion-in-Decoder for Cross-Lingual Question Answering","This work describes its two-stage system for the Multilingual Information Access (MIA) 2022 Shared Task on Cross-Lingual Open-Retrieval Question Answering and shows the efficacy of using entity representations, sparse retrieval signals to help dense retrieval, and Fusion-in-Decoder.","MIA",2022,"Zhucheng Tu,Sarguna Padmanabhan",1,18,1
"5e7efbfb74e953b1e97f6f854e48475384ec87e6","https://www.semanticscholar.org/paper/5e7efbfb74e953b1e97f6f854e48475384ec87e6",3,"SpaceQA: Answering Questions about the Design of Space Missions and Space Craft Concepts","This work presents SpaceQA, to the best of its knowledge the first open-domain QA system in Space mission design, and adopts a state-of-the-art architecture consisting of a dense retriever and a neural reader and opt for an approach based on transfer learning rather than fine-tuning due to the lack of domain-specific annotated data.","Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",2022,"Andres Garcia-Silva,Cristian Berrio,José Manuél Gómez-Pérez,J. Martínez-Heras,A. Donati,Ilaria Roma",3,31,0
"75e59a0b5173c9e7bd6fb89e457884984dbc9ab1","https://www.semanticscholar.org/paper/75e59a0b5173c9e7bd6fb89e457884984dbc9ab1",3,"Multi-Task Retrieval-Augmented Text Generation with Relevance Sampling","A simple yet effective approach to clean the training set by utilizing a distinct property of knowledge-intensive generation: The connection of query-answer pairs to items in the knowledge base, which scales well with increased model capacity and achieves state-of-the-art results in seven KILT tasks.","ArXiv",2022,"Sebastian Hofstätter,Jiecao Chen,K. Raman,Hamed Zamani",3,34,0